{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5115f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空内核状态\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "777db9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setup_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17109ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#要设置的参数\n",
    "Ex=0#E也要放小e6倍，这里是0就不放了\n",
    "Ey=0\n",
    "Ez=0#托卡马克里面没电场\n",
    "B0=5#磁轴中心的磁感应强度为5T\n",
    "q=2.5#安全因子，注意，不是电荷\n",
    "R0=6.2#托卡马克大半径6.2m\n",
    "q_over_m = 4.822452834e1  # 电荷与质量之比\n",
    "\n",
    "#单位问题：跑太大的数，程序吃不消，得归一化。几个大数，q_over_m = 4.8e7，vx0vy0 1e6 5e6，interval 4.1473e-9，要动\n",
    "#程序中，要让轨迹相对形状不变，又因为B和位置有关，所以轨迹数值也不能变\n",
    "#a=q/m（E+vB），x=vt+0.5at^2\n",
    "#让位移x=vt+0.5at^2不变，让interval扩大e6倍，让v缩小e6倍(让v0和x0在同一量级，这样好训练)，让q_over_m缩小e6倍，E也要放小e6倍，这样a放小e12个\n",
    "def Bx(x,y,z):\n",
    "    return B0/q*(-q*R0*y+z*x)/(x**2+y**2)\n",
    "def By(x,y,z):\n",
    "    return B0/q*(q*R0*x+z*y)/(x**2+y**2)\n",
    "def Bz(x,y,z):\n",
    "    return B0/q*(-1+R0/(x**2+y**2)**0.5)\n",
    "    \n",
    "\n",
    "target_x0=torch.tensor([7.2])\n",
    "target_y0=torch.tensor([0.0])\n",
    "target_z0=torch.tensor([0.0])\n",
    "target_vx0=torch.tensor([1.0])\n",
    "target_vy0=torch.tensor([5.0])#这里是通行α粒子数据\n",
    "target_vz0=torch.tensor([0.0])\n",
    "\n",
    "\n",
    "interval=4.147267104135095e-4#根据学长给的数据取值,e-3是小圈的1/2π,e-4就是小圈的60分之一，更精确\n",
    "#总运动时间是n*interval\n",
    "learning_rate=8e-4\n",
    "\n",
    "stop_condition = 5e-4#停止训练的loss值要求\n",
    "\n",
    "\n",
    "#设置初始权重\n",
    "lamda1=2#lpde权重\n",
    "lamda2=400#lE权重\n",
    "lamda3=600#l0权重\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc698242",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100#训练中的t共n个时间点,注意画三维图的点不建议超过200个，容易炸内核\n",
    "n_all=500#总覆盖时间点数，绘图用\n",
    "jump=0#单位是interval\n",
    "n_epoch=100#每几次epoch就计数\n",
    "\n",
    "n_test=50#在n_all范围内，等距取多少个test点\n",
    "new_prefix = \"8.2.duansui-100\"  # 新的文件名前缀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd73786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "#t作为输入，x,y,z作为输出，中间三个隐藏层\n",
    "#MLP是最基础的全连接神经网络\n",
    "\n",
    "class SinActivation(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SinActivation, self).__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(0.1))  # 将a设置为可学习的参数\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.a *10* x)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1,128),#0层\n",
    "            SinActivation(),#1层\n",
    "            torch.nn.Linear(128,128),#2层\n",
    "            SinActivation(),#3\n",
    "            torch.nn.Linear(128,128),#4\n",
    "            SinActivation(),#5\n",
    "            torch.nn.Linear(128,128),#6\n",
    "            SinActivation(),#7\n",
    "            torch.nn.Linear(128,3),#8\n",
    "        )\n",
    "         # 对每个线性层进行Glorot初始化\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    \n",
    "u = MLP()  # 网络名称\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac3cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# #from ceshi_Copy1 import MLP  # 导入你的模型类定义\n",
    "\n",
    "# # 创建模型实例\n",
    "# # u = MyModel()\n",
    "\n",
    "# # 加载模型参数\n",
    "# u.load_state_dict(torch.load('3.1.1保存.pth'))\n",
    "\n",
    "# # 设置模型为评估模式（如果只是进行推理）\n",
    "# # u.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c88f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#下面是求导\n",
    "def gradients(x,t,order=1):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(x,t,grad_outputs=torch.ones_like(x),#用于计算某个标量相对于一组输入张量的梯度\n",
    "                                  create_graph = True,\n",
    "                                  only_inputs=True,)[0]#create_graph： 这是一个布尔值，如果设置为 True，则创建一个用于计算更高阶梯度的计算图。\n",
    "                                                    #这对于执行高阶梯度的操作是有用的。在训练深度学习模型时，可能需要计算模型参数的二阶梯度。\n",
    "    else:\n",
    "        return gradients(gradients(x,t),t,order = order-1)#二阶及以上导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0737703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#损失函数\n",
    "#LOSS\n",
    "loss = torch.nn.MSELoss()\n",
    "tensortarget = (target_vx0**2+target_vy0**2+target_vz0**2)**0.5\n",
    "target_initial = tensortarget.repeat(n+1).view(-1, 1)#保能量项用的\n",
    "\n",
    "def funcmiu(x,y,z,vx,vy,vz):\n",
    "    miu=(vx**2+vy**2+vz**2)/(Bx(x,y,z)**2+By(x,y,z)**2+Bz(x,y,z)**2)**0.5-(vx*Bx(x,y,z)+vy*By(x,y,z)+vz*Bz(x,y,z))**2/(Bx(x,y,z)**2+By(x,y,z)**2+Bz(x,y,z)**2)**1.5\n",
    "    return miu\n",
    "\n",
    "\n",
    "def LOSS(u):\n",
    "    \n",
    "    samples = torch.arange(jump*interval, (n_all+1+jump)*interval, step=int(n_all/n)*interval)+torch.rand(n+1) * interval*int(n_all/n)*1   #random jitter to samples 10%#实际上n+1个点\n",
    "    t = samples.view(-1, 1).requires_grad_(True)\n",
    "    x = u(t)[:, 0].view(-1, 1)\n",
    "    y = u(t)[:, 1].view(-1, 1)\n",
    "    z = u(t)[:, 2].view(-1, 1)\n",
    "    vx = gradients(x, t, 1)\n",
    "    vy = gradients(y, t, 1)\n",
    "    vz = gradients(z, t, 1)\n",
    "\n",
    "    lpde1 = loss(gradients(vx, t, 1), q_over_m*(Ex + vy * Bz(x,y,z) - vz * By(x,y,z)))\n",
    "    lpde2 = loss(gradients(vy, t, 1), q_over_m*(Ey + vz * Bx(x,y,z) - vx * Bz(x,y,z)))\n",
    "    lpde3 = loss(gradients(vz, t, 1), q_over_m*(Ez + vx * By(x,y,z) - vy * Bx(x,y,z)))\n",
    "\n",
    "    lE = loss((vx**2+vy**2+vz**2)**0.5,target_initial)\n",
    "    miu=funcmiu(x,y,z,vx,vy,vz)\n",
    "    lpde = lpde1 + lpde2 + lpde3 \n",
    "\n",
    "    t0=torch.tensor([0.0]).requires_grad_(True)\n",
    "    l00=(u(t0)[0] - target_x0)**2\n",
    "    l01=(u(t0)[1] - target_y0)**2\n",
    "    l02=(u(t0)[2] - target_z0)**2\n",
    "    l03=(gradients(u(t0)[0],t0,1) - target_vx0)**2\n",
    "    l04=(gradients(u(t0)[1],t0,1) - target_vy0)**2\n",
    "    l05=(gradients(u(t0)[2],t0,1) - target_vz0)**2\n",
    "    l0=l00+l01+l02+l03+l04+l05\n",
    "\n",
    "    return lpde,lE,l0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82fddc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(u.parameters(), lr=learning_rate)\n",
    "def funcweight(lpde):\n",
    "    lpde.backward(retain_graph=True)#初态只对第0层的weight的梯度才全是0，其他情况都有梯度\n",
    "    # 获取网络的参数列表\n",
    "    gradientlw0 = u.net[0].weight.grad.clone()\n",
    "    gradientlb0 = u.net[0].bias.grad.clone()\n",
    "    gradientlw2 = u.net[2].weight.grad.clone()\n",
    "    gradientlb2 = u.net[2].bias.grad.clone()\n",
    "    gradientlw4 = u.net[4].weight.grad.clone()\n",
    "    gradientlb4 = u.net[4].bias.grad.clone()\n",
    "    gradientlw6 = u.net[6].weight.grad.clone()\n",
    "    gradientlb6 = u.net[6].bias.grad.clone()\n",
    "    gradientlw8 = u.net[8].weight.grad.clone()\n",
    "    gradientlb8 = u.net[8].bias.grad.clone()\n",
    "    opt.zero_grad()\n",
    "    tensors_l = [gradientlw0,gradientlb0,gradientlw2,gradientlb2,gradientlw4,gradientlb4,gradientlw6,gradientlb6,\n",
    "                gradientlw8,gradientlb8]\n",
    "    squared_sums = [torch.sum(tensor ** 2) for tensor in tensors_l]\n",
    "    # 将所有平方和相加\n",
    "    total_squared_sum = sum(squared_sums)\n",
    "    l2_norm_gradient_l=(total_squared_sum.item())**0.5\n",
    "    return l2_norm_gradient_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c08a42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文本文件\n",
    "xdata = np.loadtxt('通行x_real.txt')\n",
    "# 从第四个数据开始，每隔10个数据读取一个，共读取50个数据\n",
    "xselected_data = xdata[jump::int(n_all/n_test)][:(n_test+1)]\n",
    "# 将所选数据转换为PyTorch张量\n",
    "x_real = torch.tensor(xselected_data, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "ydata = np.loadtxt('通行y_real.txt')\n",
    "yselected_data = ydata[jump::int(n_all/n_test)][:(n_test+1)]\n",
    "y_real = torch.tensor(yselected_data, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "zdata = np.loadtxt('通行z_real.txt')\n",
    "zselected_data = zdata[jump::int(n_all/n_test)][:(n_test+1)]\n",
    "z_real = torch.tensor(zselected_data, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xdata=None\n",
    "ydata=None\n",
    "zdata=None\n",
    "xselected_data=None\n",
    "yselected_data=None\n",
    "zselected_data=None\n",
    "\n",
    "#x_real：用于训练过程神经网络输出值与真实值对比，3，13,23…493共50个时刻点，对应t_test\n",
    "#x_real_plt：用于绘制真实图，0~500全点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db7929b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练过程中记录的量\n",
    "loss_list=[]#总损失，带权重\n",
    "lpde_list=[]#方程项损失\n",
    "l0_list=[]#初态损失\n",
    "lE_list=[]#能量项损失loss，也是与真实能量做对比diff\n",
    "# lamda1_list=[]#方程项权重，把保能量保磁矩也放在这一项\n",
    "# lamda2_list=[]#能量项权重\n",
    "# lamda3_list=[]#初态权重\n",
    "# l_withoutweight_list=[]#总损失，不带权重\n",
    "# time_list=[]#训练时间记录\n",
    "loss_test_list=[]#部分时刻点，输出位置与真实位置误差向量的模平方，即位置与真实值的误差\n",
    "lossmean_test_list=[]#部分时刻点，输出位置与真实位置误差的算术平均值，(sigma（xn+yn+zn）-sigma(xc+yc+zc))/n ,证明轨迹可以视为导心\n",
    "# miu_train_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8692c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_lists = [loss_list, lpde_list, l0_list, lE_list, loss_test_list, lossmean_test_list]\n",
    "file_names = ['hh_loss.txt', 'hh_lpde.txt', 'hh_l0.txt', 'hh_lE.txt', 'hh_loss_test.txt', 'hh_lossmean_test.txt']\n",
    "\n",
    "def Save():\n",
    "    for file_list, old_name in zip(file_lists, file_names):\n",
    "        # 构建新文件名，保留原始文件名中的后缀部分\n",
    "        new_name = new_prefix + old_name[2:]\n",
    "\n",
    "        # 检查是否已经存在该文件，如果存在，则在文件末尾追加写入\n",
    "        if os.path.exists(new_name):\n",
    "            mode = 'a'  # 追加模式\n",
    "        else:\n",
    "            mode = 'w'  # 新建文件模式\n",
    "\n",
    "        # 打开文件进行写入\n",
    "        with open(new_name, mode) as f:\n",
    "            for item in file_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n",
    "        # 清空列表\n",
    "        file_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb10e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100000], Loss: 1.718e+05,   LOSS_function: 6.057e+04,   LOSS_E:24.66,    LOSS_initial: 68.01,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 0.08753633499145508\n",
      "loss_compared with real:27.502,   miu_train:0.0002402,    lossmean:-2.875\n",
      "Epoch [100/100000], Loss: 2301,   LOSS_function: 663.6,   LOSS_E:0.1261,    LOSS_initial: 1.539,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 7.155179738998413\n",
      "loss_compared with real:0.83611,   miu_train:0.004188,    lossmean:-0.05178\n",
      "Epoch [200/100000], Loss: 512.3,   LOSS_function: 16.96,   LOSS_E:0.0177,    LOSS_initial: 0.7855,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 14.708080768585205\n",
      "loss_compared with real:0.2684,   miu_train:0.0002293,    lossmean:-0.07861\n",
      "Epoch [300/100000], Loss: 420.9,   LOSS_function: 3.532,   LOSS_E:0.0004229,    LOSS_initial: 0.6895,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 21.499929428100586\n",
      "loss_compared with real:0.2231,   miu_train:0.0001077,    lossmean:-0.1516\n",
      "Epoch [400/100000], Loss: 420,   LOSS_function: 3.531,   LOSS_E:0.0002757,    LOSS_initial: 0.688,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 28.25290536880493\n",
      "loss_compared with real:0.22169,   miu_train:0.0001089,    lossmean:-0.1513\n",
      "Epoch [500/100000], Loss: 419.7,   LOSS_function: 4.269,   LOSS_E:0.0002562,    LOSS_initial: 0.6851,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 35.022196769714355\n",
      "loss_compared with real:0.21949,   miu_train:0.0001172,    lossmean:-0.1557\n",
      "Epoch [600/100000], Loss: 419.1,   LOSS_function: 4.061,   LOSS_E:0.0003972,    LOSS_initial: 0.6847,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 41.83211159706116\n",
      "loss_compared with real:0.22072,   miu_train:0.0001087,    lossmean:-0.1507\n",
      "Epoch [700/100000], Loss: 418.9,   LOSS_function: 3.725,   LOSS_E:0.0004685,    LOSS_initial: 0.6854,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 48.65602660179138\n",
      "loss_compared with real:0.22083,   miu_train:0.0001083,    lossmean:-0.1492\n",
      "Epoch [800/100000], Loss: 550.4,   LOSS_function: 83.43,   LOSS_E:0.0005678,    LOSS_initial: 0.6389,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 55.55227828025818\n",
      "loss_compared with real:0.23808,   miu_train:0.0005529,    lossmean:-0.151\n",
      "Epoch [900/100000], Loss: 418.7,   LOSS_function: 4.054,   LOSS_E:0.0006669,    LOSS_initial: 0.6839,\n",
      "lamda1:2,    lamda2:400,    lamda3:600,      learn rate:0.0008,    time: 62.30179762840271\n",
      "loss_compared with real:0.21881,   miu_train:0.0001482,    lossmean:-0.1515\n",
      "Epoch [1000/100000], Loss: 616.4,   LOSS_function: 11.4,   LOSS_E:0.0006262,    LOSS_initial: 0.6723,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 69.21183443069458\n",
      "loss_compared with real:0.18855,   miu_train:0.0003129,    lossmean:-0.1337\n",
      "Epoch [1100/100000], Loss: 1061,   LOSS_function: 265.9,   LOSS_E:2.109e-05,    LOSS_initial: 0.9661,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 75.97148060798645\n",
      "loss_compared with real:0.32535,   miu_train:0.001615,    lossmean:-0.01561\n",
      "Epoch [1200/100000], Loss: 537.5,   LOSS_function: 14.01,   LOSS_E:5.24e-06,    LOSS_initial: 0.6803,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 82.89437961578369\n",
      "loss_compared with real:0.21756,   miu_train:0.0001807,    lossmean:-0.1365\n",
      "Epoch [1300/100000], Loss: 529,   LOSS_function: 17.04,   LOSS_E:3.985e-06,    LOSS_initial: 0.6647,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 89.72883749008179\n",
      "loss_compared with real:0.21337,   miu_train:0.0002031,    lossmean:-0.1466\n",
      "Epoch [1400/100000], Loss: 528.6,   LOSS_function: 16.09,   LOSS_E:4.072e-06,    LOSS_initial: 0.6656,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 96.58835339546204\n",
      "loss_compared with real:0.21331,   miu_train:0.0001986,    lossmean:-0.146\n",
      "Epoch [1500/100000], Loss: 528.4,   LOSS_function: 15.92,   LOSS_E:4.063e-06,    LOSS_initial: 0.6657,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 103.55098748207092\n",
      "loss_compared with real:0.21323,   miu_train:0.0001978,    lossmean:-0.1458\n",
      "Epoch [1600/100000], Loss: 528.2,   LOSS_function: 15.82,   LOSS_E:4.04e-06,    LOSS_initial: 0.6656,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 110.5114803314209\n",
      "loss_compared with real:0.21318,   miu_train:0.0001974,    lossmean:-0.1457\n",
      "Epoch [1700/100000], Loss: 528.1,   LOSS_function: 15.83,   LOSS_E:3.95e-06,    LOSS_initial: 0.6654,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 117.41362714767456\n",
      "loss_compared with real:0.21308,   miu_train:0.0001974,    lossmean:-0.1457\n",
      "Epoch [1800/100000], Loss: 527.9,   LOSS_function: 15.83,   LOSS_E:3.974e-06,    LOSS_initial: 0.6651,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 123.95889377593994\n",
      "loss_compared with real:0.21302,   miu_train:0.0001976,    lossmean:-0.1457\n",
      "Epoch [1900/100000], Loss: 527.6,   LOSS_function: 15.76,   LOSS_E:3.845e-06,    LOSS_initial: 0.665,\n",
      "lamda1:1.201,    lamda2:1.42e+05,    lamda3:764.2,      learn rate:0.0007616,    time: 130.4104037284851\n",
      "loss_compared with real:0.21298,   miu_train:0.0001975,    lossmean:-0.1457\n",
      "Epoch [2000/100000], Loss: 457.5,   LOSS_function: 15.87,   LOSS_E:3.888e-06,    LOSS_initial: 0.6646,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 136.88334131240845\n",
      "loss_compared with real:0.21294,   miu_train:0.0001972,    lossmean:-0.1456\n",
      "Epoch [2100/100000], Loss: 457.2,   LOSS_function: 15.78,   LOSS_E:3.691e-06,    LOSS_initial: 0.6644,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 143.32847213745117\n",
      "loss_compared with real:0.21284,   miu_train:0.0001975,    lossmean:-0.1456\n",
      "Epoch [2200/100000], Loss: 457.2,   LOSS_function: 15.9,   LOSS_E:3.685e-06,    LOSS_initial: 0.6641,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 149.92997932434082\n",
      "loss_compared with real:0.21275,   miu_train:0.0001976,    lossmean:-0.1456\n",
      "Epoch [2300/100000], Loss: 457,   LOSS_function: 15.81,   LOSS_E:3.643e-06,    LOSS_initial: 0.6639,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 156.35990023612976\n",
      "loss_compared with real:0.21266,   miu_train:0.0001981,    lossmean:-0.1456\n",
      "Epoch [2400/100000], Loss: 469.3,   LOSS_function: 11.02,   LOSS_E:8.458e-05,    LOSS_initial: 0.6727,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 162.79637575149536\n",
      "loss_compared with real:0.21317,   miu_train:0.0001907,    lossmean:-0.1413\n",
      "Epoch [2500/100000], Loss: 456.5,   LOSS_function: 15.87,   LOSS_E:3.841e-06,    LOSS_initial: 0.6631,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 169.25467228889465\n",
      "loss_compared with real:0.21248,   miu_train:0.0001984,    lossmean:-0.1455\n",
      "Epoch [2600/100000], Loss: 668.7,   LOSS_function: 5.878,   LOSS_E:0.001452,    LOSS_initial: 0.6887,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 175.76079773902893\n",
      "loss_compared with real:0.21065,   miu_train:0.0001743,    lossmean:-0.1449\n",
      "Epoch [2700/100000], Loss: 456.1,   LOSS_function: 15.94,   LOSS_E:4.089e-06,    LOSS_initial: 0.6623,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 182.197256565094\n",
      "loss_compared with real:0.21228,   miu_train:0.0001988,    lossmean:-0.1455\n",
      "Epoch [2800/100000], Loss: 455.8,   LOSS_function: 15.86,   LOSS_E:4.204e-06,    LOSS_initial: 0.662,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 188.70192074775696\n",
      "loss_compared with real:0.21231,   miu_train:0.0001977,    lossmean:-0.1455\n",
      "Epoch [2900/100000], Loss: 459.1,   LOSS_function: 15.08,   LOSS_E:3.04e-05,    LOSS_initial: 0.6626,\n",
      "lamda1:1.041,    lamda2:1.42e+05,    lamda3:662.7,      learn rate:0.000725,    time: 195.312890291214\n",
      "loss_compared with real:0.21327,   miu_train:0.0001883,    lossmean:-0.1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3000/100000], Loss: 445.3,   LOSS_function: 15.9,   LOSS_E:4.263e-06,    LOSS_initial: 0.6614,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 201.89311861991882\n",
      "loss_compared with real:0.21208,   miu_train:0.0001983,    lossmean:-0.1453\n",
      "Epoch [3100/100000], Loss: 445.1,   LOSS_function: 16.07,   LOSS_E:4.229e-06,    LOSS_initial: 0.6608,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 209.03709030151367\n",
      "loss_compared with real:0.21189,   miu_train:0.0002001,    lossmean:-0.1453\n",
      "Epoch [3200/100000], Loss: 451.7,   LOSS_function: 15.48,   LOSS_E:4.938e-05,    LOSS_initial: 0.6621,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 215.70878791809082\n",
      "loss_compared with real:0.21039,   miu_train:0.0002101,    lossmean:-0.1445\n",
      "Epoch [3300/100000], Loss: 444.8,   LOSS_function: 16.71,   LOSS_E:4.416e-06,    LOSS_initial: 0.6593,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 222.36257123947144\n",
      "loss_compared with real:0.21133,   miu_train:0.0002032,    lossmean:-0.1456\n",
      "Epoch [3400/100000], Loss: 444.5,   LOSS_function: 16.07,   LOSS_E:4.378e-06,    LOSS_initial: 0.6599,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 228.90005683898926\n",
      "loss_compared with real:0.21165,   miu_train:0.0002,    lossmean:-0.1451\n",
      "Epoch [3500/100000], Loss: 453.9,   LOSS_function: 16.97,   LOSS_E:7.397e-05,    LOSS_initial: 0.6577,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 235.4801685810089\n",
      "loss_compared with real:0.21328,   miu_train:0.0001904,    lossmean:-0.146\n",
      "Epoch [3600/100000], Loss: 444.2,   LOSS_function: 16.41,   LOSS_E:4.723e-06,    LOSS_initial: 0.6588,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 242.08065485954285\n",
      "loss_compared with real:0.21118,   miu_train:0.000203,    lossmean:-0.1452\n",
      "Epoch [3700/100000], Loss: 444.1,   LOSS_function: 15.97,   LOSS_E:5.123e-06,    LOSS_initial: 0.6592,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 248.66092944145203\n",
      "loss_compared with real:0.21122,   miu_train:0.0002013,    lossmean:-0.145\n",
      "Epoch [3800/100000], Loss: 444.5,   LOSS_function: 16.96,   LOSS_E:9.427e-06,    LOSS_initial: 0.6573,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 255.59838557243347\n",
      "loss_compared with real:0.21109,   miu_train:0.0002032,    lossmean:-0.1458\n",
      "Epoch [3900/100000], Loss: 443.7,   LOSS_function: 16.27,   LOSS_E:4.593e-06,    LOSS_initial: 0.6583,\n",
      "lamda1:1.01,    lamda2:1.42e+05,    lamda3:648.1,      learn rate:0.0006902,    time: 262.79377484321594\n",
      "loss_compared with real:0.21132,   miu_train:0.0001999,    lossmean:-0.145\n",
      "Epoch [4000/100000], Loss: 451.4,   LOSS_function: 9.249,   LOSS_E:0.0005007,    LOSS_initial: 0.6738,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 269.69007635116577\n",
      "loss_compared with real:0.22135,   miu_train:0.0001558,    lossmean:-0.137\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5484, -0.5519, -0.3181, -0.9763, -0.0851, -0.3551,  0.4579, -0.8541,\n",
      "         0.9256,  0.3267,  0.7949,  0.5490,  0.6587, -0.0416,  0.7191, -0.3318,\n",
      "         0.8759,  0.0355,  0.8221, -0.8322, -0.2944, -0.9740, -0.5236, -0.3552,\n",
      "        -0.3267, -0.4104,  0.7477, -0.6862, -0.2599,  0.4295, -0.3337, -0.1958,\n",
      "         0.1185,  0.6457, -0.7329, -0.8243, -0.7190, -0.5769, -0.2842, -0.0526,\n",
      "        -0.8394, -0.9454, -0.0671,  0.8262, -0.6417,  0.8722, -0.6895,  0.9115,\n",
      "         0.6245, -0.9558, -0.7641, -0.3802,  0.8725, -0.6079,  0.9351, -0.1289,\n",
      "        -0.9020,  0.4276, -0.2779, -0.8676,  0.8229, -0.3314,  0.2811, -0.1117,\n",
      "        -0.5475, -0.0742, -0.0355,  0.4184, -0.4361, -0.3667,  0.6216, -0.4577,\n",
      "        -0.5180,  0.8868,  0.8378, -0.4512, -0.4703,  0.0109, -0.3522, -0.5651,\n",
      "        -0.7802, -0.7463,  0.9664,  0.0079,  0.1136,  0.8335,  0.7133,  0.2499,\n",
      "        -0.0324, -0.0813,  0.6947,  0.7252, -0.6919,  0.9100,  0.2339,  0.5678,\n",
      "        -0.6693, -0.1385,  0.6206,  0.0173, -0.8601,  0.1001, -0.0019, -0.2184,\n",
      "         0.4314,  0.5112,  0.6945,  0.0566,  0.2657,  0.6716, -0.6544, -0.2720,\n",
      "         0.6036,  0.7967,  0.7702, -0.0013, -0.9782,  0.9196, -0.3198, -0.8891,\n",
      "        -0.9686,  0.9167, -0.2214,  0.3844, -0.2504,  0.4581, -0.2166,  0.1940],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.0990, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0149, -0.0203,  0.0270,  0.0854, -0.0558, -0.0400, -0.0371,  0.0288,\n",
      "        -0.0396,  0.0370, -0.0120, -0.0895,  0.0564, -0.0454,  0.0656,  0.0178,\n",
      "        -0.0207, -0.0215, -0.0256,  0.0452, -0.0668,  0.0540,  0.0301,  0.0304,\n",
      "         0.0182, -0.0082,  0.0525, -0.0407, -0.0287, -0.0809,  0.0254, -0.0779,\n",
      "         0.0793, -0.0415,  0.0561,  0.0072, -0.0566,  0.0536,  0.0409, -0.0568,\n",
      "        -0.0894, -0.0746,  0.0188,  0.0851,  0.0806,  0.0824, -0.0268,  0.0787,\n",
      "        -0.0387, -0.0091,  0.0384,  0.0273, -0.0252,  0.0103,  0.0263, -0.0114,\n",
      "         0.0657,  0.0385,  0.0457,  0.0373,  0.0097, -0.0194, -0.0206,  0.0457,\n",
      "         0.0447,  0.0172,  0.0598,  0.0217,  0.0399,  0.0251,  0.0572,  0.0085,\n",
      "        -0.0256, -0.0127, -0.0786,  0.0050, -0.0518,  0.0591, -0.0132,  0.0113,\n",
      "         0.0297, -0.0223, -0.0101,  0.0447,  0.0374, -0.0687, -0.0227, -0.0152,\n",
      "         0.0887,  0.0781,  0.0327,  0.0535, -0.0665, -0.0752,  0.0680, -0.0663,\n",
      "         0.0507,  0.0407,  0.0305,  0.0803,  0.0796,  0.0534,  0.0488,  0.0888,\n",
      "         0.0688,  0.0022, -0.0834, -0.0618,  0.0067, -0.0541,  0.0368,  0.0100,\n",
      "        -0.0400, -0.0440, -0.0130,  0.0335,  0.0551, -0.0581, -0.1070,  0.0361,\n",
      "         0.0614,  0.0221,  0.0246, -0.0234,  0.0120,  0.0158, -0.0605,  0.0613],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1154, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0539, -0.0308, -0.0430,  0.0438, -0.0457, -0.0349, -0.0866, -0.0320,\n",
      "        -0.0286,  0.0529, -0.0120, -0.0585, -0.0343,  0.0202, -0.0368, -0.0907,\n",
      "        -0.0662,  0.0678,  0.0065, -0.0856,  0.0188, -0.0240, -0.0453, -0.0240,\n",
      "         0.0257,  0.0182,  0.0747,  0.0459, -0.0645, -0.0655, -0.0281,  0.0433,\n",
      "         0.0302, -0.0341,  0.0579,  0.0786,  0.0770, -0.0007,  0.0267,  0.0829,\n",
      "        -0.0454,  0.0407,  0.0217, -0.0351,  0.0509,  0.0132, -0.0651, -0.0600,\n",
      "        -0.0091, -0.0371, -0.0719,  0.0454,  0.0578, -0.0776,  0.0481,  0.0105,\n",
      "         0.0333, -0.0786,  0.0111, -0.0798,  0.0289,  0.0580, -0.0123,  0.0845,\n",
      "         0.0645, -0.0405,  0.0184, -0.0013,  0.0086,  0.0205, -0.0704, -0.0253,\n",
      "         0.0021,  0.0504, -0.0144,  0.0488,  0.0721,  0.0158,  0.0147, -0.0159,\n",
      "         0.0906, -0.0410, -0.0755,  0.0869, -0.0066, -0.0122,  0.0259,  0.0734,\n",
      "        -0.0026, -0.0787,  0.0091, -0.0830,  0.0155, -0.0135, -0.0842,  0.0500,\n",
      "        -0.0612, -0.0636, -0.0870,  0.0734, -0.0693,  0.0117,  0.0069,  0.0315,\n",
      "        -0.0230, -0.0666,  0.0279, -0.0574, -0.0951, -0.0405, -0.0820,  0.0134,\n",
      "         0.0677, -0.0704, -0.0442, -0.0299, -0.0327, -0.0432,  0.0889, -0.0116,\n",
      "        -0.0526,  0.0397,  0.0607,  0.0765, -0.0503, -0.0688, -0.0153, -0.0548],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1017, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-3.4916e-02, -6.7849e-02, -1.1378e-02,  8.9707e-02, -9.6531e-02,\n",
      "         2.6334e-02, -3.0200e-02, -3.3633e-03,  8.0983e-02,  1.4950e-02,\n",
      "         3.1311e-02,  5.4928e-02,  4.6768e-02, -8.6251e-02, -4.3121e-02,\n",
      "         4.7278e-02, -1.6470e-03,  1.4678e-02, -7.7689e-03, -2.7165e-02,\n",
      "        -3.4708e-02,  2.9820e-03,  4.6195e-02,  6.7041e-02,  2.5363e-02,\n",
      "        -3.9493e-02,  1.0111e-02, -2.3257e-02, -1.1815e-02,  4.9927e-02,\n",
      "        -9.4714e-03,  4.2189e-02,  2.9288e-02, -2.0694e-02, -6.8437e-02,\n",
      "         3.8595e-02, -7.1824e-02, -9.1195e-02, -7.1873e-02,  5.9799e-03,\n",
      "         7.1249e-02, -8.5881e-02,  3.2823e-02,  2.5391e-02,  5.2631e-02,\n",
      "        -5.6914e-02,  9.5758e-02,  1.8348e-02, -8.9127e-02, -6.5331e-02,\n",
      "        -1.5508e-02, -6.1885e-02, -2.9836e-02,  6.9151e-02,  4.9743e-02,\n",
      "         2.8725e-02, -1.2645e-02, -6.5946e-02,  7.1618e-02,  2.9711e-02,\n",
      "         1.4532e-02, -6.4381e-02, -2.4928e-02, -4.4375e-02,  8.1339e-03,\n",
      "        -7.2774e-02, -5.0025e-02, -5.0894e-02,  3.4568e-02, -8.5427e-02,\n",
      "        -7.2300e-02, -3.7748e-02, -2.0704e-02,  1.0255e-02, -6.4404e-02,\n",
      "         9.9022e-03, -2.0315e-02, -3.4975e-02,  8.2340e-02, -1.7490e-02,\n",
      "        -6.1088e-02,  7.0182e-02, -6.8209e-04,  4.2580e-02,  1.1459e-02,\n",
      "        -8.2227e-02, -9.4890e-05, -4.6546e-02,  2.0124e-02,  1.9661e-02,\n",
      "        -3.6549e-02, -7.8906e-02,  5.8183e-02,  6.1499e-02,  1.2649e-02,\n",
      "         7.1126e-02, -5.9020e-02, -8.3019e-02,  3.7676e-02, -6.8377e-02,\n",
      "        -4.2810e-02,  3.2194e-02, -6.6544e-02, -2.2075e-02,  1.8054e-02,\n",
      "         4.4768e-02,  1.8346e-02, -8.7003e-02,  4.3286e-02, -7.4287e-02,\n",
      "         8.7258e-02,  8.7104e-02, -5.5360e-02, -6.3854e-02,  6.0474e-02,\n",
      "         6.6644e-03, -7.9811e-02,  1.7061e-02, -2.5483e-02,  3.9926e-02,\n",
      "         6.4957e-02, -5.5665e-02,  5.6871e-02, -8.2689e-02, -3.5620e-02,\n",
      "         4.1760e-02, -1.6206e-02,  5.7557e-02], requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.1031, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0424,  0.0229,  0.0497], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4100/100000], Loss: 426.1,   LOSS_function: 15.04,   LOSS_E:7.525e-06,    LOSS_initial: 0.6593,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 276.44407081604004\n",
      "loss_compared with real:0.21167,   miu_train:0.0001926,    lossmean:-0.1451\n",
      "Epoch [4200/100000], Loss: 425.9,   LOSS_function: 15.21,   LOSS_E:7.663e-06,    LOSS_initial: 0.6587,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 283.8081421852112\n",
      "loss_compared with real:0.21154,   miu_train:0.0001923,    lossmean:-0.1451\n",
      "Epoch [4300/100000], Loss: 425.7,   LOSS_function: 15.08,   LOSS_E:7.813e-06,    LOSS_initial: 0.6586,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 291.46935200691223\n",
      "loss_compared with real:0.2114,   miu_train:0.0001925,    lossmean:-0.1451\n",
      "Epoch [4400/100000], Loss: 425.4,   LOSS_function: 15.16,   LOSS_E:7.877e-06,    LOSS_initial: 0.658,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 299.16514778137207\n",
      "loss_compared with real:0.21127,   miu_train:0.0001934,    lossmean:-0.1451\n",
      "Epoch [4500/100000], Loss: 425.2,   LOSS_function: 14.97,   LOSS_E:7.887e-06,    LOSS_initial: 0.6579,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 306.9767463207245\n",
      "loss_compared with real:0.21108,   miu_train:0.0001935,    lossmean:-0.145\n",
      "Epoch [4600/100000], Loss: 425,   LOSS_function: 15.32,   LOSS_E:7.905e-06,    LOSS_initial: 0.657,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 314.7042829990387\n",
      "loss_compared with real:0.21102,   miu_train:0.0001929,    lossmean:-0.1449\n",
      "Epoch [4700/100000], Loss: 424.6,   LOSS_function: 15.03,   LOSS_E:8.049e-06,    LOSS_initial: 0.6569,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 322.36521649360657\n",
      "loss_compared with real:0.21077,   miu_train:0.0001943,    lossmean:-0.1449\n",
      "Epoch [4800/100000], Loss: 424.4,   LOSS_function: 14.89,   LOSS_E:8.143e-06,    LOSS_initial: 0.6568,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 329.9809105396271\n",
      "loss_compared with real:0.21039,   miu_train:0.000197,    lossmean:-0.145\n",
      "Epoch [4900/100000], Loss: 429.9,   LOSS_function: 13,   LOSS_E:9.972e-06,    LOSS_initial: 0.6686,\n",
      "lamda1:1.003,    lamda2:4.492e+04,    lamda3:622.9,      learn rate:0.0006571,    time: 337.6888802051544\n",
      "loss_compared with real:0.20629,   miu_train:0.0002722,    lossmean:-0.1457\n",
      "Epoch [5000/100000], Loss: 1115,   LOSS_function: 44.14,   LOSS_E:6.301e-06,    LOSS_initial: 0.6342,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 345.4007291793823\n",
      "loss_compared with real:0.20245,   miu_train:0.000731,    lossmean:-0.1391\n",
      "Epoch [5100/100000], Loss: 1079,   LOSS_function: 97.69,   LOSS_E:2.203e-05,    LOSS_initial: 0.5806,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 353.1979627609253\n",
      "loss_compared with real:0.18613,   miu_train:0.0007017,    lossmean:-0.1309\n",
      "Epoch [5200/100000], Loss: 1081,   LOSS_function: 82.54,   LOSS_E:2.75e-05,    LOSS_initial: 0.5909,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 360.8833966255188\n",
      "loss_compared with real:0.18345,   miu_train:0.0008815,    lossmean:-0.1327\n",
      "Epoch [5300/100000], Loss: 1072,   LOSS_function: 101.3,   LOSS_E:2.28e-05,    LOSS_initial: 0.574,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 368.6021509170532\n",
      "loss_compared with real:0.18434,   miu_train:0.0006986,    lossmean:-0.13\n",
      "Epoch [5400/100000], Loss: 1067,   LOSS_function: 105.5,   LOSS_E:2.126e-05,    LOSS_initial: 0.5691,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 376.2745363712311\n",
      "loss_compared with real:0.18413,   miu_train:0.0006789,    lossmean:-0.1296\n",
      "Epoch [5500/100000], Loss: 1062,   LOSS_function: 106,   LOSS_E:2.308e-05,    LOSS_initial: 0.5655,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 384.0468888282776\n",
      "loss_compared with real:0.18206,   miu_train:0.000703,    lossmean:-0.1286\n",
      "Epoch [5600/100000], Loss: 1075,   LOSS_function: 79.14,   LOSS_E:3.503e-05,    LOSS_initial: 0.5889,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 391.7957286834717\n",
      "loss_compared with real:0.17812,   miu_train:0.001092,    lossmean:-0.1324\n",
      "Epoch [5700/100000], Loss: 1055,   LOSS_function: 84.6,   LOSS_E:5.282e-05,    LOSS_initial: 0.5734,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 399.52243661880493\n",
      "loss_compared with real:0.18,   miu_train:0.0007711,    lossmean:-0.1311\n",
      "Epoch [5800/100000], Loss: 1062,   LOSS_function: 81.29,   LOSS_E:5.831e-05,    LOSS_initial: 0.5791,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 407.34460639953613\n",
      "loss_compared with real:0.18228,   miu_train:0.001084,    lossmean:-0.1304\n",
      "Epoch [5900/100000], Loss: 1043,   LOSS_function: 171.8,   LOSS_E:3.937e-05,    LOSS_initial: 0.515,\n",
      "lamda1:1.001,    lamda2:4.492e+04,    lamda3:1688,      learn rate:0.0006256,    time: 415.13442158699036\n",
      "loss_compared with real:0.17432,   miu_train:0.0007009,    lossmean:-0.1189\n",
      "Epoch [6000/100000], Loss: 1083,   LOSS_function: 115.5,   LOSS_E:5.861e-05,    LOSS_initial: 0.5276,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 422.9716444015503\n",
      "loss_compared with real:0.15288,   miu_train:0.0008838,    lossmean:-0.1084\n",
      "Epoch [6100/100000], Loss: 2229,   LOSS_function: 368.4,   LOSS_E:0.0002543,    LOSS_initial: 0.9184,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 430.78293800354004\n",
      "loss_compared with real:0.34741,   miu_train:0.002298,    lossmean:0.05395\n",
      "Epoch [6200/100000], Loss: 1654,   LOSS_function: 221.1,   LOSS_E:2.932e-06,    LOSS_initial: 0.8384,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 438.5581941604614\n",
      "loss_compared with real:0.29087,   miu_train:0.001347,    lossmean:-0.09998\n",
      "Epoch [6300/100000], Loss: 1493,   LOSS_function: 136.7,   LOSS_E:1.065e-06,    LOSS_initial: 0.7948,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 445.8812725543976\n",
      "loss_compared with real:0.26624,   miu_train:0.0008909,    lossmean:-0.1179\n",
      "Epoch [6400/100000], Loss: 1363,   LOSS_function: 79.16,   LOSS_E:5.884e-07,    LOSS_initial: 0.7526,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 453.09128403663635\n",
      "loss_compared with real:0.24856,   miu_train:0.0005839,    lossmean:-0.1227\n",
      "Epoch [6500/100000], Loss: 1262,   LOSS_function: 45.51,   LOSS_E:4.775e-07,    LOSS_initial: 0.7136,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 460.1988081932068\n",
      "loss_compared with real:0.23325,   miu_train:0.0004087,    lossmean:-0.1258\n",
      "Epoch [6600/100000], Loss: 1192,   LOSS_function: 32.99,   LOSS_E:9.427e-07,    LOSS_initial: 0.6795,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 467.4440026283264\n",
      "loss_compared with real:0.22035,   miu_train:0.0003484,    lossmean:-0.1281\n",
      "Epoch [6700/100000], Loss: 1149,   LOSS_function: 36.04,   LOSS_E:1.872e-06,    LOSS_initial: 0.6517,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 474.60255432128906\n",
      "loss_compared with real:0.21015,   miu_train:0.0003692,    lossmean:-0.1297\n",
      "Epoch [6800/100000], Loss: 1125,   LOSS_function: 47.17,   LOSS_E:2.975e-06,    LOSS_initial: 0.6305,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 481.8466396331787\n",
      "loss_compared with real:0.20259,   miu_train:0.0004308,    lossmean:-0.1306\n",
      "Epoch [6900/100000], Loss: 1114,   LOSS_function: 59.91,   LOSS_E:3.917e-06,    LOSS_initial: 0.6155,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1705,      learn rate:0.0005955,    time: 489.05971932411194\n",
      "loss_compared with real:0.19735,   miu_train:0.0005003,    lossmean:-0.1312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7000/100000], Loss: 1108,   LOSS_function: 71.04,   LOSS_E:4.636e-06,    LOSS_initial: 0.6054,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 496.25243067741394\n",
      "loss_compared with real:0.19395,   miu_train:0.0005574,    lossmean:-0.1315\n",
      "Epoch [7100/100000], Loss: 1106,   LOSS_function: 78.09,   LOSS_E:5.141e-06,    LOSS_initial: 0.5994,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 503.50903129577637\n",
      "loss_compared with real:0.19195,   miu_train:0.0005957,    lossmean:-0.1315\n",
      "Epoch [7200/100000], Loss: 1104,   LOSS_function: 83.13,   LOSS_E:5.393e-06,    LOSS_initial: 0.5955,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 510.68825793266296\n",
      "loss_compared with real:0.19067,   miu_train:0.0006222,    lossmean:-0.1315\n",
      "Epoch [7300/100000], Loss: 1104,   LOSS_function: 86.16,   LOSS_E:5.489e-06,    LOSS_initial: 0.5933,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 517.7751066684723\n",
      "loss_compared with real:0.18995,   miu_train:0.0006372,    lossmean:-0.1314\n",
      "Epoch [7400/100000], Loss: 1103,   LOSS_function: 88,   LOSS_E:5.551e-06,    LOSS_initial: 0.5919,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 524.9428825378418\n",
      "loss_compared with real:0.18949,   miu_train:0.0006468,    lossmean:-0.1313\n",
      "Epoch [7500/100000], Loss: 1103,   LOSS_function: 89,   LOSS_E:5.587e-06,    LOSS_initial: 0.5911,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 532.1005549430847\n",
      "loss_compared with real:0.18928,   miu_train:0.0006519,    lossmean:-0.1312\n",
      "Epoch [7600/100000], Loss: 1103,   LOSS_function: 89.96,   LOSS_E:5.493e-06,    LOSS_initial: 0.5905,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 539.3414890766144\n",
      "loss_compared with real:0.18913,   miu_train:0.0006554,    lossmean:-0.131\n",
      "Epoch [7700/100000], Loss: 1102,   LOSS_function: 90,   LOSS_E:5.437e-06,    LOSS_initial: 0.5903,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 546.6356694698334\n",
      "loss_compared with real:0.18909,   miu_train:0.0006551,    lossmean:-0.1309\n",
      "Epoch [7800/100000], Loss: 1102,   LOSS_function: 90.11,   LOSS_E:5.385e-06,    LOSS_initial: 0.59,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 553.9019241333008\n",
      "loss_compared with real:0.18899,   miu_train:0.0006572,    lossmean:-0.1309\n",
      "Epoch [7900/100000], Loss: 1102,   LOSS_function: 90.67,   LOSS_E:5.384e-06,    LOSS_initial: 0.5898,\n",
      "lamda1:1.001,    lamda2:1.159e+06,    lamda3:1704,      learn rate:0.000567,    time: 561.2422389984131\n",
      "loss_compared with real:0.18903,   miu_train:0.0006576,    lossmean:-0.1309\n",
      "Epoch [8000/100000], Loss: 1188,   LOSS_function: 83.66,   LOSS_E:2.329e-05,    LOSS_initial: 0.5942,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 568.795978307724\n",
      "loss_compared with real:0.18938,   miu_train:0.0006169,    lossmean:-0.1336\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5432, -0.5469, -0.3181, -0.9645, -0.0903, -0.3499,  0.4528, -0.8441,\n",
      "         0.9163,  0.3197,  0.7906,  0.5360,  0.6515, -0.0419,  0.7007, -0.3226,\n",
      "         0.8750,  0.0368,  0.8124, -0.8012, -0.2924, -0.9699, -0.5142, -0.3452,\n",
      "        -0.3169, -0.4066,  0.7185, -0.6748, -0.2497,  0.4034, -0.3264, -0.1934,\n",
      "         0.1125,  0.6452, -0.7323, -0.8046, -0.7304, -0.5755, -0.2659, -0.0612,\n",
      "        -0.8368, -0.9363, -0.0721,  0.8166, -0.6160,  0.8704, -0.6779,  0.8930,\n",
      "         0.6192, -0.9476, -0.7592, -0.3788,  0.8554, -0.5919,  0.9200, -0.1210,\n",
      "        -0.8859,  0.4177, -0.2765, -0.8604,  0.8055, -0.3318,  0.2768, -0.1096,\n",
      "        -0.5494, -0.0710, -0.0382,  0.4245, -0.4344, -0.3581,  0.6144, -0.4548,\n",
      "        -0.5121,  0.8783,  0.8130, -0.4469, -0.4557,  0.0129, -0.3418, -0.5548,\n",
      "        -0.7833, -0.7387,  0.9690,  0.0050,  0.1146,  0.8234,  0.7094,  0.2465,\n",
      "        -0.0313, -0.0723,  0.6733,  0.7159, -0.6882,  0.9101,  0.2288,  0.5637,\n",
      "        -0.6549, -0.1415,  0.6096,  0.0205, -0.8496,  0.1012, -0.0029, -0.2156,\n",
      "         0.4226,  0.5116,  0.6915,  0.0506,  0.2558,  0.6658, -0.6140, -0.2662,\n",
      "         0.5970,  0.7864,  0.7597, -0.0047, -0.9622,  0.9155, -0.3167, -0.8849,\n",
      "        -0.9652,  0.9059, -0.2171,  0.3847, -0.2496,  0.4404, -0.2176,  0.1894],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.0934, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0194, -0.0325,  0.0159,  0.0852, -0.0562, -0.0360, -0.0378,  0.0297,\n",
      "        -0.0605,  0.0401, -0.0105, -0.0950,  0.0448, -0.0472,  0.0542,  0.0071,\n",
      "        -0.0263, -0.0181, -0.0279,  0.0509, -0.0644,  0.0663,  0.0174, -0.0157,\n",
      "         0.0151, -0.0070,  0.0629, -0.0375, -0.0173, -0.0637,  0.0224, -0.0746,\n",
      "         0.0837, -0.0328,  0.0576,  0.0058, -0.0499,  0.0553,  0.0497, -0.0571,\n",
      "        -0.0854, -0.0703,  0.0263,  0.0865,  0.0625,  0.0787, -0.0249,  0.0620,\n",
      "        -0.0353, -0.0180,  0.0517,  0.0137, -0.0195,  0.0033,  0.0107, -0.0030,\n",
      "         0.0508,  0.0457,  0.0583,  0.0370,  0.0065, -0.0490, -0.0276,  0.0452,\n",
      "         0.0661, -0.0040,  0.0468,  0.0346,  0.0434,  0.0188,  0.0582,  0.0053,\n",
      "        -0.0249, -0.0130, -0.0707,  0.0269, -0.0529,  0.0484, -0.0205,  0.0165,\n",
      "         0.0054, -0.0154, -0.0102,  0.0392,  0.0401, -0.0405, -0.0203, -0.0246,\n",
      "         0.0874,  0.0895,  0.0249,  0.0561, -0.0546, -0.0919,  0.0805, -0.0717,\n",
      "         0.0525,  0.0221,  0.0233,  0.0824,  0.0769,  0.0589,  0.0400,  0.0830,\n",
      "         0.0638,  0.0042, -0.0893, -0.0735,  0.0086, -0.0560,  0.0293,  0.0130,\n",
      "        -0.0496, -0.0488,  0.0011,  0.0423,  0.0592, -0.0774, -0.1031,  0.0353,\n",
      "         0.0689,  0.0265,  0.0173, -0.0198, -0.0007,  0.0134, -0.0614,  0.0754],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1103, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 5.0978e-02, -3.9891e-02, -4.1722e-02,  5.2118e-02, -3.6855e-02,\n",
      "        -3.8222e-02, -1.1172e-01,  2.6073e-04, -2.9274e-02,  5.5768e-02,\n",
      "        -1.8436e-02, -6.1268e-02, -2.5150e-02,  2.9605e-03, -3.0721e-02,\n",
      "        -9.1360e-02, -5.8098e-02,  5.8725e-02,  9.3970e-05, -7.7111e-02,\n",
      "         1.3714e-02, -2.4043e-02, -5.3719e-02, -2.3260e-02,  2.3456e-02,\n",
      "         1.4060e-02,  5.9505e-02,  5.3894e-02, -5.6369e-02, -5.9357e-02,\n",
      "        -3.5701e-02,  3.3563e-02,  4.3831e-02, -3.2521e-02,  5.6317e-02,\n",
      "         5.4523e-02,  7.3914e-02, -5.8744e-03,  2.4092e-02,  8.5568e-02,\n",
      "        -6.0483e-02,  4.4871e-02,  2.1724e-02, -2.3442e-02,  5.3242e-02,\n",
      "         1.2746e-02, -7.5388e-02, -5.0914e-02, -2.0432e-02, -3.3810e-02,\n",
      "        -7.3497e-02,  4.5337e-02,  7.1533e-02, -6.7637e-02,  6.1772e-02,\n",
      "        -1.6705e-02,  3.1036e-02, -6.5552e-02,  1.9951e-02, -7.1201e-02,\n",
      "         4.2440e-02,  5.9644e-02, -1.5262e-02,  1.0836e-01,  7.6290e-02,\n",
      "        -4.1653e-02,  4.0217e-03, -7.5739e-03,  1.0329e-02,  1.3867e-02,\n",
      "        -8.0388e-02, -9.3325e-03,  1.1355e-02,  4.3509e-02, -1.5311e-02,\n",
      "         3.3071e-02,  7.7410e-02,  2.1914e-02,  6.2159e-03, -2.3335e-03,\n",
      "         8.0005e-02, -4.4206e-02, -8.3261e-02,  9.2583e-02,  1.5873e-02,\n",
      "        -8.4547e-03,  2.4815e-02,  8.0749e-02, -1.5133e-02, -7.6551e-02,\n",
      "         9.4713e-03, -8.5860e-02,  3.6437e-02, -2.4802e-02, -7.5063e-02,\n",
      "         3.5753e-02, -6.6522e-02, -6.4401e-02, -7.0141e-02,  7.3505e-02,\n",
      "        -7.5365e-02,  2.4285e-02, -8.4024e-03,  3.0315e-02, -2.1954e-02,\n",
      "        -6.3560e-02,  2.0389e-02, -7.2155e-02, -9.3452e-02, -2.7787e-02,\n",
      "        -6.4816e-02,  1.5727e-02,  5.7947e-02, -1.0037e-01, -4.4197e-02,\n",
      "        -3.5228e-02, -4.4707e-02, -4.5325e-02,  7.8093e-02, -2.7675e-02,\n",
      "        -4.6691e-02,  4.9594e-02,  6.0118e-02,  7.7979e-02, -5.4609e-02,\n",
      "        -7.9432e-02, -1.5575e-02, -5.1952e-02], requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.0914, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0363, -0.0759,  0.0157,  0.0813, -0.0847,  0.0275, -0.0113,  0.0019,\n",
      "         0.0913,  0.0293,  0.0240,  0.0486,  0.0452, -0.0777, -0.0409,  0.0589,\n",
      "         0.0031,  0.0196, -0.0118, -0.0271,  0.0060, -0.0021,  0.0484,  0.0857,\n",
      "        -0.0046, -0.0461, -0.0097, -0.0311, -0.0017,  0.0664,  0.0070,  0.0491,\n",
      "         0.0116, -0.0236, -0.0444,  0.0452, -0.0602, -0.0914, -0.0770,  0.0018,\n",
      "         0.0818, -0.0793,  0.0275,  0.0324,  0.0661, -0.0479,  0.0866,  0.0090,\n",
      "        -0.0812, -0.0581,  0.0142, -0.0587,  0.0037,  0.0805,  0.0529,  0.0125,\n",
      "        -0.0210, -0.0563,  0.0634,  0.0366,  0.0133, -0.0703, -0.0206, -0.0305,\n",
      "         0.0130, -0.0606, -0.0485, -0.0363,  0.0439, -0.0816, -0.0643, -0.0210,\n",
      "        -0.0395,  0.0130, -0.0753, -0.0012, -0.0261, -0.0247,  0.0772, -0.0202,\n",
      "        -0.0407,  0.0704,  0.0056,  0.0350,  0.0058, -0.0707,  0.0105, -0.0425,\n",
      "         0.0064,  0.0258, -0.0251, -0.0890,  0.0715,  0.0537,  0.0030,  0.0707,\n",
      "        -0.0659, -0.0861,  0.0513, -0.0673, -0.0326,  0.0350, -0.0680, -0.0323,\n",
      "         0.0268,  0.0337,  0.0343, -0.0809,  0.0416, -0.0607,  0.0707,  0.0703,\n",
      "        -0.0579, -0.0702,  0.0558, -0.0041, -0.0989,  0.0242, -0.0344,  0.0493,\n",
      "         0.0474, -0.0467,  0.0435, -0.0914, -0.0136,  0.0423, -0.0145,  0.0497],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0813, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0181,  0.0355,  0.0665], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8100/100000], Loss: 1178,   LOSS_function: 97.43,   LOSS_E:5.396e-06,    LOSS_initial: 0.5856,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 576.6170423030853\n",
      "loss_compared with real:0.18807,   miu_train:0.0007029,    lossmean:-0.1287\n",
      "Epoch [8200/100000], Loss: 1177,   LOSS_function: 105.4,   LOSS_E:5.966e-06,    LOSS_initial: 0.5807,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 584.1883661746979\n",
      "loss_compared with real:0.18625,   miu_train:0.0007449,    lossmean:-0.1289\n",
      "Epoch [8300/100000], Loss: 1177,   LOSS_function: 108.8,   LOSS_E:6.23e-06,    LOSS_initial: 0.5787,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 592.033772945404\n",
      "loss_compared with real:0.18555,   miu_train:0.0007622,    lossmean:-0.1289\n",
      "Epoch [8400/100000], Loss: 1176,   LOSS_function: 109.7,   LOSS_E:6.33e-06,    LOSS_initial: 0.5778,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 599.8585999011993\n",
      "loss_compared with real:0.18522,   miu_train:0.0007701,    lossmean:-0.129\n",
      "Epoch [8500/100000], Loss: 1177,   LOSS_function: 110.5,   LOSS_E:6.354e-06,    LOSS_initial: 0.5775,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 607.6555693149567\n",
      "loss_compared with real:0.18512,   miu_train:0.0007717,    lossmean:-0.1289\n",
      "Epoch [8600/100000], Loss: 1176,   LOSS_function: 110.2,   LOSS_E:6.358e-06,    LOSS_initial: 0.5772,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 615.5105767250061\n",
      "loss_compared with real:0.18502,   miu_train:0.0007725,    lossmean:-0.1289\n",
      "Epoch [8700/100000], Loss: 1175,   LOSS_function: 110.3,   LOSS_E:6.324e-06,    LOSS_initial: 0.577,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 623.3215441703796\n",
      "loss_compared with real:0.18491,   miu_train:0.0007744,    lossmean:-0.129\n",
      "Epoch [8800/100000], Loss: 1175,   LOSS_function: 110.4,   LOSS_E:6.322e-06,    LOSS_initial: 0.5767,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 631.1565420627594\n",
      "loss_compared with real:0.18489,   miu_train:0.0007738,    lossmean:-0.1289\n",
      "Epoch [8900/100000], Loss: 1175,   LOSS_function: 110.6,   LOSS_E:6.28e-06,    LOSS_initial: 0.5765,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1841,      learn rate:0.0005397,    time: 638.9711565971375\n",
      "loss_compared with real:0.18483,   miu_train:0.000774,    lossmean:-0.1288\n",
      "Epoch [9000/100000], Loss: 1178,   LOSS_function: 110.4,   LOSS_E:6.328e-06,    LOSS_initial: 0.5766,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 646.7893958091736\n",
      "loss_compared with real:0.18475,   miu_train:0.0007738,    lossmean:-0.1289\n",
      "Epoch [9100/100000], Loss: 1177,   LOSS_function: 110.8,   LOSS_E:6.299e-06,    LOSS_initial: 0.576,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 654.5938329696655\n",
      "loss_compared with real:0.18459,   miu_train:0.0007777,    lossmean:-0.1287\n",
      "Epoch [9200/100000], Loss: 1177,   LOSS_function: 111.1,   LOSS_E:6.332e-06,    LOSS_initial: 0.5756,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 662.5060489177704\n",
      "loss_compared with real:0.18447,   miu_train:0.0007793,    lossmean:-0.1287\n",
      "Epoch [9300/100000], Loss: 1176,   LOSS_function: 110.8,   LOSS_E:6.292e-06,    LOSS_initial: 0.5754,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 670.3090665340424\n",
      "loss_compared with real:0.18444,   miu_train:0.0007787,    lossmean:-0.1287\n",
      "Epoch [9400/100000], Loss: 1177,   LOSS_function: 111.4,   LOSS_E:6.289e-06,    LOSS_initial: 0.5753,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 678.0778687000275\n",
      "loss_compared with real:0.18439,   miu_train:0.0007764,    lossmean:-0.1286\n",
      "Epoch [9500/100000], Loss: 1176,   LOSS_function: 110.9,   LOSS_E:6.362e-06,    LOSS_initial: 0.575,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 685.774908542633\n",
      "loss_compared with real:0.18431,   miu_train:0.0007774,    lossmean:-0.1286\n",
      "Epoch [9600/100000], Loss: 1176,   LOSS_function: 111.2,   LOSS_E:6.237e-06,    LOSS_initial: 0.5747,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 693.6205310821533\n",
      "loss_compared with real:0.18415,   miu_train:0.0007795,    lossmean:-0.1286\n",
      "Epoch [9700/100000], Loss: 1175,   LOSS_function: 111.4,   LOSS_E:6.137e-06,    LOSS_initial: 0.5744,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 701.3567199707031\n",
      "loss_compared with real:0.18409,   miu_train:0.0007793,    lossmean:-0.1286\n",
      "Epoch [9800/100000], Loss: 1175,   LOSS_function: 111.8,   LOSS_E:6.134e-06,    LOSS_initial: 0.5739,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 709.0917208194733\n",
      "loss_compared with real:0.18396,   miu_train:0.00078,    lossmean:-0.1285\n",
      "Epoch [9900/100000], Loss: 1174,   LOSS_function: 111.5,   LOSS_E:6.17e-06,    LOSS_initial: 0.5739,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1847,      learn rate:0.0005138,    time: 716.8146433830261\n",
      "loss_compared with real:0.18386,   miu_train:0.0007796,    lossmean:-0.1285\n",
      "Epoch [10000/100000], Loss: 1188,   LOSS_function: 112,   LOSS_E:6.089e-06,    LOSS_initial: 0.5733,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 724.5500228404999\n",
      "loss_compared with real:0.18366,   miu_train:0.0007829,    lossmean:-0.1284\n",
      "Epoch [10100/100000], Loss: 1187,   LOSS_function: 114.3,   LOSS_E:6.24e-06,    LOSS_initial: 0.5718,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 732.3077709674835\n",
      "loss_compared with real:0.18319,   miu_train:0.0007946,    lossmean:-0.1281\n",
      "Epoch [10200/100000], Loss: 1186,   LOSS_function: 113.6,   LOSS_E:6.173e-06,    LOSS_initial: 0.5713,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 740.1003918647766\n",
      "loss_compared with real:0.18298,   miu_train:0.0007976,    lossmean:-0.128\n",
      "Epoch [10300/100000], Loss: 1188,   LOSS_function: 111,   LOSS_E:9.857e-06,    LOSS_initial: 0.5729,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 747.7274632453918\n",
      "loss_compared with real:0.18295,   miu_train:0.0007743,    lossmean:-0.1272\n",
      "Epoch [10400/100000], Loss: 1763,   LOSS_function: 109.5,   LOSS_E:0.00122,    LOSS_initial: 0.5795,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 754.9427514076233\n",
      "loss_compared with real:0.17553,   miu_train:0.0006982,    lossmean:-0.1236\n",
      "Epoch [10500/100000], Loss: 1185,   LOSS_function: 114.4,   LOSS_E:5.752e-06,    LOSS_initial: 0.5705,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 762.1070618629456\n",
      "loss_compared with real:0.18279,   miu_train:0.0007957,    lossmean:-0.1279\n",
      "Epoch [10600/100000], Loss: 1184,   LOSS_function: 104.1,   LOSS_E:5.47e-06,    LOSS_initial: 0.5759,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 769.3273086547852\n",
      "loss_compared with real:0.18405,   miu_train:0.0007371,    lossmean:-0.1264\n",
      "Epoch [10700/100000], Loss: 1183,   LOSS_function: 115,   LOSS_E:5.836e-06,    LOSS_initial: 0.5693,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 776.4559836387634\n",
      "loss_compared with real:0.18228,   miu_train:0.0007987,    lossmean:-0.1276\n",
      "Epoch [10800/100000], Loss: 1183,   LOSS_function: 111.2,   LOSS_E:7.004e-06,    LOSS_initial: 0.5711,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 783.7868356704712\n",
      "loss_compared with real:0.18302,   miu_train:0.0007809,    lossmean:-0.1278\n",
      "Epoch [10900/100000], Loss: 1201,   LOSS_function: 116.1,   LOSS_E:4.417e-05,    LOSS_initial: 0.5686,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1871,      learn rate:0.0004892,    time: 791.0702948570251\n",
      "loss_compared with real:0.18083,   miu_train:0.0007954,    lossmean:-0.1263\n",
      "Epoch [11000/100000], Loss: 1193,   LOSS_function: 114.1,   LOSS_E:4.859e-06,    LOSS_initial: 0.5688,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 798.3491718769073\n",
      "loss_compared with real:0.18241,   miu_train:0.0007999,    lossmean:-0.1275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11100/100000], Loss: 1191,   LOSS_function: 116.8,   LOSS_E:5.129e-06,    LOSS_initial: 0.5665,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 805.5487048625946\n",
      "loss_compared with real:0.18137,   miu_train:0.00082,    lossmean:-0.1273\n",
      "Epoch [11200/100000], Loss: 1265,   LOSS_function: 114.6,   LOSS_E:0.000169,    LOSS_initial: 0.5663,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 812.8279595375061\n",
      "loss_compared with real:0.18327,   miu_train:0.000836,    lossmean:-0.13\n",
      "Epoch [11300/100000], Loss: 1190,   LOSS_function: 117,   LOSS_E:4.66e-06,    LOSS_initial: 0.5658,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 820.0396301746368\n",
      "loss_compared with real:0.18143,   miu_train:0.0008167,    lossmean:-0.1272\n",
      "Epoch [11400/100000], Loss: 1190,   LOSS_function: 118.9,   LOSS_E:4.737e-06,    LOSS_initial: 0.5647,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 827.2459297180176\n",
      "loss_compared with real:0.18089,   miu_train:0.0008196,    lossmean:-0.1271\n",
      "Epoch [11500/100000], Loss: 1189,   LOSS_function: 112.4,   LOSS_E:6.601e-06,    LOSS_initial: 0.5675,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 834.4485204219818\n",
      "loss_compared with real:0.18215,   miu_train:0.0007945,    lossmean:-0.1272\n",
      "Epoch [11600/100000], Loss: 1188,   LOSS_function: 118.7,   LOSS_E:4.91e-06,    LOSS_initial: 0.5637,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 841.6230056285858\n",
      "loss_compared with real:0.18045,   miu_train:0.0008212,    lossmean:-0.1268\n",
      "Epoch [11700/100000], Loss: 1187,   LOSS_function: 117.6,   LOSS_E:4.934e-06,    LOSS_initial: 0.564,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 848.7278645038605\n",
      "loss_compared with real:0.18051,   miu_train:0.0008198,    lossmean:-0.1267\n",
      "Epoch [11800/100000], Loss: 1185,   LOSS_function: 118.3,   LOSS_E:4.609e-06,    LOSS_initial: 0.5628,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 856.0412249565125\n",
      "loss_compared with real:0.18,   miu_train:0.0008262,    lossmean:-0.1267\n",
      "Epoch [11900/100000], Loss: 1185,   LOSS_function: 117.6,   LOSS_E:6.261e-06,    LOSS_initial: 0.5628,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1892,      learn rate:0.0004657,    time: 863.2627687454224\n",
      "loss_compared with real:0.18005,   miu_train:0.0008228,    lossmean:-0.1268\n",
      "Epoch [12000/100000], Loss: 1201,   LOSS_function: 119.6,   LOSS_E:4.63e-06,    LOSS_initial: 0.561,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 870.61297082901\n",
      "loss_compared with real:0.17964,   miu_train:0.00084,    lossmean:-0.1269\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5425, -0.5461, -0.3174, -0.9647, -0.0899, -0.3495,  0.4522, -0.8441,\n",
      "         0.9163,  0.3199,  0.7901,  0.5350,  0.6518, -0.0415,  0.6997, -0.3227,\n",
      "         0.8753,  0.0362,  0.8121, -0.8001, -0.2920, -0.9684, -0.5141, -0.3440,\n",
      "        -0.3156, -0.4060,  0.7161, -0.6746, -0.2489,  0.4017, -0.3255, -0.1930,\n",
      "         0.1120,  0.6449, -0.7329, -0.8041, -0.7292, -0.5754, -0.2650, -0.0606,\n",
      "        -0.8362, -0.9356, -0.0713,  0.8152, -0.6155,  0.8699, -0.6775,  0.8928,\n",
      "         0.6184, -0.9479, -0.7588, -0.3783,  0.8546, -0.5904,  0.9199, -0.1207,\n",
      "        -0.8858,  0.4177, -0.2758, -0.8604,  0.8051, -0.3320,  0.2761, -0.1099,\n",
      "        -0.5497, -0.0724, -0.0375,  0.4241, -0.4338, -0.3570,  0.6130, -0.4540,\n",
      "        -0.5124,  0.8783,  0.8114, -0.4460, -0.4546,  0.0135, -0.3415, -0.5545,\n",
      "        -0.7831, -0.7389,  0.9685,  0.0054,  0.1153,  0.8237,  0.7096,  0.2459,\n",
      "        -0.0319, -0.0728,  0.6731,  0.7134, -0.6870,  0.9098,  0.2292,  0.5640,\n",
      "        -0.6539, -0.1422,  0.6095,  0.0211, -0.8510,  0.1003, -0.0036, -0.2152,\n",
      "         0.4230,  0.5105,  0.6905,  0.0513,  0.2563,  0.6651, -0.6108, -0.2658,\n",
      "         0.5959,  0.7864,  0.7582, -0.0045, -0.9621,  0.9177, -0.3164, -0.8836,\n",
      "        -0.9643,  0.9055, -0.2178,  0.3830, -0.2490,  0.4395, -0.2175,  0.1894],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.0930, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0185, -0.0317,  0.0161,  0.0852, -0.0560, -0.0356, -0.0366,  0.0294,\n",
      "        -0.0610,  0.0401, -0.0105, -0.0957,  0.0442, -0.0472,  0.0548,  0.0082,\n",
      "        -0.0255, -0.0187, -0.0283,  0.0521, -0.0641,  0.0660,  0.0178, -0.0154,\n",
      "         0.0149, -0.0063,  0.0623, -0.0379, -0.0181, -0.0645,  0.0232, -0.0749,\n",
      "         0.0849, -0.0329,  0.0574,  0.0055, -0.0502,  0.0562,  0.0493, -0.0575,\n",
      "        -0.0852, -0.0691,  0.0261,  0.0864,  0.0615,  0.0779, -0.0254,  0.0626,\n",
      "        -0.0348, -0.0185,  0.0523,  0.0148, -0.0200,  0.0036,  0.0128, -0.0019,\n",
      "         0.0506,  0.0462,  0.0574,  0.0369,  0.0060, -0.0494, -0.0289,  0.0463,\n",
      "         0.0659, -0.0055,  0.0463,  0.0342,  0.0436,  0.0183,  0.0590,  0.0047,\n",
      "        -0.0249, -0.0133, -0.0723,  0.0266, -0.0525,  0.0485, -0.0200,  0.0163,\n",
      "         0.0065, -0.0161, -0.0100,  0.0407,  0.0398, -0.0414, -0.0217, -0.0240,\n",
      "         0.0874,  0.0899,  0.0242,  0.0550, -0.0560, -0.0903,  0.0804, -0.0710,\n",
      "         0.0524,  0.0241,  0.0236,  0.0825,  0.0766,  0.0584,  0.0411,  0.0831,\n",
      "         0.0643,  0.0050, -0.0893, -0.0728,  0.0093, -0.0550,  0.0296,  0.0131,\n",
      "        -0.0503, -0.0482,  0.0009,  0.0421,  0.0584, -0.0779, -0.1040,  0.0371,\n",
      "         0.0694,  0.0259,  0.0170, -0.0196, -0.0010,  0.0138, -0.0617,  0.0754],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1099, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0508, -0.0459, -0.0419,  0.0520, -0.0364, -0.0373, -0.1117,  0.0007,\n",
      "        -0.0301,  0.0557, -0.0194, -0.0616, -0.0250,  0.0035, -0.0314, -0.0918,\n",
      "        -0.0592,  0.0586, -0.0004, -0.0776,  0.0138, -0.0242, -0.0531, -0.0209,\n",
      "         0.0228,  0.0151,  0.0593,  0.0542, -0.0560, -0.0595, -0.0364,  0.0336,\n",
      "         0.0436, -0.0333,  0.0545,  0.0543,  0.0737, -0.0063,  0.0240,  0.0855,\n",
      "        -0.0603,  0.0444,  0.0218, -0.0232,  0.0531,  0.0130, -0.0755, -0.0507,\n",
      "        -0.0186, -0.0339, -0.0711,  0.0403,  0.0725, -0.0702,  0.0623, -0.0176,\n",
      "         0.0306, -0.0667,  0.0196, -0.0734,  0.0430,  0.0597, -0.0155,  0.1073,\n",
      "         0.0760, -0.0422,  0.0024, -0.0082,  0.0114,  0.0139, -0.0797, -0.0099,\n",
      "         0.0111,  0.0438, -0.0166,  0.0328,  0.0773,  0.0229,  0.0061, -0.0014,\n",
      "         0.0801, -0.0448, -0.0833,  0.0922,  0.0166, -0.0085,  0.0239,  0.0806,\n",
      "        -0.0148, -0.0759,  0.0094, -0.0860,  0.0368, -0.0234, -0.0752,  0.0345,\n",
      "        -0.0668, -0.0645, -0.0702,  0.0729, -0.0755,  0.0245, -0.0088,  0.0304,\n",
      "        -0.0225, -0.0638,  0.0199, -0.0716, -0.0938, -0.0268, -0.0617,  0.0150,\n",
      "         0.0575, -0.1010, -0.0460, -0.0352, -0.0441, -0.0458,  0.0786, -0.0299,\n",
      "        -0.0467,  0.0493,  0.0606,  0.0780, -0.0554, -0.0796, -0.0139, -0.0516],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.0908, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0367, -0.0762,  0.0147,  0.0818, -0.0846,  0.0268, -0.0107,  0.0022,\n",
      "         0.0909,  0.0302,  0.0246,  0.0493,  0.0450, -0.0772, -0.0405,  0.0586,\n",
      "         0.0018,  0.0198, -0.0118, -0.0270,  0.0044, -0.0016,  0.0495,  0.0873,\n",
      "        -0.0044, -0.0459, -0.0087, -0.0312, -0.0014,  0.0676,  0.0068,  0.0496,\n",
      "         0.0117, -0.0225, -0.0444,  0.0446, -0.0610, -0.0922, -0.0770,  0.0030,\n",
      "         0.0857, -0.0794,  0.0271,  0.0311,  0.0661, -0.0473,  0.0863,  0.0087,\n",
      "        -0.0812, -0.0575,  0.0150, -0.0583,  0.0030,  0.0795,  0.0516,  0.0129,\n",
      "        -0.0213, -0.0570,  0.0636,  0.0363,  0.0126, -0.0701, -0.0204, -0.0313,\n",
      "         0.0129, -0.0582, -0.0471, -0.0375,  0.0433, -0.0783, -0.0643, -0.0212,\n",
      "        -0.0396,  0.0158, -0.0721, -0.0016, -0.0271, -0.0237,  0.0774, -0.0216,\n",
      "        -0.0410,  0.0703,  0.0059,  0.0351,  0.0058, -0.0722,  0.0063, -0.0423,\n",
      "         0.0070,  0.0256, -0.0250, -0.0900,  0.0720,  0.0525,  0.0033,  0.0696,\n",
      "        -0.0651, -0.0864,  0.0512, -0.0673, -0.0328,  0.0352, -0.0676, -0.0333,\n",
      "         0.0264,  0.0336,  0.0335, -0.0805,  0.0399, -0.0612,  0.0709,  0.0702,\n",
      "        -0.0576, -0.0700,  0.0555, -0.0042, -0.0986,  0.0238, -0.0345,  0.0490,\n",
      "         0.0474, -0.0462,  0.0425, -0.0914, -0.0130,  0.0424, -0.0150,  0.0500],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0804, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0200,  0.0384,  0.0653], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12100/100000], Loss: 1200,   LOSS_function: 122.2,   LOSS_E:4.816e-06,    LOSS_initial: 0.5589,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 877.907744884491\n",
      "loss_compared with real:0.17896,   miu_train:0.0008472,    lossmean:-0.1263\n",
      "Epoch [12200/100000], Loss: 1199,   LOSS_function: 122.2,   LOSS_E:4.952e-06,    LOSS_initial: 0.5581,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 885.0803172588348\n",
      "loss_compared with real:0.17905,   miu_train:0.0008563,    lossmean:-0.1261\n",
      "Epoch [12300/100000], Loss: 1197,   LOSS_function: 122.5,   LOSS_E:3.886e-06,    LOSS_initial: 0.5575,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 892.8534963130951\n",
      "loss_compared with real:0.17851,   miu_train:0.0008476,    lossmean:-0.126\n",
      "Epoch [12400/100000], Loss: 1197,   LOSS_function: 121.6,   LOSS_E:3.436e-06,    LOSS_initial: 0.5578,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 900.6340620517731\n",
      "loss_compared with real:0.17938,   miu_train:0.0008399,    lossmean:-0.1263\n",
      "Epoch [12500/100000], Loss: 1194,   LOSS_function: 123.5,   LOSS_E:3.697e-06,    LOSS_initial: 0.5556,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 908.4023928642273\n",
      "loss_compared with real:0.17795,   miu_train:0.0008522,    lossmean:-0.1257\n",
      "Epoch [12600/100000], Loss: 1196,   LOSS_function: 121,   LOSS_E:7.598e-06,    LOSS_initial: 0.5567,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 916.2359952926636\n",
      "loss_compared with real:0.17918,   miu_train:0.0008384,    lossmean:-0.1259\n",
      "Epoch [12700/100000], Loss: 1192,   LOSS_function: 124.7,   LOSS_E:3.524e-06,    LOSS_initial: 0.5537,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 924.0570967197418\n",
      "loss_compared with real:0.1774,   miu_train:0.000855,    lossmean:-0.1255\n",
      "Epoch [12800/100000], Loss: 1190,   LOSS_function: 124.4,   LOSS_E:4.679e-06,    LOSS_initial: 0.5528,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 931.8305811882019\n",
      "loss_compared with real:0.17632,   miu_train:0.0008597,    lossmean:-0.1252\n",
      "Epoch [12900/100000], Loss: 2830,   LOSS_function: 110.5,   LOSS_E:0.003524,    LOSS_initial: 0.559,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1924,      learn rate:0.0004433,    time: 939.8135125637054\n",
      "loss_compared with real:0.17755,   miu_train:0.0008977,    lossmean:-0.132\n",
      "Epoch [13000/100000], Loss: 1204,   LOSS_function: 125.4,   LOSS_E:3.153e-06,    LOSS_initial: 0.5507,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 947.6082446575165\n",
      "loss_compared with real:0.17632,   miu_train:0.0008713,    lossmean:-0.1251\n",
      "Epoch [13100/100000], Loss: 1201,   LOSS_function: 129.7,   LOSS_E:3.3e-06,    LOSS_initial: 0.547,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 955.3320095539093\n",
      "loss_compared with real:0.17519,   miu_train:0.0008894,    lossmean:-0.1245\n",
      "Epoch [13200/100000], Loss: 1302,   LOSS_function: 116.5,   LOSS_E:0.0002289,    LOSS_initial: 0.5515,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 963.2155301570892\n",
      "loss_compared with real:0.18189,   miu_train:0.0008619,    lossmean:-0.1274\n",
      "Epoch [13300/100000], Loss: 1196,   LOSS_function: 129.6,   LOSS_E:3.132e-06,    LOSS_initial: 0.5444,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 970.9882440567017\n",
      "loss_compared with real:0.17423,   miu_train:0.0008922,    lossmean:-0.1241\n",
      "Epoch [13400/100000], Loss: 1232,   LOSS_function: 129.2,   LOSS_E:8.144e-05,    LOSS_initial: 0.5446,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 978.8673267364502\n",
      "loss_compared with real:0.17188,   miu_train:0.0008634,    lossmean:-0.121\n",
      "Epoch [13500/100000], Loss: 1190,   LOSS_function: 130.2,   LOSS_E:2.948e-06,    LOSS_initial: 0.5412,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 986.6819984912872\n",
      "loss_compared with real:0.17314,   miu_train:0.0009017,    lossmean:-0.1235\n",
      "Epoch [13600/100000], Loss: 1211,   LOSS_function: 128.3,   LOSS_E:4.793e-05,    LOSS_initial: 0.5419,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 994.5130877494812\n",
      "loss_compared with real:0.17624,   miu_train:0.0008871,    lossmean:-0.1243\n",
      "Epoch [13700/100000], Loss: 1184,   LOSS_function: 132.5,   LOSS_E:2.808e-06,    LOSS_initial: 0.5367,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 1002.3734798431396\n",
      "loss_compared with real:0.17188,   miu_train:0.0009086,    lossmean:-0.1228\n",
      "Epoch [13800/100000], Loss: 1255,   LOSS_function: 134.1,   LOSS_E:0.0001539,    LOSS_initial: 0.5362,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 1010.1536462306976\n",
      "loss_compared with real:0.17752,   miu_train:0.0008465,    lossmean:-0.1232\n",
      "Epoch [13900/100000], Loss: 1176,   LOSS_function: 135.5,   LOSS_E:2.771e-06,    LOSS_initial: 0.5311,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1956,      learn rate:0.0004221,    time: 1017.9942343235016\n",
      "loss_compared with real:0.17025,   miu_train:0.0009176,    lossmean:-0.1219\n",
      "Epoch [14000/100000], Loss: 1175,   LOSS_function: 136.4,   LOSS_E:2.884e-06,    LOSS_initial: 0.5273,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1025.8721764087677\n",
      "loss_compared with real:0.16853,   miu_train:0.0009416,    lossmean:-0.1212\n",
      "Epoch [14100/100000], Loss: 3168,   LOSS_function: 154.3,   LOSS_E:0.004236,    LOSS_initial: 0.528,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1033.5622532367706\n",
      "loss_compared with real:0.15393,   miu_train:0.0008013,    lossmean:-0.1133\n",
      "Epoch [14200/100000], Loss: 1162,   LOSS_function: 144.5,   LOSS_E:2.683e-06,    LOSS_initial: 0.517,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1041.3726851940155\n",
      "loss_compared with real:0.16591,   miu_train:0.0009657,    lossmean:-0.1197\n",
      "Epoch [14300/100000], Loss: 1318,   LOSS_function: 136.2,   LOSS_E:0.0003532,    LOSS_initial: 0.5171,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1048.9335734844208\n",
      "loss_compared with real:0.16986,   miu_train:0.00101,    lossmean:-0.1202\n",
      "Epoch [14400/100000], Loss: 1147,   LOSS_function: 151.5,   LOSS_E:2.815e-06,    LOSS_initial: 0.5054,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1056.137769460678\n",
      "loss_compared with real:0.162,   miu_train:0.001026,    lossmean:-0.1177\n",
      "Epoch [14500/100000], Loss: 1179,   LOSS_function: 151.6,   LOSS_E:8.431e-05,    LOSS_initial: 0.5025,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1063.312132358551\n",
      "loss_compared with real:0.16197,   miu_train:0.001031,    lossmean:-0.1156\n",
      "Epoch [14600/100000], Loss: 1128,   LOSS_function: 166,   LOSS_E:3.165e-06,    LOSS_initial: 0.4883,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1070.5996243953705\n",
      "loss_compared with real:0.15733,   miu_train:0.001127,    lossmean:-0.1148\n",
      "Epoch [14700/100000], Loss: 1278,   LOSS_function: 164,   LOSS_E:0.0003383,    LOSS_initial: 0.4862,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1077.7812592983246\n",
      "loss_compared with real:0.1597,   miu_train:0.001135,    lossmean:-0.1136\n",
      "Epoch [14800/100000], Loss: 1116,   LOSS_function: 194.6,   LOSS_E:3.968e-06,    LOSS_initial: 0.4677,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1085.021816253662\n",
      "loss_compared with real:0.15167,   miu_train:0.001245,    lossmean:-0.1105\n",
      "Epoch [14900/100000], Loss: 1193,   LOSS_function: 201.8,   LOSS_E:0.0001658,    LOSS_initial: 0.4645,\n",
      "lamda1:1.001,    lamda2:4.664e+05,    lamda3:1966,      learn rate:0.0004018,    time: 1092.04727602005\n",
      "loss_compared with real:0.14833,   miu_train:0.001246,    lossmean:-0.1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15000/100000], Loss: 1126,   LOSS_function: 212.9,   LOSS_E:4.677e-06,    LOSS_initial: 0.4541,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1099.2677462100983\n",
      "loss_compared with real:0.1476,   miu_train:0.001394,    lossmean:-0.1078\n",
      "Epoch [15100/100000], Loss: 1125,   LOSS_function: 223.9,   LOSS_E:6.579e-06,    LOSS_initial: 0.448,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1106.4789080619812\n",
      "loss_compared with real:0.14508,   miu_train:0.001455,    lossmean:-0.1058\n",
      "Epoch [15200/100000], Loss: 1129,   LOSS_function: 222.8,   LOSS_E:1.228e-05,    LOSS_initial: 0.4491,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1113.6421689987183\n",
      "loss_compared with real:0.14442,   miu_train:0.001445,    lossmean:-0.1061\n",
      "Epoch [15300/100000], Loss: 1142,   LOSS_function: 227.2,   LOSS_E:4.295e-05,    LOSS_initial: 0.4461,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1120.7343394756317\n",
      "loss_compared with real:0.14378,   miu_train:0.001493,    lossmean:-0.1055\n",
      "Epoch [15400/100000], Loss: 1120,   LOSS_function: 228.2,   LOSS_E:5.243e-06,    LOSS_initial: 0.4437,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1127.8713660240173\n",
      "loss_compared with real:0.14413,   miu_train:0.001476,    lossmean:-0.1056\n",
      "Epoch [15500/100000], Loss: 1137,   LOSS_function: 222.3,   LOSS_E:4.545e-05,    LOSS_initial: 0.4455,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1135.1151707172394\n",
      "loss_compared with real:0.1424,   miu_train:0.001466,    lossmean:-0.1059\n",
      "Epoch [15600/100000], Loss: 1120,   LOSS_function: 229.1,   LOSS_E:5.706e-06,    LOSS_initial: 0.4432,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1142.3358352184296\n",
      "loss_compared with real:0.14267,   miu_train:0.001473,    lossmean:-0.1049\n",
      "Epoch [15700/100000], Loss: 1130,   LOSS_function: 221,   LOSS_E:3.157e-05,    LOSS_initial: 0.4462,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1149.588252067566\n",
      "loss_compared with real:0.14456,   miu_train:0.001503,    lossmean:-0.1063\n",
      "Epoch [15800/100000], Loss: 1120,   LOSS_function: 228.8,   LOSS_E:8.768e-06,    LOSS_initial: 0.4426,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1156.9532239437103\n",
      "loss_compared with real:0.14125,   miu_train:0.00153,    lossmean:-0.1049\n",
      "Epoch [15900/100000], Loss: 1117,   LOSS_function: 235.3,   LOSS_E:7.698e-06,    LOSS_initial: 0.438,\n",
      "lamda1:1,    lamda2:4.664e+05,    lamda3:2005,      learn rate:0.0003825,    time: 1164.3509275913239\n",
      "loss_compared with real:0.14342,   miu_train:0.001472,    lossmean:-0.105\n",
      "Epoch [16000/100000], Loss: 1054,   LOSS_function: 219.1,   LOSS_E:4.087e-05,    LOSS_initial: 0.4473,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1171.6162884235382\n",
      "loss_compared with real:0.14281,   miu_train:0.001356,    lossmean:-0.1047\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5414, -0.5445, -0.3163, -0.9645, -0.0896, -0.3491,  0.4516, -0.8430,\n",
      "         0.9161,  0.3197,  0.7895,  0.5343,  0.6518, -0.0406,  0.6980, -0.3220,\n",
      "         0.8750,  0.0359,  0.8109, -0.7998, -0.2922, -0.9668, -0.5134, -0.3419,\n",
      "        -0.3122, -0.4050,  0.7064, -0.6726, -0.2488,  0.4004, -0.3245, -0.1925,\n",
      "         0.1122,  0.6449, -0.7322, -0.8034, -0.7273, -0.5751, -0.2641, -0.0602,\n",
      "        -0.8356, -0.9333, -0.0702,  0.8109, -0.6154,  0.8690, -0.6765,  0.8932,\n",
      "         0.6173, -0.9482, -0.7580, -0.3778,  0.8535, -0.5873,  0.9191, -0.1209,\n",
      "        -0.8826,  0.4163, -0.2752, -0.8592,  0.8053, -0.3315,  0.2746, -0.1101,\n",
      "        -0.5498, -0.0733, -0.0360,  0.4239, -0.4334, -0.3553,  0.6112, -0.4523,\n",
      "        -0.5124,  0.8786,  0.8093, -0.4446, -0.4544,  0.0140, -0.3415, -0.5533,\n",
      "        -0.7830, -0.7384,  0.9682,  0.0055,  0.1156,  0.8229,  0.7094,  0.2452,\n",
      "        -0.0323, -0.0733,  0.6720,  0.7100, -0.6848,  0.9097,  0.2296,  0.5642,\n",
      "        -0.6533, -0.1425,  0.6096,  0.0218, -0.8526,  0.0990, -0.0046, -0.2141,\n",
      "         0.4238,  0.5063,  0.6889,  0.0519,  0.2570,  0.6639, -0.6055, -0.2648,\n",
      "         0.5933,  0.7858,  0.7555, -0.0045, -0.9622,  0.9203, -0.3163, -0.8813,\n",
      "        -0.9631,  0.9040, -0.2187,  0.3816, -0.2479,  0.4359, -0.2174,  0.1890],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.0931, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0177, -0.0301,  0.0160,  0.0860, -0.0556, -0.0348, -0.0359,  0.0293,\n",
      "        -0.0627,  0.0399, -0.0108, -0.0969,  0.0430, -0.0465,  0.0554,  0.0098,\n",
      "        -0.0240, -0.0201, -0.0292,  0.0521, -0.0643,  0.0658,  0.0200, -0.0152,\n",
      "         0.0159, -0.0054,  0.0620, -0.0389, -0.0188, -0.0655,  0.0242, -0.0761,\n",
      "         0.0866, -0.0328,  0.0576,  0.0043, -0.0513,  0.0562,  0.0488, -0.0574,\n",
      "        -0.0842, -0.0690,  0.0253,  0.0860,  0.0605,  0.0766, -0.0238,  0.0631,\n",
      "        -0.0326, -0.0204,  0.0534,  0.0119, -0.0193,  0.0036,  0.0140, -0.0004,\n",
      "         0.0503,  0.0471,  0.0578,  0.0362,  0.0056, -0.0493, -0.0308,  0.0471,\n",
      "         0.0657, -0.0032,  0.0446,  0.0323,  0.0426,  0.0169,  0.0598,  0.0026,\n",
      "        -0.0256, -0.0124, -0.0715,  0.0260, -0.0502,  0.0489, -0.0190,  0.0158,\n",
      "         0.0066, -0.0177, -0.0102,  0.0415,  0.0382, -0.0422, -0.0245, -0.0231,\n",
      "         0.0887,  0.0899,  0.0223,  0.0536, -0.0602, -0.0869,  0.0797, -0.0701,\n",
      "         0.0523,  0.0274,  0.0243,  0.0824,  0.0770,  0.0577,  0.0406,  0.0831,\n",
      "         0.0655,  0.0069, -0.0888, -0.0718,  0.0107, -0.0520,  0.0302,  0.0133,\n",
      "        -0.0536, -0.0465,  0.0002,  0.0419,  0.0580, -0.0786, -0.1060,  0.0394,\n",
      "         0.0703,  0.0250,  0.0173, -0.0205, -0.0008,  0.0150, -0.0615,  0.0754],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1099, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0507, -0.0434, -0.0421,  0.0513, -0.0346, -0.0358, -0.1120,  0.0009,\n",
      "        -0.0307,  0.0564, -0.0218, -0.0607, -0.0240,  0.0042, -0.0330, -0.0924,\n",
      "        -0.0602,  0.0586, -0.0026, -0.0767,  0.0127, -0.0241, -0.0528, -0.0196,\n",
      "         0.0231,  0.0170,  0.0572,  0.0549, -0.0541, -0.0598, -0.0384,  0.0339,\n",
      "         0.0431, -0.0339,  0.0535,  0.0545,  0.0731, -0.0077,  0.0236,  0.0850,\n",
      "        -0.0619,  0.0439,  0.0215, -0.0221,  0.0527,  0.0136, -0.0767, -0.0504,\n",
      "        -0.0163, -0.0343, -0.0698,  0.0357,  0.0725, -0.0709,  0.0622, -0.0185,\n",
      "         0.0290, -0.0684,  0.0187, -0.0740,  0.0435,  0.0586, -0.0158,  0.1066,\n",
      "         0.0745, -0.0431, -0.0002, -0.0096,  0.0033,  0.0156, -0.0763, -0.0109,\n",
      "         0.0106,  0.0449, -0.0193,  0.0326,  0.0770,  0.0239,  0.0039, -0.0008,\n",
      "         0.0804, -0.0454, -0.0826,  0.0916,  0.0176, -0.0094,  0.0235,  0.0807,\n",
      "        -0.0145, -0.0743,  0.0102, -0.0865,  0.0388, -0.0227, -0.0757,  0.0259,\n",
      "        -0.0663, -0.0654, -0.0700,  0.0732, -0.0759,  0.0259, -0.0088,  0.0325,\n",
      "        -0.0245, -0.0640,  0.0184, -0.0710, -0.0951, -0.0232, -0.0550,  0.0125,\n",
      "         0.0571, -0.1015, -0.0482, -0.0334, -0.0422, -0.0468,  0.0811, -0.0334,\n",
      "        -0.0464,  0.0468,  0.0618,  0.0779, -0.0567, -0.0792, -0.0137, -0.0511],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.0905, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0379, -0.0783,  0.0144,  0.0814, -0.0817,  0.0262, -0.0116, -0.0018,\n",
      "         0.0884,  0.0338,  0.0279,  0.0525,  0.0510, -0.0764, -0.0413,  0.0592,\n",
      "        -0.0055,  0.0199, -0.0124, -0.0260,  0.0030, -0.0010,  0.0506,  0.0989,\n",
      "        -0.0016, -0.0396, -0.0083, -0.0256, -0.0006,  0.0685,  0.0072,  0.0514,\n",
      "         0.0115, -0.0213, -0.0438,  0.0447, -0.0626, -0.0944, -0.0703,  0.0051,\n",
      "         0.0909, -0.0809,  0.0270,  0.0299,  0.0680, -0.0470,  0.0852,  0.0068,\n",
      "        -0.0816, -0.0577,  0.0142, -0.0580,  0.0019,  0.0781,  0.0477,  0.0122,\n",
      "        -0.0227, -0.0597,  0.0635,  0.0351,  0.0132, -0.0683, -0.0210, -0.0326,\n",
      "         0.0117, -0.0552, -0.0461, -0.0371,  0.0405, -0.0699, -0.0655, -0.0213,\n",
      "        -0.0400,  0.0227, -0.0698, -0.0052, -0.0298, -0.0211,  0.0794, -0.0242,\n",
      "        -0.0450,  0.0702,  0.0064,  0.0351,  0.0064, -0.0672, -0.0001, -0.0416,\n",
      "         0.0077,  0.0244, -0.0246, -0.0951,  0.0726,  0.0514,  0.0038,  0.0691,\n",
      "        -0.0593, -0.0867,  0.0510, -0.0676, -0.0344,  0.0345, -0.0669, -0.0374,\n",
      "         0.0241,  0.0342,  0.0340, -0.0814,  0.0341, -0.0647,  0.0653,  0.0696,\n",
      "        -0.0590, -0.0704,  0.0550, -0.0058, -0.0957,  0.0236, -0.0348,  0.0487,\n",
      "         0.0483, -0.0457,  0.0426, -0.0903, -0.0084,  0.0426, -0.0164,  0.0506],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0794, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0194,  0.0497,  0.0708], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16100/100000], Loss: 1037,   LOSS_function: 205.6,   LOSS_E:5.663e-06,    LOSS_initial: 0.4519,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1178.9237763881683\n",
      "loss_compared with real:0.14571,   miu_train:0.001416,    lossmean:-0.1075\n",
      "Epoch [16200/100000], Loss: 1035,   LOSS_function: 200.5,   LOSS_E:5.612e-06,    LOSS_initial: 0.4533,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1186.090383052826\n",
      "loss_compared with real:0.14563,   miu_train:0.001413,    lossmean:-0.1077\n",
      "Epoch [16300/100000], Loss: 1034,   LOSS_function: 211.7,   LOSS_E:5.459e-06,    LOSS_initial: 0.4467,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1193.7828018665314\n",
      "loss_compared with real:0.1461,   miu_train:0.00135,    lossmean:-0.1069\n",
      "Epoch [16400/100000], Loss: 1036,   LOSS_function: 194.3,   LOSS_E:6.061e-06,    LOSS_initial: 0.4573,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1201.7449550628662\n",
      "loss_compared with real:0.14328,   miu_train:0.001496,    lossmean:-0.1079\n",
      "Epoch [16500/100000], Loss: 1034,   LOSS_function: 186.9,   LOSS_E:6.343e-06,    LOSS_initial: 0.4602,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1209.6520237922668\n",
      "loss_compared with real:0.14365,   miu_train:0.001493,    lossmean:-0.1077\n",
      "Epoch [16600/100000], Loss: 1032,   LOSS_function: 193.9,   LOSS_E:6.303e-06,    LOSS_initial: 0.455,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1217.3244278430939\n",
      "loss_compared with real:0.14326,   miu_train:0.001517,    lossmean:-0.1079\n",
      "Epoch [16700/100000], Loss: 1027,   LOSS_function: 209.2,   LOSS_E:6.036e-06,    LOSS_initial: 0.4441,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1225.1474494934082\n",
      "loss_compared with real:0.14442,   miu_train:0.001375,    lossmean:-0.1064\n",
      "Epoch [16800/100000], Loss: 1698,   LOSS_function: 239.5,   LOSS_E:0.001964,    LOSS_initial: 0.4367,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1232.9228780269623\n",
      "loss_compared with real:0.14046,   miu_train:0.001254,    lossmean:-0.1055\n",
      "Epoch [16900/100000], Loss: 1021,   LOSS_function: 205.3,   LOSS_E:6.345e-06,    LOSS_initial: 0.4431,\n",
      "lamda1:1.001,    lamda2:3.343e+05,    lamda3:1836,      learn rate:0.0003642,    time: 1240.8375036716461\n",
      "loss_compared with real:0.14295,   miu_train:0.001428,    lossmean:-0.1071\n",
      "Epoch [17000/100000], Loss: 872.3,   LOSS_function: 192.9,   LOSS_E:0.0005107,    LOSS_initial: 0.4688,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1248.6426861286163\n",
      "loss_compared with real:0.14706,   miu_train:0.001303,    lossmean:-0.1087\n",
      "Epoch [17100/100000], Loss: 780.4,   LOSS_function: 124.8,   LOSS_E:5.81e-06,    LOSS_initial: 0.4932,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1256.5175013542175\n",
      "loss_compared with real:0.15958,   miu_train:0.00093,    lossmean:-0.1169\n",
      "Epoch [17200/100000], Loss: 824.1,   LOSS_function: 125.6,   LOSS_E:1.094e-05,    LOSS_initial: 0.5251,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1264.2951445579529\n",
      "loss_compared with real:0.14991,   miu_train:0.001476,    lossmean:-0.1143\n",
      "Epoch [17300/100000], Loss: 812.6,   LOSS_function: 120.8,   LOSS_E:1.076e-05,    LOSS_initial: 0.5201,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1272.1642825603485\n",
      "loss_compared with real:0.15107,   miu_train:0.001185,    lossmean:-0.1105\n",
      "Epoch [17400/100000], Loss: 773.3,   LOSS_function: 130.1,   LOSS_E:5.411e-06,    LOSS_initial: 0.4839,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1280.0584628582\n",
      "loss_compared with real:0.15612,   miu_train:0.0009118,    lossmean:-0.1146\n",
      "Epoch [17500/100000], Loss: 774.7,   LOSS_function: 121.6,   LOSS_E:6.765e-06,    LOSS_initial: 0.4912,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1287.850610256195\n",
      "loss_compared with real:0.15451,   miu_train:0.0009896,    lossmean:-0.1142\n",
      "Epoch [17600/100000], Loss: 771.8,   LOSS_function: 125.6,   LOSS_E:6.724e-06,    LOSS_initial: 0.486,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1295.6258656978607\n",
      "loss_compared with real:0.15383,   miu_train:0.00104,    lossmean:-0.1136\n",
      "Epoch [17700/100000], Loss: 767.9,   LOSS_function: 132.2,   LOSS_E:6.055e-06,    LOSS_initial: 0.4782,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1303.4043326377869\n",
      "loss_compared with real:0.15551,   miu_train:0.0008998,    lossmean:-0.1147\n",
      "Epoch [17800/100000], Loss: 764.7,   LOSS_function: 127.2,   LOSS_E:6.583e-06,    LOSS_initial: 0.4795,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1311.226956129074\n",
      "loss_compared with real:0.1534,   miu_train:0.0009173,    lossmean:-0.1138\n",
      "Epoch [17900/100000], Loss: 761.7,   LOSS_function: 134.5,   LOSS_E:6.976e-06,    LOSS_initial: 0.4717,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1328,      learn rate:0.0003467,    time: 1319.1292564868927\n",
      "loss_compared with real:0.15169,   miu_train:0.0008779,    lossmean:-0.1109\n",
      "Epoch [18000/100000], Loss: 623.1,   LOSS_function: 125.8,   LOSS_E:8.608e-06,    LOSS_initial: 0.4793,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1326.991426706314\n",
      "loss_compared with real:0.14662,   miu_train:0.000773,    lossmean:-0.1084\n",
      "Epoch [18100/100000], Loss: 621.6,   LOSS_function: 113.5,   LOSS_E:5.863e-06,    LOSS_initial: 0.49,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1334.8681993484497\n",
      "loss_compared with real:0.16638,   miu_train:0.000598,    lossmean:-0.1193\n",
      "Epoch [18200/100000], Loss: 640.1,   LOSS_function: 148,   LOSS_E:6.728e-06,    LOSS_initial: 0.4744,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1342.6307468414307\n",
      "loss_compared with real:0.16621,   miu_train:0.000634,    lossmean:-0.1166\n",
      "Epoch [18300/100000], Loss: 630.5,   LOSS_function: 135.4,   LOSS_E:6.026e-06,    LOSS_initial: 0.4774,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1350.2554733753204\n",
      "loss_compared with real:0.16737,   miu_train:0.0006199,    lossmean:-0.1184\n",
      "Epoch [18400/100000], Loss: 622.1,   LOSS_function: 95.92,   LOSS_E:9.46e-06,    LOSS_initial: 0.5071,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1357.4312961101532\n",
      "loss_compared with real:0.15147,   miu_train:0.001116,    lossmean:-0.1148\n",
      "Epoch [18500/100000], Loss: 603.7,   LOSS_function: 84.79,   LOSS_E:7.101e-06,    LOSS_initial: 0.5003,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1364.6635041236877\n",
      "loss_compared with real:0.15926,   miu_train:0.0007426,    lossmean:-0.1177\n",
      "Epoch [18600/100000], Loss: 600.8,   LOSS_function: 88.72,   LOSS_E:6.895e-06,    LOSS_initial: 0.4938,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1371.8728086948395\n",
      "loss_compared with real:0.15955,   miu_train:0.0007579,    lossmean:-0.1176\n",
      "Epoch [18700/100000], Loss: 598.1,   LOSS_function: 90.55,   LOSS_E:6.506e-06,    LOSS_initial: 0.4894,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1379.1366882324219\n",
      "loss_compared with real:0.15828,   miu_train:0.0007205,    lossmean:-0.1158\n",
      "Epoch [18800/100000], Loss: 596.3,   LOSS_function: 98.94,   LOSS_E:5.997e-06,    LOSS_initial: 0.4797,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1386.3194363117218\n",
      "loss_compared with real:0.15778,   miu_train:0.0007114,    lossmean:-0.115\n",
      "Epoch [18900/100000], Loss: 593.2,   LOSS_function: 100.3,   LOSS_E:6.031e-06,    LOSS_initial: 0.4753,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:1035,      learn rate:0.00033,    time: 1393.4916579723358\n",
      "loss_compared with real:0.15771,   miu_train:0.0007574,    lossmean:-0.1148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19000/100000], Loss: 520,   LOSS_function: 95.11,   LOSS_E:6.808e-06,    LOSS_initial: 0.4802,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1400.8045063018799\n",
      "loss_compared with real:0.14924,   miu_train:0.000656,    lossmean:-0.1125\n",
      "Epoch [19100/100000], Loss: 515,   LOSS_function: 80.62,   LOSS_E:4.721e-06,    LOSS_initial: 0.4913,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1407.9951283931732\n",
      "loss_compared with real:0.15964,   miu_train:0.0006417,    lossmean:-0.1167\n",
      "Epoch [19200/100000], Loss: 566.9,   LOSS_function: 107.4,   LOSS_E:1.027e-05,    LOSS_initial: 0.519,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1415.2194645404816\n",
      "loss_compared with real:0.14975,   miu_train:0.001437,    lossmean:-0.1125\n",
      "Epoch [19300/100000], Loss: 511.7,   LOSS_function: 79.65,   LOSS_E:8.311e-06,    LOSS_initial: 0.4881,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1422.420667886734\n",
      "loss_compared with real:0.15625,   miu_train:0.0006409,    lossmean:-0.1145\n",
      "Epoch [19400/100000], Loss: 512.5,   LOSS_function: 90.52,   LOSS_E:9.297e-06,    LOSS_initial: 0.4766,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1429.561681509018\n",
      "loss_compared with real:0.15462,   miu_train:0.0006359,    lossmean:-0.1122\n",
      "Epoch [19500/100000], Loss: 510.1,   LOSS_function: 84.31,   LOSS_E:3.684e-06,    LOSS_initial: 0.4817,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1436.8172166347504\n",
      "loss_compared with real:0.15623,   miu_train:0.0006514,    lossmean:-0.115\n",
      "Epoch [19600/100000], Loss: 521.6,   LOSS_function: 111.7,   LOSS_E:3.671e-06,    LOSS_initial: 0.4637,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1444.0102291107178\n",
      "loss_compared with real:0.15946,   miu_train:0.0006506,    lossmean:-0.1147\n",
      "Epoch [19700/100000], Loss: 606.4,   LOSS_function: 133.3,   LOSS_E:2.024e-05,    LOSS_initial: 0.533,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1451.2391736507416\n",
      "loss_compared with real:0.14681,   miu_train:0.0009785,    lossmean:-0.09803\n",
      "Epoch [19800/100000], Loss: 744.5,   LOSS_function: 109.1,   LOSS_E:0.00202,    LOSS_initial: 0.4647,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1458.557264328003\n",
      "loss_compared with real:0.1549,   miu_train:0.0006392,    lossmean:-0.1117\n",
      "Epoch [19900/100000], Loss: 519.7,   LOSS_function: 109.8,   LOSS_E:3.591e-06,    LOSS_initial: 0.4636,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:882.9,      learn rate:0.0003142,    time: 1465.903106212616\n",
      "loss_compared with real:0.15861,   miu_train:0.0006993,    lossmean:-0.1157\n",
      "Epoch [20000/100000], Loss: 448.4,   LOSS_function: 82.56,   LOSS_E:4.004e-06,    LOSS_initial: 0.4828,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1473.1489760875702\n",
      "loss_compared with real:0.1503,   miu_train:0.0006781,    lossmean:-0.1115\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5399, -0.5442, -0.3147, -0.9659, -0.0899, -0.3482,  0.4484, -0.8414,\n",
      "         0.9149,  0.3183,  0.7884,  0.5348,  0.6507, -0.0396,  0.6980, -0.3190,\n",
      "         0.8744,  0.0367,  0.8088, -0.8000, -0.2919, -0.9660, -0.5128, -0.3389,\n",
      "        -0.3089, -0.4044,  0.7049, -0.6694, -0.2485,  0.4012, -0.3232, -0.1928,\n",
      "         0.1122,  0.6434, -0.7314, -0.8038, -0.7268, -0.5735, -0.2637, -0.0594,\n",
      "        -0.8344, -0.9307, -0.0694,  0.8057, -0.6150,  0.8679, -0.6772,  0.8922,\n",
      "         0.6152, -0.9471, -0.7574, -0.3768,  0.8541, -0.5867,  0.9205, -0.1197,\n",
      "        -0.8807,  0.4155, -0.2746, -0.8583,  0.8049, -0.3305,  0.2720, -0.1097,\n",
      "        -0.5497, -0.0723, -0.0362,  0.4223, -0.4324, -0.3551,  0.6106, -0.4514,\n",
      "        -0.5110,  0.8794,  0.8081, -0.4426, -0.4566,  0.0121, -0.3410, -0.5523,\n",
      "        -0.7834, -0.7369,  0.9677,  0.0055,  0.1150,  0.8204,  0.7087,  0.2453,\n",
      "        -0.0321, -0.0727,  0.6709,  0.7081, -0.6839,  0.9097,  0.2290,  0.5634,\n",
      "        -0.6535, -0.1423,  0.6117,  0.0209, -0.8540,  0.0985, -0.0040, -0.2122,\n",
      "         0.4241,  0.5028,  0.6889,  0.0519,  0.2574,  0.6628, -0.6038, -0.2647,\n",
      "         0.5929,  0.7836,  0.7555, -0.0047, -0.9623,  0.9183, -0.3164, -0.8785,\n",
      "        -0.9613,  0.9030, -0.2194,  0.3813, -0.2470,  0.4372, -0.2166,  0.1865],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.0970, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0180, -0.0289,  0.0159,  0.0851, -0.0564, -0.0351, -0.0359,  0.0291,\n",
      "        -0.0634,  0.0404, -0.0110, -0.0955,  0.0449, -0.0452,  0.0556,  0.0077,\n",
      "        -0.0264, -0.0214, -0.0308,  0.0519, -0.0655,  0.0657,  0.0214, -0.0154,\n",
      "         0.0171, -0.0036,  0.0632, -0.0403, -0.0174, -0.0649,  0.0230, -0.0777,\n",
      "         0.0839, -0.0322,  0.0571,  0.0024, -0.0527,  0.0523,  0.0487, -0.0561,\n",
      "        -0.0838, -0.0669,  0.0251,  0.0850,  0.0585,  0.0770, -0.0145,  0.0622,\n",
      "        -0.0318, -0.0218,  0.0504,  0.0084, -0.0196,  0.0048,  0.0123,  0.0020,\n",
      "         0.0501,  0.0478,  0.0595,  0.0362,  0.0059, -0.0493, -0.0327,  0.0454,\n",
      "         0.0663,  0.0016,  0.0422,  0.0315,  0.0410,  0.0250,  0.0585,  0.0002,\n",
      "        -0.0261, -0.0119, -0.0694,  0.0257, -0.0503,  0.0484, -0.0187,  0.0162,\n",
      "         0.0060, -0.0185, -0.0107,  0.0410,  0.0378, -0.0422, -0.0201, -0.0233,\n",
      "         0.0883,  0.0896,  0.0211,  0.0557, -0.0591, -0.0858,  0.0783, -0.0690,\n",
      "         0.0520,  0.0263,  0.0259,  0.0824,  0.0777,  0.0580,  0.0410,  0.0790,\n",
      "         0.0665,  0.0082, -0.0879, -0.0712,  0.0118, -0.0526,  0.0301,  0.0138,\n",
      "        -0.0546, -0.0471, -0.0009,  0.0410,  0.0566, -0.0769, -0.1070,  0.0385,\n",
      "         0.0695,  0.0244,  0.0177, -0.0196,  0.0002,  0.0155, -0.0617,  0.0754],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1138, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0502, -0.0445, -0.0438,  0.0509, -0.0359, -0.0364, -0.1122,  0.0007,\n",
      "        -0.0309,  0.0572, -0.0208, -0.0626, -0.0228,  0.0036, -0.0320, -0.0922,\n",
      "        -0.0594,  0.0599, -0.0052, -0.0766,  0.0117, -0.0239, -0.0532, -0.0195,\n",
      "         0.0253,  0.0166,  0.0560,  0.0534, -0.0533, -0.0622, -0.0387,  0.0352,\n",
      "         0.0431, -0.0322,  0.0573,  0.0541,  0.0726, -0.0083,  0.0254,  0.0854,\n",
      "        -0.0621,  0.0445,  0.0218, -0.0206,  0.0540,  0.0133, -0.0782, -0.0503,\n",
      "        -0.0159, -0.0336, -0.0708,  0.0364,  0.0727, -0.0725,  0.0540, -0.0191,\n",
      "         0.0272, -0.0694,  0.0199, -0.0729,  0.0426,  0.0587, -0.0156,  0.1063,\n",
      "         0.0743, -0.0417, -0.0015, -0.0109,  0.0045,  0.0166, -0.0760, -0.0092,\n",
      "         0.0111,  0.0460, -0.0181,  0.0326,  0.0766,  0.0238,  0.0017, -0.0015,\n",
      "         0.0807, -0.0462, -0.0796,  0.0927,  0.0187, -0.0085,  0.0249,  0.0820,\n",
      "        -0.0152, -0.0760,  0.0118, -0.0864,  0.0394, -0.0232, -0.0745,  0.0267,\n",
      "        -0.0691, -0.0652, -0.0690,  0.0736, -0.0760,  0.0262, -0.0090,  0.0348,\n",
      "        -0.0239, -0.0630,  0.0166, -0.0712, -0.0985, -0.0220, -0.0562,  0.0135,\n",
      "         0.0589, -0.1002, -0.0493, -0.0326, -0.0420, -0.0441,  0.0797, -0.0323,\n",
      "        -0.0429,  0.0475,  0.0616,  0.0777, -0.0578, -0.0803, -0.0140, -0.0512],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.0941, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0389, -0.0779,  0.0148,  0.0804, -0.0790,  0.0274, -0.0108,  0.0022,\n",
      "         0.0848,  0.0399,  0.0380,  0.0527,  0.0468, -0.0781, -0.0415,  0.0608,\n",
      "        -0.0098,  0.0189, -0.0124, -0.0260,  0.0031, -0.0009,  0.0505,  0.0969,\n",
      "        -0.0059, -0.0493, -0.0090, -0.0201, -0.0009,  0.0695,  0.0094,  0.0494,\n",
      "         0.0109, -0.0210, -0.0445,  0.0466, -0.0578, -0.0938, -0.0741,  0.0024,\n",
      "         0.0924, -0.0813,  0.0282,  0.0318,  0.0682, -0.0475,  0.0854,  0.0072,\n",
      "        -0.0844, -0.0572,  0.0160, -0.0489,  0.0026,  0.0775,  0.0486,  0.0104,\n",
      "        -0.0240, -0.0594,  0.0628,  0.0332,  0.0139, -0.0678, -0.0220, -0.0344,\n",
      "         0.0099, -0.0524, -0.0407, -0.0353,  0.0424, -0.0767, -0.0636, -0.0213,\n",
      "        -0.0425,  0.0232, -0.0706, -0.0104, -0.0349, -0.0210,  0.0812, -0.0274,\n",
      "        -0.0455,  0.0690,  0.0057,  0.0294,  0.0088, -0.0674, -0.0008, -0.0408,\n",
      "         0.0074,  0.0237, -0.0231, -0.0934,  0.0735,  0.0517,  0.0053,  0.0693,\n",
      "        -0.0581, -0.0818,  0.0515, -0.0674, -0.0330,  0.0408, -0.0673, -0.0390,\n",
      "         0.0264,  0.0313,  0.0332, -0.0819,  0.0368, -0.0660,  0.0719,  0.0695,\n",
      "        -0.0596, -0.0691,  0.0567, -0.0058, -0.0956,  0.0221, -0.0362,  0.0487,\n",
      "         0.0474, -0.0444,  0.0427, -0.0869, -0.0044,  0.0431, -0.0154,  0.0525],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0801, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0497,  0.0510,  0.0706], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20100/100000], Loss: 449,   LOSS_function: 70.7,   LOSS_E:2.905e-06,    LOSS_initial: 0.4995,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1480.4815063476562\n",
      "loss_compared with real:0.15824,   miu_train:0.0006272,    lossmean:-0.1157\n",
      "Epoch [20200/100000], Loss: 464.7,   LOSS_function: 85.4,   LOSS_E:7.298e-05,    LOSS_initial: 0.4905,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1487.6951417922974\n",
      "loss_compared with real:0.16159,   miu_train:0.0005326,    lossmean:-0.1196\n",
      "Epoch [20300/100000], Loss: 447.5,   LOSS_function: 68.51,   LOSS_E:3.754e-06,    LOSS_initial: 0.5002,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1495.335459947586\n",
      "loss_compared with real:0.16131,   miu_train:0.0006643,    lossmean:-0.1176\n",
      "Epoch [20400/100000], Loss: 469,   LOSS_function: 109.3,   LOSS_E:7.592e-06,    LOSS_initial: 0.4742,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1503.1753633022308\n",
      "loss_compared with real:0.16389,   miu_train:0.0006144,    lossmean:-0.1158\n",
      "Epoch [20500/100000], Loss: 449.3,   LOSS_function: 69.89,   LOSS_E:3.022e-05,    LOSS_initial: 0.4969,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1510.9435999393463\n",
      "loss_compared with real:0.15937,   miu_train:0.0006246,    lossmean:-0.1165\n",
      "Epoch [20600/100000], Loss: 449.9,   LOSS_function: 70.1,   LOSS_E:1.92e-05,    LOSS_initial: 0.4991,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1518.7514896392822\n",
      "loss_compared with real:0.16101,   miu_train:0.0005938,    lossmean:-0.1169\n",
      "Epoch [20700/100000], Loss: 447,   LOSS_function: 71.75,   LOSS_E:4.254e-06,    LOSS_initial: 0.4953,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1526.4728801250458\n",
      "loss_compared with real:0.16197,   miu_train:0.000604,    lossmean:-0.118\n",
      "Epoch [20800/100000], Loss: 448.2,   LOSS_function: 76.31,   LOSS_E:3.935e-06,    LOSS_initial: 0.4909,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1534.3099427223206\n",
      "loss_compared with real:0.16024,   miu_train:0.0005767,    lossmean:-0.1164\n",
      "Epoch [20900/100000], Loss: 447.6,   LOSS_function: 65.1,   LOSS_E:2.961e-06,    LOSS_initial: 0.505,\n",
      "lamda1:1.001,    lamda2:1.113e+05,    lamda3:756.6,      learn rate:0.0002991,    time: 1542.091160774231\n",
      "loss_compared with real:0.1594,   miu_train:0.0006257,    lossmean:-0.1174\n",
      "Epoch [21000/100000], Loss: 459.4,   LOSS_function: 75.46,   LOSS_E:2.971e-05,    LOSS_initial: 0.4901,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1549.8042368888855\n",
      "loss_compared with real:0.16132,   miu_train:0.0006288,    lossmean:-0.1186\n",
      "Epoch [21100/100000], Loss: 465.3,   LOSS_function: 54.4,   LOSS_E:4.234e-06,    LOSS_initial: 0.5301,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1557.6905801296234\n",
      "loss_compared with real:0.16867,   miu_train:0.0004524,    lossmean:-0.1221\n",
      "Epoch [21200/100000], Loss: 462.7,   LOSS_function: 61.17,   LOSS_E:1.963e-06,    LOSS_initial: 0.5185,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1565.5248687267303\n",
      "loss_compared with real:0.16906,   miu_train:0.0005127,    lossmean:-0.1224\n",
      "Epoch [21300/100000], Loss: 459.2,   LOSS_function: 60.57,   LOSS_E:1.991e-06,    LOSS_initial: 0.5147,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1573.3810634613037\n",
      "loss_compared with real:0.1684,   miu_train:0.000534,    lossmean:-0.1223\n",
      "Epoch [21400/100000], Loss: 460.3,   LOSS_function: 63.82,   LOSS_E:2.003e-06,    LOSS_initial: 0.5119,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1581.132878780365\n",
      "loss_compared with real:0.16584,   miu_train:0.000529,    lossmean:-0.1209\n",
      "Epoch [21500/100000], Loss: 461.4,   LOSS_function: 67.24,   LOSS_E:2.102e-06,    LOSS_initial: 0.5089,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1589.0131928920746\n",
      "loss_compared with real:0.16548,   miu_train:0.0005378,    lossmean:-0.1205\n",
      "Epoch [21600/100000], Loss: 458.3,   LOSS_function: 65.47,   LOSS_E:1.988e-06,    LOSS_initial: 0.5072,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1596.8980107307434\n",
      "loss_compared with real:0.16546,   miu_train:0.000543,    lossmean:-0.1204\n",
      "Epoch [21700/100000], Loss: 457.3,   LOSS_function: 67.17,   LOSS_E:2.02e-06,    LOSS_initial: 0.5038,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1604.7413964271545\n",
      "loss_compared with real:0.16418,   miu_train:0.0005543,    lossmean:-0.1198\n",
      "Epoch [21800/100000], Loss: 457,   LOSS_function: 67.44,   LOSS_E:2.009e-06,    LOSS_initial: 0.503,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1612.50439286232\n",
      "loss_compared with real:0.1633,   miu_train:0.000563,    lossmean:-0.1191\n",
      "Epoch [21900/100000], Loss: 457.6,   LOSS_function: 68.89,   LOSS_E:2.011e-06,    LOSS_initial: 0.5019,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:773.7,      learn rate:0.0002848,    time: 1620.3270688056946\n",
      "loss_compared with real:0.16168,   miu_train:0.0005727,    lossmean:-0.1184\n",
      "Epoch [22000/100000], Loss: 430.2,   LOSS_function: 68.24,   LOSS_E:2.011e-06,    LOSS_initial: 0.5013,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1627.9641733169556\n",
      "loss_compared with real:0.15938,   miu_train:0.0005448,    lossmean:-0.1168\n",
      "Epoch [22100/100000], Loss: 431.7,   LOSS_function: 66.52,   LOSS_E:1.789e-06,    LOSS_initial: 0.5057,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1635.7807042598724\n",
      "loss_compared with real:0.16209,   miu_train:0.0005366,    lossmean:-0.1184\n",
      "Epoch [22200/100000], Loss: 430.3,   LOSS_function: 67.69,   LOSS_E:1.679e-06,    LOSS_initial: 0.5023,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1643.6055574417114\n",
      "loss_compared with real:0.16306,   miu_train:0.000536,    lossmean:-0.1187\n",
      "Epoch [22300/100000], Loss: 428.8,   LOSS_function: 61.31,   LOSS_E:1.726e-06,    LOSS_initial: 0.5091,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1651.3158535957336\n",
      "loss_compared with real:0.16065,   miu_train:0.0005531,    lossmean:-0.1178\n",
      "Epoch [22400/100000], Loss: 430.1,   LOSS_function: 65.89,   LOSS_E:1.624e-06,    LOSS_initial: 0.5044,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1658.439653635025\n",
      "loss_compared with real:0.16298,   miu_train:0.0005639,    lossmean:-0.1186\n",
      "Epoch [22500/100000], Loss: 429.8,   LOSS_function: 63.42,   LOSS_E:1.775e-06,    LOSS_initial: 0.5074,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1665.6730289459229\n",
      "loss_compared with real:0.16052,   miu_train:0.0005693,    lossmean:-0.1176\n",
      "Epoch [22600/100000], Loss: 431.3,   LOSS_function: 66.04,   LOSS_E:1.905e-06,    LOSS_initial: 0.5059,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1672.822536945343\n",
      "loss_compared with real:0.16133,   miu_train:0.0006065,    lossmean:-0.1178\n",
      "Epoch [22700/100000], Loss: 430.4,   LOSS_function: 66.89,   LOSS_E:1.756e-06,    LOSS_initial: 0.5035,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1680.1146535873413\n",
      "loss_compared with real:0.16187,   miu_train:0.000587,    lossmean:-0.1185\n",
      "Epoch [22800/100000], Loss: 434.1,   LOSS_function: 76.05,   LOSS_E:1.703e-06,    LOSS_initial: 0.496,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1687.308845281601\n",
      "loss_compared with real:0.16216,   miu_train:0.0005158,    lossmean:-0.117\n",
      "Epoch [22900/100000], Loss: 437.5,   LOSS_function: 90.76,   LOSS_E:4.657e-06,    LOSS_initial: 0.4795,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:721.3,      learn rate:0.0002711,    time: 1694.4933640956879\n",
      "loss_compared with real:0.16407,   miu_train:0.0005492,    lossmean:-0.1172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23000/100000], Loss: 581.5,   LOSS_function: 81.8,   LOSS_E:3.853e-06,    LOSS_initial: 0.4861,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1701.7261519432068\n",
      "loss_compared with real:0.17199,   miu_train:0.0008001,    lossmean:-0.1232\n",
      "Epoch [23100/100000], Loss: 574,   LOSS_function: 108,   LOSS_E:5.229e-06,    LOSS_initial: 0.453,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1708.8871893882751\n",
      "loss_compared with real:0.14632,   miu_train:0.0008834,    lossmean:-0.1092\n",
      "Epoch [23200/100000], Loss: 573.3,   LOSS_function: 109.9,   LOSS_E:1.315e-05,    LOSS_initial: 0.4492,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1716.1172904968262\n",
      "loss_compared with real:0.14247,   miu_train:0.0008338,    lossmean:-0.1068\n",
      "Epoch [23300/100000], Loss: 583.6,   LOSS_function: 107.4,   LOSS_E:2.781e-05,    LOSS_initial: 0.4594,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1723.3558633327484\n",
      "loss_compared with real:0.14745,   miu_train:0.001151,    lossmean:-0.1109\n",
      "Epoch [23400/100000], Loss: 578.3,   LOSS_function: 126.9,   LOSS_E:4.76e-05,    LOSS_initial: 0.4323,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1730.580065727234\n",
      "loss_compared with real:0.14181,   miu_train:0.0008929,    lossmean:-0.1066\n",
      "Epoch [23500/100000], Loss: 747,   LOSS_function: 133.2,   LOSS_E:0.001089,    LOSS_initial: 0.4305,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1738.2125418186188\n",
      "loss_compared with real:0.13995,   miu_train:0.0008446,    lossmean:-0.105\n",
      "Epoch [23600/100000], Loss: 569.9,   LOSS_function: 131.1,   LOSS_E:5.541e-06,    LOSS_initial: 0.4264,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1745.4293992519379\n",
      "loss_compared with real:0.14008,   miu_train:0.0008514,    lossmean:-0.1048\n",
      "Epoch [23700/100000], Loss: 569.8,   LOSS_function: 115.2,   LOSS_E:7.763e-06,    LOSS_initial: 0.4415,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1752.6749911308289\n",
      "loss_compared with real:0.14147,   miu_train:0.000991,    lossmean:-0.1072\n",
      "Epoch [23800/100000], Loss: 565.3,   LOSS_function: 109.9,   LOSS_E:2.774e-06,    LOSS_initial: 0.443,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1760.004230260849\n",
      "loss_compared with real:0.14052,   miu_train:0.0009609,    lossmean:-0.1063\n",
      "Epoch [23900/100000], Loss: 567.9,   LOSS_function: 104.5,   LOSS_E:2.022e-05,    LOSS_initial: 0.4482,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1027,      learn rate:0.0002581,    time: 1767.282101392746\n",
      "loss_compared with real:0.1368,   miu_train:0.001059,    lossmean:-0.1051\n",
      "Epoch [24000/100000], Loss: 589.9,   LOSS_function: 127,   LOSS_E:3.025e-06,    LOSS_initial: 0.4261,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1774.6074192523956\n",
      "loss_compared with real:0.14173,   miu_train:0.00104,    lossmean:-0.1071\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5392, -0.5428, -0.3129, -0.9646, -0.0897, -0.3474,  0.4486, -0.8405,\n",
      "         0.9145,  0.3176,  0.7873,  0.5341,  0.6504, -0.0392,  0.6968, -0.3165,\n",
      "         0.8739,  0.0366,  0.8078, -0.7996, -0.2919, -0.9653, -0.5120, -0.3382,\n",
      "        -0.3050, -0.4036,  0.7031, -0.6693, -0.2482,  0.4003, -0.3219, -0.1930,\n",
      "         0.1120,  0.6435, -0.7313, -0.8033, -0.7257, -0.5723, -0.2625, -0.0591,\n",
      "        -0.8336, -0.9282, -0.0671,  0.8031, -0.6143,  0.8670, -0.6765,  0.8914,\n",
      "         0.6140, -0.9479, -0.7573, -0.3765,  0.8536, -0.5853,  0.9205, -0.1193,\n",
      "        -0.8794,  0.4136, -0.2746, -0.8575,  0.8032, -0.3299,  0.2691, -0.1092,\n",
      "        -0.5497, -0.0723, -0.0355,  0.4217, -0.4320, -0.3547,  0.6099, -0.4503,\n",
      "        -0.5107,  0.8797,  0.8069, -0.4414, -0.4561,  0.0128, -0.3408, -0.5503,\n",
      "        -0.7831, -0.7362,  0.9674,  0.0056,  0.1149,  0.8193,  0.7080,  0.2440,\n",
      "        -0.0322, -0.0733,  0.6708,  0.7059, -0.6825,  0.9094,  0.2287,  0.5626,\n",
      "        -0.6532, -0.1422,  0.6118,  0.0212, -0.8546,  0.0977, -0.0045, -0.2106,\n",
      "         0.4245,  0.4994,  0.6883,  0.0522,  0.2573,  0.6621, -0.6017, -0.2630,\n",
      "         0.5914,  0.7833,  0.7534, -0.0045, -0.9623,  0.9181, -0.3160, -0.8773,\n",
      "        -0.9606,  0.9005, -0.2192,  0.3801, -0.2462,  0.4345, -0.2168,  0.1857],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.0977, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0179, -0.0266,  0.0165,  0.0857, -0.0560, -0.0346, -0.0352,  0.0291,\n",
      "        -0.0646,  0.0401, -0.0112, -0.0970,  0.0442, -0.0470,  0.0555,  0.0068,\n",
      "        -0.0260, -0.0216, -0.0316,  0.0522, -0.0655,  0.0653,  0.0223, -0.0157,\n",
      "         0.0175, -0.0027,  0.0643, -0.0410, -0.0177, -0.0666,  0.0236, -0.0783,\n",
      "         0.0849, -0.0319,  0.0575,  0.0028, -0.0525,  0.0556,  0.0485, -0.0550,\n",
      "        -0.0831, -0.0680,  0.0252,  0.0847,  0.0583,  0.0763, -0.0135,  0.0623,\n",
      "        -0.0298, -0.0241,  0.0487,  0.0084, -0.0192,  0.0050,  0.0111,  0.0031,\n",
      "         0.0503,  0.0488,  0.0595,  0.0355,  0.0081, -0.0497, -0.0341,  0.0463,\n",
      "         0.0662,  0.0011,  0.0408,  0.0301,  0.0407,  0.0231,  0.0592,  0.0004,\n",
      "        -0.0267, -0.0118, -0.0693,  0.0245, -0.0497,  0.0483, -0.0180,  0.0165,\n",
      "         0.0062, -0.0195, -0.0110,  0.0431,  0.0379, -0.0431, -0.0211, -0.0229,\n",
      "         0.0886,  0.0904,  0.0194,  0.0536, -0.0622, -0.0832,  0.0790, -0.0695,\n",
      "         0.0517,  0.0278,  0.0267,  0.0828,  0.0780,  0.0584,  0.0417,  0.0797,\n",
      "         0.0668,  0.0092, -0.0869, -0.0703,  0.0126, -0.0509,  0.0298,  0.0140,\n",
      "        -0.0546, -0.0455,  0.0005,  0.0414,  0.0571, -0.0761, -0.1082,  0.0400,\n",
      "         0.0690,  0.0248,  0.0179, -0.0210,  0.0011,  0.0167, -0.0611,  0.0755],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1145, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0506, -0.0442, -0.0444,  0.0502, -0.0346, -0.0356, -0.1120,  0.0010,\n",
      "        -0.0303,  0.0579, -0.0223, -0.0625, -0.0220,  0.0049, -0.0332, -0.0915,\n",
      "        -0.0597,  0.0586, -0.0079, -0.0771,  0.0115, -0.0241, -0.0541, -0.0235,\n",
      "         0.0248,  0.0175,  0.0548,  0.0536, -0.0539, -0.0623, -0.0392,  0.0359,\n",
      "         0.0431, -0.0324,  0.0581,  0.0536,  0.0726, -0.0088,  0.0237,  0.0863,\n",
      "        -0.0631,  0.0446,  0.0221, -0.0195,  0.0528,  0.0137, -0.0779, -0.0502,\n",
      "        -0.0214, -0.0346, -0.0696,  0.0362,  0.0733, -0.0724,  0.0514, -0.0194,\n",
      "         0.0251, -0.0697,  0.0199, -0.0728,  0.0425,  0.0566, -0.0164,  0.1078,\n",
      "         0.0741, -0.0383, -0.0027, -0.0123,  0.0017,  0.0171, -0.0734, -0.0102,\n",
      "         0.0110,  0.0463, -0.0187,  0.0329,  0.0768,  0.0259, -0.0040, -0.0015,\n",
      "         0.0808, -0.0466, -0.0749,  0.0921,  0.0200, -0.0086,  0.0243,  0.0827,\n",
      "        -0.0149, -0.0757,  0.0115, -0.0868,  0.0414, -0.0232, -0.0716,  0.0263,\n",
      "        -0.0650, -0.0642, -0.0685,  0.0732, -0.0767,  0.0266, -0.0089,  0.0370,\n",
      "        -0.0251, -0.0625,  0.0156, -0.0708, -0.0987, -0.0184, -0.0553,  0.0127,\n",
      "         0.0594, -0.0993, -0.0515, -0.0317, -0.0415, -0.0445,  0.0813, -0.0324,\n",
      "        -0.0431,  0.0455,  0.0620,  0.0783, -0.0585, -0.0806, -0.0145, -0.0514],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.0945, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0397, -0.0779,  0.0154,  0.0801, -0.0793,  0.0272, -0.0119, -0.0002,\n",
      "         0.0828,  0.0406,  0.0360,  0.0537,  0.0465, -0.0780, -0.0428,  0.0616,\n",
      "        -0.0112,  0.0185, -0.0129, -0.0257,  0.0029, -0.0015,  0.0512,  0.0982,\n",
      "        -0.0051, -0.0471, -0.0093, -0.0211, -0.0002,  0.0695,  0.0099,  0.0509,\n",
      "         0.0102, -0.0210, -0.0418,  0.0470, -0.0599, -0.0945, -0.0717,  0.0036,\n",
      "         0.0936, -0.0818,  0.0286,  0.0317,  0.0689, -0.0485,  0.0837,  0.0068,\n",
      "        -0.0847, -0.0579,  0.0154, -0.0496,  0.0024,  0.0774,  0.0431,  0.0103,\n",
      "        -0.0259, -0.0600,  0.0618,  0.0323,  0.0153, -0.0659, -0.0228, -0.0337,\n",
      "         0.0093, -0.0516, -0.0407, -0.0346,  0.0421, -0.0735, -0.0656, -0.0208,\n",
      "        -0.0423,  0.0248, -0.0701, -0.0171, -0.0346, -0.0202,  0.0834, -0.0268,\n",
      "        -0.0472,  0.0694,  0.0065,  0.0305,  0.0088, -0.0662, -0.0005, -0.0389,\n",
      "         0.0076,  0.0230, -0.0211, -0.0962,  0.0736,  0.0516,  0.0009,  0.0692,\n",
      "        -0.0556, -0.0815,  0.0517, -0.0657, -0.0341,  0.0389, -0.0665, -0.0395,\n",
      "         0.0249,  0.0328,  0.0330, -0.0843,  0.0351, -0.0700,  0.0685,  0.0692,\n",
      "        -0.0595, -0.0695,  0.0567, -0.0095, -0.0957,  0.0225, -0.0366,  0.0491,\n",
      "         0.0442, -0.0434,  0.0429, -0.0870, -0.0026,  0.0438, -0.0156,  0.0526],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0794, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0468,  0.0515,  0.0714], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24100/100000], Loss: 595.1,   LOSS_function: 109.1,   LOSS_E:3.676e-06,    LOSS_initial: 0.4473,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1781.902173280716\n",
      "loss_compared with real:0.13345,   miu_train:0.001132,    lossmean:-0.103\n",
      "Epoch [24200/100000], Loss: 596.9,   LOSS_function: 107.7,   LOSS_E:6.221e-05,    LOSS_initial: 0.4417,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1789.029140472412\n",
      "loss_compared with real:0.13637,   miu_train:0.001145,    lossmean:-0.1045\n",
      "Epoch [24300/100000], Loss: 600.8,   LOSS_function: 129.2,   LOSS_E:7.672e-05,    LOSS_initial: 0.4235,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1796.6403794288635\n",
      "loss_compared with real:0.13221,   miu_train:0.001078,    lossmean:-0.1017\n",
      "Epoch [24400/100000], Loss: 594.6,   LOSS_function: 133.4,   LOSS_E:4.051e-05,    LOSS_initial: 0.4191,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1804.5256307125092\n",
      "loss_compared with real:0.13962,   miu_train:0.001313,    lossmean:-0.1051\n",
      "Epoch [24500/100000], Loss: 590,   LOSS_function: 138.5,   LOSS_E:3.699e-06,    LOSS_initial: 0.4155,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1812.316645860672\n",
      "loss_compared with real:0.13231,   miu_train:0.0009656,    lossmean:-0.1019\n",
      "Epoch [24600/100000], Loss: 585.6,   LOSS_function: 149.7,   LOSS_E:3.046e-06,    LOSS_initial: 0.4012,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1820.1015048027039\n",
      "loss_compared with real:0.13218,   miu_train:0.0009025,    lossmean:-0.1007\n",
      "Epoch [24700/100000], Loss: 583.6,   LOSS_function: 156.4,   LOSS_E:6.563e-06,    LOSS_initial: 0.3926,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1827.9503257274628\n",
      "loss_compared with real:0.13377,   miu_train:0.0009622,    lossmean:-0.1032\n",
      "Epoch [24800/100000], Loss: 584.4,   LOSS_function: 127.6,   LOSS_E:3.48e-06,    LOSS_initial: 0.4204,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1835.6957318782806\n",
      "loss_compared with real:0.13222,   miu_train:0.001087,    lossmean:-0.102\n",
      "Epoch [24900/100000], Loss: 602.3,   LOSS_function: 129.6,   LOSS_E:0.0001233,    LOSS_initial: 0.4176,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1085,      learn rate:0.0002457,    time: 1843.502874135971\n",
      "loss_compared with real:0.12943,   miu_train:0.001253,    lossmean:-0.1021\n",
      "Epoch [25000/100000], Loss: 646.7,   LOSS_function: 138.7,   LOSS_E:9.831e-06,    LOSS_initial: 0.4097,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1852.3941078186035\n",
      "loss_compared with real:0.13827,   miu_train:0.001243,    lossmean:-0.1058\n",
      "Epoch [25100/100000], Loss: 636.8,   LOSS_function: 177.1,   LOSS_E:7.456e-06,    LOSS_initial: 0.3709,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1861.0034284591675\n",
      "loss_compared with real:0.12216,   miu_train:0.001249,    lossmean:-0.09654\n",
      "Epoch [25200/100000], Loss: 679.4,   LOSS_function: 218,   LOSS_E:0.0002285,    LOSS_initial: 0.3441,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1869.297443151474\n",
      "loss_compared with real:0.12034,   miu_train:0.0009937,    lossmean:-0.09447\n",
      "Epoch [25300/100000], Loss: 703.2,   LOSS_function: 188.9,   LOSS_E:0.0004188,    LOSS_initial: 0.3626,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1877.2063195705414\n",
      "loss_compared with real:0.12327,   miu_train:0.001228,    lossmean:-0.09629\n",
      "Epoch [25400/100000], Loss: 639.6,   LOSS_function: 152.5,   LOSS_E:3.583e-05,    LOSS_initial: 0.3895,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1885.060039281845\n",
      "loss_compared with real:0.1183,   miu_train:0.00126,    lossmean:-0.09461\n",
      "Epoch [25500/100000], Loss: 632.2,   LOSS_function: 168.8,   LOSS_E:5.807e-05,    LOSS_initial: 0.3675,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1892.8362703323364\n",
      "loss_compared with real:0.11692,   miu_train:0.0012,    lossmean:-0.09447\n",
      "Epoch [25600/100000], Loss: 647,   LOSS_function: 217.5,   LOSS_E:7.312e-05,    LOSS_initial: 0.3381,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1900.6905446052551\n",
      "loss_compared with real:0.11374,   miu_train:0.001043,    lossmean:-0.09002\n",
      "Epoch [25700/100000], Loss: 674.6,   LOSS_function: 218.8,   LOSS_E:0.0002321,    LOSS_initial: 0.3391,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1908.3795099258423\n",
      "loss_compared with real:0.11899,   miu_train:0.000985,    lossmean:-0.09478\n",
      "Epoch [25800/100000], Loss: 620.9,   LOSS_function: 148.9,   LOSS_E:5.125e-05,    LOSS_initial: 0.3753,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1916.1776971817017\n",
      "loss_compared with real:0.12001,   miu_train:0.001414,    lossmean:-0.09573\n",
      "Epoch [25900/100000], Loss: 971.2,   LOSS_function: 202.1,   LOSS_E:0.002255,    LOSS_initial: 0.3344,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1236,      learn rate:0.0002339,    time: 1924.0255172252655\n",
      "loss_compared with real:0.11285,   miu_train:0.001178,    lossmean:-0.08997\n",
      "Epoch [26000/100000], Loss: 581.9,   LOSS_function: 167.8,   LOSS_E:4.599e-06,    LOSS_initial: 0.3573,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1932.021339416504\n",
      "loss_compared with real:0.11347,   miu_train:0.001297,    lossmean:-0.09208\n",
      "Epoch [26100/100000], Loss: 607.2,   LOSS_function: 223.7,   LOSS_E:3.753e-06,    LOSS_initial: 0.3309,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1939.7623953819275\n",
      "loss_compared with real:0.1172,   miu_train:0.001034,    lossmean:-0.08941\n",
      "Epoch [26200/100000], Loss: 599.1,   LOSS_function: 141.4,   LOSS_E:5.651e-05,    LOSS_initial: 0.3879,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1947.518660068512\n",
      "loss_compared with real:0.11706,   miu_train:0.001521,    lossmean:-0.09459\n",
      "Epoch [26300/100000], Loss: 582.5,   LOSS_function: 197,   LOSS_E:3.515e-06,    LOSS_initial: 0.3327,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1955.1505794525146\n",
      "loss_compared with real:0.11162,   miu_train:0.001041,    lossmean:-0.08712\n",
      "Epoch [26400/100000], Loss: 575.2,   LOSS_function: 180.4,   LOSS_E:3.305e-06,    LOSS_initial: 0.3408,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1962.3838427066803\n",
      "loss_compared with real:0.11614,   miu_train:0.001186,    lossmean:-0.09158\n",
      "Epoch [26500/100000], Loss: 567.4,   LOSS_function: 200.5,   LOSS_E:8.488e-06,    LOSS_initial: 0.3159,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1969.5504431724548\n",
      "loss_compared with real:0.11078,   miu_train:0.001132,    lossmean:-0.08693\n",
      "Epoch [26600/100000], Loss: 569.6,   LOSS_function: 148.3,   LOSS_E:4.17e-06,    LOSS_initial: 0.3635,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1976.7813532352448\n",
      "loss_compared with real:0.11433,   miu_train:0.001303,    lossmean:-0.08909\n",
      "Epoch [26700/100000], Loss: 579.2,   LOSS_function: 195.7,   LOSS_E:3.877e-06,    LOSS_initial: 0.3309,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1983.9367744922638\n",
      "loss_compared with real:0.11429,   miu_train:0.001248,    lossmean:-0.08821\n",
      "Epoch [26800/100000], Loss: 568.8,   LOSS_function: 168.2,   LOSS_E:8.675e-05,    LOSS_initial: 0.3344,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1991.241027355194\n",
      "loss_compared with real:0.11294,   miu_train:0.001226,    lossmean:-0.08906\n",
      "Epoch [26900/100000], Loss: 624.6,   LOSS_function: 137.4,   LOSS_E:0.0004437,    LOSS_initial: 0.3607,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1157,      learn rate:0.0002227,    time: 1998.586843252182\n",
      "loss_compared with real:0.11489,   miu_train:0.001607,    lossmean:-0.09073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27000/100000], Loss: 623.8,   LOSS_function: 184.5,   LOSS_E:4.75e-06,    LOSS_initial: 0.3281,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2005.746387720108\n",
      "loss_compared with real:0.12368,   miu_train:0.001966,    lossmean:-0.09544\n",
      "Epoch [27100/100000], Loss: 706.4,   LOSS_function: 81.02,   LOSS_E:9.16e-06,    LOSS_initial: 0.4669,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2013.0985219478607\n",
      "loss_compared with real:0.10667,   miu_train:0.001167,    lossmean:-0.07927\n",
      "Epoch [27200/100000], Loss: 624.4,   LOSS_function: 210.6,   LOSS_E:6.823e-06,    LOSS_initial: 0.3088,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2020.211360692978\n",
      "loss_compared with real:0.10037,   miu_train:0.001409,    lossmean:-0.08099\n",
      "Epoch [27300/100000], Loss: 1027,   LOSS_function: 204.5,   LOSS_E:0.002609,    LOSS_initial: 0.3073,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2027.380581855774\n",
      "loss_compared with real:0.10291,   miu_train:0.001854,    lossmean:-0.08322\n",
      "Epoch [27400/100000], Loss: 621.6,   LOSS_function: 228.2,   LOSS_E:6.508e-06,    LOSS_initial: 0.2935,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2034.6217136383057\n",
      "loss_compared with real:0.10271,   miu_train:0.001649,    lossmean:-0.08415\n",
      "Epoch [27500/100000], Loss: 628.1,   LOSS_function: 231.8,   LOSS_E:9.811e-05,    LOSS_initial: 0.2848,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2041.8316218852997\n",
      "loss_compared with real:0.099402,   miu_train:0.00149,    lossmean:-0.07798\n",
      "Epoch [27600/100000], Loss: 627.6,   LOSS_function: 286.8,   LOSS_E:9.794e-06,    LOSS_initial: 0.2537,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2049.1088354587555\n",
      "loss_compared with real:0.10029,   miu_train:0.001396,    lossmean:-0.07844\n",
      "Epoch [27700/100000], Loss: 645.5,   LOSS_function: 290.8,   LOSS_E:0.0001755,    LOSS_initial: 0.2446,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2056.3234765529633\n",
      "loss_compared with real:0.095468,   miu_train:0.001283,    lossmean:-0.07736\n",
      "Epoch [27800/100000], Loss: 606.7,   LOSS_function: 151.1,   LOSS_E:8.184e-06,    LOSS_initial: 0.3399,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2063.7403774261475\n",
      "loss_compared with real:0.099981,   miu_train:0.001859,    lossmean:-0.07799\n",
      "Epoch [27900/100000], Loss: 618.9,   LOSS_function: 266.4,   LOSS_E:5.07e-05,    LOSS_initial: 0.2576,\n",
      "lamda1:1.001,    lamda2:1.577e+05,    lamda3:1336,      learn rate:0.000212,    time: 2071.0618391036987\n",
      "loss_compared with real:0.097208,   miu_train:0.001474,    lossmean:-0.0776\n",
      "Epoch [28000/100000], Loss: 445.9,   LOSS_function: 120.2,   LOSS_E:8.431e-05,    LOSS_initial: 0.378,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2078.3756885528564\n",
      "loss_compared with real:0.092169,   miu_train:0.0007359,    lossmean:-0.0687\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5372, -0.5412, -0.3106, -0.9653, -0.0884, -0.3454,  0.4471, -0.8389,\n",
      "         0.9129,  0.3165,  0.7853,  0.5334,  0.6494, -0.0385,  0.6957, -0.3155,\n",
      "         0.8739,  0.0365,  0.8054, -0.7980, -0.2912, -0.9635, -0.5109, -0.3357,\n",
      "        -0.3015, -0.4018,  0.7025, -0.6685, -0.2473,  0.3995, -0.3197, -0.1925,\n",
      "         0.1109,  0.6427, -0.7307, -0.8018, -0.7244, -0.5711, -0.2608, -0.0576,\n",
      "        -0.8314, -0.9215, -0.0659,  0.7979, -0.6128,  0.8656, -0.6751,  0.8903,\n",
      "         0.6103, -0.9487, -0.7577, -0.3742,  0.8544, -0.5840,  0.9206, -0.1183,\n",
      "        -0.8772,  0.4135, -0.2733, -0.8564,  0.7979, -0.3297,  0.2666, -0.1091,\n",
      "        -0.5495, -0.0722, -0.0347,  0.4200, -0.4300, -0.3538,  0.6085, -0.4484,\n",
      "        -0.5095,  0.8795,  0.8056, -0.4392, -0.4552,  0.0129, -0.3394, -0.5491,\n",
      "        -0.7826, -0.7344,  0.9659,  0.0067,  0.1150,  0.8171,  0.7068,  0.2424,\n",
      "        -0.0327, -0.0739,  0.6699,  0.7020, -0.6812,  0.9089,  0.2281,  0.5610,\n",
      "        -0.6529, -0.1421,  0.6121,  0.0215, -0.8583,  0.0971, -0.0045, -0.2085,\n",
      "         0.4248,  0.4949,  0.6883,  0.0531,  0.2573,  0.6602, -0.6006, -0.2614,\n",
      "         0.5907,  0.7811,  0.7492, -0.0042, -0.9610,  0.9166, -0.3142, -0.8747,\n",
      "        -0.9589,  0.9000, -0.2189,  0.3792, -0.2443,  0.4334, -0.2152,  0.1851],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1037, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0182, -0.0265,  0.0175,  0.0844, -0.0552, -0.0348, -0.0335,  0.0286,\n",
      "        -0.0632,  0.0399, -0.0118, -0.0976,  0.0447, -0.0478,  0.0562,  0.0056,\n",
      "        -0.0273, -0.0216, -0.0325,  0.0534, -0.0659,  0.0648,  0.0256, -0.0161,\n",
      "         0.0179, -0.0022,  0.0666, -0.0421, -0.0175, -0.0671,  0.0229, -0.0794,\n",
      "         0.0851, -0.0306,  0.0589,  0.0017, -0.0534,  0.0532,  0.0490, -0.0544,\n",
      "        -0.0828, -0.0670,  0.0249,  0.0833,  0.0587,  0.0755, -0.0122,  0.0621,\n",
      "        -0.0294, -0.0251,  0.0483,  0.0088, -0.0195,  0.0066,  0.0108,  0.0056,\n",
      "         0.0503,  0.0500,  0.0607,  0.0359,  0.0071, -0.0496, -0.0357,  0.0456,\n",
      "         0.0666,  0.0039,  0.0407,  0.0309,  0.0425,  0.0231,  0.0609,  0.0020,\n",
      "        -0.0268, -0.0139, -0.0682,  0.0247, -0.0500,  0.0482, -0.0181,  0.0176,\n",
      "         0.0068, -0.0206, -0.0109,  0.0446,  0.0386, -0.0430, -0.0214, -0.0227,\n",
      "         0.0881,  0.0906,  0.0175,  0.0511, -0.0635, -0.0814,  0.0779, -0.0691,\n",
      "         0.0547,  0.0285,  0.0269,  0.0841,  0.0794,  0.0592,  0.0409,  0.0783,\n",
      "         0.0671,  0.0127, -0.0866, -0.0706,  0.0140, -0.0489,  0.0297,  0.0142,\n",
      "        -0.0528, -0.0445,  0.0012,  0.0427,  0.0557, -0.0749, -0.1098,  0.0399,\n",
      "         0.0683,  0.0245,  0.0188, -0.0226,  0.0022,  0.0190, -0.0613,  0.0760],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1205, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0497, -0.0446, -0.0451,  0.0502, -0.0338, -0.0348, -0.1123,  0.0005,\n",
      "        -0.0303,  0.0595, -0.0240, -0.0631, -0.0199,  0.0054, -0.0350, -0.0889,\n",
      "        -0.0599,  0.0556, -0.0089, -0.0771,  0.0125, -0.0219, -0.0574, -0.0281,\n",
      "         0.0256,  0.0173,  0.0514,  0.0530, -0.0522, -0.0629, -0.0401,  0.0383,\n",
      "         0.0437, -0.0329,  0.0569,  0.0550,  0.0725, -0.0108,  0.0214,  0.0851,\n",
      "        -0.0641,  0.0457,  0.0244, -0.0184,  0.0490,  0.0135, -0.0790, -0.0539,\n",
      "        -0.0352, -0.0352, -0.0708,  0.0372,  0.0744, -0.0717,  0.0503, -0.0202,\n",
      "         0.0225, -0.0714,  0.0198, -0.0715,  0.0417,  0.0533, -0.0165,  0.1104,\n",
      "         0.0742, -0.0358, -0.0034, -0.0153,  0.0006,  0.0179, -0.0719, -0.0117,\n",
      "         0.0126,  0.0465, -0.0189,  0.0314,  0.0775,  0.0271, -0.0034, -0.0039,\n",
      "         0.0807, -0.0476, -0.0774,  0.0927,  0.0218, -0.0075,  0.0254,  0.0842,\n",
      "        -0.0156, -0.0762,  0.0107, -0.0883,  0.0432, -0.0239, -0.0738,  0.0261,\n",
      "        -0.0546, -0.0625, -0.0673,  0.0716, -0.0783,  0.0264, -0.0097,  0.0389,\n",
      "        -0.0260, -0.0608,  0.0199, -0.0714, -0.0983, -0.0211, -0.0549,  0.0135,\n",
      "         0.0595, -0.0989, -0.0538, -0.0303, -0.0418, -0.0443,  0.0832, -0.0347,\n",
      "        -0.0427,  0.0433,  0.0614,  0.0787, -0.0597, -0.0816, -0.0144, -0.0511],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1002, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0409, -0.0785,  0.0158,  0.0790, -0.0850,  0.0281, -0.0134, -0.0093,\n",
      "         0.0798,  0.0392,  0.0287,  0.0578,  0.0408, -0.0780, -0.0434,  0.0634,\n",
      "        -0.0090,  0.0194, -0.0128, -0.0254,  0.0033, -0.0016,  0.0535,  0.0971,\n",
      "        -0.0044, -0.0431, -0.0094, -0.0220, -0.0001,  0.0708,  0.0118,  0.0547,\n",
      "         0.0074, -0.0191, -0.0402,  0.0482, -0.0608, -0.0983, -0.0709,  0.0083,\n",
      "         0.0962, -0.0830,  0.0298,  0.0326,  0.0695, -0.0504,  0.0812,  0.0060,\n",
      "        -0.0857, -0.0594,  0.0147, -0.0460,  0.0038,  0.0761,  0.0329,  0.0092,\n",
      "        -0.0243, -0.0600,  0.0606,  0.0298,  0.0178, -0.0636, -0.0247, -0.0332,\n",
      "         0.0084, -0.0506, -0.0392, -0.0305,  0.0421, -0.0751, -0.0598, -0.0216,\n",
      "        -0.0421,  0.0269, -0.0707, -0.0193, -0.0346, -0.0185,  0.0848, -0.0271,\n",
      "        -0.0438,  0.0711,  0.0076,  0.0402,  0.0098, -0.0694, -0.0007, -0.0366,\n",
      "         0.0062,  0.0218, -0.0216, -0.0970,  0.0739,  0.0507, -0.0183,  0.0685,\n",
      "        -0.0563, -0.0804,  0.0522, -0.0637, -0.0362,  0.0353, -0.0664, -0.0409,\n",
      "         0.0237,  0.0332,  0.0324, -0.0867,  0.0376, -0.0682,  0.0579,  0.0694,\n",
      "        -0.0596, -0.0689,  0.0573, -0.0151, -0.0960,  0.0225, -0.0359,  0.0500,\n",
      "         0.0335, -0.0410,  0.0434, -0.0882, -0.0027,  0.0448, -0.0148,  0.0535],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0809, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0391,  0.0522,  0.0695], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28100/100000], Loss: 427.8,   LOSS_function: 119.6,   LOSS_E:7.304e-06,    LOSS_initial: 0.3711,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2085.569615125656\n",
      "loss_compared with real:0.12451,   miu_train:0.0009778,    lossmean:-0.0953\n",
      "Epoch [28200/100000], Loss: 494.3,   LOSS_function: 112.9,   LOSS_E:0.0004419,    LOSS_initial: 0.379,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2092.7781705856323\n",
      "loss_compared with real:0.12709,   miu_train:0.001034,    lossmean:-0.09694\n",
      "Epoch [28300/100000], Loss: 448,   LOSS_function: 125.8,   LOSS_E:0.0001237,    LOSS_initial: 0.3664,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2100.452127933502\n",
      "loss_compared with real:0.12107,   miu_train:0.0008667,    lossmean:-0.09503\n",
      "Epoch [28400/100000], Loss: 421.2,   LOSS_function: 101.5,   LOSS_E:6.468e-06,    LOSS_initial: 0.3852,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2108.3247170448303\n",
      "loss_compared with real:0.12115,   miu_train:0.0008993,    lossmean:-0.09444\n",
      "Epoch [28500/100000], Loss: 420.4,   LOSS_function: 101.9,   LOSS_E:7.372e-06,    LOSS_initial: 0.3836,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2116.0015988349915\n",
      "loss_compared with real:0.12574,   miu_train:0.0009801,    lossmean:-0.09591\n",
      "Epoch [28600/100000], Loss: 416.6,   LOSS_function: 110.3,   LOSS_E:6.651e-06,    LOSS_initial: 0.369,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2123.7708084583282\n",
      "loss_compared with real:0.12398,   miu_train:0.001004,    lossmean:-0.09593\n",
      "Epoch [28700/100000], Loss: 422.8,   LOSS_function: 111.5,   LOSS_E:8.016e-06,    LOSS_initial: 0.3748,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2131.7197794914246\n",
      "loss_compared with real:0.12178,   miu_train:0.0008986,    lossmean:-0.09498\n",
      "Epoch [28800/100000], Loss: 457.1,   LOSS_function: 122.6,   LOSS_E:0.0003,    LOSS_initial: 0.3486,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2139.5731761455536\n",
      "loss_compared with real:0.12469,   miu_train:0.001008,    lossmean:-0.09799\n",
      "Epoch [28900/100000], Loss: 432.6,   LOSS_function: 148.9,   LOSS_E:7.297e-06,    LOSS_initial: 0.3414,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:827.1,      learn rate:0.0002018,    time: 2147.380141735077\n",
      "loss_compared with real:0.12096,   miu_train:0.0009478,    lossmean:-0.09364\n",
      "Epoch [29000/100000], Loss: 384.5,   LOSS_function: 99.92,   LOSS_E:7.527e-06,    LOSS_initial: 0.3847,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2155.1900763511658\n",
      "loss_compared with real:0.11328,   miu_train:0.0008011,    lossmean:-0.08934\n",
      "Epoch [29100/100000], Loss: 377.9,   LOSS_function: 99.97,   LOSS_E:6.809e-06,    LOSS_initial: 0.3759,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2162.864862203598\n",
      "loss_compared with real:0.12575,   miu_train:0.0008338,    lossmean:-0.09617\n",
      "Epoch [29200/100000], Loss: 376.7,   LOSS_function: 95.97,   LOSS_E:6.217e-06,    LOSS_initial: 0.3797,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2170.6210432052612\n",
      "loss_compared with real:0.1233,   miu_train:0.0008063,    lossmean:-0.09696\n",
      "Epoch [29300/100000], Loss: 388.2,   LOSS_function: 97.9,   LOSS_E:6.799e-06,    LOSS_initial: 0.3927,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2178.405382156372\n",
      "loss_compared with real:0.12462,   miu_train:0.0008084,    lossmean:-0.09524\n",
      "Epoch [29400/100000], Loss: 385.3,   LOSS_function: 114.1,   LOSS_E:7.321e-06,    LOSS_initial: 0.3666,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2186.2160782814026\n",
      "loss_compared with real:0.12386,   miu_train:0.0008151,    lossmean:-0.09504\n",
      "Epoch [29500/100000], Loss: 381.5,   LOSS_function: 83.45,   LOSS_E:7.166e-06,    LOSS_initial: 0.4032,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2194.107202768326\n",
      "loss_compared with real:0.12218,   miu_train:0.00092,    lossmean:-0.09541\n",
      "Epoch [29600/100000], Loss: 378.8,   LOSS_function: 86.41,   LOSS_E:6.962e-06,    LOSS_initial: 0.3955,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2201.973604440689\n",
      "loss_compared with real:0.12417,   miu_train:0.0008949,    lossmean:-0.09523\n",
      "Epoch [29700/100000], Loss: 376.7,   LOSS_function: 96.26,   LOSS_E:8.138e-05,    LOSS_initial: 0.3637,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2209.804586648941\n",
      "loss_compared with real:0.12831,   miu_train:0.001172,    lossmean:-0.09709\n",
      "Epoch [29800/100000], Loss: 374.2,   LOSS_function: 114.9,   LOSS_E:3.381e-05,    LOSS_initial: 0.3449,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2217.548793077469\n",
      "loss_compared with real:0.13299,   miu_train:0.001109,    lossmean:-0.09853\n",
      "Epoch [29900/100000], Loss: 403.1,   LOSS_function: 88.09,   LOSS_E:0.000172,    LOSS_initial: 0.3918,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:736.3,      learn rate:0.0001921,    time: 2225.468852519989\n",
      "loss_compared with real:0.12095,   miu_train:0.0008075,    lossmean:-0.08944\n",
      "Epoch [30000/100000], Loss: 403.5,   LOSS_function: 113.1,   LOSS_E:5.569e-06,    LOSS_initial: 0.3599,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2233.2725439071655\n",
      "loss_compared with real:0.12603,   miu_train:0.001052,    lossmean:-0.09811\n",
      "Epoch [30100/100000], Loss: 398.4,   LOSS_function: 86.68,   LOSS_E:6.765e-06,    LOSS_initial: 0.3863,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2241.029193878174\n",
      "loss_compared with real:0.11581,   miu_train:0.0011,    lossmean:-0.09058\n",
      "Epoch [30200/100000], Loss: 409.4,   LOSS_function: 162.7,   LOSS_E:1.826e-05,    LOSS_initial: 0.3031,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2248.805302143097\n",
      "loss_compared with real:0.11066,   miu_train:0.0009548,    lossmean:-0.08558\n",
      "Epoch [30300/100000], Loss: 397.8,   LOSS_function: 135.7,   LOSS_E:6.339e-06,    LOSS_initial: 0.3246,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2256.364350795746\n",
      "loss_compared with real:0.11303,   miu_train:0.0008987,    lossmean:-0.08786\n",
      "Epoch [30400/100000], Loss: 415.7,   LOSS_function: 85.43,   LOSS_E:1.066e-05,    LOSS_initial: 0.4086,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2263.7249104976654\n",
      "loss_compared with real:0.11144,   miu_train:0.001244,    lossmean:-0.08967\n",
      "Epoch [30500/100000], Loss: 390.4,   LOSS_function: 114.3,   LOSS_E:1.31e-05,    LOSS_initial: 0.3408,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2270.8376288414\n",
      "loss_compared with real:0.11583,   miu_train:0.001198,    lossmean:-0.09244\n",
      "Epoch [30600/100000], Loss: 394.7,   LOSS_function: 83,   LOSS_E:5.506e-06,    LOSS_initial: 0.3865,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2278.10374212265\n",
      "loss_compared with real:0.12067,   miu_train:0.001853,    lossmean:-0.09463\n",
      "Epoch [30700/100000], Loss: 388.8,   LOSS_function: 101.6,   LOSS_E:1.288e-05,    LOSS_initial: 0.3546,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2285.293930530548\n",
      "loss_compared with real:0.11021,   miu_train:0.001008,    lossmean:-0.08828\n",
      "Epoch [30800/100000], Loss: 380.8,   LOSS_function: 90.56,   LOSS_E:7.343e-06,    LOSS_initial: 0.3595,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2292.5011155605316\n",
      "loss_compared with real:0.10704,   miu_train:0.001118,    lossmean:-0.08268\n",
      "Epoch [30900/100000], Loss: 385.5,   LOSS_function: 88.07,   LOSS_E:6.08e-06,    LOSS_initial: 0.3686,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:804,      learn rate:0.0001829,    time: 2299.6058950424194\n",
      "loss_compared with real:0.10464,   miu_train:0.001005,    lossmean:-0.0849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31000/100000], Loss: 573.8,   LOSS_function: 198.1,   LOSS_E:5.14e-06,    LOSS_initial: 0.2622,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2306.8379049301147\n",
      "loss_compared with real:0.1238,   miu_train:0.002563,    lossmean:-0.09406\n",
      "Epoch [31100/100000], Loss: 750,   LOSS_function: 211.4,   LOSS_E:2.449e-05,    LOSS_initial: 0.3741,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2314.0602877140045\n",
      "loss_compared with real:0.12369,   miu_train:0.001481,    lossmean:-0.09501\n",
      "Epoch [31200/100000], Loss: 754.4,   LOSS_function: 225.5,   LOSS_E:0.0002149,    LOSS_initial: 0.3469,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2321.120217561722\n",
      "loss_compared with real:0.11349,   miu_train:0.001528,    lossmean:-0.09111\n",
      "Epoch [31300/100000], Loss: 706.3,   LOSS_function: 214.5,   LOSS_E:2.375e-05,    LOSS_initial: 0.3414,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2328.449320077896\n",
      "loss_compared with real:0.11251,   miu_train:0.001635,    lossmean:-0.08877\n",
      "Epoch [31400/100000], Loss: 698.6,   LOSS_function: 210.1,   LOSS_E:2.081e-05,    LOSS_initial: 0.3394,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2335.571479320526\n",
      "loss_compared with real:0.11151,   miu_train:0.001693,    lossmean:-0.08884\n",
      "Epoch [31500/100000], Loss: 822.3,   LOSS_function: 213.6,   LOSS_E:0.000631,    LOSS_initial: 0.358,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2342.7980654239655\n",
      "loss_compared with real:0.10946,   miu_train:0.002187,    lossmean:-0.08696\n",
      "Epoch [31600/100000], Loss: 695.4,   LOSS_function: 229.5,   LOSS_E:1.861e-05,    LOSS_initial: 0.3238,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2349.9905364513397\n",
      "loss_compared with real:0.10805,   miu_train:0.001557,    lossmean:-0.08666\n",
      "Epoch [31700/100000], Loss: 693.5,   LOSS_function: 197.4,   LOSS_E:0.0001237,    LOSS_initial: 0.3337,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2357.226958990097\n",
      "loss_compared with real:0.10939,   miu_train:0.001904,    lossmean:-0.0886\n",
      "Epoch [31800/100000], Loss: 667,   LOSS_function: 212,   LOSS_E:3.642e-05,    LOSS_initial: 0.3143,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2364.447921037674\n",
      "loss_compared with real:0.11208,   miu_train:0.001569,    lossmean:-0.09032\n",
      "Epoch [31900/100000], Loss: 696.9,   LOSS_function: 181.7,   LOSS_E:5.286e-05,    LOSS_initial: 0.3547,\n",
      "lamda1:1.001,    lamda2:1.534e+05,    lamda3:1429,      learn rate:0.0001741,    time: 2371.6542687416077\n",
      "loss_compared with real:0.10427,   miu_train:0.002156,    lossmean:-0.0862\n",
      "Epoch [32000/100000], Loss: 609.4,   LOSS_function: 186.6,   LOSS_E:6.634e-05,    LOSS_initial: 0.3479,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2378.8659489154816\n",
      "loss_compared with real:0.097032,   miu_train:0.001666,    lossmean:-0.07771\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5357, -0.5404, -0.3101, -0.9665, -0.0874, -0.3429,  0.4462, -0.8378,\n",
      "         0.9118,  0.3157,  0.7836,  0.5330,  0.6486, -0.0384,  0.6941, -0.3157,\n",
      "         0.8744,  0.0360,  0.8034, -0.7944, -0.2898, -0.9617, -0.5106, -0.3343,\n",
      "        -0.3012, -0.4009,  0.7001, -0.6675, -0.2467,  0.3997, -0.3191, -0.1919,\n",
      "         0.1105,  0.6420, -0.7302, -0.7966, -0.7224, -0.5716, -0.2606, -0.0557,\n",
      "        -0.8286, -0.9134, -0.0647,  0.7919, -0.6126,  0.8632, -0.6740,  0.8886,\n",
      "         0.6076, -0.9490, -0.7573, -0.3719,  0.8542, -0.5836,  0.9206, -0.1169,\n",
      "        -0.8742,  0.4136, -0.2719, -0.8557,  0.7955, -0.3301,  0.2654, -0.1097,\n",
      "        -0.5492, -0.0722, -0.0341,  0.4183, -0.4284, -0.3536,  0.6070, -0.4478,\n",
      "        -0.5087,  0.8784,  0.8046, -0.4379, -0.4544,  0.0135, -0.3393, -0.5507,\n",
      "        -0.7795, -0.7336,  0.9638,  0.0076,  0.1148,  0.8160,  0.7062,  0.2416,\n",
      "        -0.0334, -0.0747,  0.6695,  0.6982, -0.6806,  0.9080,  0.2278,  0.5599,\n",
      "        -0.6525, -0.1424,  0.6122,  0.0219, -0.8618,  0.0948, -0.0045, -0.2072,\n",
      "         0.4252,  0.4938,  0.6881,  0.0536,  0.2581,  0.6585, -0.6004, -0.2592,\n",
      "         0.5889,  0.7783,  0.7472, -0.0039, -0.9598,  0.9130, -0.3130, -0.8729,\n",
      "        -0.9573,  0.9009, -0.2195,  0.3765, -0.2431,  0.4298, -0.2134,  0.1846],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1081, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 1.9219e-02, -2.7904e-02,  2.4865e-02,  8.2406e-02, -5.6343e-02,\n",
      "        -3.4375e-02, -3.0253e-02,  2.7855e-02, -6.1985e-02,  3.9123e-02,\n",
      "        -1.3187e-02, -9.7401e-02,  4.3324e-02, -5.0015e-02,  5.7226e-02,\n",
      "         7.9922e-03, -2.7236e-02, -2.4519e-02, -3.3961e-02,  5.1983e-02,\n",
      "        -6.6909e-02,  6.2206e-02,  2.5459e-02, -1.5659e-02,  1.8693e-02,\n",
      "        -4.4828e-05,  6.8634e-02, -4.2727e-02, -1.5587e-02, -6.8963e-02,\n",
      "         1.9935e-02, -8.0042e-02,  8.5242e-02, -3.0629e-02,  6.0881e-02,\n",
      "         9.1086e-04, -5.1819e-02,  5.2158e-02,  4.8434e-02, -4.9345e-02,\n",
      "        -8.3081e-02, -6.5230e-02,  2.5462e-02,  8.2430e-02,  6.0166e-02,\n",
      "         7.5980e-02, -1.2745e-02,  6.1938e-02, -2.7062e-02, -2.5793e-02,\n",
      "         4.6720e-02,  1.0446e-02, -2.0098e-02,  6.0856e-03,  1.1123e-02,\n",
      "         6.8007e-03,  5.1675e-02,  4.8663e-02,  6.0419e-02,  3.8138e-02,\n",
      "         3.9958e-03, -4.8334e-02, -3.7352e-02,  4.5390e-02,  6.6852e-02,\n",
      "         5.7964e-03,  4.1691e-02,  3.2515e-02,  4.3023e-02,  2.2718e-02,\n",
      "         6.1171e-02, -9.5446e-06, -2.6959e-02, -1.7655e-02, -6.8659e-02,\n",
      "         2.1486e-02, -5.1032e-02,  5.0094e-02, -1.5286e-02,  1.7399e-02,\n",
      "         7.8906e-03, -2.1888e-02, -1.1221e-02,  4.3614e-02,  3.8937e-02,\n",
      "        -4.2871e-02, -2.1877e-02, -2.1498e-02,  8.7062e-02,  9.3935e-02,\n",
      "         1.8909e-02,  4.6825e-02, -6.1300e-02, -8.0130e-02,  7.6483e-02,\n",
      "        -6.8401e-02,  5.3497e-02,  2.7952e-02,  2.6699e-02,  8.3949e-02,\n",
      "         8.0080e-02,  5.9390e-02,  4.4110e-02,  7.5168e-02,  6.8766e-02,\n",
      "         1.4209e-02, -8.5935e-02, -6.9254e-02,  1.6126e-02, -4.6647e-02,\n",
      "         2.9215e-02,  1.4064e-02, -5.2044e-02, -4.3891e-02, -1.0523e-03,\n",
      "         4.3512e-02,  5.5733e-02, -7.5717e-02, -1.1296e-01,  3.8342e-02,\n",
      "         6.4633e-02,  2.4973e-02,  1.9947e-02, -2.2405e-02,  2.9461e-03,\n",
      "         2.3377e-02, -6.0226e-02,  7.6097e-02], requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1249, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0484, -0.0512, -0.0484,  0.0521, -0.0308, -0.0345, -0.1128,  0.0015,\n",
      "        -0.0293,  0.0601, -0.0271, -0.0660, -0.0184,  0.0054, -0.0346, -0.0872,\n",
      "        -0.0603,  0.0544, -0.0090, -0.0804,  0.0131, -0.0216, -0.0550, -0.0285,\n",
      "         0.0244,  0.0192,  0.0492,  0.0569, -0.0520, -0.0668, -0.0408,  0.0402,\n",
      "         0.0443, -0.0326,  0.0579,  0.0536,  0.0704, -0.0140,  0.0198,  0.0851,\n",
      "        -0.0625,  0.0445,  0.0273, -0.0220,  0.0468,  0.0134, -0.0818, -0.0583,\n",
      "        -0.0345, -0.0369, -0.0721,  0.0377,  0.0679, -0.0714,  0.0513, -0.0202,\n",
      "         0.0233, -0.0683,  0.0200, -0.0710,  0.0418,  0.0521, -0.0148,  0.1113,\n",
      "         0.0742, -0.0371, -0.0023, -0.0157,  0.0008,  0.0182, -0.0753, -0.0094,\n",
      "         0.0142,  0.0453, -0.0183,  0.0285,  0.0767,  0.0278, -0.0035, -0.0059,\n",
      "         0.0800, -0.0475, -0.0782,  0.0921,  0.0227, -0.0064,  0.0258,  0.0840,\n",
      "        -0.0156, -0.0799,  0.0116, -0.0892,  0.0419, -0.0176, -0.0761,  0.0236,\n",
      "        -0.0584, -0.0616, -0.0672,  0.0692, -0.0794,  0.0271, -0.0109,  0.0392,\n",
      "        -0.0258, -0.0600,  0.0220, -0.0709, -0.0969, -0.0216, -0.0558,  0.0135,\n",
      "         0.0609, -0.1071, -0.0547, -0.0312, -0.0432, -0.0441,  0.0847, -0.0353,\n",
      "        -0.0422,  0.0440,  0.0621,  0.0796, -0.0590, -0.0821, -0.0141, -0.0529],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1042, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0402, -0.0798,  0.0161,  0.0792, -0.0829,  0.0284, -0.0120, -0.0134,\n",
      "         0.0781,  0.0353,  0.0223,  0.0602,  0.0219, -0.0738, -0.0460,  0.0619,\n",
      "        -0.0040,  0.0198, -0.0128, -0.0250,  0.0029, -0.0013,  0.0529,  0.0937,\n",
      "        -0.0019, -0.0356, -0.0091, -0.0208, -0.0009,  0.0680,  0.0107,  0.0606,\n",
      "         0.0057, -0.0136, -0.0438,  0.0475, -0.0593, -0.1046, -0.0742,  0.0078,\n",
      "         0.0991, -0.0843,  0.0309,  0.0336,  0.0712, -0.0523,  0.0792,  0.0065,\n",
      "        -0.0855, -0.0597,  0.0160, -0.0332,  0.0041,  0.0738,  0.0326,  0.0095,\n",
      "        -0.0250, -0.0592,  0.0597,  0.0299,  0.0183, -0.0616, -0.0270, -0.0357,\n",
      "         0.0088, -0.0508, -0.0392, -0.0295,  0.0411, -0.0807, -0.0560, -0.0259,\n",
      "        -0.0435,  0.0290, -0.0706, -0.0183, -0.0331, -0.0175,  0.0856, -0.0266,\n",
      "        -0.0422,  0.0711,  0.0059,  0.0444,  0.0104, -0.0635, -0.0016, -0.0367,\n",
      "         0.0040,  0.0206, -0.0204, -0.0933,  0.0733,  0.0478, -0.0189,  0.0684,\n",
      "        -0.0565, -0.0804,  0.0516, -0.0602, -0.0388,  0.0333, -0.0679, -0.0405,\n",
      "         0.0237,  0.0331,  0.0301, -0.0869,  0.0393, -0.0672,  0.0599,  0.0691,\n",
      "        -0.0597, -0.0683,  0.0572, -0.0117, -0.0971,  0.0242, -0.0357,  0.0500,\n",
      "         0.0333, -0.0399,  0.0442, -0.0913, -0.0052,  0.0451, -0.0127,  0.0537],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0805, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0329,  0.0518,  0.0678], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32100/100000], Loss: 598.5,   LOSS_function: 143.4,   LOSS_E:1.111e-05,    LOSS_initial: 0.3855,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2386.093681335449\n",
      "loss_compared with real:0.12437,   miu_train:0.001168,    lossmean:-0.09815\n",
      "Epoch [32200/100000], Loss: 591.2,   LOSS_function: 145.3,   LOSS_E:1.013e-05,    LOSS_initial: 0.3778,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2393.5379042625427\n",
      "loss_compared with real:0.12272,   miu_train:0.001213,    lossmean:-0.09695\n",
      "Epoch [32300/100000], Loss: 589.7,   LOSS_function: 153.4,   LOSS_E:1.01e-05,    LOSS_initial: 0.3697,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2401.3483426570892\n",
      "loss_compared with real:0.12242,   miu_train:0.00124,    lossmean:-0.09671\n",
      "Epoch [32400/100000], Loss: 590.2,   LOSS_function: 161.3,   LOSS_E:1.007e-05,    LOSS_initial: 0.3633,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2409.191234111786\n",
      "loss_compared with real:0.1198,   miu_train:0.00123,    lossmean:-0.09502\n",
      "Epoch [32500/100000], Loss: 580.5,   LOSS_function: 150.6,   LOSS_E:9.54e-06,    LOSS_initial: 0.3643,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2416.9592928886414\n",
      "loss_compared with real:0.11814,   miu_train:0.001225,    lossmean:-0.09382\n",
      "Epoch [32600/100000], Loss: 574.1,   LOSS_function: 151.7,   LOSS_E:9.024e-06,    LOSS_initial: 0.358,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2424.8789649009705\n",
      "loss_compared with real:0.11692,   miu_train:0.001286,    lossmean:-0.09329\n",
      "Epoch [32700/100000], Loss: 574.7,   LOSS_function: 154.9,   LOSS_E:8.21e-06,    LOSS_initial: 0.3559,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2432.7402708530426\n",
      "loss_compared with real:0.1148,   miu_train:0.001247,    lossmean:-0.09213\n",
      "Epoch [32800/100000], Loss: 570.7,   LOSS_function: 160.8,   LOSS_E:7.578e-06,    LOSS_initial: 0.3476,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2440.4989829063416\n",
      "loss_compared with real:0.11409,   miu_train:0.001316,    lossmean:-0.09162\n",
      "Epoch [32900/100000], Loss: 561.1,   LOSS_function: 155.4,   LOSS_E:7.081e-06,    LOSS_initial: 0.3442,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1174,      learn rate:0.0001658,    time: 2448.297848701477\n",
      "loss_compared with real:0.11177,   miu_train:0.001382,    lossmean:-0.09023\n",
      "Epoch [33000/100000], Loss: 593.4,   LOSS_function: 170.3,   LOSS_E:5.606e-06,    LOSS_initial: 0.3325,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2456.215206861496\n",
      "loss_compared with real:0.11134,   miu_train:0.001481,    lossmean:-0.08987\n",
      "Epoch [33100/100000], Loss: 589.3,   LOSS_function: 181.2,   LOSS_E:6.474e-06,    LOSS_initial: 0.3205,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2464.0669507980347\n",
      "loss_compared with real:0.10418,   miu_train:0.001546,    lossmean:-0.08514\n",
      "Epoch [33200/100000], Loss: 602,   LOSS_function: 168.2,   LOSS_E:9.893e-06,    LOSS_initial: 0.3402,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2472.0134694576263\n",
      "loss_compared with real:0.10315,   miu_train:0.001736,    lossmean:-0.08475\n",
      "Epoch [33300/100000], Loss: 595,   LOSS_function: 206.6,   LOSS_E:5.309e-06,    LOSS_initial: 0.3052,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2479.8221156597137\n",
      "loss_compared with real:0.10241,   miu_train:0.001501,    lossmean:-0.08314\n",
      "Epoch [33400/100000], Loss: 594.8,   LOSS_function: 184.4,   LOSS_E:6.003e-06,    LOSS_initial: 0.3224,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2487.592132806778\n",
      "loss_compared with real:0.10238,   miu_train:0.001618,    lossmean:-0.08378\n",
      "Epoch [33500/100000], Loss: 600.5,   LOSS_function: 178.6,   LOSS_E:1.526e-05,    LOSS_initial: 0.3299,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2495.391947031021\n",
      "loss_compared with real:0.10217,   miu_train:0.001785,    lossmean:-0.08395\n",
      "Epoch [33600/100000], Loss: 596.5,   LOSS_function: 227.1,   LOSS_E:6.678e-06,    LOSS_initial: 0.29,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2503.254402399063\n",
      "loss_compared with real:0.10098,   miu_train:0.001509,    lossmean:-0.08293\n",
      "Epoch [33700/100000], Loss: 578.8,   LOSS_function: 182.6,   LOSS_E:5.513e-06,    LOSS_initial: 0.3113,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2511.0680491924286\n",
      "loss_compared with real:0.1014,   miu_train:0.0016,    lossmean:-0.08303\n",
      "Epoch [33800/100000], Loss: 588.9,   LOSS_function: 156.5,   LOSS_E:1.445e-05,    LOSS_initial: 0.3384,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2518.9120404720306\n",
      "loss_compared with real:0.10117,   miu_train:0.001731,    lossmean:-0.08329\n",
      "Epoch [33900/100000], Loss: 591.7,   LOSS_function: 184.2,   LOSS_E:8.294e-06,    LOSS_initial: 0.3198,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:1268,      learn rate:0.0001578,    time: 2526.8895919322968\n",
      "loss_compared with real:0.10349,   miu_train:0.001829,    lossmean:-0.08534\n",
      "Epoch [34000/100000], Loss: 495.8,   LOSS_function: 174.7,   LOSS_E:9.447e-06,    LOSS_initial: 0.3263,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2534.8740060329437\n",
      "loss_compared with real:0.09722,   miu_train:0.001359,    lossmean:-0.08057\n",
      "Epoch [34100/100000], Loss: 495.7,   LOSS_function: 152.4,   LOSS_E:5.162e-06,    LOSS_initial: 0.3499,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2542.7635045051575\n",
      "loss_compared with real:0.11503,   miu_train:0.001198,    lossmean:-0.09079\n",
      "Epoch [34200/100000], Loss: 491.9,   LOSS_function: 156.4,   LOSS_E:4.9e-06,    LOSS_initial: 0.3419,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2550.597147464752\n",
      "loss_compared with real:0.11469,   miu_train:0.00123,    lossmean:-0.09107\n",
      "Epoch [34300/100000], Loss: 511.2,   LOSS_function: 183,   LOSS_E:1.484e-05,    LOSS_initial: 0.3324,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2558.193403482437\n",
      "loss_compared with real:0.1139,   miu_train:0.00112,    lossmean:-0.08992\n",
      "Epoch [34400/100000], Loss: 481.3,   LOSS_function: 142.7,   LOSS_E:1.737e-05,    LOSS_initial: 0.3425,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2565.4009687900543\n",
      "loss_compared with real:0.11488,   miu_train:0.001243,    lossmean:-0.08989\n",
      "Epoch [34500/100000], Loss: 490.1,   LOSS_function: 136.5,   LOSS_E:1.353e-05,    LOSS_initial: 0.3586,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2572.525856733322\n",
      "loss_compared with real:0.11438,   miu_train:0.001228,    lossmean:-0.09088\n",
      "Epoch [34600/100000], Loss: 488,   LOSS_function: 137,   LOSS_E:8.461e-06,    LOSS_initial: 0.3571,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2579.725496530533\n",
      "loss_compared with real:0.11514,   miu_train:0.001178,    lossmean:-0.09103\n",
      "Epoch [34700/100000], Loss: 488.8,   LOSS_function: 136,   LOSS_E:2.515e-05,    LOSS_initial: 0.3553,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2587.0120289325714\n",
      "loss_compared with real:0.11598,   miu_train:0.00113,    lossmean:-0.09019\n",
      "Epoch [34800/100000], Loss: 490,   LOSS_function: 138.5,   LOSS_E:5.965e-06,    LOSS_initial: 0.3581,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2594.20428442955\n",
      "loss_compared with real:0.11682,   miu_train:0.001212,    lossmean:-0.093\n",
      "Epoch [34900/100000], Loss: 484,   LOSS_function: 131.7,   LOSS_E:4.532e-06,    LOSS_initial: 0.3593,\n",
      "lamda1:1.001,    lamda2:2.141e+05,    lamda3:977.5,      learn rate:0.0001502,    time: 2601.3527026176453\n",
      "loss_compared with real:0.11582,   miu_train:0.001257,    lossmean:-0.09188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35000/100000], Loss: 528.7,   LOSS_function: 131.6,   LOSS_E:2.294e-05,    LOSS_initial: 0.353,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2608.6561136245728\n",
      "loss_compared with real:0.1184,   miu_train:0.001386,    lossmean:-0.09403\n",
      "Epoch [35100/100000], Loss: 568.1,   LOSS_function: 132.9,   LOSS_E:8.046e-06,    LOSS_initial: 0.3926,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2615.906801700592\n",
      "loss_compared with real:0.13505,   miu_train:0.001133,    lossmean:-0.09829\n",
      "Epoch [35200/100000], Loss: 557.3,   LOSS_function: 130,   LOSS_E:7.243e-06,    LOSS_initial: 0.3857,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2622.998293876648\n",
      "loss_compared with real:0.12632,   miu_train:0.001132,    lossmean:-0.1004\n",
      "Epoch [35300/100000], Loss: 559,   LOSS_function: 135.5,   LOSS_E:7.779e-06,    LOSS_initial: 0.382,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2630.138157606125\n",
      "loss_compared with real:0.12473,   miu_train:0.001143,    lossmean:-0.09933\n",
      "Epoch [35400/100000], Loss: 554.2,   LOSS_function: 132.9,   LOSS_E:8.082e-06,    LOSS_initial: 0.38,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2637.378014564514\n",
      "loss_compared with real:0.12348,   miu_train:0.001155,    lossmean:-0.09819\n",
      "Epoch [35500/100000], Loss: 550.2,   LOSS_function: 135.2,   LOSS_E:8.198e-06,    LOSS_initial: 0.3742,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2644.5669655799866\n",
      "loss_compared with real:0.12181,   miu_train:0.001178,    lossmean:-0.09711\n",
      "Epoch [35600/100000], Loss: 547.4,   LOSS_function: 136.9,   LOSS_E:8.157e-06,    LOSS_initial: 0.3701,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2651.9207649230957\n",
      "loss_compared with real:0.12102,   miu_train:0.001194,    lossmean:-0.09663\n",
      "Epoch [35700/100000], Loss: 545.8,   LOSS_function: 135.5,   LOSS_E:8.17e-06,    LOSS_initial: 0.37,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2659.44411945343\n",
      "loss_compared with real:0.11993,   miu_train:0.001194,    lossmean:-0.09572\n",
      "Epoch [35800/100000], Loss: 545.5,   LOSS_function: 141,   LOSS_E:7.812e-06,    LOSS_initial: 0.3648,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2666.696856021881\n",
      "loss_compared with real:0.11955,   miu_train:0.001201,    lossmean:-0.09544\n",
      "Epoch [35900/100000], Loss: 542,   LOSS_function: 141.6,   LOSS_E:7.542e-06,    LOSS_initial: 0.3611,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1101,      learn rate:0.000143,    time: 2673.835289478302\n",
      "loss_compared with real:0.1188,   miu_train:0.001222,    lossmean:-0.0947\n",
      "Epoch [36000/100000], Loss: 582.5,   LOSS_function: 148.1,   LOSS_E:6.794e-06,    LOSS_initial: 0.3572,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2681.146418094635\n",
      "loss_compared with real:0.11687,   miu_train:0.001273,    lossmean:-0.09367\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5352, -0.5403, -0.3091, -0.9663, -0.0874, -0.3429,  0.4462, -0.8372,\n",
      "         0.9116,  0.3156,  0.7828,  0.5327,  0.6486, -0.0381,  0.6931, -0.3149,\n",
      "         0.8744,  0.0360,  0.8027, -0.7942, -0.2897, -0.9610, -0.5100, -0.3339,\n",
      "        -0.3013, -0.4007,  0.6980, -0.6670, -0.2465,  0.3986, -0.3188, -0.1913,\n",
      "         0.1103,  0.6419, -0.7296, -0.7957, -0.7218, -0.5711, -0.2605, -0.0549,\n",
      "        -0.8284, -0.9122, -0.0646,  0.7912, -0.6117,  0.8626, -0.6733,  0.8877,\n",
      "         0.6060, -0.9496, -0.7569, -0.3720,  0.8532, -0.5821,  0.9204, -0.1164,\n",
      "        -0.8728,  0.4137, -0.2720, -0.8549,  0.7938, -0.3300,  0.2657, -0.1095,\n",
      "        -0.5485, -0.0718, -0.0343,  0.4177, -0.4277, -0.3530,  0.6067, -0.4481,\n",
      "        -0.5084,  0.8779,  0.8035, -0.4377, -0.4544,  0.0131, -0.3390, -0.5498,\n",
      "        -0.7817, -0.7332,  0.9634,  0.0077,  0.1146,  0.8153,  0.7059,  0.2414,\n",
      "        -0.0330, -0.0751,  0.6688,  0.6971, -0.6803,  0.9075,  0.2274,  0.5593,\n",
      "        -0.6522, -0.1419,  0.6101,  0.0219, -0.8615,  0.0940, -0.0042, -0.2060,\n",
      "         0.4248,  0.4936,  0.6877,  0.0533,  0.2581,  0.6579, -0.6003, -0.2588,\n",
      "         0.5888,  0.7781,  0.7459, -0.0038, -0.9591,  0.9114, -0.3127, -0.8720,\n",
      "        -0.9570,  0.8997, -0.2195,  0.3752, -0.2429,  0.4284, -0.2131,  0.1846],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1065, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0189, -0.0286,  0.0252,  0.0828, -0.0557, -0.0338, -0.0299,  0.0281,\n",
      "        -0.0608,  0.0381, -0.0129, -0.0982,  0.0432, -0.0492,  0.0572,  0.0083,\n",
      "        -0.0282, -0.0245, -0.0333,  0.0513, -0.0669,  0.0626,  0.0251, -0.0153,\n",
      "         0.0187, -0.0002,  0.0694, -0.0432, -0.0157, -0.0697,  0.0197, -0.0805,\n",
      "         0.0852, -0.0306,  0.0597,  0.0012, -0.0515,  0.0520,  0.0485, -0.0480,\n",
      "        -0.0804, -0.0653,  0.0255,  0.0822,  0.0604,  0.0755, -0.0141,  0.0615,\n",
      "        -0.0275, -0.0257,  0.0469,  0.0109, -0.0205,  0.0056,  0.0101,  0.0069,\n",
      "         0.0515,  0.0485,  0.0603,  0.0374,  0.0044, -0.0475, -0.0380,  0.0455,\n",
      "         0.0666,  0.0055,  0.0420,  0.0313,  0.0429,  0.0230,  0.0610,  0.0009,\n",
      "        -0.0283, -0.0180, -0.0685,  0.0213, -0.0499,  0.0500, -0.0124,  0.0172,\n",
      "         0.0078, -0.0220, -0.0119,  0.0445,  0.0395, -0.0420, -0.0213, -0.0214,\n",
      "         0.0866,  0.0947,  0.0182,  0.0454, -0.0607, -0.0807,  0.0762, -0.0681,\n",
      "         0.0508,  0.0279,  0.0271,  0.0836,  0.0794,  0.0592,  0.0431,  0.0764,\n",
      "         0.0692,  0.0138, -0.0859, -0.0687,  0.0173, -0.0476,  0.0297,  0.0149,\n",
      "        -0.0520, -0.0434, -0.0006,  0.0429,  0.0565, -0.0755, -0.1131,  0.0384,\n",
      "         0.0639,  0.0246,  0.0206, -0.0235,  0.0033,  0.0230, -0.0596,  0.0758],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1234, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0485, -0.0515, -0.0489,  0.0518, -0.0300, -0.0341, -0.1121,  0.0030,\n",
      "        -0.0288,  0.0607, -0.0297, -0.0671, -0.0198,  0.0044, -0.0355, -0.0875,\n",
      "        -0.0602,  0.0548, -0.0094, -0.0816,  0.0127, -0.0222, -0.0547, -0.0295,\n",
      "         0.0253,  0.0207,  0.0490,  0.0573, -0.0526, -0.0668, -0.0419,  0.0415,\n",
      "         0.0449, -0.0336,  0.0576,  0.0537,  0.0697, -0.0140,  0.0189,  0.0878,\n",
      "        -0.0622,  0.0448,  0.0275, -0.0232,  0.0466,  0.0142, -0.0816, -0.0607,\n",
      "        -0.0354, -0.0374, -0.0692,  0.0382,  0.0675, -0.0722,  0.0507, -0.0199,\n",
      "         0.0230, -0.0675,  0.0203, -0.0715,  0.0413,  0.0523, -0.0148,  0.1114,\n",
      "         0.0738, -0.0370, -0.0024, -0.0138,  0.0006,  0.0182, -0.0750, -0.0098,\n",
      "         0.0142,  0.0471, -0.0188,  0.0276,  0.0764,  0.0273, -0.0056, -0.0062,\n",
      "         0.0799, -0.0477, -0.0754,  0.0916,  0.0228, -0.0068,  0.0272,  0.0842,\n",
      "        -0.0154, -0.0803,  0.0114, -0.0906,  0.0414, -0.0185, -0.0766,  0.0236,\n",
      "        -0.0593, -0.0602, -0.0673,  0.0681, -0.0790,  0.0275, -0.0112,  0.0403,\n",
      "        -0.0276, -0.0595,  0.0201, -0.0717, -0.0973, -0.0202, -0.0563,  0.0135,\n",
      "         0.0617, -0.1076, -0.0553, -0.0311, -0.0428, -0.0437,  0.0851, -0.0367,\n",
      "        -0.0421,  0.0429,  0.0626,  0.0795, -0.0584, -0.0825, -0.0142, -0.0535],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1027, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0405, -0.0794,  0.0157,  0.0791, -0.0808,  0.0292, -0.0122, -0.0151,\n",
      "         0.0777,  0.0348,  0.0203,  0.0616,  0.0201, -0.0710, -0.0490,  0.0615,\n",
      "        -0.0043,  0.0195, -0.0127, -0.0233,  0.0036, -0.0023,  0.0536,  0.0964,\n",
      "        -0.0017, -0.0325, -0.0087, -0.0205, -0.0011,  0.0669,  0.0090,  0.0637,\n",
      "         0.0046, -0.0120, -0.0422,  0.0469, -0.0603, -0.1051, -0.0741,  0.0102,\n",
      "         0.0996, -0.0846,  0.0316,  0.0339,  0.0725, -0.0525,  0.0778,  0.0061,\n",
      "        -0.0852, -0.0600,  0.0149, -0.0310,  0.0045,  0.0743,  0.0323,  0.0095,\n",
      "        -0.0280, -0.0592,  0.0597,  0.0300,  0.0182, -0.0616, -0.0269, -0.0348,\n",
      "         0.0089, -0.0504, -0.0402, -0.0299,  0.0402, -0.0782, -0.0550, -0.0267,\n",
      "        -0.0439,  0.0329, -0.0702, -0.0204, -0.0329, -0.0171,  0.0866, -0.0265,\n",
      "        -0.0431,  0.0715,  0.0049,  0.0451,  0.0112, -0.0574, -0.0013, -0.0367,\n",
      "         0.0042,  0.0199, -0.0197, -0.0940,  0.0715,  0.0465, -0.0193,  0.0685,\n",
      "        -0.0553, -0.0805,  0.0518, -0.0602, -0.0401,  0.0326, -0.0676, -0.0407,\n",
      "         0.0239,  0.0344,  0.0355, -0.0875,  0.0336, -0.0673,  0.0620,  0.0694,\n",
      "        -0.0589, -0.0682,  0.0566, -0.0107, -0.0976,  0.0266, -0.0371,  0.0500,\n",
      "         0.0332, -0.0398,  0.0439, -0.0927, -0.0064,  0.0471, -0.0119,  0.0535],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0790, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0282,  0.0519,  0.0677], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36100/100000], Loss: 579.9,   LOSS_function: 160.3,   LOSS_E:6.963e-06,    LOSS_initial: 0.345,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2688.352266073227\n",
      "loss_compared with real:0.10996,   miu_train:0.001344,    lossmean:-0.08929\n",
      "Epoch [36200/100000], Loss: 580.7,   LOSS_function: 173.5,   LOSS_E:6.431e-06,    LOSS_initial: 0.3348,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2695.6379475593567\n",
      "loss_compared with real:0.10916,   miu_train:0.001426,    lossmean:-0.08905\n",
      "Epoch [36300/100000], Loss: 572.6,   LOSS_function: 162.4,   LOSS_E:5.898e-06,    LOSS_initial: 0.3374,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2703.184605360031\n",
      "loss_compared with real:0.1089,   miu_train:0.001389,    lossmean:-0.08827\n",
      "Epoch [36400/100000], Loss: 562,   LOSS_function: 164.5,   LOSS_E:5.665e-06,    LOSS_initial: 0.3271,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2710.956800222397\n",
      "loss_compared with real:0.10843,   miu_train:0.001492,    lossmean:-0.08849\n",
      "Epoch [36500/100000], Loss: 563.9,   LOSS_function: 169.5,   LOSS_E:5.343e-06,    LOSS_initial: 0.3246,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2718.7165203094482\n",
      "loss_compared with real:0.10551,   miu_train:0.001486,    lossmean:-0.0865\n",
      "Epoch [36600/100000], Loss: 561.7,   LOSS_function: 181.2,   LOSS_E:4.619e-06,    LOSS_initial: 0.3133,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2726.57493019104\n",
      "loss_compared with real:0.10451,   miu_train:0.001492,    lossmean:-0.08592\n",
      "Epoch [36700/100000], Loss: 560.6,   LOSS_function: 184.2,   LOSS_E:4.498e-06,    LOSS_initial: 0.3099,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2734.338842153549\n",
      "loss_compared with real:0.10347,   miu_train:0.001533,    lossmean:-0.08472\n",
      "Epoch [36800/100000], Loss: 565.8,   LOSS_function: 166.1,   LOSS_E:5.048e-06,    LOSS_initial: 0.329,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2742.184829711914\n",
      "loss_compared with real:0.10157,   miu_train:0.001592,    lossmean:-0.08371\n",
      "Epoch [36900/100000], Loss: 570,   LOSS_function: 182.2,   LOSS_E:5.47e-06,    LOSS_initial: 0.319,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:1209,      learn rate:0.0001362,    time: 2750.0042164325714\n",
      "loss_compared with real:0.10389,   miu_train:0.001761,    lossmean:-0.08557\n",
      "Epoch [37000/100000], Loss: 460,   LOSS_function: 161.8,   LOSS_E:5.067e-06,    LOSS_initial: 0.3319,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2757.8382885456085\n",
      "loss_compared with real:0.098776,   miu_train:0.001375,    lossmean:-0.08185\n",
      "Epoch [37100/100000], Loss: 455,   LOSS_function: 124.2,   LOSS_E:3.815e-06,    LOSS_initial: 0.3689,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2765.5951764583588\n",
      "loss_compared with real:0.11687,   miu_train:0.001205,    lossmean:-0.09223\n",
      "Epoch [37200/100000], Loss: 452.3,   LOSS_function: 118.8,   LOSS_E:3.787e-06,    LOSS_initial: 0.372,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2773.496786594391\n",
      "loss_compared with real:0.11748,   miu_train:0.00118,    lossmean:-0.09247\n",
      "Epoch [37300/100000], Loss: 459.8,   LOSS_function: 141.1,   LOSS_E:3.148e-06,    LOSS_initial: 0.3557,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2781.363457918167\n",
      "loss_compared with real:0.11884,   miu_train:0.001193,    lossmean:-0.09269\n",
      "Epoch [37400/100000], Loss: 458.9,   LOSS_function: 147.9,   LOSS_E:3.543e-06,    LOSS_initial: 0.3468,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2789.304885864258\n",
      "loss_compared with real:0.11838,   miu_train:0.00112,    lossmean:-0.09249\n",
      "Epoch [37500/100000], Loss: 516.8,   LOSS_function: 132.9,   LOSS_E:0.0001631,    LOSS_initial: 0.3633,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2797.19184756279\n",
      "loss_compared with real:0.12212,   miu_train:0.001162,    lossmean:-0.09311\n",
      "Epoch [37600/100000], Loss: 443.8,   LOSS_function: 115.5,   LOSS_E:3.4e-06,    LOSS_initial: 0.3664,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2804.9392540454865\n",
      "loss_compared with real:0.11989,   miu_train:0.001257,    lossmean:-0.09434\n",
      "Epoch [37700/100000], Loss: 468.9,   LOSS_function: 116.6,   LOSS_E:7.342e-06,    LOSS_initial: 0.3916,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2812.7193355560303\n",
      "loss_compared with real:0.12055,   miu_train:0.00133,    lossmean:-0.0951\n",
      "Epoch [37800/100000], Loss: 459.7,   LOSS_function: 137.6,   LOSS_E:3.11e-06,    LOSS_initial: 0.3594,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2820.5249104499817\n",
      "loss_compared with real:0.12027,   miu_train:0.001141,    lossmean:-0.09432\n",
      "Epoch [37900/100000], Loss: 459,   LOSS_function: 110.3,   LOSS_E:4.667e-06,    LOSS_initial: 0.3887,\n",
      "lamda1:1.001,    lamda2:3.644e+05,    lamda3:892.4,      learn rate:0.0001296,    time: 2828.2392778396606\n",
      "loss_compared with real:0.11892,   miu_train:0.001229,    lossmean:-0.09383\n",
      "Epoch [38000/100000], Loss: 413.4,   LOSS_function: 118.3,   LOSS_E:0.0001066,    LOSS_initial: 0.3752,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2836.0748982429504\n",
      "loss_compared with real:0.12008,   miu_train:0.001079,    lossmean:-0.0958\n",
      "Epoch [38100/100000], Loss: 391.7,   LOSS_function: 90.42,   LOSS_E:3.525e-06,    LOSS_initial: 0.4069,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2843.885925769806\n",
      "loss_compared with real:0.12859,   miu_train:0.0009081,    lossmean:-0.09903\n",
      "Epoch [38200/100000], Loss: 397.5,   LOSS_function: 93.71,   LOSS_E:4.262e-06,    LOSS_initial: 0.4101,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2851.7655017375946\n",
      "loss_compared with real:0.1295,   miu_train:0.001041,    lossmean:-0.1005\n",
      "Epoch [38300/100000], Loss: 399.4,   LOSS_function: 97.44,   LOSS_E:3.673e-06,    LOSS_initial: 0.4077,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2859.4005184173584\n",
      "loss_compared with real:0.12909,   miu_train:0.001004,    lossmean:-0.09924\n",
      "Epoch [38400/100000], Loss: 398.1,   LOSS_function: 98.76,   LOSS_E:3.249e-06,    LOSS_initial: 0.4043,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2866.609236240387\n",
      "loss_compared with real:0.12848,   miu_train:0.0008544,    lossmean:-0.09959\n",
      "Epoch [38500/100000], Loss: 414.9,   LOSS_function: 140.6,   LOSS_E:2.443e-06,    LOSS_initial: 0.3705,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2873.816830396652\n",
      "loss_compared with real:0.12884,   miu_train:0.0008676,    lossmean:-0.09849\n",
      "Epoch [38600/100000], Loss: 392,   LOSS_function: 98.22,   LOSS_E:2.808e-06,    LOSS_initial: 0.3968,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2881.072389125824\n",
      "loss_compared with real:0.13,   miu_train:0.0009114,    lossmean:-0.09999\n",
      "Epoch [38700/100000], Loss: 418.3,   LOSS_function: 139.2,   LOSS_E:2.699e-06,    LOSS_initial: 0.377,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2888.1736176013947\n",
      "loss_compared with real:0.12724,   miu_train:0.0008545,    lossmean:-0.09718\n",
      "Epoch [38800/100000], Loss: 395.3,   LOSS_function: 92.05,   LOSS_E:3.896e-06,    LOSS_initial: 0.4094,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2895.390661239624\n",
      "loss_compared with real:0.13251,   miu_train:0.001022,    lossmean:-0.1021\n",
      "Epoch [38900/100000], Loss: 399.4,   LOSS_function: 103.1,   LOSS_E:2.69e-06,    LOSS_initial: 0.4002,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:738.8,      learn rate:0.0001234,    time: 2902.557201385498\n",
      "loss_compared with real:0.13073,   miu_train:0.0008823,    lossmean:-0.1009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39000/100000], Loss: 833.4,   LOSS_function: 154.4,   LOSS_E:3.441e-06,    LOSS_initial: 0.3646,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2909.7893192768097\n",
      "loss_compared with real:0.14014,   miu_train:0.002164,    lossmean:-0.1028\n",
      "Epoch [39100/100000], Loss: 753.9,   LOSS_function: 295.1,   LOSS_E:8.221e-06,    LOSS_initial: 0.2457,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2917.033362388611\n",
      "loss_compared with real:0.082179,   miu_train:0.002346,    lossmean:-0.07375\n",
      "Epoch [39200/100000], Loss: 734.7,   LOSS_function: 273.6,   LOSS_E:8.938e-06,    LOSS_initial: 0.2469,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2924.228512763977\n",
      "loss_compared with real:0.078387,   miu_train:0.002474,    lossmean:-0.07054\n",
      "Epoch [39300/100000], Loss: 716.4,   LOSS_function: 259.7,   LOSS_E:1.003e-05,    LOSS_initial: 0.2444,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2932.6524641513824\n",
      "loss_compared with real:0.074421,   miu_train:0.002444,    lossmean:-0.06697\n",
      "Epoch [39400/100000], Loss: 740.3,   LOSS_function: 389.7,   LOSS_E:1.079e-05,    LOSS_initial: 0.1873,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2939.8914222717285\n",
      "loss_compared with real:0.072054,   miu_train:0.002388,    lossmean:-0.06477\n",
      "Epoch [39500/100000], Loss: 703.4,   LOSS_function: 254,   LOSS_E:1.167e-05,    LOSS_initial: 0.2404,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2947.141293525696\n",
      "loss_compared with real:0.074095,   miu_train:0.002737,    lossmean:-0.06667\n",
      "Epoch [39600/100000], Loss: 774.6,   LOSS_function: 260.5,   LOSS_E:1.839e-05,    LOSS_initial: 0.2746,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2954.4282596111298\n",
      "loss_compared with real:0.069848,   miu_train:0.002949,    lossmean:-0.06292\n",
      "Epoch [39700/100000], Loss: 723.9,   LOSS_function: 330.4,   LOSS_E:1.23e-05,    LOSS_initial: 0.2102,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2961.6768641471863\n",
      "loss_compared with real:0.068366,   miu_train:0.002387,    lossmean:-0.06075\n",
      "Epoch [39800/100000], Loss: 714.1,   LOSS_function: 323.3,   LOSS_E:1.213e-05,    LOSS_initial: 0.2088,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2969.009104013443\n",
      "loss_compared with real:0.066497,   miu_train:0.002669,    lossmean:-0.06121\n",
      "Epoch [39900/100000], Loss: 707.5,   LOSS_function: 285.5,   LOSS_E:1.405e-05,    LOSS_initial: 0.2255,\n",
      "lamda1:1.001,    lamda2:1.667e+05,    lamda3:1861,      learn rate:0.0001175,    time: 2976.134813785553\n",
      "loss_compared with real:0.069475,   miu_train:0.003155,    lossmean:-0.064\n",
      "Epoch [40000/100000], Loss: 814.9,   LOSS_function: 335.9,   LOSS_E:1.232e-05,    LOSS_initial: 0.2076,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 2983.3576958179474\n",
      "loss_compared with real:0.06699,   miu_train:0.003129,    lossmean:-0.0596\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5345, -0.5399, -0.3088, -0.9662, -0.0873, -0.3423,  0.4458, -0.8360,\n",
      "         0.9108,  0.3147,  0.7823,  0.5326,  0.6480, -0.0382,  0.6929, -0.3145,\n",
      "         0.8743,  0.0358,  0.8016, -0.7937, -0.2890, -0.9608, -0.5096, -0.3329,\n",
      "        -0.3010, -0.4001,  0.6977, -0.6664, -0.2466,  0.3981, -0.3188, -0.1915,\n",
      "         0.1107,  0.6416, -0.7288, -0.7940, -0.7215, -0.5702, -0.2603, -0.0546,\n",
      "        -0.8272, -0.9119, -0.0649,  0.7912, -0.6115,  0.8624, -0.6730,  0.8873,\n",
      "         0.6038, -0.9496, -0.7567, -0.3713,  0.8530, -0.5826,  0.9205, -0.1163,\n",
      "        -0.8730,  0.4136, -0.2724, -0.8543,  0.7929, -0.3293,  0.2653, -0.1090,\n",
      "        -0.5486, -0.0715, -0.0339,  0.4177, -0.4271, -0.3526,  0.6065, -0.4480,\n",
      "        -0.5079,  0.8779,  0.8022, -0.4372, -0.4539,  0.0130, -0.3390, -0.5492,\n",
      "        -0.7824, -0.7325,  0.9624,  0.0078,  0.1147,  0.8140,  0.7051,  0.2414,\n",
      "        -0.0329, -0.0750,  0.6676,  0.6967, -0.6801,  0.9072,  0.2269,  0.5592,\n",
      "        -0.6521, -0.1419,  0.6095,  0.0218, -0.8629,  0.0940, -0.0040, -0.2059,\n",
      "         0.4249,  0.4924,  0.6876,  0.0532,  0.2581,  0.6572, -0.6003, -0.2589,\n",
      "         0.5881,  0.7775,  0.7432, -0.0041, -0.9588,  0.9111, -0.3127, -0.8711,\n",
      "        -0.9567,  0.8989, -0.2192,  0.3746, -0.2423,  0.4283, -0.2129,  0.1842],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1095, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0200, -0.0284,  0.0253,  0.0830, -0.0555, -0.0339, -0.0299,  0.0281,\n",
      "        -0.0604,  0.0381, -0.0130, -0.0989,  0.0430, -0.0496,  0.0572,  0.0082,\n",
      "        -0.0274, -0.0244, -0.0332,  0.0504, -0.0671,  0.0627,  0.0252, -0.0147,\n",
      "         0.0188, -0.0006,  0.0698, -0.0434, -0.0156, -0.0697,  0.0199, -0.0807,\n",
      "         0.0852, -0.0304,  0.0608,  0.0009, -0.0519,  0.0526,  0.0487, -0.0482,\n",
      "        -0.0813, -0.0650,  0.0256,  0.0819,  0.0602,  0.0757, -0.0132,  0.0623,\n",
      "        -0.0270, -0.0266,  0.0463,  0.0091, -0.0208,  0.0054,  0.0085,  0.0078,\n",
      "         0.0515,  0.0475,  0.0606,  0.0368,  0.0046, -0.0466, -0.0385,  0.0456,\n",
      "         0.0669,  0.0058,  0.0410,  0.0321,  0.0421,  0.0226,  0.0602,  0.0010,\n",
      "        -0.0281, -0.0182, -0.0674,  0.0212, -0.0494,  0.0503, -0.0124,  0.0173,\n",
      "         0.0071, -0.0223, -0.0119,  0.0450,  0.0391, -0.0413, -0.0221, -0.0213,\n",
      "         0.0867,  0.0951,  0.0188,  0.0450, -0.0604, -0.0797,  0.0761, -0.0685,\n",
      "         0.0506,  0.0280,  0.0268,  0.0833,  0.0788,  0.0594,  0.0433,  0.0765,\n",
      "         0.0695,  0.0139, -0.0859, -0.0696,  0.0181, -0.0471,  0.0295,  0.0155,\n",
      "        -0.0514, -0.0435, -0.0002,  0.0424,  0.0563, -0.0762, -0.1132,  0.0385,\n",
      "         0.0646,  0.0245,  0.0211, -0.0235,  0.0035,  0.0232, -0.0599,  0.0760],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1265, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0480, -0.0517, -0.0515,  0.0511, -0.0300, -0.0340, -0.1116,  0.0023,\n",
      "        -0.0282,  0.0614, -0.0305, -0.0683, -0.0187,  0.0042, -0.0362, -0.0871,\n",
      "        -0.0600,  0.0542, -0.0092, -0.0827,  0.0123, -0.0223, -0.0551, -0.0295,\n",
      "         0.0251,  0.0212,  0.0482,  0.0580, -0.0528, -0.0668, -0.0424,  0.0410,\n",
      "         0.0452, -0.0340,  0.0586,  0.0545,  0.0699, -0.0130,  0.0180,  0.0881,\n",
      "        -0.0633,  0.0453,  0.0276, -0.0251,  0.0463,  0.0146, -0.0816, -0.0607,\n",
      "        -0.0354, -0.0375, -0.0684,  0.0383,  0.0671, -0.0725,  0.0508, -0.0200,\n",
      "         0.0232, -0.0675,  0.0212, -0.0722,  0.0410,  0.0514, -0.0150,  0.1115,\n",
      "         0.0738, -0.0374, -0.0013, -0.0138, -0.0006,  0.0175, -0.0752, -0.0101,\n",
      "         0.0144,  0.0468, -0.0190,  0.0267,  0.0771,  0.0273, -0.0055, -0.0066,\n",
      "         0.0795, -0.0480, -0.0739,  0.0917,  0.0231, -0.0069,  0.0256,  0.0848,\n",
      "        -0.0154, -0.0802,  0.0112, -0.0932,  0.0410, -0.0206, -0.0769,  0.0235,\n",
      "        -0.0575, -0.0600, -0.0669,  0.0673, -0.0794,  0.0278, -0.0115,  0.0411,\n",
      "        -0.0286, -0.0587,  0.0208, -0.0723, -0.0971, -0.0215, -0.0561,  0.0142,\n",
      "         0.0610, -0.1085, -0.0556, -0.0309, -0.0425, -0.0441,  0.0857, -0.0378,\n",
      "        -0.0423,  0.0424,  0.0623,  0.0808, -0.0581, -0.0832, -0.0144, -0.0540],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1058, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0395, -0.0795,  0.0162,  0.0789, -0.0794,  0.0296, -0.0124, -0.0173,\n",
      "         0.0777,  0.0343,  0.0192,  0.0619,  0.0191, -0.0679, -0.0499,  0.0616,\n",
      "        -0.0038,  0.0193, -0.0135, -0.0234,  0.0049, -0.0014,  0.0537,  0.0973,\n",
      "        -0.0025, -0.0317, -0.0093, -0.0197, -0.0017,  0.0674,  0.0080,  0.0649,\n",
      "         0.0052, -0.0103, -0.0399,  0.0475, -0.0612, -0.1063, -0.0738,  0.0100,\n",
      "         0.0992, -0.0852,  0.0325,  0.0343,  0.0730, -0.0531,  0.0766,  0.0065,\n",
      "        -0.0835, -0.0610,  0.0141, -0.0291,  0.0054,  0.0746,  0.0318,  0.0100,\n",
      "        -0.0283, -0.0589,  0.0592,  0.0298,  0.0186, -0.0611, -0.0267, -0.0344,\n",
      "         0.0092, -0.0500, -0.0407, -0.0307,  0.0388, -0.0780, -0.0534, -0.0275,\n",
      "        -0.0443,  0.0324, -0.0703, -0.0232, -0.0326, -0.0167,  0.0872, -0.0261,\n",
      "        -0.0426,  0.0705,  0.0054,  0.0459,  0.0118, -0.0540, -0.0011, -0.0364,\n",
      "         0.0038,  0.0191, -0.0192, -0.0940,  0.0697,  0.0458, -0.0196,  0.0687,\n",
      "        -0.0553, -0.0803,  0.0529, -0.0593, -0.0410,  0.0326, -0.0670, -0.0403,\n",
      "         0.0235,  0.0355,  0.0380, -0.0889,  0.0276, -0.0674,  0.0606,  0.0688,\n",
      "        -0.0576, -0.0679,  0.0572, -0.0132, -0.0980,  0.0303, -0.0375,  0.0509,\n",
      "         0.0334, -0.0394,  0.0436, -0.0939, -0.0085,  0.0472, -0.0115,  0.0535],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0794, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0236,  0.0510,  0.0672], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40100/100000], Loss: 1798,   LOSS_function: 301.3,   LOSS_E:1.74e-06,    LOSS_initial: 0.6967,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 2990.5981764793396\n",
      "loss_compared with real:0.02599,   miu_train:0.002094,    lossmean:0.05789\n",
      "Epoch [40200/100000], Loss: 1409,   LOSS_function: 233.9,   LOSS_E:1.961e-06,    LOSS_initial: 0.5465,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 2997.871391773224\n",
      "loss_compared with real:0.07087,   miu_train:0.001639,    lossmean:-0.0285\n",
      "Epoch [40300/100000], Loss: 1290,   LOSS_function: 217.7,   LOSS_E:2.553e-06,    LOSS_initial: 0.4974,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3005.527473449707\n",
      "loss_compared with real:0.099524,   miu_train:0.001548,    lossmean:-0.0673\n",
      "Epoch [40400/100000], Loss: 1230,   LOSS_function: 209,   LOSS_E:2.794e-06,    LOSS_initial: 0.4731,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3013.4128324985504\n",
      "loss_compared with real:0.11255,   miu_train:0.001516,    lossmean:-0.08281\n",
      "Epoch [40500/100000], Loss: 1193,   LOSS_function: 205.4,   LOSS_E:3.139e-06,    LOSS_initial: 0.4573,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3021.2138838768005\n",
      "loss_compared with real:0.11843,   miu_train:0.001505,    lossmean:-0.08956\n",
      "Epoch [40600/100000], Loss: 1170,   LOSS_function: 205.8,   LOSS_E:3.473e-06,    LOSS_initial: 0.446,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3028.9788348674774\n",
      "loss_compared with real:0.12188,   miu_train:0.001506,    lossmean:-0.09325\n",
      "Epoch [40700/100000], Loss: 1151,   LOSS_function: 205.4,   LOSS_E:3.489e-06,    LOSS_initial: 0.4374,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3036.792494535446\n",
      "loss_compared with real:0.12423,   miu_train:0.001514,    lossmean:-0.09558\n",
      "Epoch [40800/100000], Loss: 1140,   LOSS_function: 209.3,   LOSS_E:3.408e-06,    LOSS_initial: 0.4303,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3044.7813239097595\n",
      "loss_compared with real:0.12572,   miu_train:0.001527,    lossmean:-0.09707\n",
      "Epoch [40900/100000], Loss: 1127,   LOSS_function: 209.5,   LOSS_E:3.409e-06,    LOSS_initial: 0.4239,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2141,      learn rate:0.0001118,    time: 3052.6104085445404\n",
      "loss_compared with real:0.12636,   miu_train:0.001545,    lossmean:-0.09784\n",
      "Epoch [41000/100000], Loss: 1131,   LOSS_function: 212.2,   LOSS_E:3.422e-06,    LOSS_initial: 0.4177,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3060.519816637039\n",
      "loss_compared with real:0.12626,   miu_train:0.001571,    lossmean:-0.09801\n",
      "Epoch [41100/100000], Loss: 1125,   LOSS_function: 222.7,   LOSS_E:3.31e-06,    LOSS_initial: 0.4099,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3068.270106315613\n",
      "loss_compared with real:0.12523,   miu_train:0.001625,    lossmean:-0.09757\n",
      "Epoch [41200/100000], Loss: 1115,   LOSS_function: 224.5,   LOSS_E:3.301e-06,    LOSS_initial: 0.4046,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3076.0096096992493\n",
      "loss_compared with real:0.12423,   miu_train:0.001648,    lossmean:-0.09708\n",
      "Epoch [41300/100000], Loss: 1103,   LOSS_function: 225.5,   LOSS_E:3.149e-06,    LOSS_initial: 0.399,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3083.8224716186523\n",
      "loss_compared with real:0.12313,   miu_train:0.001679,    lossmean:-0.0965\n",
      "Epoch [41400/100000], Loss: 1100,   LOSS_function: 233.4,   LOSS_E:3.542e-06,    LOSS_initial: 0.3933,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3091.7087631225586\n",
      "loss_compared with real:0.12186,   miu_train:0.001712,    lossmean:-0.09586\n",
      "Epoch [41500/100000], Loss: 1090,   LOSS_function: 234.2,   LOSS_E:3.51e-06,    LOSS_initial: 0.3883,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3099.6297385692596\n",
      "loss_compared with real:0.12062,   miu_train:0.00174,    lossmean:-0.09516\n",
      "Epoch [41600/100000], Loss: 1084,   LOSS_function: 238.7,   LOSS_E:3.717e-06,    LOSS_initial: 0.3835,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3107.7090430259705\n",
      "loss_compared with real:0.11936,   miu_train:0.001768,    lossmean:-0.09448\n",
      "Epoch [41700/100000], Loss: 1077,   LOSS_function: 241.4,   LOSS_E:3.96e-06,    LOSS_initial: 0.3786,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3115.618398666382\n",
      "loss_compared with real:0.11815,   miu_train:0.001796,    lossmean:-0.09382\n",
      "Epoch [41800/100000], Loss: 1069,   LOSS_function: 244.2,   LOSS_E:3.877e-06,    LOSS_initial: 0.3736,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3123.4766449928284\n",
      "loss_compared with real:0.11685,   miu_train:0.001829,    lossmean:-0.09312\n",
      "Epoch [41900/100000], Loss: 1069,   LOSS_function: 253.4,   LOSS_E:4.038e-06,    LOSS_initial: 0.3694,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2178,      learn rate:0.0001065,    time: 3131.293568611145\n",
      "loss_compared with real:0.11569,   miu_train:0.001852,    lossmean:-0.09246\n",
      "Epoch [42000/100000], Loss: 1066,   LOSS_function: 248.1,   LOSS_E:4.06e-06,    LOSS_initial: 0.3647,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3139.1740922927856\n",
      "loss_compared with real:0.11444,   miu_train:0.001885,    lossmean:-0.09175\n",
      "Epoch [42100/100000], Loss: 1064,   LOSS_function: 259,   LOSS_E:4.665e-06,    LOSS_initial: 0.3584,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3146.901515483856\n",
      "loss_compared with real:0.11269,   miu_train:0.001942,    lossmean:-0.09075\n",
      "Epoch [42200/100000], Loss: 1065,   LOSS_function: 267.7,   LOSS_E:4.93e-06,    LOSS_initial: 0.3544,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3154.6691751480103\n",
      "loss_compared with real:0.11155,   miu_train:0.001966,    lossmean:-0.09004\n",
      "Epoch [42300/100000], Loss: 1053,   LOSS_function: 265.3,   LOSS_E:4.931e-06,    LOSS_initial: 0.3504,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3162.2426941394806\n",
      "loss_compared with real:0.11054,   miu_train:0.001996,    lossmean:-0.08949\n",
      "Epoch [42400/100000], Loss: 1053,   LOSS_function: 272.8,   LOSS_E:5.285e-06,    LOSS_initial: 0.3465,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3169.370978116989\n",
      "loss_compared with real:0.10961,   miu_train:0.002019,    lossmean:-0.08895\n",
      "Epoch [42500/100000], Loss: 1048,   LOSS_function: 275.1,   LOSS_E:5.644e-06,    LOSS_initial: 0.3425,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3176.6501603126526\n",
      "loss_compared with real:0.1085,   miu_train:0.002051,    lossmean:-0.08832\n",
      "Epoch [42600/100000], Loss: 1045,   LOSS_function: 279,   LOSS_E:6.017e-06,    LOSS_initial: 0.339,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3184.0705354213715\n",
      "loss_compared with real:0.10772,   miu_train:0.002073,    lossmean:-0.08783\n",
      "Epoch [42700/100000], Loss: 1036,   LOSS_function: 278.7,   LOSS_E:6.134e-06,    LOSS_initial: 0.3351,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3191.328007698059\n",
      "loss_compared with real:0.10683,   miu_train:0.002104,    lossmean:-0.08733\n",
      "Epoch [42800/100000], Loss: 1031,   LOSS_function: 279.4,   LOSS_E:6.471e-06,    LOSS_initial: 0.3318,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3198.591522216797\n",
      "loss_compared with real:0.10609,   miu_train:0.002126,    lossmean:-0.08693\n",
      "Epoch [42900/100000], Loss: 1032,   LOSS_function: 286.2,   LOSS_E:6.943e-06,    LOSS_initial: 0.3288,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2210,      learn rate:0.0001014,    time: 3205.82715511322\n",
      "loss_compared with real:0.10535,   miu_train:0.002145,    lossmean:-0.08645\n",
      "Epoch [43000/100000], Loss: 1044,   LOSS_function: 283.2,   LOSS_E:6.874e-06,    LOSS_initial: 0.3251,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3213.121376991272\n",
      "loss_compared with real:0.1043,   miu_train:0.002178,    lossmean:-0.08581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43100/100000], Loss: 1047,   LOSS_function: 301.2,   LOSS_E:7.358e-06,    LOSS_initial: 0.3179,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3220.207806825638\n",
      "loss_compared with real:0.10204,   miu_train:0.002258,    lossmean:-0.08444\n",
      "Epoch [43200/100000], Loss: 1036,   LOSS_function: 296.4,   LOSS_E:7.449e-06,    LOSS_initial: 0.3152,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3227.438595533371\n",
      "loss_compared with real:0.10102,   miu_train:0.002275,    lossmean:-0.08383\n",
      "Epoch [43300/100000], Loss: 1036,   LOSS_function: 300.6,   LOSS_E:7.764e-06,    LOSS_initial: 0.3127,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3234.5649650096893\n",
      "loss_compared with real:0.10035,   miu_train:0.00229,    lossmean:-0.08339\n",
      "Epoch [43400/100000], Loss: 1024,   LOSS_function: 297.4,   LOSS_E:7.911e-06,    LOSS_initial: 0.309,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3241.749259710312\n",
      "loss_compared with real:0.099818,   miu_train:0.002326,    lossmean:-0.08315\n",
      "Epoch [43500/100000], Loss: 1027,   LOSS_function: 302.6,   LOSS_E:8.86e-06,    LOSS_initial: 0.3066,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3249.099507331848\n",
      "loss_compared with real:0.099033,   miu_train:0.002338,    lossmean:-0.08264\n",
      "Epoch [43600/100000], Loss: 1030,   LOSS_function: 312.2,   LOSS_E:8.694e-06,    LOSS_initial: 0.3041,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3256.440994977951\n",
      "loss_compared with real:0.098533,   miu_train:0.002353,    lossmean:-0.08225\n",
      "Epoch [43700/100000], Loss: 1020,   LOSS_function: 305.3,   LOSS_E:9.378e-06,    LOSS_initial: 0.3015,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3263.6993396282196\n",
      "loss_compared with real:0.097614,   miu_train:0.002374,    lossmean:-0.08173\n",
      "Epoch [43800/100000], Loss: 1025,   LOSS_function: 317.7,   LOSS_E:9.103e-06,    LOSS_initial: 0.2989,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3270.9726021289825\n",
      "loss_compared with real:0.097342,   miu_train:0.002393,    lossmean:-0.08148\n",
      "Epoch [43900/100000], Loss: 1023,   LOSS_function: 318.5,   LOSS_E:9.721e-06,    LOSS_initial: 0.297,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2281,      learn rate:9.649e-05,    time: 3278.181225538254\n",
      "loss_compared with real:0.096627,   miu_train:0.0024,    lossmean:-0.08125\n",
      "Epoch [44000/100000], Loss: 1080,   LOSS_function: 313.3,   LOSS_E:7.921e-05,    LOSS_initial: 0.296,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3285.3026723861694\n",
      "loss_compared with real:0.09541,   miu_train:0.002405,    lossmean:-0.08077\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5329, -0.5376, -0.3071, -0.9673, -0.0859, -0.3409,  0.4443, -0.8379,\n",
      "         0.9130,  0.3165,  0.7808,  0.5299,  0.6501, -0.0362,  0.6901, -0.3159,\n",
      "         0.8761,  0.0341,  0.8030, -0.7950, -0.2871, -0.9591, -0.5108, -0.3318,\n",
      "        -0.2970, -0.3987,  0.6957, -0.6649, -0.2447,  0.3946, -0.3168, -0.1895,\n",
      "         0.1090,  0.6405, -0.7314, -0.7968, -0.7198, -0.5704, -0.2583, -0.0524,\n",
      "        -0.8260, -0.9120, -0.0634,  0.7917, -0.6100,  0.8611, -0.6752,  0.8862,\n",
      "         0.6020, -0.9508, -0.7557, -0.3699,  0.8519, -0.5810,  0.9229, -0.1152,\n",
      "        -0.8759,  0.4153, -0.2712, -0.8557,  0.7894, -0.3308,  0.2639, -0.1105,\n",
      "        -0.5501, -0.0731, -0.0326,  0.4163, -0.4252, -0.3506,  0.6047, -0.4465,\n",
      "        -0.5096,  0.8758,  0.8032, -0.4355, -0.4520,  0.0146, -0.3371, -0.5497,\n",
      "        -0.7806, -0.7345,  0.9608,  0.0093,  0.1162,  0.8157,  0.7067,  0.2395,\n",
      "        -0.0343, -0.0765,  0.6693,  0.6943, -0.6778,  0.9045,  0.2283,  0.5603,\n",
      "        -0.6497, -0.1432,  0.6120,  0.0233, -0.8648,  0.0918, -0.0056, -0.2074,\n",
      "         0.4263,  0.4918,  0.6850,  0.0547,  0.2592,  0.6551, -0.6005, -0.2582,\n",
      "         0.5905,  0.7800,  0.7412, -0.0026, -0.9563,  0.9120, -0.3121, -0.8701,\n",
      "        -0.9547,  0.8953, -0.2203,  0.3764, -0.2410,  0.4220, -0.2109,  0.1855],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1050, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0182, -0.0254,  0.0236,  0.0806, -0.0538, -0.0347, -0.0287,  0.0273,\n",
      "        -0.0632,  0.0399, -0.0104, -0.0998,  0.0454, -0.0522,  0.0588,  0.0057,\n",
      "        -0.0269, -0.0256, -0.0349,  0.0522, -0.0642,  0.0612,  0.0229, -0.0150,\n",
      "         0.0167, -0.0035,  0.0682, -0.0450, -0.0190, -0.0755,  0.0191, -0.0800,\n",
      "         0.0866, -0.0314,  0.0576,  0.0006, -0.0527,  0.0544,  0.0490, -0.0528,\n",
      "        -0.0815, -0.0630,  0.0232,  0.0842,  0.0618,  0.0730, -0.0158,  0.0651,\n",
      "        -0.0305, -0.0200,  0.0489,  0.0129, -0.0217,  0.0065,  0.0078,  0.0055,\n",
      "         0.0499,  0.0514,  0.0580,  0.0380,  0.0041, -0.0483, -0.0407,  0.0472,\n",
      "         0.0657,  0.0027,  0.0441,  0.0252,  0.0416,  0.0250,  0.0629, -0.0005,\n",
      "        -0.0270, -0.0196, -0.0689,  0.0244, -0.0496,  0.0476, -0.0178,  0.0163,\n",
      "         0.0107, -0.0234, -0.0108,  0.0483,  0.0413, -0.0435, -0.0202, -0.0211,\n",
      "         0.0843,  0.0972,  0.0178,  0.0427, -0.0662, -0.0811,  0.0745, -0.0669,\n",
      "         0.0559,  0.0307,  0.0286,  0.0835,  0.0769,  0.0580,  0.0452,  0.0741,\n",
      "         0.0716,  0.0073, -0.0886, -0.0681,  0.0169, -0.0459,  0.0285,  0.0169,\n",
      "        -0.0497, -0.0426, -0.0022,  0.0424,  0.0553, -0.0756, -0.1145,  0.0417,\n",
      "         0.0628,  0.0227,  0.0192, -0.0209,  0.0015,  0.0238, -0.0620,  0.0780],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1217, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0490, -0.0478, -0.0517,  0.0475, -0.0316, -0.0338, -0.1120,  0.0005,\n",
      "        -0.0292,  0.0630, -0.0304, -0.0653, -0.0222,  0.0054, -0.0421, -0.0850,\n",
      "        -0.0577,  0.0534, -0.0075, -0.0826,  0.0137, -0.0225, -0.0555, -0.0317,\n",
      "         0.0266,  0.0211,  0.0494,  0.0571, -0.0545, -0.0675, -0.0413,  0.0387,\n",
      "         0.0451, -0.0347,  0.0591,  0.0544,  0.0729, -0.0149,  0.0188,  0.0862,\n",
      "        -0.0644,  0.0472,  0.0271, -0.0246,  0.0470,  0.0129, -0.0722, -0.0612,\n",
      "        -0.0347, -0.0369, -0.0705,  0.0368,  0.0721, -0.0702,  0.0494, -0.0213,\n",
      "         0.0218, -0.0712,  0.0217, -0.0706,  0.0407,  0.0493, -0.0176,  0.1125,\n",
      "         0.0734, -0.0378, -0.0039, -0.0122,  0.0011,  0.0180, -0.0752, -0.0141,\n",
      "         0.0152,  0.0475, -0.0203,  0.0255,  0.0756,  0.0301, -0.0012, -0.0082,\n",
      "         0.0792, -0.0493, -0.0770,  0.0913,  0.0203, -0.0085,  0.0273,  0.0853,\n",
      "        -0.0163, -0.0806,  0.0100, -0.0962,  0.0413, -0.0181, -0.0740,  0.0261,\n",
      "        -0.0516, -0.0559, -0.0681,  0.0666, -0.0784,  0.0278, -0.0137,  0.0401,\n",
      "        -0.0297, -0.0577,  0.0199, -0.0725, -0.0984, -0.0217, -0.0559,  0.0137,\n",
      "         0.0598, -0.1089, -0.0557, -0.0295, -0.0426, -0.0463,  0.0853, -0.0400,\n",
      "        -0.0437,  0.0418,  0.0613,  0.0818, -0.0602, -0.0837, -0.0127, -0.0541],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1028, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0393, -0.0732,  0.0153,  0.0794, -0.0815,  0.0310, -0.0167, -0.0220,\n",
      "         0.0803,  0.0364,  0.0192,  0.0646,  0.0198, -0.0663, -0.0511,  0.0607,\n",
      "        -0.0041,  0.0190, -0.0164, -0.0248,  0.0082,  0.0044,  0.0585,  0.0992,\n",
      "        -0.0059, -0.0285, -0.0091, -0.0262, -0.0060,  0.0711,  0.0009,  0.0568,\n",
      "         0.0047, -0.0087, -0.0345,  0.0430, -0.0651, -0.1059, -0.0701,  0.0106,\n",
      "         0.0980, -0.0838,  0.0350,  0.0336,  0.0702, -0.0519,  0.0770,  0.0082,\n",
      "        -0.0841, -0.0641,  0.0155, -0.0312,  0.0058,  0.0766,  0.0300,  0.0137,\n",
      "        -0.0273, -0.0558,  0.0602,  0.0310,  0.0211, -0.0628, -0.0252, -0.0314,\n",
      "         0.0118, -0.0513, -0.0439, -0.0281,  0.0364, -0.0755, -0.0501, -0.0288,\n",
      "        -0.0418,  0.0336, -0.0711, -0.0254, -0.0305, -0.0154,  0.0878, -0.0238,\n",
      "        -0.0399,  0.0720,  0.0106,  0.0465,  0.0131, -0.0540, -0.0009, -0.0375,\n",
      "         0.0059,  0.0177, -0.0170, -0.0957,  0.0713,  0.0432, -0.0194,  0.0687,\n",
      "        -0.0580, -0.0786,  0.0567, -0.0570, -0.0395,  0.0314, -0.0640, -0.0363,\n",
      "         0.0239,  0.0411,  0.0439, -0.0930,  0.0089, -0.0687,  0.0529,  0.0698,\n",
      "        -0.0562, -0.0651,  0.0629, -0.0189, -0.0985,  0.0358, -0.0369,  0.0542,\n",
      "         0.0348, -0.0390,  0.0420, -0.0909, -0.0118,  0.0491, -0.0119,  0.0586],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0794, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0185,  0.0410,  0.0702], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44100/100000], Loss: 1025,   LOSS_function: 332.7,   LOSS_E:1.087e-05,    LOSS_initial: 0.2872,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3292.502790212631\n",
      "loss_compared with real:0.090944,   miu_train:0.002499,    lossmean:-0.07849\n",
      "Epoch [44200/100000], Loss: 1016,   LOSS_function: 332.3,   LOSS_E:1.236e-05,    LOSS_initial: 0.2834,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3299.70791220665\n",
      "loss_compared with real:0.089922,   miu_train:0.002528,    lossmean:-0.07792\n",
      "Epoch [44300/100000], Loss: 1017,   LOSS_function: 341.9,   LOSS_E:1.279e-05,    LOSS_initial: 0.2795,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3307.3504362106323\n",
      "loss_compared with real:0.089167,   miu_train:0.002563,    lossmean:-0.07745\n",
      "Epoch [44400/100000], Loss: 997.4,   LOSS_function: 330,   LOSS_E:1.345e-05,    LOSS_initial: 0.2761,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3315.1842527389526\n",
      "loss_compared with real:0.088436,   miu_train:0.00259,    lossmean:-0.07705\n",
      "Epoch [44500/100000], Loss: 1005,   LOSS_function: 342.5,   LOSS_E:1.49e-05,    LOSS_initial: 0.2736,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3323.075029373169\n",
      "loss_compared with real:0.087525,   miu_train:0.002607,    lossmean:-0.07634\n",
      "Epoch [44600/100000], Loss: 986.7,   LOSS_function: 331.2,   LOSS_E:1.509e-05,    LOSS_initial: 0.2705,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3330.8760719299316\n",
      "loss_compared with real:0.086636,   miu_train:0.002629,    lossmean:-0.07573\n",
      "Epoch [44700/100000], Loss: 987.8,   LOSS_function: 343.4,   LOSS_E:1.585e-05,    LOSS_initial: 0.2656,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3338.7118809223175\n",
      "loss_compared with real:0.085966,   miu_train:0.002674,    lossmean:-0.07546\n",
      "Epoch [44800/100000], Loss: 972.4,   LOSS_function: 332.9,   LOSS_E:1.691e-05,    LOSS_initial: 0.2632,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3346.4711294174194\n",
      "loss_compared with real:0.084619,   miu_train:0.002686,    lossmean:-0.07461\n",
      "Epoch [44900/100000], Loss: 977.6,   LOSS_function: 341.9,   LOSS_E:1.861e-05,    LOSS_initial: 0.261,\n",
      "lamda1:1,    lamda2:7.919e+05,    lamda3:2379,      learn rate:9.186e-05,    time: 3354.2486250400543\n",
      "loss_compared with real:0.083915,   miu_train:0.002692,    lossmean:-0.07402\n",
      "Epoch [45000/100000], Loss: 1135,   LOSS_function: 343.6,   LOSS_E:2.035e-05,    LOSS_initial: 0.2577,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3362.1437051296234\n",
      "loss_compared with real:0.083191,   miu_train:0.002793,    lossmean:-0.07379\n",
      "Epoch [45100/100000], Loss: 1275,   LOSS_function: 363.7,   LOSS_E:2.439e-05,    LOSS_initial: 0.2935,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3369.893392562866\n",
      "loss_compared with real:0.12451,   miu_train:0.002614,    lossmean:-0.04829\n",
      "Epoch [45200/100000], Loss: 1163,   LOSS_function: 388.1,   LOSS_E:1.38e-05,    LOSS_initial: 0.2747,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3378.003322124481\n",
      "loss_compared with real:0.10035,   miu_train:0.002757,    lossmean:-0.0609\n",
      "Epoch [45300/100000], Loss: 1134,   LOSS_function: 378.4,   LOSS_E:1.254e-05,    LOSS_initial: 0.2709,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3385.8710432052612\n",
      "loss_compared with real:0.094975,   miu_train:0.00275,    lossmean:-0.06865\n",
      "Epoch [45400/100000], Loss: 1121,   LOSS_function: 370.7,   LOSS_E:1.2e-05,    LOSS_initial: 0.2707,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3393.721963405609\n",
      "loss_compared with real:0.094284,   miu_train:0.002714,    lossmean:-0.07173\n",
      "Epoch [45500/100000], Loss: 1106,   LOSS_function: 357.2,   LOSS_E:1.19e-05,    LOSS_initial: 0.2706,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3401.465242624283\n",
      "loss_compared with real:0.09475,   miu_train:0.002699,    lossmean:-0.07349\n",
      "Epoch [45600/100000], Loss: 1105,   LOSS_function: 358.2,   LOSS_E:1.117e-05,    LOSS_initial: 0.2723,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3409.3118031024933\n",
      "loss_compared with real:0.095531,   miu_train:0.002664,    lossmean:-0.07483\n",
      "Epoch [45700/100000], Loss: 1094,   LOSS_function: 349.8,   LOSS_E:1.062e-05,    LOSS_initial: 0.2732,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3417.074019432068\n",
      "loss_compared with real:0.096092,   miu_train:0.002645,    lossmean:-0.07603\n",
      "Epoch [45800/100000], Loss: 1092,   LOSS_function: 348.9,   LOSS_E:1.044e-05,    LOSS_initial: 0.2734,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3424.987752199173\n",
      "loss_compared with real:0.096458,   miu_train:0.002647,    lossmean:-0.07713\n",
      "Epoch [45900/100000], Loss: 1088,   LOSS_function: 342.7,   LOSS_E:1.038e-05,    LOSS_initial: 0.2746,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2390,      learn rate:8.745e-05,    time: 3432.7254734039307\n",
      "loss_compared with real:0.096624,   miu_train:0.002632,    lossmean:-0.0779\n",
      "Epoch [46000/100000], Loss: 1125,   LOSS_function: 338.9,   LOSS_E:9.928e-06,    LOSS_initial: 0.2749,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3440.554795742035\n",
      "loss_compared with real:0.09666,   miu_train:0.002634,    lossmean:-0.07858\n",
      "Epoch [46100/100000], Loss: 1130,   LOSS_function: 362,   LOSS_E:9.744e-06,    LOSS_initial: 0.2683,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3448.360867023468\n",
      "loss_compared with real:0.094213,   miu_train:0.002753,    lossmean:-0.07833\n",
      "Epoch [46200/100000], Loss: 1134,   LOSS_function: 367.6,   LOSS_E:9.567e-06,    LOSS_initial: 0.2683,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3456.1958408355713\n",
      "loss_compared with real:0.093007,   miu_train:0.002753,    lossmean:-0.0777\n",
      "Epoch [46300/100000], Loss: 1122,   LOSS_function: 354.1,   LOSS_E:9.848e-06,    LOSS_initial: 0.2681,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3463.8086009025574\n",
      "loss_compared with real:0.09234,   miu_train:0.002755,    lossmean:-0.07742\n",
      "Epoch [46400/100000], Loss: 1123,   LOSS_function: 355.7,   LOSS_E:9.807e-06,    LOSS_initial: 0.268,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3471.091435432434\n",
      "loss_compared with real:0.092058,   miu_train:0.002759,    lossmean:-0.07749\n",
      "Epoch [46500/100000], Loss: 1131,   LOSS_function: 364.2,   LOSS_E:9.702e-06,    LOSS_initial: 0.2679,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3478.297564268112\n",
      "loss_compared with real:0.092215,   miu_train:0.00276,    lossmean:-0.07772\n",
      "Epoch [46600/100000], Loss: 1123,   LOSS_function: 361.1,   LOSS_E:9.36e-06,    LOSS_initial: 0.2673,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3485.588700532913\n",
      "loss_compared with real:0.091864,   miu_train:0.00277,    lossmean:-0.07769\n",
      "Epoch [46700/100000], Loss: 1117,   LOSS_function: 356.2,   LOSS_E:9.18e-06,    LOSS_initial: 0.2676,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3492.7873435020447\n",
      "loss_compared with real:0.091778,   miu_train:0.002762,    lossmean:-0.0776\n",
      "Epoch [46800/100000], Loss: 1129,   LOSS_function: 368.1,   LOSS_E:9.285e-06,    LOSS_initial: 0.2673,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3500.029379606247\n",
      "loss_compared with real:0.091692,   miu_train:0.002766,    lossmean:-0.07776\n",
      "Epoch [46900/100000], Loss: 1123,   LOSS_function: 357.1,   LOSS_E:9.354e-06,    LOSS_initial: 0.2691,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2548,      learn rate:8.325e-05,    time: 3507.132131576538\n",
      "loss_compared with real:0.091403,   miu_train:0.002735,    lossmean:-0.07744\n",
      "Epoch [47000/100000], Loss: 1178,   LOSS_function: 368.5,   LOSS_E:9.763e-06,    LOSS_initial: 0.2674,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3514.513076543808\n",
      "loss_compared with real:0.091422,   miu_train:0.002756,    lossmean:-0.07754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47100/100000], Loss: 1167,   LOSS_function: 379.4,   LOSS_E:9.653e-06,    LOSS_initial: 0.2599,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3521.7612867355347\n",
      "loss_compared with real:0.088242,   miu_train:0.002895,    lossmean:-0.07614\n",
      "Epoch [47200/100000], Loss: 1164,   LOSS_function: 374.4,   LOSS_E:9.473e-06,    LOSS_initial: 0.2608,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3528.959797143936\n",
      "loss_compared with real:0.087367,   miu_train:0.002866,    lossmean:-0.07534\n",
      "Epoch [47300/100000], Loss: 1154,   LOSS_function: 367.7,   LOSS_E:9.574e-06,    LOSS_initial: 0.2596,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3536.1871995925903\n",
      "loss_compared with real:0.087141,   miu_train:0.002887,    lossmean:-0.07525\n",
      "Epoch [47400/100000], Loss: 1162,   LOSS_function: 379.3,   LOSS_E:9.417e-06,    LOSS_initial: 0.2586,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3543.412011384964\n",
      "loss_compared with real:0.08734,   miu_train:0.002897,    lossmean:-0.0753\n",
      "Epoch [47500/100000], Loss: 1167,   LOSS_function: 381.9,   LOSS_E:9.339e-06,    LOSS_initial: 0.2597,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3550.620190143585\n",
      "loss_compared with real:0.086721,   miu_train:0.002868,    lossmean:-0.07496\n",
      "Epoch [47600/100000], Loss: 1159,   LOSS_function: 375.6,   LOSS_E:9.628e-06,    LOSS_initial: 0.258,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3557.883237838745\n",
      "loss_compared with real:0.086955,   miu_train:0.002902,    lossmean:-0.07509\n",
      "Epoch [47700/100000], Loss: 1159,   LOSS_function: 376.4,   LOSS_E:9.479e-06,    LOSS_initial: 0.2583,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3565.0907373428345\n",
      "loss_compared with real:0.08662,   miu_train:0.002889,    lossmean:-0.07489\n",
      "Epoch [47800/100000], Loss: 1157,   LOSS_function: 379.4,   LOSS_E:9.144e-06,    LOSS_initial: 0.2574,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3572.335105419159\n",
      "loss_compared with real:0.086806,   miu_train:0.002893,    lossmean:-0.07487\n",
      "Epoch [47900/100000], Loss: 1158,   LOSS_function: 378.7,   LOSS_E:9.43e-06,    LOSS_initial: 0.2572,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2713,      learn rate:7.925e-05,    time: 3579.513488292694\n",
      "loss_compared with real:0.086435,   miu_train:0.002897,    lossmean:-0.07483\n",
      "Epoch [48000/100000], Loss: 1204,   LOSS_function: 388.9,   LOSS_E:9.616e-06,    LOSS_initial: 0.2583,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3586.768262386322\n",
      "loss_compared with real:0.086087,   miu_train:0.002868,    lossmean:-0.07448\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5330, -0.5383, -0.3071, -0.9678, -0.0861, -0.3408,  0.4447, -0.8379,\n",
      "         0.9130,  0.3165,  0.7811,  0.5302,  0.6504, -0.0361,  0.6898, -0.3153,\n",
      "         0.8760,  0.0352,  0.8030, -0.7938, -0.2870, -0.9594, -0.5108, -0.3319,\n",
      "        -0.2960, -0.3989,  0.6955, -0.6643, -0.2450,  0.3933, -0.3160, -0.1894,\n",
      "         0.1090,  0.6406, -0.7313, -0.7972, -0.7197, -0.5722, -0.2582, -0.0525,\n",
      "        -0.8258, -0.9104, -0.0636,  0.7917, -0.6103,  0.8611, -0.6750,  0.8861,\n",
      "         0.6020, -0.9512, -0.7558, -0.3702,  0.8523, -0.5808,  0.9229, -0.1151,\n",
      "        -0.8731,  0.4163, -0.2715, -0.8567,  0.7893, -0.3311,  0.2648, -0.1103,\n",
      "        -0.5500, -0.0726, -0.0329,  0.4166, -0.4253, -0.3503,  0.6046, -0.4468,\n",
      "        -0.5096,  0.8760,  0.8033, -0.4362, -0.4520,  0.0146, -0.3369, -0.5486,\n",
      "        -0.7810, -0.7347,  0.9617,  0.0090,  0.1161,  0.8157,  0.7069,  0.2397,\n",
      "        -0.0340, -0.0765,  0.6693,  0.6939, -0.6781,  0.9045,  0.2282,  0.5601,\n",
      "        -0.6497, -0.1433,  0.6127,  0.0228, -0.8637,  0.0915, -0.0055, -0.2067,\n",
      "         0.4264,  0.4916,  0.6850,  0.0546,  0.2587,  0.6551, -0.6004, -0.2581,\n",
      "         0.5888,  0.7799,  0.7410, -0.0028, -0.9569,  0.9120, -0.3123, -0.8700,\n",
      "        -0.9546,  0.8937, -0.2205,  0.3766, -0.2413,  0.4225, -0.2116,  0.1854],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1046, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0180, -0.0254,  0.0238,  0.0808, -0.0547, -0.0345, -0.0271,  0.0274,\n",
      "        -0.0621,  0.0398, -0.0104, -0.0997,  0.0458, -0.0517,  0.0589,  0.0053,\n",
      "        -0.0275, -0.0262, -0.0331,  0.0526, -0.0645,  0.0599,  0.0235, -0.0151,\n",
      "         0.0170, -0.0040,  0.0680, -0.0457, -0.0173, -0.0757,  0.0191, -0.0803,\n",
      "         0.0864, -0.0313,  0.0580, -0.0005, -0.0529,  0.0543,  0.0491, -0.0516,\n",
      "        -0.0813, -0.0626,  0.0243,  0.0838,  0.0616,  0.0728, -0.0160,  0.0658,\n",
      "        -0.0312, -0.0199,  0.0526,  0.0120, -0.0213,  0.0064,  0.0076,  0.0053,\n",
      "         0.0501,  0.0522,  0.0580,  0.0372,  0.0067, -0.0486, -0.0404,  0.0470,\n",
      "         0.0656,  0.0030,  0.0441,  0.0249,  0.0430,  0.0244,  0.0620, -0.0007,\n",
      "        -0.0260, -0.0202, -0.0688,  0.0241, -0.0500,  0.0484, -0.0181,  0.0167,\n",
      "         0.0107, -0.0230, -0.0110,  0.0485,  0.0412, -0.0433, -0.0201, -0.0212,\n",
      "         0.0832,  0.0946,  0.0185,  0.0457, -0.0666, -0.0810,  0.0748, -0.0671,\n",
      "         0.0559,  0.0307,  0.0285,  0.0847,  0.0766,  0.0583,  0.0449,  0.0733,\n",
      "         0.0719,  0.0068, -0.0875, -0.0681,  0.0166, -0.0467,  0.0285,  0.0171,\n",
      "        -0.0501, -0.0429, -0.0026,  0.0425,  0.0558, -0.0757, -0.1145,  0.0406,\n",
      "         0.0635,  0.0237,  0.0205, -0.0208,  0.0019,  0.0238, -0.0618,  0.0777],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1214, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0493, -0.0483, -0.0520,  0.0473, -0.0315, -0.0336, -0.1118, -0.0014,\n",
      "        -0.0290,  0.0627, -0.0301, -0.0652, -0.0221,  0.0056, -0.0421, -0.0852,\n",
      "        -0.0573,  0.0533, -0.0077, -0.0823,  0.0132, -0.0222, -0.0552, -0.0320,\n",
      "         0.0265,  0.0214,  0.0494,  0.0533, -0.0544, -0.0676, -0.0412,  0.0387,\n",
      "         0.0453, -0.0345,  0.0573,  0.0545,  0.0731, -0.0149,  0.0171,  0.0861,\n",
      "        -0.0645,  0.0473,  0.0274, -0.0244,  0.0470,  0.0129, -0.0723, -0.0609,\n",
      "        -0.0349, -0.0374, -0.0668,  0.0373,  0.0718, -0.0707,  0.0500, -0.0211,\n",
      "         0.0212, -0.0715,  0.0215, -0.0702,  0.0407,  0.0492, -0.0178,  0.1114,\n",
      "         0.0736, -0.0378, -0.0028, -0.0125,  0.0013,  0.0180, -0.0771, -0.0133,\n",
      "         0.0150,  0.0470, -0.0202,  0.0251,  0.0754,  0.0292,  0.0019, -0.0082,\n",
      "         0.0795, -0.0490, -0.0762,  0.0913,  0.0203, -0.0084,  0.0285,  0.0854,\n",
      "        -0.0166, -0.0800,  0.0097, -0.0967,  0.0412, -0.0186, -0.0743,  0.0262,\n",
      "        -0.0496, -0.0568, -0.0680,  0.0669, -0.0785,  0.0274, -0.0132,  0.0400,\n",
      "        -0.0297, -0.0578,  0.0200, -0.0749, -0.0981, -0.0211, -0.0547,  0.0135,\n",
      "         0.0601, -0.1087, -0.0555, -0.0297, -0.0430, -0.0463,  0.0855, -0.0402,\n",
      "        -0.0439,  0.0414,  0.0614,  0.0818, -0.0596, -0.0838, -0.0131, -0.0538],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1025, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0392, -0.0737,  0.0151,  0.0793, -0.0814,  0.0302, -0.0176, -0.0223,\n",
      "         0.0806,  0.0386,  0.0203,  0.0640,  0.0207, -0.0639, -0.0511,  0.0610,\n",
      "        -0.0047,  0.0181, -0.0164, -0.0240,  0.0077,  0.0028,  0.0591,  0.0995,\n",
      "        -0.0061, -0.0282, -0.0091, -0.0271, -0.0076,  0.0719,  0.0005,  0.0527,\n",
      "         0.0039, -0.0087, -0.0343,  0.0431, -0.0651, -0.1058, -0.0690,  0.0107,\n",
      "         0.0983, -0.0840,  0.0352,  0.0327,  0.0700, -0.0522,  0.0777,  0.0082,\n",
      "        -0.0843, -0.0637,  0.0148, -0.0315,  0.0056,  0.0765,  0.0296,  0.0138,\n",
      "        -0.0272, -0.0568,  0.0603,  0.0309,  0.0213, -0.0630, -0.0249, -0.0310,\n",
      "         0.0119, -0.0515, -0.0417, -0.0279,  0.0365, -0.0763, -0.0490, -0.0288,\n",
      "        -0.0416,  0.0331, -0.0715, -0.0242, -0.0305, -0.0148,  0.0882, -0.0264,\n",
      "        -0.0392,  0.0719,  0.0093,  0.0474,  0.0146, -0.0537, -0.0019, -0.0375,\n",
      "         0.0059,  0.0167, -0.0164, -0.0954,  0.0720,  0.0430, -0.0194,  0.0691,\n",
      "        -0.0584, -0.0785,  0.0564, -0.0570, -0.0392,  0.0312, -0.0639, -0.0357,\n",
      "         0.0240,  0.0423,  0.0446, -0.0930,  0.0095, -0.0696,  0.0492,  0.0698,\n",
      "        -0.0578, -0.0661,  0.0624, -0.0186, -0.0987,  0.0369, -0.0362,  0.0530,\n",
      "         0.0350, -0.0389,  0.0418, -0.0888, -0.0111,  0.0491, -0.0119,  0.0588],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0793, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0337,  0.0400,  0.0716], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48100/100000], Loss: 1181,   LOSS_function: 391.1,   LOSS_E:9.286e-06,    LOSS_initial: 0.2503,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3594.0625245571136\n",
      "loss_compared with real:0.083903,   miu_train:0.003006,    lossmean:-0.07342\n",
      "Epoch [48200/100000], Loss: 1186,   LOSS_function: 396.8,   LOSS_E:9.491e-06,    LOSS_initial: 0.2496,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3601.2558224201202\n",
      "loss_compared with real:0.083597,   miu_train:0.003014,    lossmean:-0.07307\n",
      "Epoch [48300/100000], Loss: 1193,   LOSS_function: 399.6,   LOSS_E:9.853e-06,    LOSS_initial: 0.25,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3608.831651687622\n",
      "loss_compared with real:0.082992,   miu_train:0.002991,    lossmean:-0.07272\n",
      "Epoch [48400/100000], Loss: 1183,   LOSS_function: 394.7,   LOSS_E:9.77e-06,    LOSS_initial: 0.2486,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3616.7353937625885\n",
      "loss_compared with real:0.083337,   miu_train:0.003011,    lossmean:-0.07297\n",
      "Epoch [48500/100000], Loss: 1180,   LOSS_function: 390.8,   LOSS_E:9.737e-06,    LOSS_initial: 0.2488,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3624.4388661384583\n",
      "loss_compared with real:0.082977,   miu_train:0.002998,    lossmean:-0.07242\n",
      "Epoch [48600/100000], Loss: 1161,   LOSS_function: 382.2,   LOSS_E:9.439e-06,    LOSS_initial: 0.2462,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3632.227658510208\n",
      "loss_compared with real:0.082985,   miu_train:0.003047,    lossmean:-0.0727\n",
      "Epoch [48700/100000], Loss: 1174,   LOSS_function: 389.8,   LOSS_E:9.447e-06,    LOSS_initial: 0.2478,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3640.0007820129395\n",
      "loss_compared with real:0.082476,   miu_train:0.002998,    lossmean:-0.07221\n",
      "Epoch [48800/100000], Loss: 1179,   LOSS_function: 398.3,   LOSS_E:9.751e-06,    LOSS_initial: 0.2458,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3647.8512001037598\n",
      "loss_compared with real:0.08209,   miu_train:0.003019,    lossmean:-0.07206\n",
      "Epoch [48900/100000], Loss: 1166,   LOSS_function: 382.1,   LOSS_E:1.003e-05,    LOSS_initial: 0.2461,\n",
      "lamda1:1,    lamda2:8.595e+06,    lamda3:2835,      learn rate:7.545e-05,    time: 3655.5678770542145\n",
      "loss_compared with real:0.082068,   miu_train:0.003025,    lossmean:-0.07187\n",
      "Epoch [49000/100000], Loss: 1132,   LOSS_function: 394.3,   LOSS_E:1.521e-05,    LOSS_initial: 0.2457,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3663.489118337631\n",
      "loss_compared with real:0.082316,   miu_train:0.002982,    lossmean:-0.0721\n",
      "Epoch [49100/100000], Loss: 1124,   LOSS_function: 415.5,   LOSS_E:1.037e-05,    LOSS_initial: 0.2402,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3671.2387886047363\n",
      "loss_compared with real:0.076876,   miu_train:0.003064,    lossmean:-0.07\n",
      "Epoch [49200/100000], Loss: 1115,   LOSS_function: 416.9,   LOSS_E:1.085e-05,    LOSS_initial: 0.2361,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3679.1470351219177\n",
      "loss_compared with real:0.076576,   miu_train:0.003112,    lossmean:-0.06972\n",
      "Epoch [49300/100000], Loss: 1107,   LOSS_function: 410.3,   LOSS_E:1.133e-05,    LOSS_initial: 0.235,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3686.857301235199\n",
      "loss_compared with real:0.075763,   miu_train:0.003109,    lossmean:-0.06922\n",
      "Epoch [49400/100000], Loss: 1098,   LOSS_function: 406.4,   LOSS_E:1.144e-05,    LOSS_initial: 0.2333,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3694.757050037384\n",
      "loss_compared with real:0.075251,   miu_train:0.003109,    lossmean:-0.06885\n",
      "Epoch [49500/100000], Loss: 1104,   LOSS_function: 415.2,   LOSS_E:1.207e-05,    LOSS_initial: 0.2315,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3702.4885165691376\n",
      "loss_compared with real:0.074616,   miu_train:0.003115,    lossmean:-0.06819\n",
      "Epoch [49600/100000], Loss: 1100,   LOSS_function: 422.7,   LOSS_E:1.245e-05,    LOSS_initial: 0.227,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3710.3890388011932\n",
      "loss_compared with real:0.073981,   miu_train:0.003168,    lossmean:-0.06793\n",
      "Epoch [49700/100000], Loss: 1075,   LOSS_function: 405.9,   LOSS_E:1.304e-05,    LOSS_initial: 0.2237,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3718.057217359543\n",
      "loss_compared with real:0.073533,   miu_train:0.003219,    lossmean:-0.06732\n",
      "Epoch [49800/100000], Loss: 1096,   LOSS_function: 426.8,   LOSS_E:1.399e-05,    LOSS_initial: 0.2227,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3725.8801555633545\n",
      "loss_compared with real:0.07294,   miu_train:0.003175,    lossmean:-0.06666\n",
      "Epoch [49900/100000], Loss: 1086,   LOSS_function: 428.4,   LOSS_E:1.43e-05,    LOSS_initial: 0.2184,\n",
      "lamda1:1,    lamda2:2.801e+06,    lamda3:2828,      learn rate:7.183e-05,    time: 3733.675071954727\n",
      "loss_compared with real:0.072778,   miu_train:0.003209,    lossmean:-0.0667\n",
      "Epoch [50000/100000], Loss: 1317,   LOSS_function: 410.7,   LOSS_E:1.414e-05,    LOSS_initial: 0.2179,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3741.506236553192\n",
      "loss_compared with real:0.071472,   miu_train:0.003294,    lossmean:-0.06604\n",
      "Epoch [50100/100000], Loss: 3925,   LOSS_function: 437.8,   LOSS_E:5.129e-05,    LOSS_initial: 0.8606,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3749.342005968094\n",
      "loss_compared with real:0.10811,   miu_train:0.002602,    lossmean:0.0002332\n",
      "Epoch [50200/100000], Loss: 3097,   LOSS_function: 310.2,   LOSS_E:4.052e-05,    LOSS_initial: 0.6911,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3757.181557893753\n",
      "loss_compared with real:0.17357,   miu_train:0.001894,    lossmean:-0.08188\n",
      "Epoch [50300/100000], Loss: 2691,   LOSS_function: 284.9,   LOSS_E:3.162e-05,    LOSS_initial: 0.6207,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3764.9336528778076\n",
      "loss_compared with real:0.18667,   miu_train:0.001747,    lossmean:-0.1197\n",
      "Epoch [50400/100000], Loss: 2406,   LOSS_function: 278.3,   LOSS_E:2.502e-05,    LOSS_initial: 0.57,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3772.172065973282\n",
      "loss_compared with real:0.18033,   miu_train:0.001706,    lossmean:-0.1321\n",
      "Epoch [50500/100000], Loss: 2148,   LOSS_function: 272.8,   LOSS_E:1.952e-05,    LOSS_initial: 0.5205,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3779.474764108658\n",
      "loss_compared with real:0.1704,   miu_train:0.001693,    lossmean:-0.1339\n",
      "Epoch [50600/100000], Loss: 1896,   LOSS_function: 275,   LOSS_E:1.548e-05,    LOSS_initial: 0.4597,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3786.731424808502\n",
      "loss_compared with real:0.16302,   miu_train:0.001733,    lossmean:-0.1325\n",
      "Epoch [50700/100000], Loss: 1578,   LOSS_function: 318.7,   LOSS_E:1.005e-05,    LOSS_initial: 0.3711,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3793.8389451503754\n",
      "loss_compared with real:0.15694,   miu_train:0.002118,    lossmean:-0.1289\n",
      "Epoch [50800/100000], Loss: 1377,   LOSS_function: 436.7,   LOSS_E:5.288e-06,    LOSS_initial: 0.2928,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3801.0338068008423\n",
      "loss_compared with real:0.13185,   miu_train:0.002865,    lossmean:-0.1127\n",
      "Epoch [50900/100000], Loss: 1314,   LOSS_function: 480,   LOSS_E:4.055e-06,    LOSS_initial: 0.2645,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2843,      learn rate:6.838e-05,    time: 3808.2182066440582\n",
      "loss_compared with real:0.10234,   miu_train:0.003171,    lossmean:-0.09274\n",
      "Epoch [51000/100000], Loss: 1336,   LOSS_function: 495,   LOSS_E:3.542e-06,    LOSS_initial: 0.2538,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3815.6103131771088\n",
      "loss_compared with real:0.087393,   miu_train:0.003278,    lossmean:-0.08057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51100/100000], Loss: 1312,   LOSS_function: 516.1,   LOSS_E:3.123e-06,    LOSS_initial: 0.2418,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3822.8282766342163\n",
      "loss_compared with real:0.079371,   miu_train:0.003463,    lossmean:-0.07393\n",
      "Epoch [51200/100000], Loss: 1295,   LOSS_function: 515.7,   LOSS_E:2.838e-06,    LOSS_initial: 0.2381,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3830.0474741458893\n",
      "loss_compared with real:0.07532,   miu_train:0.003497,    lossmean:-0.07023\n",
      "Epoch [51300/100000], Loss: 1289,   LOSS_function: 521.5,   LOSS_E:2.543e-06,    LOSS_initial: 0.2365,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3837.212343454361\n",
      "loss_compared with real:0.073268,   miu_train:0.003501,    lossmean:-0.0684\n",
      "Epoch [51400/100000], Loss: 1274,   LOSS_function: 513.8,   LOSS_E:2.44e-06,    LOSS_initial: 0.2347,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3844.6371400356293\n",
      "loss_compared with real:0.072372,   miu_train:0.003517,    lossmean:-0.06768\n",
      "Epoch [51500/100000], Loss: 1283,   LOSS_function: 528,   LOSS_E:2.269e-06,    LOSS_initial: 0.234,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3851.890503883362\n",
      "loss_compared with real:0.071851,   miu_train:0.003515,    lossmean:-0.06731\n",
      "Epoch [51600/100000], Loss: 1273,   LOSS_function: 522.6,   LOSS_E:2.169e-06,    LOSS_initial: 0.2331,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3859.2003128528595\n",
      "loss_compared with real:0.071479,   miu_train:0.00352,    lossmean:-0.06707\n",
      "Epoch [51700/100000], Loss: 1269,   LOSS_function: 523.2,   LOSS_E:2.122e-06,    LOSS_initial: 0.232,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3866.5465445518494\n",
      "loss_compared with real:0.071272,   miu_train:0.003537,    lossmean:-0.06698\n",
      "Epoch [51800/100000], Loss: 1269,   LOSS_function: 524.9,   LOSS_E:2.052e-06,    LOSS_initial: 0.2318,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3873.91166472435\n",
      "loss_compared with real:0.071204,   miu_train:0.003535,    lossmean:-0.06674\n",
      "Epoch [51900/100000], Loss: 1266,   LOSS_function: 524.2,   LOSS_E:2.059e-06,    LOSS_initial: 0.2312,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3028,      learn rate:6.51e-05,    time: 3881.2560777664185\n",
      "loss_compared with real:0.071294,   miu_train:0.00354,    lossmean:-0.06676\n",
      "Epoch [52000/100000], Loss: 1253,   LOSS_function: 511.5,   LOSS_E:2.064e-06,    LOSS_initial: 0.2313,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3888.483907222748\n",
      "loss_compared with real:0.071202,   miu_train:0.003528,    lossmean:-0.06652\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5330, -0.5404, -0.3070, -0.9681, -0.0852, -0.3406,  0.4449, -0.8380,\n",
      "         0.9130,  0.3166,  0.7808,  0.5307,  0.6506, -0.0360,  0.6895, -0.3158,\n",
      "         0.8761,  0.0357,  0.8031, -0.7927, -0.2869, -0.9593, -0.5112, -0.3318,\n",
      "        -0.2965, -0.3992,  0.6949, -0.6638, -0.2456,  0.3939, -0.3167, -0.1893,\n",
      "         0.1085,  0.6405, -0.7310, -0.7975, -0.7194, -0.5743, -0.2579, -0.0521,\n",
      "        -0.8254, -0.9068, -0.0634,  0.7888, -0.6105,  0.8612, -0.6746,  0.8858,\n",
      "         0.6019, -0.9526, -0.7564, -0.3701,  0.8525, -0.5806,  0.9246, -0.1145,\n",
      "        -0.8721,  0.4168, -0.2715, -0.8578,  0.7892, -0.3317,  0.2650, -0.1109,\n",
      "        -0.5499, -0.0729, -0.0325,  0.4164, -0.4252, -0.3517,  0.6044, -0.4471,\n",
      "        -0.5096,  0.8759,  0.8034, -0.4369, -0.4520,  0.0150, -0.3375, -0.5507,\n",
      "        -0.7811, -0.7348,  0.9625,  0.0093,  0.1160,  0.8161,  0.7071,  0.2397,\n",
      "        -0.0340, -0.0775,  0.6693,  0.6932, -0.6782,  0.9045,  0.2283,  0.5602,\n",
      "        -0.6497, -0.1434,  0.6131,  0.0229, -0.8627,  0.0904, -0.0052, -0.2043,\n",
      "         0.4263,  0.4917,  0.6853,  0.0547,  0.2590,  0.6551, -0.6006, -0.2576,\n",
      "         0.5876,  0.7798,  0.7409, -0.0029, -0.9600,  0.9115, -0.3129, -0.8698,\n",
      "        -0.9544,  0.8930, -0.2210,  0.3788, -0.2413,  0.4229, -0.2104,  0.1853],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1042, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0177, -0.0255,  0.0260,  0.0814, -0.0571, -0.0344, -0.0252,  0.0269,\n",
      "        -0.0621,  0.0394, -0.0107, -0.0998,  0.0459, -0.0510,  0.0588,  0.0055,\n",
      "        -0.0273, -0.0270, -0.0346,  0.0529, -0.0642,  0.0588,  0.0256, -0.0151,\n",
      "         0.0176, -0.0030,  0.0683, -0.0469, -0.0171, -0.0762,  0.0172, -0.0804,\n",
      "         0.0855, -0.0313,  0.0583, -0.0004, -0.0527,  0.0537,  0.0491, -0.0482,\n",
      "        -0.0815, -0.0621,  0.0256,  0.0837,  0.0592,  0.0729, -0.0161,  0.0652,\n",
      "        -0.0314, -0.0197,  0.0534,  0.0117, -0.0214,  0.0059,  0.0080,  0.0051,\n",
      "         0.0508,  0.0528,  0.0587,  0.0389,  0.0086, -0.0491, -0.0404,  0.0464,\n",
      "         0.0655,  0.0042,  0.0449,  0.0250,  0.0516,  0.0234,  0.0622, -0.0009,\n",
      "        -0.0260, -0.0216, -0.0689,  0.0230, -0.0503,  0.0518, -0.0178,  0.0170,\n",
      "         0.0109, -0.0223, -0.0111,  0.0491,  0.0413, -0.0431, -0.0191, -0.0211,\n",
      "         0.0808,  0.0940,  0.0191,  0.0467, -0.0665, -0.0811,  0.0746, -0.0667,\n",
      "         0.0553,  0.0301,  0.0280,  0.0856,  0.0767,  0.0584,  0.0447,  0.0722,\n",
      "         0.0722,  0.0068, -0.0871, -0.0681,  0.0163, -0.0466,  0.0285,  0.0171,\n",
      "        -0.0506, -0.0432, -0.0033,  0.0425,  0.0559, -0.0754, -0.1149,  0.0398,\n",
      "         0.0643,  0.0240,  0.0225, -0.0216,  0.0025,  0.0243, -0.0614,  0.0773],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1211, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0494, -0.0504, -0.0497,  0.0471, -0.0313, -0.0335, -0.1115, -0.0018,\n",
      "        -0.0289,  0.0624, -0.0293, -0.0659, -0.0217,  0.0056, -0.0422, -0.0860,\n",
      "        -0.0573,  0.0537, -0.0081, -0.0820,  0.0129, -0.0224, -0.0545, -0.0324,\n",
      "         0.0254,  0.0215,  0.0494,  0.0541, -0.0542, -0.0679, -0.0421,  0.0385,\n",
      "         0.0453, -0.0341,  0.0571,  0.0547,  0.0730, -0.0144,  0.0140,  0.0859,\n",
      "        -0.0647,  0.0472,  0.0283, -0.0244,  0.0467,  0.0130, -0.0732, -0.0593,\n",
      "        -0.0346, -0.0388, -0.0666,  0.0385,  0.0718, -0.0709,  0.0510, -0.0209,\n",
      "         0.0211, -0.0715,  0.0214, -0.0696,  0.0409,  0.0498, -0.0180,  0.1108,\n",
      "         0.0740, -0.0378, -0.0022, -0.0123,  0.0012,  0.0182, -0.0788, -0.0127,\n",
      "         0.0148,  0.0468, -0.0199,  0.0248,  0.0752,  0.0288,  0.0040, -0.0088,\n",
      "         0.0798, -0.0488, -0.0755,  0.0914,  0.0203, -0.0083,  0.0291,  0.0854,\n",
      "        -0.0142, -0.0794,  0.0091, -0.0967,  0.0414, -0.0185, -0.0744,  0.0263,\n",
      "        -0.0445, -0.0573, -0.0680,  0.0674, -0.0785,  0.0276, -0.0128,  0.0403,\n",
      "        -0.0304, -0.0580,  0.0205, -0.0759, -0.0975, -0.0208, -0.0544,  0.0134,\n",
      "         0.0609, -0.1083, -0.0557, -0.0308, -0.0477, -0.0458,  0.0856, -0.0399,\n",
      "        -0.0442,  0.0409,  0.0615,  0.0819, -0.0590, -0.0839, -0.0136, -0.0537],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1021, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0390, -0.0777,  0.0158,  0.0794, -0.0831,  0.0302, -0.0179, -0.0221,\n",
      "         0.0811,  0.0415,  0.0215,  0.0639,  0.0238, -0.0617, -0.0513,  0.0614,\n",
      "        -0.0047,  0.0180, -0.0135, -0.0237,  0.0068,  0.0017,  0.0592,  0.0995,\n",
      "        -0.0055, -0.0290, -0.0089, -0.0272, -0.0034,  0.0726,  0.0017,  0.0501,\n",
      "         0.0038, -0.0086, -0.0346,  0.0429, -0.0647, -0.1053, -0.0692,  0.0106,\n",
      "         0.0977, -0.0844,  0.0350,  0.0330,  0.0700, -0.0526,  0.0782,  0.0083,\n",
      "        -0.0842, -0.0631,  0.0118, -0.0315,  0.0053,  0.0770,  0.0297,  0.0137,\n",
      "        -0.0273, -0.0581,  0.0607,  0.0307,  0.0212, -0.0633, -0.0245, -0.0305,\n",
      "         0.0122, -0.0514, -0.0405, -0.0279,  0.0377, -0.0782, -0.0491, -0.0282,\n",
      "        -0.0417,  0.0322, -0.0734, -0.0233, -0.0304, -0.0145,  0.0878, -0.0275,\n",
      "        -0.0386,  0.0716,  0.0055,  0.0471,  0.0154, -0.0531, -0.0038, -0.0376,\n",
      "         0.0059,  0.0158, -0.0174, -0.0950,  0.0718,  0.0429, -0.0194,  0.0692,\n",
      "        -0.0584, -0.0785,  0.0557, -0.0573, -0.0392,  0.0308, -0.0642, -0.0353,\n",
      "         0.0241,  0.0433,  0.0443, -0.0929,  0.0227, -0.0697,  0.0402,  0.0698,\n",
      "        -0.0610, -0.0675,  0.0610, -0.0159, -0.0991,  0.0360, -0.0363,  0.0510,\n",
      "         0.0353, -0.0387,  0.0417, -0.0867, -0.0104,  0.0494, -0.0120,  0.0586],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0791, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0531,  0.0562,  0.0744], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52100/100000], Loss: 1258,   LOSS_function: 517.4,   LOSS_E:1.999e-06,    LOSS_initial: 0.2314,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3895.73469042778\n",
      "loss_compared with real:0.071296,   miu_train:0.003522,    lossmean:-0.0665\n",
      "Epoch [52200/100000], Loss: 1246,   LOSS_function: 502.2,   LOSS_E:2.127e-06,    LOSS_initial: 0.2319,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3902.9494535923004\n",
      "loss_compared with real:0.0712,   miu_train:0.003506,    lossmean:-0.06634\n",
      "Epoch [52300/100000], Loss: 1236,   LOSS_function: 495.1,   LOSS_E:2.092e-06,    LOSS_initial: 0.2311,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3910.5070440769196\n",
      "loss_compared with real:0.071392,   miu_train:0.003519,    lossmean:-0.06639\n",
      "Epoch [52400/100000], Loss: 1236,   LOSS_function: 494.8,   LOSS_E:2.007e-06,    LOSS_initial: 0.2318,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3918.2590911388397\n",
      "loss_compared with real:0.07146,   miu_train:0.0035,    lossmean:-0.06631\n",
      "Epoch [52500/100000], Loss: 1248,   LOSS_function: 504.7,   LOSS_E:2.1e-06,    LOSS_initial: 0.2316,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3925.9313151836395\n",
      "loss_compared with real:0.071324,   miu_train:0.003489,    lossmean:-0.06613\n",
      "Epoch [52600/100000], Loss: 1239,   LOSS_function: 502.2,   LOSS_E:1.963e-06,    LOSS_initial: 0.2305,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3933.7628087997437\n",
      "loss_compared with real:0.071421,   miu_train:0.003502,    lossmean:-0.06618\n",
      "Epoch [52700/100000], Loss: 1236,   LOSS_function: 497.7,   LOSS_E:2.101e-06,    LOSS_initial: 0.2302,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3941.475823402405\n",
      "loss_compared with real:0.071596,   miu_train:0.003497,    lossmean:-0.06631\n",
      "Epoch [52800/100000], Loss: 1297,   LOSS_function: 489.6,   LOSS_E:5.293e-06,    LOSS_initial: 0.2317,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3949.337554216385\n",
      "loss_compared with real:0.071454,   miu_train:0.003446,    lossmean:-0.0661\n",
      "Epoch [52900/100000], Loss: 1254,   LOSS_function: 485.3,   LOSS_E:3.407e-06,    LOSS_initial: 0.2314,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:3022,      learn rate:6.197e-05,    time: 3957.1214377880096\n",
      "loss_compared with real:0.071478,   miu_train:0.003456,    lossmean:-0.06599\n",
      "Epoch [53000/100000], Loss: 1213,   LOSS_function: 487.4,   LOSS_E:2.043e-06,    LOSS_initial: 0.2315,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 3964.993396997452\n",
      "loss_compared with real:0.071855,   miu_train:0.003435,    lossmean:-0.06629\n",
      "Epoch [53100/100000], Loss: 1210,   LOSS_function: 477.7,   LOSS_E:2.063e-06,    LOSS_initial: 0.2334,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 3972.7860476970673\n",
      "loss_compared with real:0.072243,   miu_train:0.003393,    lossmean:-0.06644\n",
      "Epoch [53200/100000], Loss: 1219,   LOSS_function: 478.9,   LOSS_E:2.739e-06,    LOSS_initial: 0.2316,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 3980.6102929115295\n",
      "loss_compared with real:0.072723,   miu_train:0.00341,    lossmean:-0.06677\n",
      "Epoch [53300/100000], Loss: 1214,   LOSS_function: 483.1,   LOSS_E:2.151e-06,    LOSS_initial: 0.2326,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 3988.435751438141\n",
      "loss_compared with real:0.072681,   miu_train:0.003378,    lossmean:-0.06702\n",
      "Epoch [53400/100000], Loss: 1190,   LOSS_function: 453,   LOSS_E:2.14e-06,    LOSS_initial: 0.2345,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 3996.1369965076447\n",
      "loss_compared with real:0.073888,   miu_train:0.003326,    lossmean:-0.06646\n",
      "Epoch [53500/100000], Loss: 1217,   LOSS_function: 481.8,   LOSS_E:2.31e-06,    LOSS_initial: 0.2327,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 4004.0257370471954\n",
      "loss_compared with real:0.072575,   miu_train:0.003341,    lossmean:-0.06693\n",
      "Epoch [53600/100000], Loss: 1197,   LOSS_function: 444.2,   LOSS_E:2.77e-06,    LOSS_initial: 0.2357,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 4011.8662672042847\n",
      "loss_compared with real:0.074134,   miu_train:0.003278,    lossmean:-0.06521\n",
      "Epoch [53700/100000], Loss: 1197,   LOSS_function: 464.3,   LOSS_E:2.437e-06,    LOSS_initial: 0.2312,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 4019.676024198532\n",
      "loss_compared with real:0.072816,   miu_train:0.003344,    lossmean:-0.06725\n",
      "Epoch [53800/100000], Loss: 1205,   LOSS_function: 453.8,   LOSS_E:3.219e-06,    LOSS_initial: 0.2319,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 4027.4086334705353\n",
      "loss_compared with real:0.073201,   miu_train:0.003323,    lossmean:-0.06689\n",
      "Epoch [53900/100000], Loss: 1192,   LOSS_function: 450.1,   LOSS_E:2.677e-06,    LOSS_initial: 0.2327,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2955,      learn rate:5.9e-05,    time: 4035.1872203350067\n",
      "loss_compared with real:0.072653,   miu_train:0.003291,    lossmean:-0.06665\n",
      "Epoch [54000/100000], Loss: 1170,   LOSS_function: 450.1,   LOSS_E:2.362e-06,    LOSS_initial: 0.2323,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4043.1085839271545\n",
      "loss_compared with real:0.0731,   miu_train:0.003275,    lossmean:-0.06688\n",
      "Epoch [54100/100000], Loss: 1162,   LOSS_function: 435.2,   LOSS_E:2.309e-06,    LOSS_initial: 0.2353,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4050.8717999458313\n",
      "loss_compared with real:0.072688,   miu_train:0.003222,    lossmean:-0.06729\n",
      "Epoch [54200/100000], Loss: 1184,   LOSS_function: 433.2,   LOSS_E:3.905e-06,    LOSS_initial: 0.2324,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4058.7124452590942\n",
      "loss_compared with real:0.074129,   miu_train:0.003247,    lossmean:-0.06687\n",
      "Epoch [54300/100000], Loss: 1317,   LOSS_function: 437.4,   LOSS_E:1.005e-05,    LOSS_initial: 0.2338,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4066.3714299201965\n",
      "loss_compared with real:0.074411,   miu_train:0.003209,    lossmean:-0.06662\n",
      "Epoch [54400/100000], Loss: 1230,   LOSS_function: 445.1,   LOSS_E:5.839e-06,    LOSS_initial: 0.2306,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4073.5369691848755\n",
      "loss_compared with real:0.074236,   miu_train:0.003231,    lossmean:-0.06738\n",
      "Epoch [54500/100000], Loss: 1345,   LOSS_function: 439.2,   LOSS_E:1.127e-05,    LOSS_initial: 0.2344,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4080.703335762024\n",
      "loss_compared with real:0.073375,   miu_train:0.003155,    lossmean:-0.06779\n",
      "Epoch [54600/100000], Loss: 1167,   LOSS_function: 444.1,   LOSS_E:2.339e-06,    LOSS_initial: 0.2337,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4087.749852180481\n",
      "loss_compared with real:0.073116,   miu_train:0.003175,    lossmean:-0.0678\n",
      "Epoch [54700/100000], Loss: 1206,   LOSS_function: 427.8,   LOSS_E:5.138e-06,    LOSS_initial: 0.2334,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4094.9201078414917\n",
      "loss_compared with real:0.07455,   miu_train:0.00319,    lossmean:-0.06644\n",
      "Epoch [54800/100000], Loss: 1267,   LOSS_function: 437.2,   LOSS_E:7.837e-06,    LOSS_initial: 0.2321,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4102.062201976776\n",
      "loss_compared with real:0.07287,   miu_train:0.003159,    lossmean:-0.0679\n",
      "Epoch [54900/100000], Loss: 1314,   LOSS_function: 431,   LOSS_E:1.1e-05,    LOSS_initial: 0.2283,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2889,      learn rate:5.617e-05,    time: 4109.224758863449\n",
      "loss_compared with real:0.073813,   miu_train:0.003236,    lossmean:-0.06744\n",
      "Epoch [55000/100000], Loss: 1232,   LOSS_function: 422.8,   LOSS_E:8.039e-06,    LOSS_initial: 0.2318,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4116.344856739044\n",
      "loss_compared with real:0.072566,   miu_train:0.003171,    lossmean:-0.06798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55100/100000], Loss: 1143,   LOSS_function: 407,   LOSS_E:3.835e-06,    LOSS_initial: 0.2362,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4123.510652303696\n",
      "loss_compared with real:0.07385,   miu_train:0.003075,    lossmean:-0.06845\n",
      "Epoch [55200/100000], Loss: 1153,   LOSS_function: 405.5,   LOSS_E:4.191e-06,    LOSS_initial: 0.2378,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4130.636428833008\n",
      "loss_compared with real:0.074141,   miu_train:0.00302,    lossmean:-0.06881\n",
      "Epoch [55300/100000], Loss: 1165,   LOSS_function: 407.4,   LOSS_E:4.675e-06,    LOSS_initial: 0.238,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4137.86848282814\n",
      "loss_compared with real:0.073681,   miu_train:0.003016,    lossmean:-0.06897\n",
      "Epoch [55400/100000], Loss: 1844,   LOSS_function: 407.2,   LOSS_E:3.852e-05,    LOSS_initial: 0.2353,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4145.090172767639\n",
      "loss_compared with real:0.074433,   miu_train:0.003013,    lossmean:-0.06889\n",
      "Epoch [55500/100000], Loss: 1160,   LOSS_function: 402.8,   LOSS_E:4.692e-06,    LOSS_initial: 0.2376,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4152.267082929611\n",
      "loss_compared with real:0.073486,   miu_train:0.002982,    lossmean:-0.06875\n",
      "Epoch [55600/100000], Loss: 2048,   LOSS_function: 410.6,   LOSS_E:4.847e-05,    LOSS_initial: 0.2347,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4159.546383857727\n",
      "loss_compared with real:0.075987,   miu_train:0.003035,    lossmean:-0.06673\n",
      "Epoch [55700/100000], Loss: 1119,   LOSS_function: 408,   LOSS_E:2.661e-06,    LOSS_initial: 0.2357,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4166.721668243408\n",
      "loss_compared with real:0.073521,   miu_train:0.003,    lossmean:-0.06903\n",
      "Epoch [55800/100000], Loss: 1140,   LOSS_function: 415.6,   LOSS_E:3.298e-06,    LOSS_initial: 0.2361,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4174.082087755203\n",
      "loss_compared with real:0.07376,   miu_train:0.002981,    lossmean:-0.06815\n",
      "Epoch [55900/100000], Loss: 1103,   LOSS_function: 389.3,   LOSS_E:2.685e-06,    LOSS_initial: 0.2368,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2785,      learn rate:5.347e-05,    time: 4181.237044811249\n",
      "loss_compared with real:0.073342,   miu_train:0.002981,    lossmean:-0.06889\n",
      "Epoch [56000/100000], Loss: 1085,   LOSS_function: 401.4,   LOSS_E:2.713e-06,    LOSS_initial: 0.2373,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4188.389565706253\n",
      "loss_compared with real:0.073351,   miu_train:0.002938,    lossmean:-0.06912\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5330, -0.5402, -0.3073, -0.9684, -0.0854, -0.3408,  0.4451, -0.8378,\n",
      "         0.9129,  0.3167,  0.7815,  0.5308,  0.6507, -0.0357,  0.6895, -0.3153,\n",
      "         0.8760,  0.0368,  0.8029, -0.7935, -0.2863, -0.9595, -0.5115, -0.3321,\n",
      "        -0.2971, -0.3996,  0.6945, -0.6637, -0.2463,  0.3918, -0.3162, -0.1893,\n",
      "         0.1084,  0.6405, -0.7307, -0.7975, -0.7195, -0.5739, -0.2593, -0.0516,\n",
      "        -0.8251, -0.9064, -0.0640,  0.7894, -0.6107,  0.8613, -0.6741,  0.8858,\n",
      "         0.6016, -0.9524, -0.7570, -0.3703,  0.8530, -0.5806,  0.9248, -0.1146,\n",
      "        -0.8731,  0.4172, -0.2719, -0.8577,  0.7892, -0.3317,  0.2653, -0.1108,\n",
      "        -0.5497, -0.0722, -0.0327,  0.4165, -0.4251, -0.3515,  0.6045, -0.4479,\n",
      "        -0.5095,  0.8759,  0.8034, -0.4372, -0.4527,  0.0145, -0.3380, -0.5500,\n",
      "        -0.7812, -0.7348,  0.9632,  0.0092,  0.1158,  0.8160,  0.7070,  0.2399,\n",
      "        -0.0336, -0.0781,  0.6690,  0.6932, -0.6783,  0.9045,  0.2281,  0.5599,\n",
      "        -0.6498, -0.1433,  0.6131,  0.0222, -0.8628,  0.0905, -0.0051, -0.2030,\n",
      "         0.4263,  0.4914,  0.6853,  0.0542,  0.2591,  0.6550, -0.6008, -0.2576,\n",
      "         0.5872,  0.7801,  0.7404, -0.0037, -0.9600,  0.9121, -0.3134, -0.8695,\n",
      "        -0.9543,  0.8912, -0.2208,  0.3774, -0.2415,  0.4231, -0.2101,  0.1856],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1042, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0185, -0.0258,  0.0257,  0.0816, -0.0568, -0.0344, -0.0252,  0.0273,\n",
      "        -0.0629,  0.0387, -0.0107, -0.0997,  0.0477, -0.0513,  0.0588,  0.0052,\n",
      "        -0.0266, -0.0274, -0.0358,  0.0557, -0.0648,  0.0582,  0.0260, -0.0150,\n",
      "         0.0180, -0.0034,  0.0680, -0.0474, -0.0171, -0.0761,  0.0176, -0.0805,\n",
      "         0.0847, -0.0313,  0.0589, -0.0008, -0.0525,  0.0532,  0.0493, -0.0492,\n",
      "        -0.0815, -0.0619,  0.0249,  0.0836,  0.0590,  0.0728, -0.0174,  0.0659,\n",
      "        -0.0319, -0.0195,  0.0552,  0.0131, -0.0215,  0.0063,  0.0082,  0.0050,\n",
      "         0.0511,  0.0536,  0.0591,  0.0372,  0.0102, -0.0492, -0.0401,  0.0457,\n",
      "         0.0654,  0.0042,  0.0451,  0.0251,  0.0526,  0.0240,  0.0618, -0.0023,\n",
      "        -0.0263, -0.0220, -0.0684,  0.0234, -0.0501,  0.0522, -0.0179,  0.0172,\n",
      "         0.0108, -0.0225, -0.0113,  0.0494,  0.0414, -0.0424, -0.0188, -0.0212,\n",
      "         0.0801,  0.0951,  0.0194,  0.0462, -0.0673, -0.0812,  0.0746, -0.0670,\n",
      "         0.0555,  0.0305,  0.0281,  0.0869,  0.0772,  0.0586,  0.0441,  0.0718,\n",
      "         0.0728,  0.0068, -0.0866, -0.0682,  0.0164, -0.0479,  0.0287,  0.0174,\n",
      "        -0.0504, -0.0443, -0.0018,  0.0424,  0.0574, -0.0768, -0.1151,  0.0404,\n",
      "         0.0642,  0.0238,  0.0241, -0.0225,  0.0023,  0.0239, -0.0611,  0.0768],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1211, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0495, -0.0507, -0.0493,  0.0474, -0.0313, -0.0335, -0.1115, -0.0022,\n",
      "        -0.0288,  0.0624, -0.0290, -0.0658, -0.0214,  0.0053, -0.0420, -0.0861,\n",
      "        -0.0583,  0.0537, -0.0082, -0.0815,  0.0126, -0.0224, -0.0545, -0.0323,\n",
      "         0.0260,  0.0215,  0.0493,  0.0530, -0.0542, -0.0679, -0.0423,  0.0383,\n",
      "         0.0451, -0.0339,  0.0569,  0.0542,  0.0731, -0.0144,  0.0139,  0.0851,\n",
      "        -0.0649,  0.0473,  0.0285, -0.0245,  0.0465,  0.0131, -0.0744, -0.0577,\n",
      "        -0.0352, -0.0390, -0.0664,  0.0391,  0.0733, -0.0712,  0.0510, -0.0208,\n",
      "         0.0210, -0.0716,  0.0213, -0.0696,  0.0410,  0.0496, -0.0174,  0.1107,\n",
      "         0.0739, -0.0379, -0.0014, -0.0124,  0.0010,  0.0182, -0.0791, -0.0124,\n",
      "         0.0146,  0.0467, -0.0200,  0.0244,  0.0752,  0.0278,  0.0046, -0.0069,\n",
      "         0.0799, -0.0487, -0.0753,  0.0913,  0.0203, -0.0083,  0.0294,  0.0854,\n",
      "        -0.0140, -0.0792,  0.0088, -0.0967,  0.0414, -0.0188, -0.0750,  0.0263,\n",
      "        -0.0430, -0.0576, -0.0680,  0.0675, -0.0785,  0.0273, -0.0126,  0.0405,\n",
      "        -0.0304, -0.0580,  0.0203, -0.0762, -0.0976, -0.0207, -0.0536,  0.0133,\n",
      "         0.0612, -0.1083, -0.0558, -0.0310, -0.0477, -0.0459,  0.0857, -0.0398,\n",
      "        -0.0440,  0.0411,  0.0615,  0.0819, -0.0586, -0.0840, -0.0139, -0.0535],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1021, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0391, -0.0791,  0.0170,  0.0795, -0.0835,  0.0302, -0.0182, -0.0224,\n",
      "         0.0814,  0.0416,  0.0219,  0.0638,  0.0231, -0.0611, -0.0513,  0.0614,\n",
      "        -0.0049,  0.0180, -0.0136, -0.0238,  0.0067,  0.0017,  0.0593,  0.0996,\n",
      "        -0.0061, -0.0288, -0.0087, -0.0253, -0.0068,  0.0720,  0.0029,  0.0499,\n",
      "         0.0037, -0.0087, -0.0344,  0.0464, -0.0646, -0.1051, -0.0689,  0.0098,\n",
      "         0.0975, -0.0843,  0.0349,  0.0329,  0.0698, -0.0527,  0.0788,  0.0083,\n",
      "        -0.0843, -0.0631,  0.0124, -0.0316,  0.0052,  0.0771,  0.0295,  0.0136,\n",
      "        -0.0273, -0.0582,  0.0607,  0.0308,  0.0214, -0.0635, -0.0246, -0.0303,\n",
      "         0.0129, -0.0514, -0.0408, -0.0277,  0.0383, -0.0778, -0.0493, -0.0282,\n",
      "        -0.0417,  0.0289, -0.0736, -0.0232, -0.0304, -0.0143,  0.0877, -0.0271,\n",
      "        -0.0384,  0.0706,  0.0037,  0.0465,  0.0158, -0.0530, -0.0039, -0.0377,\n",
      "         0.0060,  0.0156, -0.0173, -0.0952,  0.0718,  0.0428, -0.0193,  0.0696,\n",
      "        -0.0584, -0.0785,  0.0556, -0.0575, -0.0390,  0.0308, -0.0646, -0.0353,\n",
      "         0.0243,  0.0432,  0.0440, -0.0929,  0.0256, -0.0701,  0.0391,  0.0697,\n",
      "        -0.0611, -0.0676,  0.0604, -0.0159, -0.0981,  0.0335, -0.0364,  0.0512,\n",
      "         0.0355, -0.0387,  0.0418, -0.0868, -0.0114,  0.0496, -0.0121,  0.0586],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0791, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0437,  0.0510,  0.0814], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56100/100000], Loss: 1066,   LOSS_function: 371,   LOSS_E:2.665e-06,    LOSS_initial: 0.242,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4195.650913238525\n",
      "loss_compared with real:0.075123,   miu_train:0.002843,    lossmean:-0.06986\n",
      "Epoch [56200/100000], Loss: 1207,   LOSS_function: 397.6,   LOSS_E:8.508e-06,    LOSS_initial: 0.2405,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4202.879946947098\n",
      "loss_compared with real:0.075955,   miu_train:0.00287,    lossmean:-0.06986\n",
      "Epoch [56300/100000], Loss: 1322,   LOSS_function: 368.1,   LOSS_E:1.541e-05,    LOSS_initial: 0.2419,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4210.247080087662\n",
      "loss_compared with real:0.075844,   miu_train:0.002853,    lossmean:-0.06979\n",
      "Epoch [56400/100000], Loss: 1074,   LOSS_function: 367.6,   LOSS_E:3.375e-06,    LOSS_initial: 0.2409,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4217.940217256546\n",
      "loss_compared with real:0.075837,   miu_train:0.002854,    lossmean:-0.06958\n",
      "Epoch [56500/100000], Loss: 1055,   LOSS_function: 360.6,   LOSS_E:2.364e-06,    LOSS_initial: 0.2438,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4225.781964302063\n",
      "loss_compared with real:0.075314,   miu_train:0.002766,    lossmean:-0.0699\n",
      "Epoch [56600/100000], Loss: 1074,   LOSS_function: 376.8,   LOSS_E:2.615e-06,    LOSS_initial: 0.2431,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4233.535208940506\n",
      "loss_compared with real:0.075032,   miu_train:0.002777,    lossmean:-0.0705\n",
      "Epoch [56700/100000], Loss: 1070,   LOSS_function: 369.9,   LOSS_E:2.922e-06,    LOSS_initial: 0.242,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4241.3926503658295\n",
      "loss_compared with real:0.07428,   miu_train:0.002811,    lossmean:-0.06975\n",
      "Epoch [56800/100000], Loss: 1949,   LOSS_function: 364.1,   LOSS_E:4.666e-05,    LOSS_initial: 0.2408,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4249.12292098999\n",
      "loss_compared with real:0.074779,   miu_train:0.002847,    lossmean:-0.07014\n",
      "Epoch [56900/100000], Loss: 1698,   LOSS_function: 374.7,   LOSS_E:3.42e-05,    LOSS_initial: 0.2375,\n",
      "lamda1:1,    lamda2:2.029e+07,    lamda3:2649,      learn rate:5.09e-05,    time: 4256.8799459934235\n",
      "loss_compared with real:0.075202,   miu_train:0.002872,    lossmean:-0.07001\n",
      "Epoch [57000/100000], Loss: 1406,   LOSS_function: 371.1,   LOSS_E:0.0001008,    LOSS_initial: 0.2375,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4264.719338417053\n",
      "loss_compared with real:0.074356,   miu_train:0.002902,    lossmean:-0.06989\n",
      "Epoch [57100/100000], Loss: 982.6,   LOSS_function: 380.8,   LOSS_E:3.153e-06,    LOSS_initial: 0.233,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4272.53022646904\n",
      "loss_compared with real:0.07459,   miu_train:0.002862,    lossmean:-0.06954\n",
      "Epoch [57200/100000], Loss: 965.8,   LOSS_function: 368.2,   LOSS_E:3.383e-06,    LOSS_initial: 0.2309,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4280.267298698425\n",
      "loss_compared with real:0.073804,   miu_train:0.002865,    lossmean:-0.06836\n",
      "Epoch [57300/100000], Loss: 947.1,   LOSS_function: 351.4,   LOSS_E:3.66e-06,    LOSS_initial: 0.2297,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4288.089994192123\n",
      "loss_compared with real:0.073117,   miu_train:0.002869,    lossmean:-0.06799\n",
      "Epoch [57400/100000], Loss: 981.4,   LOSS_function: 387.6,   LOSS_E:4.108e-06,    LOSS_initial: 0.2281,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4295.944414615631\n",
      "loss_compared with real:0.072508,   miu_train:0.002854,    lossmean:-0.0675\n",
      "Epoch [57500/100000], Loss: 971.7,   LOSS_function: 380.3,   LOSS_E:4.361e-06,    LOSS_initial: 0.2268,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4303.816038608551\n",
      "loss_compared with real:0.072217,   miu_train:0.002852,    lossmean:-0.06738\n",
      "Epoch [57600/100000], Loss: 961.3,   LOSS_function: 376.9,   LOSS_E:4.57e-06,    LOSS_initial: 0.2236,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4311.550025939941\n",
      "loss_compared with real:0.071978,   miu_train:0.002886,    lossmean:-0.06726\n",
      "Epoch [57700/100000], Loss: 952.4,   LOSS_function: 363.6,   LOSS_E:4.66e-06,    LOSS_initial: 0.2252,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4319.26984333992\n",
      "loss_compared with real:0.071082,   miu_train:0.002856,    lossmean:-0.06683\n",
      "Epoch [57800/100000], Loss: 940.3,   LOSS_function: 352.2,   LOSS_E:4.763e-06,    LOSS_initial: 0.2247,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4327.059937238693\n",
      "loss_compared with real:0.070275,   miu_train:0.002838,    lossmean:-0.06603\n",
      "Epoch [57900/100000], Loss: 957.5,   LOSS_function: 380.7,   LOSS_E:5.114e-06,    LOSS_initial: 0.2197,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2524,      learn rate:4.846e-05,    time: 4334.915757894516\n",
      "loss_compared with real:0.069971,   miu_train:0.002874,    lossmean:-0.06576\n",
      "Epoch [58000/100000], Loss: 955,   LOSS_function: 376.8,   LOSS_E:4.816e-06,    LOSS_initial: 0.2206,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4342.725772380829\n",
      "loss_compared with real:0.070265,   miu_train:0.002857,    lossmean:-0.06596\n",
      "Epoch [58100/100000], Loss: 930.6,   LOSS_function: 348.6,   LOSS_E:5.01e-06,    LOSS_initial: 0.2218,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4350.538306713104\n",
      "loss_compared with real:0.06956,   miu_train:0.002833,    lossmean:-0.06511\n",
      "Epoch [58200/100000], Loss: 944.8,   LOSS_function: 373.1,   LOSS_E:5.295e-06,    LOSS_initial: 0.2172,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4358.315936803818\n",
      "loss_compared with real:0.069356,   miu_train:0.002872,    lossmean:-0.06531\n",
      "Epoch [58300/100000], Loss: 933.9,   LOSS_function: 362.7,   LOSS_E:5.237e-06,    LOSS_initial: 0.2171,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4366.256628751755\n",
      "loss_compared with real:0.068629,   miu_train:0.002882,    lossmean:-0.06477\n",
      "Epoch [58400/100000], Loss: 918.8,   LOSS_function: 357.8,   LOSS_E:5.315e-06,    LOSS_initial: 0.2129,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4373.564067363739\n",
      "loss_compared with real:0.068208,   miu_train:0.002921,    lossmean:-0.06486\n",
      "Epoch [58500/100000], Loss: 921.6,   LOSS_function: 359,   LOSS_E:5.013e-06,    LOSS_initial: 0.2141,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4380.693968296051\n",
      "loss_compared with real:0.067577,   miu_train:0.002896,    lossmean:-0.06419\n",
      "Epoch [58600/100000], Loss: 912.4,   LOSS_function: 357.2,   LOSS_E:5.1e-06,    LOSS_initial: 0.211,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4387.813238859177\n",
      "loss_compared with real:0.067236,   miu_train:0.002923,    lossmean:-0.06371\n",
      "Epoch [58700/100000], Loss: 916,   LOSS_function: 355.7,   LOSS_E:5.389e-06,    LOSS_initial: 0.2125,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4394.931718349457\n",
      "loss_compared with real:0.066491,   miu_train:0.002859,    lossmean:-0.06293\n",
      "Epoch [58800/100000], Loss: 900.6,   LOSS_function: 348.7,   LOSS_E:5.487e-06,    LOSS_initial: 0.209,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4402.098945379257\n",
      "loss_compared with real:0.066377,   miu_train:0.002915,    lossmean:-0.06265\n",
      "Epoch [58900/100000], Loss: 917,   LOSS_function: 356.5,   LOSS_E:5.436e-06,    LOSS_initial: 0.2125,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2526,      learn rate:4.614e-05,    time: 4409.1417491436005\n",
      "loss_compared with real:0.065744,   miu_train:0.00283,    lossmean:-0.06168\n",
      "Epoch [59000/100000], Loss: 909.5,   LOSS_function: 376.9,   LOSS_E:5.169e-06,    LOSS_initial: 0.2066,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4416.414242267609\n",
      "loss_compared with real:0.064893,   miu_train:0.002854,    lossmean:-0.06156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59100/100000], Loss: 875.7,   LOSS_function: 340.8,   LOSS_E:5.831e-06,    LOSS_initial: 0.2064,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4423.548321485519\n",
      "loss_compared with real:0.066156,   miu_train:0.002894,    lossmean:-0.0622\n",
      "Epoch [59200/100000], Loss: 893.4,   LOSS_function: 366.4,   LOSS_E:4.949e-06,    LOSS_initial: 0.2047,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4430.859430551529\n",
      "loss_compared with real:0.064849,   miu_train:0.002872,    lossmean:-0.06159\n",
      "Epoch [59300/100000], Loss: 892,   LOSS_function: 359.7,   LOSS_E:4.67e-06,    LOSS_initial: 0.2073,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4438.088266134262\n",
      "loss_compared with real:0.064367,   miu_train:0.002867,    lossmean:-0.06118\n",
      "Epoch [59400/100000], Loss: 870.2,   LOSS_function: 333.9,   LOSS_E:4.497e-06,    LOSS_initial: 0.2093,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4445.128479242325\n",
      "loss_compared with real:0.063426,   miu_train:0.002862,    lossmean:-0.06016\n",
      "Epoch [59500/100000], Loss: 875.5,   LOSS_function: 360,   LOSS_E:5.345e-06,    LOSS_initial: 0.1994,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4452.325234889984\n",
      "loss_compared with real:0.063044,   miu_train:0.002894,    lossmean:-0.06023\n",
      "Epoch [59600/100000], Loss: 895.4,   LOSS_function: 376.7,   LOSS_E:5.352e-06,    LOSS_initial: 0.2007,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4459.617371559143\n",
      "loss_compared with real:0.062341,   miu_train:0.002831,    lossmean:-0.0597\n",
      "Epoch [59700/100000], Loss: 853.8,   LOSS_function: 337.2,   LOSS_E:5.008e-06,    LOSS_initial: 0.2004,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4466.8735864162445\n",
      "loss_compared with real:0.062323,   miu_train:0.002926,    lossmean:-0.05999\n",
      "Epoch [59800/100000], Loss: 889.3,   LOSS_function: 378.9,   LOSS_E:6.352e-06,    LOSS_initial: 0.1955,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4474.06006026268\n",
      "loss_compared with real:0.061291,   miu_train:0.002938,    lossmean:-0.05884\n",
      "Epoch [59900/100000], Loss: 896,   LOSS_function: 361.8,   LOSS_E:1.155e-05,    LOSS_initial: 0.1961,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2469,      learn rate:4.392e-05,    time: 4481.20036649704\n",
      "loss_compared with real:0.060606,   miu_train:0.002906,    lossmean:-0.05811\n",
      "Epoch [60000/100000], Loss: 803.2,   LOSS_function: 337.2,   LOSS_E:5.669e-06,    LOSS_initial: 0.1992,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4488.397862434387\n",
      "loss_compared with real:0.059448,   miu_train:0.002739,    lossmean:-0.05724\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5328, -0.5399, -0.3077, -0.9687, -0.0860, -0.3410,  0.4451, -0.8376,\n",
      "         0.9126,  0.3168,  0.7832,  0.5307,  0.6507, -0.0348,  0.6897, -0.3142,\n",
      "         0.8759,  0.0375,  0.8026, -0.7952, -0.2850, -0.9597, -0.5118, -0.3322,\n",
      "        -0.2972, -0.3999,  0.6945, -0.6639, -0.2479,  0.3898, -0.3143, -0.1893,\n",
      "         0.1082,  0.6405, -0.7299, -0.7973, -0.7198, -0.5733, -0.2645, -0.0506,\n",
      "        -0.8241, -0.9063, -0.0650,  0.7901, -0.6111,  0.8615, -0.6729,  0.8858,\n",
      "         0.6008, -0.9522, -0.7577, -0.3705,  0.8538, -0.5808,  0.9252, -0.1147,\n",
      "        -0.8785,  0.4175, -0.2726, -0.8576,  0.7888, -0.3316,  0.2653, -0.1109,\n",
      "        -0.5495, -0.0705, -0.0331,  0.4167, -0.4248, -0.3508,  0.6046, -0.4488,\n",
      "        -0.5093,  0.8760,  0.8032, -0.4371, -0.4544,  0.0131, -0.3393, -0.5497,\n",
      "        -0.7813, -0.7346,  0.9632,  0.0093,  0.1153,  0.8156,  0.7069,  0.2399,\n",
      "        -0.0330, -0.0787,  0.6686,  0.6929, -0.6783,  0.9044,  0.2279,  0.5595,\n",
      "        -0.6498, -0.1431,  0.6137,  0.0211, -0.8634,  0.0905, -0.0046, -0.2021,\n",
      "         0.4262,  0.4909,  0.6852,  0.0534,  0.2598,  0.6547, -0.6011, -0.2576,\n",
      "         0.5877,  0.7807,  0.7397, -0.0057, -0.9600,  0.9130, -0.3140, -0.8690,\n",
      "        -0.9541,  0.8888, -0.2205,  0.3760, -0.2415,  0.4233, -0.2088,  0.1857],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1049, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 2.0415e-02, -2.5618e-02,  2.5130e-02,  8.1403e-02, -5.6970e-02,\n",
      "        -3.4273e-02, -2.5491e-02,  2.7601e-02, -6.2760e-02,  3.8180e-02,\n",
      "        -1.0597e-02, -9.9636e-02,  4.9530e-02, -5.2219e-02,  5.8893e-02,\n",
      "         4.5824e-03, -2.6025e-02, -2.7845e-02, -3.7022e-02,  6.4314e-02,\n",
      "        -6.4369e-02,  5.7372e-02,  2.6108e-02, -1.4932e-02,  1.8481e-02,\n",
      "        -4.3298e-03,  6.7796e-02, -4.7304e-02, -1.7012e-02, -7.6128e-02,\n",
      "         1.7884e-02, -8.0685e-02,  8.3929e-02, -3.1205e-02,  5.9932e-02,\n",
      "        -1.1488e-03, -5.2304e-02,  5.3001e-02,  4.9367e-02, -5.0224e-02,\n",
      "        -8.1623e-02, -6.1808e-02,  2.4340e-02,  8.3560e-02,  5.9026e-02,\n",
      "         7.2551e-02, -1.8308e-02,  6.6376e-02, -3.2296e-02, -1.9442e-02,\n",
      "         6.0147e-02,  1.5586e-02, -2.2046e-02,  6.8455e-03,  8.3531e-03,\n",
      "         5.0716e-03,  5.1682e-02,  5.4689e-02,  5.9198e-02,  3.5833e-02,\n",
      "         1.1015e-02, -4.9286e-02, -4.0131e-02,  4.4582e-02,  6.5333e-02,\n",
      "         4.3298e-03,  4.5229e-02,  2.5172e-02,  5.2663e-02,  2.4864e-02,\n",
      "         6.1676e-02, -8.1827e-03, -2.6511e-02, -2.2229e-02, -6.7466e-02,\n",
      "         2.3892e-02, -5.0620e-02,  5.2283e-02, -1.8147e-02,  1.7407e-02,\n",
      "         1.0763e-02, -2.3096e-02, -1.1680e-02,  4.9806e-02,  4.1422e-02,\n",
      "        -4.0493e-02, -1.8397e-02, -2.1399e-02,  7.9471e-02,  9.6861e-02,\n",
      "         1.9337e-02,  4.4685e-02, -6.8792e-02, -8.0813e-02,  7.4452e-02,\n",
      "        -6.7544e-02,  5.6736e-02,  3.1763e-02,  2.8780e-02,  8.7945e-02,\n",
      "         7.7902e-02,  5.8769e-02,  4.3615e-02,  7.0957e-02,  7.4115e-02,\n",
      "         6.7960e-03, -8.6194e-02, -6.8205e-02,  1.6905e-02, -5.1039e-02,\n",
      "         2.8878e-02,  1.7871e-02, -4.9958e-02, -4.8530e-02,  4.2521e-05,\n",
      "         4.2417e-02,  5.7911e-02, -8.0228e-02, -1.1611e-01,  4.0730e-02,\n",
      "         6.3510e-02,  2.3695e-02,  2.5499e-02, -2.3877e-02, -3.2732e-04,\n",
      "         2.3611e-02, -6.0865e-02,  7.5794e-02], requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1217, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0495, -0.0510, -0.0484,  0.0478, -0.0313, -0.0335, -0.1114, -0.0020,\n",
      "        -0.0288,  0.0623, -0.0289, -0.0655, -0.0211,  0.0045, -0.0422, -0.0867,\n",
      "        -0.0607,  0.0539, -0.0084, -0.0809,  0.0117, -0.0225, -0.0546, -0.0323,\n",
      "         0.0270,  0.0217,  0.0491,  0.0523, -0.0542, -0.0679, -0.0427,  0.0382,\n",
      "         0.0450, -0.0337,  0.0569,  0.0526,  0.0728, -0.0144,  0.0135,  0.0849,\n",
      "        -0.0650,  0.0472,  0.0288, -0.0246,  0.0462,  0.0131, -0.0752, -0.0562,\n",
      "        -0.0355, -0.0394, -0.0665,  0.0395,  0.0767, -0.0714,  0.0513, -0.0208,\n",
      "         0.0208, -0.0716,  0.0212, -0.0715,  0.0411,  0.0499, -0.0168,  0.1104,\n",
      "         0.0749, -0.0379, -0.0007, -0.0125,  0.0004,  0.0181, -0.0791, -0.0122,\n",
      "         0.0145,  0.0465, -0.0201,  0.0244,  0.0752,  0.0270,  0.0051, -0.0063,\n",
      "         0.0800, -0.0487, -0.0752,  0.0913,  0.0204, -0.0081,  0.0295,  0.0855,\n",
      "        -0.0137, -0.0790,  0.0086, -0.0966,  0.0413, -0.0193, -0.0752,  0.0262,\n",
      "        -0.0416, -0.0574, -0.0680,  0.0678, -0.0786,  0.0266, -0.0122,  0.0411,\n",
      "        -0.0306, -0.0579,  0.0204, -0.0762, -0.0972, -0.0207, -0.0518,  0.0133,\n",
      "         0.0615, -0.1083, -0.0559, -0.0314, -0.0479, -0.0458,  0.0857, -0.0397,\n",
      "        -0.0439,  0.0412,  0.0615,  0.0818, -0.0575, -0.0840, -0.0144, -0.0534],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1025, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0391, -0.0798,  0.0174,  0.0794, -0.0844,  0.0302, -0.0186, -0.0224,\n",
      "         0.0810,  0.0416,  0.0226,  0.0637,  0.0232, -0.0607, -0.0517,  0.0614,\n",
      "        -0.0048,  0.0180, -0.0133, -0.0239,  0.0060,  0.0018,  0.0593,  0.0996,\n",
      "        -0.0067, -0.0286, -0.0085, -0.0246, -0.0079,  0.0701,  0.0050,  0.0503,\n",
      "         0.0039, -0.0086, -0.0344,  0.0483, -0.0645, -0.1051, -0.0693,  0.0102,\n",
      "         0.0973, -0.0843,  0.0349,  0.0329,  0.0698, -0.0532,  0.0793,  0.0084,\n",
      "        -0.0843, -0.0627,  0.0131, -0.0316,  0.0051,  0.0768,  0.0294,  0.0134,\n",
      "        -0.0272, -0.0584,  0.0608,  0.0307,  0.0215, -0.0636, -0.0246, -0.0303,\n",
      "         0.0134, -0.0513, -0.0411, -0.0277,  0.0389, -0.0778, -0.0496, -0.0281,\n",
      "        -0.0417,  0.0272, -0.0742, -0.0232, -0.0303, -0.0141,  0.0876, -0.0270,\n",
      "        -0.0381,  0.0700,  0.0033,  0.0462,  0.0161, -0.0527, -0.0059, -0.0377,\n",
      "         0.0060,  0.0153, -0.0176, -0.0952,  0.0717,  0.0427, -0.0193,  0.0702,\n",
      "        -0.0584, -0.0784,  0.0554, -0.0576, -0.0388,  0.0308, -0.0651, -0.0362,\n",
      "         0.0244,  0.0431,  0.0442, -0.0929,  0.0234, -0.0705,  0.0407,  0.0699,\n",
      "        -0.0617, -0.0675,  0.0602, -0.0155, -0.0966,  0.0310, -0.0364,  0.0500,\n",
      "         0.0355, -0.0386,  0.0423, -0.0865, -0.0119,  0.0497, -0.0121,  0.0585],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0793, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0193,  0.0577,  0.0864], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60100/100000], Loss: 848.3,   LOSS_function: 331,   LOSS_E:1.03e-05,    LOSS_initial: 0.2134,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4495.65867805481\n",
      "loss_compared with real:0.06467,   miu_train:0.002597,    lossmean:-0.0609\n",
      "Epoch [60200/100000], Loss: 840.3,   LOSS_function: 318.9,   LOSS_E:1.207e-05,    LOSS_initial: 0.2118,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4502.871577978134\n",
      "loss_compared with real:0.065275,   miu_train:0.002682,    lossmean:-0.06129\n",
      "Epoch [60300/100000], Loss: 837.5,   LOSS_function: 344.6,   LOSS_E:4.819e-06,    LOSS_initial: 0.213,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4510.022583246231\n",
      "loss_compared with real:0.064423,   miu_train:0.002628,    lossmean:-0.06098\n",
      "Epoch [60400/100000], Loss: 826.9,   LOSS_function: 331.1,   LOSS_E:6.055e-06,    LOSS_initial: 0.2119,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4517.820188522339\n",
      "loss_compared with real:0.063847,   miu_train:0.002653,    lossmean:-0.06113\n",
      "Epoch [60500/100000], Loss: 926.4,   LOSS_function: 324,   LOSS_E:3.219e-05,    LOSS_initial: 0.2091,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4525.538041114807\n",
      "loss_compared with real:0.063524,   miu_train:0.002651,    lossmean:-0.06003\n",
      "Epoch [60600/100000], Loss: 909.5,   LOSS_function: 327.4,   LOSS_E:2.678e-05,    LOSS_initial: 0.2104,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4533.288533449173\n",
      "loss_compared with real:0.064093,   miu_train:0.002617,    lossmean:-0.06075\n",
      "Epoch [60700/100000], Loss: 827.8,   LOSS_function: 342.5,   LOSS_E:5.019e-06,    LOSS_initial: 0.2092,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4541.121885061264\n",
      "loss_compared with real:0.062881,   miu_train:0.002663,    lossmean:-0.06021\n",
      "Epoch [60800/100000], Loss: 823,   LOSS_function: 315.3,   LOSS_E:1.176e-05,    LOSS_initial: 0.2062,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4548.940080165863\n",
      "loss_compared with real:0.063243,   miu_train:0.002727,    lossmean:-0.0601\n",
      "Epoch [60900/100000], Loss: 814.6,   LOSS_function: 329.4,   LOSS_E:4.598e-06,    LOSS_initial: 0.21,\n",
      "lamda1:1,    lamda2:4.319e+06,    lamda3:2215,      learn rate:4.181e-05,    time: 4556.673357725143\n",
      "loss_compared with real:0.063026,   miu_train:0.00269,    lossmean:-0.0599\n",
      "Epoch [61000/100000], Loss: 751.5,   LOSS_function: 307,   LOSS_E:5.739e-06,    LOSS_initial: 0.21,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4564.660575866699\n",
      "loss_compared with real:0.062757,   miu_train:0.002608,    lossmean:-0.0598\n",
      "Epoch [61100/100000], Loss: 755.9,   LOSS_function: 295.2,   LOSS_E:4.449e-06,    LOSS_initial: 0.221,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4572.587986946106\n",
      "loss_compared with real:0.068074,   miu_train:0.002495,    lossmean:-0.06326\n",
      "Epoch [61200/100000], Loss: 752.2,   LOSS_function: 291.5,   LOSS_E:4.524e-06,    LOSS_initial: 0.2208,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4580.409091711044\n",
      "loss_compared with real:0.06758,   miu_train:0.002501,    lossmean:-0.06326\n",
      "Epoch [61300/100000], Loss: 776.3,   LOSS_function: 294.1,   LOSS_E:9.598e-06,    LOSS_initial: 0.2206,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4588.275255203247\n",
      "loss_compared with real:0.067575,   miu_train:0.002489,    lossmean:-0.06339\n",
      "Epoch [61400/100000], Loss: 775.7,   LOSS_function: 288.7,   LOSS_E:9.62e-06,    LOSS_initial: 0.2229,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4596.009143829346\n",
      "loss_compared with real:0.067429,   miu_train:0.002444,    lossmean:-0.0634\n",
      "Epoch [61500/100000], Loss: 750,   LOSS_function: 276.9,   LOSS_E:5.651e-06,    LOSS_initial: 0.2246,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4603.850630283356\n",
      "loss_compared with real:0.066708,   miu_train:0.002471,    lossmean:-0.06267\n",
      "Epoch [61600/100000], Loss: 770.8,   LOSS_function: 298,   LOSS_E:5.866e-06,    LOSS_initial: 0.224,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4611.6329646110535\n",
      "loss_compared with real:0.066917,   miu_train:0.002411,    lossmean:-0.06271\n",
      "Epoch [61700/100000], Loss: 759.2,   LOSS_function: 279.1,   LOSS_E:7.733e-06,    LOSS_initial: 0.2236,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4619.448999166489\n",
      "loss_compared with real:0.06634,   miu_train:0.002448,    lossmean:-0.06227\n",
      "Epoch [61800/100000], Loss: 753.8,   LOSS_function: 306.3,   LOSS_E:4.055e-06,    LOSS_initial: 0.2152,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4627.269521951675\n",
      "loss_compared with real:0.06736,   miu_train:0.002523,    lossmean:-0.06288\n",
      "Epoch [61900/100000], Loss: 765.8,   LOSS_function: 290.8,   LOSS_E:6.737e-06,    LOSS_initial: 0.2232,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1997,      learn rate:3.981e-05,    time: 4635.09073638916\n",
      "loss_compared with real:0.065655,   miu_train:0.00238,    lossmean:-0.06244\n",
      "Epoch [62000/100000], Loss: 721,   LOSS_function: 281.2,   LOSS_E:9.413e-06,    LOSS_initial: 0.2237,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4642.928068161011\n",
      "loss_compared with real:0.066092,   miu_train:0.002325,    lossmean:-0.06174\n",
      "Epoch [62100/100000], Loss: 690,   LOSS_function: 251.4,   LOSS_E:3.72e-06,    LOSS_initial: 0.2368,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4650.644407749176\n",
      "loss_compared with real:0.072945,   miu_train:0.002284,    lossmean:-0.06647\n",
      "Epoch [62200/100000], Loss: 699.7,   LOSS_function: 268.7,   LOSS_E:3.87e-06,    LOSS_initial: 0.2322,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4658.414598464966\n",
      "loss_compared with real:0.07217,   miu_train:0.002256,    lossmean:-0.06625\n",
      "Epoch [62300/100000], Loss: 705.1,   LOSS_function: 259.1,   LOSS_E:4.414e-06,    LOSS_initial: 0.2393,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4666.259029865265\n",
      "loss_compared with real:0.071981,   miu_train:0.002216,    lossmean:-0.06601\n",
      "Epoch [62400/100000], Loss: 722.9,   LOSS_function: 302.8,   LOSS_E:3.315e-06,    LOSS_initial: 0.2274,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4673.684356451035\n",
      "loss_compared with real:0.071959,   miu_train:0.002272,    lossmean:-0.06613\n",
      "Epoch [62500/100000], Loss: 689,   LOSS_function: 255.3,   LOSS_E:3.436e-06,    LOSS_initial: 0.2348,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4680.965811491013\n",
      "loss_compared with real:0.072628,   miu_train:0.002284,    lossmean:-0.06644\n",
      "Epoch [62600/100000], Loss: 686.4,   LOSS_function: 250.3,   LOSS_E:4.122e-06,    LOSS_initial: 0.2344,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4688.1381549835205\n",
      "loss_compared with real:0.07227,   miu_train:0.002233,    lossmean:-0.06631\n",
      "Epoch [62700/100000], Loss: 692.8,   LOSS_function: 256.1,   LOSS_E:3.154e-06,    LOSS_initial: 0.2371,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4695.400267124176\n",
      "loss_compared with real:0.07209,   miu_train:0.002251,    lossmean:-0.06613\n",
      "Epoch [62800/100000], Loss: 686.6,   LOSS_function: 256.6,   LOSS_E:4.015e-06,    LOSS_initial: 0.2313,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4702.6178596019745\n",
      "loss_compared with real:0.072049,   miu_train:0.002342,    lossmean:-0.06637\n",
      "Epoch [62900/100000], Loss: 716.9,   LOSS_function: 277.5,   LOSS_E:5.092e-06,    LOSS_initial: 0.2339,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1784,      learn rate:3.789e-05,    time: 4709.766198158264\n",
      "loss_compared with real:0.071667,   miu_train:0.002168,    lossmean:-0.06551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63000/100000], Loss: 696.7,   LOSS_function: 267.3,   LOSS_E:8.242e-06,    LOSS_initial: 0.2281,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4716.999276638031\n",
      "loss_compared with real:0.072108,   miu_train:0.002288,    lossmean:-0.06602\n",
      "Epoch [63100/100000], Loss: 678.2,   LOSS_function: 263.2,   LOSS_E:4.126e-06,    LOSS_initial: 0.23,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4724.195331096649\n",
      "loss_compared with real:0.073215,   miu_train:0.002219,    lossmean:-0.06712\n",
      "Epoch [63200/100000], Loss: 667.6,   LOSS_function: 235.1,   LOSS_E:4.5e-06,    LOSS_initial: 0.2392,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4731.436817407608\n",
      "loss_compared with real:0.072907,   miu_train:0.002169,    lossmean:-0.06699\n",
      "Epoch [63300/100000], Loss: 661.2,   LOSS_function: 239.5,   LOSS_E:3.269e-06,    LOSS_initial: 0.2361,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4738.582064151764\n",
      "loss_compared with real:0.073633,   miu_train:0.002235,    lossmean:-0.06766\n",
      "Epoch [63400/100000], Loss: 724.5,   LOSS_function: 272.9,   LOSS_E:1.075e-05,    LOSS_initial: 0.2347,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4745.765523195267\n",
      "loss_compared with real:0.073342,   miu_train:0.002221,    lossmean:-0.06666\n",
      "Epoch [63500/100000], Loss: 675.1,   LOSS_function: 258.4,   LOSS_E:2.96e-06,    LOSS_initial: 0.234,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4753.051517248154\n",
      "loss_compared with real:0.072808,   miu_train:0.002209,    lossmean:-0.06665\n",
      "Epoch [63600/100000], Loss: 686.8,   LOSS_function: 244.1,   LOSS_E:1.047e-05,    LOSS_initial: 0.2302,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4760.445321083069\n",
      "loss_compared with real:0.074231,   miu_train:0.002255,    lossmean:-0.06724\n",
      "Epoch [63700/100000], Loss: 654.9,   LOSS_function: 242.4,   LOSS_E:3.401e-06,    LOSS_initial: 0.2304,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4767.705740690231\n",
      "loss_compared with real:0.072951,   miu_train:0.002316,    lossmean:-0.0671\n",
      "Epoch [63800/100000], Loss: 674.4,   LOSS_function: 245.1,   LOSS_E:5.157e-06,    LOSS_initial: 0.2358,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4775.011512756348\n",
      "loss_compared with real:0.071987,   miu_train:0.002228,    lossmean:-0.06642\n",
      "Epoch [63900/100000], Loss: 703.5,   LOSS_function: 265.1,   LOSS_E:8.607e-06,    LOSS_initial: 0.2324,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1726,      learn rate:3.608e-05,    time: 4782.19017124176\n",
      "loss_compared with real:0.072065,   miu_train:0.00223,    lossmean:-0.06658\n",
      "Epoch [64000/100000], Loss: 653.3,   LOSS_function: 247.9,   LOSS_E:5.738e-06,    LOSS_initial: 0.2323,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4789.401618003845\n",
      "loss_compared with real:0.072393,   miu_train:0.002178,    lossmean:-0.0664\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5326, -0.5395, -0.3080, -0.9687, -0.0864, -0.3411,  0.4449, -0.8374,\n",
      "         0.9123,  0.3169,  0.7807,  0.5307,  0.6505, -0.0345,  0.6898, -0.3145,\n",
      "         0.8758,  0.0375,  0.8022, -0.7951, -0.2839, -0.9597, -0.5118, -0.3319,\n",
      "        -0.2967, -0.3997,  0.6952, -0.6639, -0.2481,  0.3889, -0.3146, -0.1895,\n",
      "         0.1077,  0.6405, -0.7285, -0.7969, -0.7198, -0.5729, -0.2648, -0.0502,\n",
      "        -0.8232, -0.9061, -0.0653,  0.7902, -0.6110,  0.8613, -0.6727,  0.8858,\n",
      "         0.6001, -0.9519, -0.7580, -0.3705,  0.8542, -0.5809,  0.9253, -0.1148,\n",
      "        -0.8790,  0.4174, -0.2727, -0.8575,  0.7884, -0.3314,  0.2652, -0.1110,\n",
      "        -0.5495, -0.0691, -0.0335,  0.4167, -0.4245, -0.3504,  0.6046, -0.4491,\n",
      "        -0.5091,  0.8760,  0.8031, -0.4368, -0.4549,  0.0126, -0.3391, -0.5497,\n",
      "        -0.7812, -0.7345,  0.9627,  0.0093,  0.1150,  0.8153,  0.7068,  0.2399,\n",
      "        -0.0329, -0.0787,  0.6685,  0.6926, -0.6783,  0.9045,  0.2279,  0.5593,\n",
      "        -0.6498, -0.1430,  0.6142,  0.0205, -0.8636,  0.0903, -0.0043, -0.2016,\n",
      "         0.4263,  0.4908,  0.6851,  0.0534,  0.2603,  0.6546, -0.6011, -0.2576,\n",
      "         0.5879,  0.7805,  0.7394, -0.0063, -0.9599,  0.9129, -0.3144, -0.8685,\n",
      "        -0.9540,  0.8870, -0.2205,  0.3759, -0.2414,  0.4234, -0.2081,  0.1851],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1059, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0205, -0.0252,  0.0248,  0.0812, -0.0573, -0.0342, -0.0259,  0.0277,\n",
      "        -0.0624,  0.0381, -0.0104, -0.0996,  0.0498, -0.0525,  0.0590,  0.0044,\n",
      "        -0.0256, -0.0280, -0.0373,  0.0645, -0.0637,  0.0571,  0.0258, -0.0149,\n",
      "         0.0185, -0.0044,  0.0678, -0.0464, -0.0168, -0.0759,  0.0181, -0.0809,\n",
      "         0.0836, -0.0310,  0.0604, -0.0013, -0.0525,  0.0532,  0.0493, -0.0503,\n",
      "        -0.0816, -0.0618,  0.0243,  0.0835,  0.0593,  0.0725, -0.0181,  0.0665,\n",
      "        -0.0321, -0.0196,  0.0604,  0.0157, -0.0224,  0.0070,  0.0070,  0.0053,\n",
      "         0.0519,  0.0548,  0.0592,  0.0360,  0.0110, -0.0495, -0.0403,  0.0443,\n",
      "         0.0654,  0.0043,  0.0450,  0.0252,  0.0524,  0.0250,  0.0617, -0.0087,\n",
      "        -0.0267, -0.0222, -0.0666,  0.0241, -0.0518,  0.0524, -0.0182,  0.0174,\n",
      "         0.0108, -0.0241, -0.0119,  0.0499,  0.0412, -0.0402, -0.0184, -0.0214,\n",
      "         0.0793,  0.0978,  0.0182,  0.0444, -0.0688, -0.0808,  0.0744, -0.0675,\n",
      "         0.0573,  0.0311,  0.0294,  0.0883,  0.0782,  0.0589,  0.0441,  0.0696,\n",
      "         0.0746,  0.0070, -0.0859, -0.0680,  0.0173, -0.0513,  0.0289,  0.0177,\n",
      "        -0.0497, -0.0490, -0.0003,  0.0425,  0.0576, -0.0802, -0.1163,  0.0407,\n",
      "         0.0636,  0.0236,  0.0254, -0.0234, -0.0019,  0.0238, -0.0611,  0.0750],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1226, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0493, -0.0513, -0.0483,  0.0485, -0.0312, -0.0336, -0.1114, -0.0007,\n",
      "        -0.0288,  0.0623, -0.0290, -0.0654, -0.0207,  0.0046, -0.0427, -0.0866,\n",
      "        -0.0604,  0.0539, -0.0088, -0.0815,  0.0114, -0.0221, -0.0551, -0.0323,\n",
      "         0.0264,  0.0215,  0.0489,  0.0522, -0.0541, -0.0676, -0.0427,  0.0385,\n",
      "         0.0452, -0.0342,  0.0570,  0.0510,  0.0723, -0.0145,  0.0129,  0.0852,\n",
      "        -0.0650,  0.0471,  0.0291, -0.0243,  0.0455,  0.0130, -0.0747, -0.0560,\n",
      "        -0.0344, -0.0401, -0.0664,  0.0396,  0.0783, -0.0713,  0.0514, -0.0208,\n",
      "         0.0207, -0.0714,  0.0212, -0.0724,  0.0409,  0.0502, -0.0163,  0.1100,\n",
      "         0.0757, -0.0381, -0.0005, -0.0128,  0.0001,  0.0178, -0.0789, -0.0123,\n",
      "         0.0157,  0.0466, -0.0206,  0.0250,  0.0751,  0.0267,  0.0053, -0.0072,\n",
      "         0.0800, -0.0487, -0.0753,  0.0914,  0.0204, -0.0080,  0.0297,  0.0856,\n",
      "        -0.0133, -0.0793,  0.0104, -0.0967,  0.0409, -0.0197, -0.0758,  0.0257,\n",
      "        -0.0424, -0.0572, -0.0677,  0.0679, -0.0788,  0.0258, -0.0121,  0.0417,\n",
      "        -0.0305, -0.0579,  0.0204, -0.0764, -0.0966, -0.0203, -0.0501,  0.0134,\n",
      "         0.0616, -0.1081, -0.0556, -0.0313, -0.0482, -0.0456,  0.0860, -0.0391,\n",
      "        -0.0439,  0.0413,  0.0615,  0.0817, -0.0566, -0.0841, -0.0144, -0.0535],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1032, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0391, -0.0798,  0.0152,  0.0793, -0.0845,  0.0300, -0.0188, -0.0206,\n",
      "         0.0787,  0.0419,  0.0234,  0.0630,  0.0243, -0.0606, -0.0513,  0.0616,\n",
      "        -0.0042,  0.0177, -0.0132, -0.0238,  0.0053,  0.0016,  0.0594,  0.0998,\n",
      "        -0.0057, -0.0284, -0.0087, -0.0245, -0.0078,  0.0691,  0.0037,  0.0495,\n",
      "         0.0035, -0.0084, -0.0354,  0.0479, -0.0642, -0.1052, -0.0703,  0.0114,\n",
      "         0.0973, -0.0843,  0.0349,  0.0329,  0.0699, -0.0534,  0.0793,  0.0077,\n",
      "        -0.0842, -0.0612,  0.0114, -0.0316,  0.0051,  0.0767,  0.0293,  0.0133,\n",
      "        -0.0276, -0.0590,  0.0607,  0.0298,  0.0210, -0.0632, -0.0246, -0.0304,\n",
      "         0.0114, -0.0511, -0.0402, -0.0285,  0.0389, -0.0784, -0.0490, -0.0280,\n",
      "        -0.0424,  0.0369, -0.0747, -0.0236, -0.0306, -0.0139,  0.0876, -0.0272,\n",
      "        -0.0381,  0.0707,  0.0037,  0.0467,  0.0158, -0.0523, -0.0075, -0.0375,\n",
      "         0.0058,  0.0154, -0.0178, -0.0952,  0.0717,  0.0427, -0.0202,  0.0701,\n",
      "        -0.0584, -0.0783,  0.0539, -0.0576, -0.0386,  0.0309, -0.0650, -0.0367,\n",
      "         0.0241,  0.0429,  0.0445, -0.0926,  0.0232, -0.0699,  0.0409,  0.0701,\n",
      "        -0.0626, -0.0677,  0.0605, -0.0148, -0.0970,  0.0335, -0.0364,  0.0470,\n",
      "         0.0354, -0.0383,  0.0425, -0.0859, -0.0121,  0.0497, -0.0120,  0.0584],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0795, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0310,  0.0574,  0.0884], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64100/100000], Loss: 665.3,   LOSS_function: 221.7,   LOSS_E:9.7e-06,    LOSS_initial: 0.2452,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4796.727648973465\n",
      "loss_compared with real:0.075035,   miu_train:0.002094,    lossmean:-0.06805\n",
      "Epoch [64200/100000], Loss: 642.2,   LOSS_function: 236.5,   LOSS_E:3.703e-06,    LOSS_initial: 0.2378,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4803.98848938942\n",
      "loss_compared with real:0.074942,   miu_train:0.00211,    lossmean:-0.06862\n",
      "Epoch [64300/100000], Loss: 655.8,   LOSS_function: 232.1,   LOSS_E:6.828e-06,    LOSS_initial: 0.2406,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4811.274129390717\n",
      "loss_compared with real:0.074808,   miu_train:0.002118,    lossmean:-0.06769\n",
      "Epoch [64400/100000], Loss: 643,   LOSS_function: 232.9,   LOSS_E:4.109e-06,    LOSS_initial: 0.2394,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4819.009469985962\n",
      "loss_compared with real:0.074426,   miu_train:0.002109,    lossmean:-0.068\n",
      "Epoch [64500/100000], Loss: 691.8,   LOSS_function: 261.3,   LOSS_E:8.852e-06,    LOSS_initial: 0.2394,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4826.813927412033\n",
      "loss_compared with real:0.074102,   miu_train:0.002079,    lossmean:-0.06742\n",
      "Epoch [64600/100000], Loss: 647.3,   LOSS_function: 229,   LOSS_E:3.187e-06,    LOSS_initial: 0.2469,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4834.585446834564\n",
      "loss_compared with real:0.074578,   miu_train:0.002097,    lossmean:-0.06758\n",
      "Epoch [64700/100000], Loss: 644,   LOSS_function: 247,   LOSS_E:4.211e-06,    LOSS_initial: 0.2312,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4842.30409693718\n",
      "loss_compared with real:0.074075,   miu_train:0.002147,    lossmean:-0.0676\n",
      "Epoch [64800/100000], Loss: 646.5,   LOSS_function: 242.3,   LOSS_E:4.609e-06,    LOSS_initial: 0.2346,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4850.153785705566\n",
      "loss_compared with real:0.073947,   miu_train:0.002136,    lossmean:-0.06744\n",
      "Epoch [64900/100000], Loss: 630.1,   LOSS_function: 210.6,   LOSS_E:4.409e-06,    LOSS_initial: 0.2444,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1638,      learn rate:3.434e-05,    time: 4857.928482532501\n",
      "loss_compared with real:0.074096,   miu_train:0.002064,    lossmean:-0.06716\n",
      "Epoch [65000/100000], Loss: 675.8,   LOSS_function: 267.8,   LOSS_E:3.71e-06,    LOSS_initial: 0.2338,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4865.689329862595\n",
      "loss_compared with real:0.073956,   miu_train:0.002047,    lossmean:-0.06679\n",
      "Epoch [65100/100000], Loss: 644.5,   LOSS_function: 248.1,   LOSS_E:3.882e-06,    LOSS_initial: 0.2264,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4873.475651741028\n",
      "loss_compared with real:0.072766,   miu_train:0.002279,    lossmean:-0.06704\n",
      "Epoch [65200/100000], Loss: 673.7,   LOSS_function: 273.4,   LOSS_E:4.711e-06,    LOSS_initial: 0.2266,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4881.271889925003\n",
      "loss_compared with real:0.073082,   miu_train:0.002212,    lossmean:-0.06615\n",
      "Epoch [65300/100000], Loss: 674.8,   LOSS_function: 278.4,   LOSS_E:3.731e-06,    LOSS_initial: 0.2268,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4889.051348209381\n",
      "loss_compared with real:0.07254,   miu_train:0.002215,    lossmean:-0.06625\n",
      "Epoch [65400/100000], Loss: 648.7,   LOSS_function: 238.4,   LOSS_E:5.224e-06,    LOSS_initial: 0.2312,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4896.935209989548\n",
      "loss_compared with real:0.072221,   miu_train:0.002178,    lossmean:-0.06609\n",
      "Epoch [65500/100000], Loss: 664.9,   LOSS_function: 252.2,   LOSS_E:5.996e-06,    LOSS_initial: 0.2307,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4904.776604652405\n",
      "loss_compared with real:0.071959,   miu_train:0.002139,    lossmean:-0.06577\n",
      "Epoch [65600/100000], Loss: 654.5,   LOSS_function: 253.3,   LOSS_E:3.797e-06,    LOSS_initial: 0.2295,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4912.707401037216\n",
      "loss_compared with real:0.071411,   miu_train:0.002156,    lossmean:-0.06544\n",
      "Epoch [65700/100000], Loss: 656.3,   LOSS_function: 239.2,   LOSS_E:5.407e-06,    LOSS_initial: 0.2348,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4920.631714582443\n",
      "loss_compared with real:0.071317,   miu_train:0.002123,    lossmean:-0.06546\n",
      "Epoch [65800/100000], Loss: 681,   LOSS_function: 251.7,   LOSS_E:9.787e-06,    LOSS_initial: 0.2309,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4928.411873579025\n",
      "loss_compared with real:0.071911,   miu_train:0.002159,    lossmean:-0.06537\n",
      "Epoch [65900/100000], Loss: 648.3,   LOSS_function: 245.6,   LOSS_E:4.043e-06,    LOSS_initial: 0.2298,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1676,      learn rate:3.27e-05,    time: 4936.20140504837\n",
      "loss_compared with real:0.071059,   miu_train:0.002163,    lossmean:-0.0653\n",
      "Epoch [66000/100000], Loss: 693.7,   LOSS_function: 277.3,   LOSS_E:6.072e-06,    LOSS_initial: 0.2209,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4943.983133554459\n",
      "loss_compared with real:0.071826,   miu_train:0.002245,    lossmean:-0.06633\n",
      "Epoch [66100/100000], Loss: 660.4,   LOSS_function: 257.6,   LOSS_E:3.769e-06,    LOSS_initial: 0.2188,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4951.82627415657\n",
      "loss_compared with real:0.069365,   miu_train:0.002414,    lossmean:-0.06448\n",
      "Epoch [66200/100000], Loss: 668.6,   LOSS_function: 262.4,   LOSS_E:6.433e-06,    LOSS_initial: 0.2142,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4959.744777679443\n",
      "loss_compared with real:0.068733,   miu_train:0.002325,    lossmean:-0.06351\n",
      "Epoch [66300/100000], Loss: 658.2,   LOSS_function: 253.5,   LOSS_E:3.932e-06,    LOSS_initial: 0.2194,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4967.578777551651\n",
      "loss_compared with real:0.06777,   miu_train:0.002376,    lossmean:-0.06338\n",
      "Epoch [66400/100000], Loss: 654.6,   LOSS_function: 243.2,   LOSS_E:3.682e-06,    LOSS_initial: 0.2239,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4975.1272513866425\n",
      "loss_compared with real:0.067313,   miu_train:0.00231,    lossmean:-0.06304\n",
      "Epoch [66500/100000], Loss: 670.8,   LOSS_function: 270.3,   LOSS_E:5.035e-06,    LOSS_initial: 0.2144,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4982.285821914673\n",
      "loss_compared with real:0.06788,   miu_train:0.002319,    lossmean:-0.06297\n",
      "Epoch [66600/100000], Loss: 719.7,   LOSS_function: 261.5,   LOSS_E:1.712e-05,    LOSS_initial: 0.2175,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4989.451021671295\n",
      "loss_compared with real:0.067984,   miu_train:0.002312,    lossmean:-0.06312\n",
      "Epoch [66700/100000], Loss: 673.9,   LOSS_function: 253.5,   LOSS_E:4.895e-06,    LOSS_initial: 0.226,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 4996.712446689606\n",
      "loss_compared with real:0.067385,   miu_train:0.00222,    lossmean:-0.06249\n",
      "Epoch [66800/100000], Loss: 664.1,   LOSS_function: 251.8,   LOSS_E:4.935e-06,    LOSS_initial: 0.2213,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 5003.881148815155\n",
      "loss_compared with real:0.067242,   miu_train:0.002232,    lossmean:-0.06217\n",
      "Epoch [66900/100000], Loss: 682.9,   LOSS_function: 265.8,   LOSS_E:3.786e-06,    LOSS_initial: 0.2269,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1766,      learn rate:3.113e-05,    time: 5011.066952466965\n",
      "loss_compared with real:0.067218,   miu_train:0.002225,    lossmean:-0.0622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67000/100000], Loss: 688.9,   LOSS_function: 282.5,   LOSS_E:5.612e-06,    LOSS_initial: 0.2145,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5018.22900557518\n",
      "loss_compared with real:0.066284,   miu_train:0.002225,    lossmean:-0.0618\n",
      "Epoch [67100/100000], Loss: 665,   LOSS_function: 272.2,   LOSS_E:3.805e-06,    LOSS_initial: 0.2112,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5025.4993715286255\n",
      "loss_compared with real:0.06705,   miu_train:0.002376,    lossmean:-0.06271\n",
      "Epoch [67200/100000], Loss: 657.6,   LOSS_function: 267.2,   LOSS_E:4.818e-06,    LOSS_initial: 0.2075,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5032.769629955292\n",
      "loss_compared with real:0.067332,   miu_train:0.002408,    lossmean:-0.06237\n",
      "Epoch [67300/100000], Loss: 649,   LOSS_function: 253.7,   LOSS_E:4.029e-06,    LOSS_initial: 0.2121,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5039.87121462822\n",
      "loss_compared with real:0.066241,   miu_train:0.002352,    lossmean:-0.06189\n",
      "Epoch [67400/100000], Loss: 649.5,   LOSS_function: 255.8,   LOSS_E:4.305e-06,    LOSS_initial: 0.2105,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5047.040860652924\n",
      "loss_compared with real:0.066617,   miu_train:0.002426,    lossmean:-0.06222\n",
      "Epoch [67500/100000], Loss: 654.9,   LOSS_function: 257.7,   LOSS_E:5.749e-06,    LOSS_initial: 0.209,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5054.435047626495\n",
      "loss_compared with real:0.066458,   miu_train:0.00248,    lossmean:-0.0624\n",
      "Epoch [67600/100000], Loss: 655.2,   LOSS_function: 246.6,   LOSS_E:7.863e-06,    LOSS_initial: 0.2103,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5061.744593143463\n",
      "loss_compared with real:0.065847,   miu_train:0.002381,    lossmean:-0.06172\n",
      "Epoch [67700/100000], Loss: 649,   LOSS_function: 249.7,   LOSS_E:4.319e-06,    LOSS_initial: 0.2136,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5069.03875207901\n",
      "loss_compared with real:0.066014,   miu_train:0.002349,    lossmean:-0.06156\n",
      "Epoch [67800/100000], Loss: 665.8,   LOSS_function: 267.1,   LOSS_E:4.364e-06,    LOSS_initial: 0.2132,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5076.1737632751465\n",
      "loss_compared with real:0.06476,   miu_train:0.002275,    lossmean:-0.06054\n",
      "Epoch [67900/100000], Loss: 635.3,   LOSS_function: 245.4,   LOSS_E:5.745e-06,    LOSS_initial: 0.2049,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1781,      learn rate:2.963e-05,    time: 5083.383753061295\n",
      "loss_compared with real:0.066261,   miu_train:0.002472,    lossmean:-0.06178\n",
      "Epoch [68000/100000], Loss: 601.3,   LOSS_function: 235.8,   LOSS_E:6.983e-06,    LOSS_initial: 0.2208,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5090.7179634571075\n",
      "loss_compared with real:0.064234,   miu_train:0.00218,    lossmean:-0.0601\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5322, -0.5393, -0.3082, -0.9688, -0.0869, -0.3410,  0.4447, -0.8373,\n",
      "         0.9121,  0.3169,  0.7799,  0.5307,  0.6505, -0.0343,  0.6899, -0.3143,\n",
      "         0.8758,  0.0375,  0.8020, -0.7950, -0.2828, -0.9597, -0.5119, -0.3317,\n",
      "        -0.2964, -0.3997,  0.6959, -0.6640, -0.2485,  0.3873, -0.3148, -0.1897,\n",
      "         0.1076,  0.6405, -0.7276, -0.7965, -0.7198, -0.5726, -0.2652, -0.0500,\n",
      "        -0.8227, -0.9060, -0.0654,  0.7904, -0.6110,  0.8612, -0.6725,  0.8857,\n",
      "         0.5997, -0.9517, -0.7582, -0.3705,  0.8545, -0.5810,  0.9255, -0.1149,\n",
      "        -0.8793,  0.4175, -0.2727, -0.8575,  0.7881, -0.3312,  0.2652, -0.1111,\n",
      "        -0.5495, -0.0678, -0.0338,  0.4167, -0.4243, -0.3499,  0.6046, -0.4492,\n",
      "        -0.5090,  0.8761,  0.8030, -0.4367, -0.4557,  0.0123, -0.3391, -0.5496,\n",
      "        -0.7812, -0.7343,  0.9623,  0.0092,  0.1148,  0.8150,  0.7067,  0.2400,\n",
      "        -0.0327, -0.0787,  0.6682,  0.6924, -0.6783,  0.9045,  0.2279,  0.5592,\n",
      "        -0.6498, -0.1429,  0.6147,  0.0201, -0.8636,  0.0902, -0.0040, -0.2012,\n",
      "         0.4263,  0.4906,  0.6849,  0.0533,  0.2606,  0.6544, -0.6011, -0.2576,\n",
      "         0.5882,  0.7804,  0.7391, -0.0071, -0.9599,  0.9129, -0.3146, -0.8682,\n",
      "        -0.9539,  0.8855, -0.2205,  0.3757, -0.2414,  0.4235, -0.2077,  0.1847],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1069, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0206, -0.0250,  0.0246,  0.0811, -0.0576, -0.0342, -0.0263,  0.0278,\n",
      "        -0.0621,  0.0379, -0.0103, -0.0995,  0.0502, -0.0527,  0.0591,  0.0043,\n",
      "        -0.0254, -0.0281, -0.0375,  0.0666, -0.0629,  0.0569,  0.0255, -0.0149,\n",
      "         0.0187, -0.0044,  0.0678, -0.0461, -0.0167, -0.0756,  0.0183, -0.0811,\n",
      "         0.0834, -0.0309,  0.0612, -0.0015, -0.0525,  0.0533,  0.0492, -0.0509,\n",
      "        -0.0816, -0.0618,  0.0242,  0.0835,  0.0593,  0.0725, -0.0181,  0.0665,\n",
      "        -0.0320, -0.0198,  0.0607,  0.0159, -0.0227,  0.0072,  0.0063,  0.0055,\n",
      "         0.0525,  0.0547,  0.0593,  0.0354,  0.0113, -0.0496, -0.0404,  0.0439,\n",
      "         0.0655,  0.0044,  0.0449,  0.0252,  0.0522,  0.0255,  0.0616, -0.0090,\n",
      "        -0.0268, -0.0222, -0.0661,  0.0242, -0.0523,  0.0524, -0.0180,  0.0175,\n",
      "         0.0108, -0.0253, -0.0121,  0.0500,  0.0410, -0.0396, -0.0183, -0.0215,\n",
      "         0.0792,  0.0985,  0.0172,  0.0443, -0.0688, -0.0805,  0.0743, -0.0675,\n",
      "         0.0574,  0.0302,  0.0298,  0.0886,  0.0783,  0.0591,  0.0444,  0.0682,\n",
      "         0.0753,  0.0071, -0.0857, -0.0681,  0.0175, -0.0519,  0.0289,  0.0178,\n",
      "        -0.0496, -0.0492, -0.0005,  0.0426,  0.0575, -0.0806, -0.1166,  0.0406,\n",
      "         0.0636,  0.0235,  0.0255, -0.0231, -0.0028,  0.0238, -0.0612,  0.0740],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1235, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0492, -0.0516, -0.0482,  0.0488, -0.0311, -0.0338, -0.1115,  0.0008,\n",
      "        -0.0288,  0.0624, -0.0290, -0.0654, -0.0199,  0.0049, -0.0428, -0.0868,\n",
      "        -0.0602,  0.0548, -0.0092, -0.0817,  0.0111, -0.0222, -0.0550, -0.0322,\n",
      "         0.0261,  0.0213,  0.0487,  0.0515, -0.0541, -0.0672, -0.0427,  0.0386,\n",
      "         0.0453, -0.0348,  0.0572,  0.0508,  0.0719, -0.0144,  0.0130,  0.0858,\n",
      "        -0.0651,  0.0471,  0.0292, -0.0239,  0.0455,  0.0130, -0.0745, -0.0560,\n",
      "        -0.0336, -0.0406, -0.0662,  0.0397,  0.0810, -0.0713,  0.0515, -0.0207,\n",
      "         0.0206, -0.0714,  0.0213, -0.0728,  0.0409,  0.0504, -0.0161,  0.1096,\n",
      "         0.0760, -0.0381, -0.0002, -0.0131,  0.0003,  0.0176, -0.0787, -0.0123,\n",
      "         0.0168,  0.0470, -0.0208,  0.0261,  0.0750,  0.0265,  0.0054, -0.0078,\n",
      "         0.0800, -0.0488, -0.0751,  0.0915,  0.0204, -0.0079,  0.0297,  0.0858,\n",
      "        -0.0129, -0.0794,  0.0118, -0.0966,  0.0405, -0.0204, -0.0759,  0.0254,\n",
      "        -0.0427, -0.0570, -0.0676,  0.0680, -0.0790,  0.0250, -0.0119,  0.0422,\n",
      "        -0.0305, -0.0579,  0.0205, -0.0770, -0.0962, -0.0202, -0.0479,  0.0135,\n",
      "         0.0619, -0.1081, -0.0554, -0.0312, -0.0486, -0.0454,  0.0862, -0.0387,\n",
      "        -0.0439,  0.0413,  0.0614,  0.0817, -0.0561, -0.0842, -0.0144, -0.0536],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1038, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0391, -0.0796,  0.0132,  0.0792, -0.0847,  0.0299, -0.0189, -0.0174,\n",
      "         0.0781,  0.0422,  0.0238,  0.0625,  0.0256, -0.0606, -0.0509,  0.0623,\n",
      "        -0.0037,  0.0175, -0.0130, -0.0232,  0.0051,  0.0014,  0.0594,  0.1000,\n",
      "        -0.0047, -0.0284, -0.0088, -0.0246, -0.0074,  0.0685,  0.0030,  0.0491,\n",
      "         0.0036, -0.0080, -0.0365,  0.0476, -0.0638, -0.1053, -0.0718,  0.0118,\n",
      "         0.0974, -0.0847,  0.0350,  0.0331,  0.0701, -0.0536,  0.0792,  0.0060,\n",
      "        -0.0842, -0.0601,  0.0098, -0.0317,  0.0053,  0.0765,  0.0293,  0.0132,\n",
      "        -0.0283, -0.0605,  0.0606,  0.0259,  0.0208, -0.0630, -0.0246, -0.0307,\n",
      "         0.0109, -0.0510, -0.0388, -0.0302,  0.0390, -0.0789, -0.0484, -0.0280,\n",
      "        -0.0444,  0.0462, -0.0750, -0.0242, -0.0313, -0.0139,  0.0877, -0.0274,\n",
      "        -0.0383,  0.0722,  0.0038,  0.0469,  0.0157, -0.0519, -0.0085, -0.0374,\n",
      "         0.0052,  0.0155, -0.0180, -0.0951,  0.0718,  0.0428, -0.0208,  0.0699,\n",
      "        -0.0584, -0.0783,  0.0520, -0.0576, -0.0386,  0.0310, -0.0649, -0.0376,\n",
      "         0.0238,  0.0428,  0.0446, -0.0925,  0.0220, -0.0696,  0.0415,  0.0704,\n",
      "        -0.0631, -0.0695,  0.0606, -0.0144, -0.0974,  0.0339, -0.0364,  0.0451,\n",
      "         0.0353, -0.0381,  0.0427, -0.0842, -0.0120,  0.0497, -0.0120,  0.0584],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0797, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0370,  0.0612,  0.0894], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68100/100000], Loss: 599.8,   LOSS_function: 230.5,   LOSS_E:3.481e-06,    LOSS_initial: 0.2332,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5098.090695619583\n",
      "loss_compared with real:0.074349,   miu_train:0.002063,    lossmean:-0.06699\n",
      "Epoch [68200/100000], Loss: 589.4,   LOSS_function: 219.9,   LOSS_E:4.306e-06,    LOSS_initial: 0.2311,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5105.205067157745\n",
      "loss_compared with real:0.074126,   miu_train:0.002088,    lossmean:-0.06729\n",
      "Epoch [68300/100000], Loss: 605.9,   LOSS_function: 220.4,   LOSS_E:6.779e-06,    LOSS_initial: 0.2345,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5112.373106956482\n",
      "loss_compared with real:0.074348,   miu_train:0.002008,    lossmean:-0.06677\n",
      "Epoch [68400/100000], Loss: 615,   LOSS_function: 247.3,   LOSS_E:5.22e-06,    LOSS_initial: 0.2272,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5120.101888179779\n",
      "loss_compared with real:0.074394,   miu_train:0.002047,    lossmean:-0.06675\n",
      "Epoch [68500/100000], Loss: 602.3,   LOSS_function: 217.6,   LOSS_E:4.588e-06,    LOSS_initial: 0.2402,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5127.961358308792\n",
      "loss_compared with real:0.073429,   miu_train:0.001979,    lossmean:-0.06627\n",
      "Epoch [68600/100000], Loss: 613.5,   LOSS_function: 249.1,   LOSS_E:3.394e-06,    LOSS_initial: 0.2302,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5135.747899055481\n",
      "loss_compared with real:0.073689,   miu_train:0.002075,    lossmean:-0.06631\n",
      "Epoch [68700/100000], Loss: 607.8,   LOSS_function: 208.8,   LOSS_E:5.813e-06,    LOSS_initial: 0.2462,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5143.597765445709\n",
      "loss_compared with real:0.073747,   miu_train:0.001999,    lossmean:-0.06654\n",
      "Epoch [68800/100000], Loss: 586.2,   LOSS_function: 215.4,   LOSS_E:4.17e-06,    LOSS_initial: 0.2322,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5151.309318780899\n",
      "loss_compared with real:0.074363,   miu_train:0.002087,    lossmean:-0.06688\n",
      "Epoch [68900/100000], Loss: 584.3,   LOSS_function: 211.3,   LOSS_E:5.21e-06,    LOSS_initial: 0.2307,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1518,      learn rate:2.821e-05,    time: 5159.084892034531\n",
      "loss_compared with real:0.074379,   miu_train:0.002149,    lossmean:-0.06704\n",
      "Epoch [69000/100000], Loss: 582.2,   LOSS_function: 223.1,   LOSS_E:5.061e-06,    LOSS_initial: 0.2312,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5166.892325878143\n",
      "loss_compared with real:0.073879,   miu_train:0.002069,    lossmean:-0.06635\n",
      "Epoch [69100/100000], Loss: 583.8,   LOSS_function: 219.9,   LOSS_E:3.872e-06,    LOSS_initial: 0.238,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5174.702322721481\n",
      "loss_compared with real:0.076518,   miu_train:0.001997,    lossmean:-0.06803\n",
      "Epoch [69200/100000], Loss: 586.7,   LOSS_function: 228.1,   LOSS_E:4.498e-06,    LOSS_initial: 0.2325,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5182.5243191719055\n",
      "loss_compared with real:0.075589,   miu_train:0.002007,    lossmean:-0.06788\n",
      "Epoch [69300/100000], Loss: 571.1,   LOSS_function: 197.7,   LOSS_E:3.967e-06,    LOSS_initial: 0.2443,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5190.289452552795\n",
      "loss_compared with real:0.075878,   miu_train:0.001929,    lossmean:-0.0675\n",
      "Epoch [69400/100000], Loss: 561.7,   LOSS_function: 203.4,   LOSS_E:3.628e-06,    LOSS_initial: 0.2349,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5198.019034147263\n",
      "loss_compared with real:0.076608,   miu_train:0.002074,    lossmean:-0.0686\n",
      "Epoch [69500/100000], Loss: 579,   LOSS_function: 224.7,   LOSS_E:4.49e-06,    LOSS_initial: 0.2297,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5205.668396472931\n",
      "loss_compared with real:0.076421,   miu_train:0.002114,    lossmean:-0.06828\n",
      "Epoch [69600/100000], Loss: 563,   LOSS_function: 201.9,   LOSS_E:4.594e-06,    LOSS_initial: 0.234,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5213.479517698288\n",
      "loss_compared with real:0.074947,   miu_train:0.002029,    lossmean:-0.0677\n",
      "Epoch [69700/100000], Loss: 594.7,   LOSS_function: 231.4,   LOSS_E:5.044e-06,    LOSS_initial: 0.2342,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5221.4223737716675\n",
      "loss_compared with real:0.075764,   miu_train:0.002023,    lossmean:-0.0679\n",
      "Epoch [69800/100000], Loss: 570.9,   LOSS_function: 205.7,   LOSS_E:3.824e-06,    LOSS_initial: 0.2391,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5229.278366088867\n",
      "loss_compared with real:0.074443,   miu_train:0.001958,    lossmean:-0.06676\n",
      "Epoch [69900/100000], Loss: 589.1,   LOSS_function: 225,   LOSS_E:5.444e-06,    LOSS_initial: 0.2335,\n",
      "lamda1:1.001,    lamda2:4.319e+06,    lamda3:1458,      learn rate:2.686e-05,    time: 5237.1538009643555\n",
      "loss_compared with real:0.074925,   miu_train:0.002048,    lossmean:-0.06733\n",
      "Epoch [70000/100000], Loss: 535.9,   LOSS_function: 204.3,   LOSS_E:1.075e-05,    LOSS_initial: 0.2356,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5244.969779014587\n",
      "loss_compared with real:0.075627,   miu_train:0.001976,    lossmean:-0.06747\n",
      "Epoch [70100/100000], Loss: 532.7,   LOSS_function: 199.1,   LOSS_E:3.212e-06,    LOSS_initial: 0.2457,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5252.848471164703\n",
      "loss_compared with real:0.078306,   miu_train:0.001918,    lossmean:-0.06907\n",
      "Epoch [70200/100000], Loss: 542.5,   LOSS_function: 209.2,   LOSS_E:3.103e-06,    LOSS_initial: 0.2456,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5260.688614606857\n",
      "loss_compared with real:0.078505,   miu_train:0.001919,    lossmean:-0.06912\n",
      "Epoch [70300/100000], Loss: 526.7,   LOSS_function: 193.1,   LOSS_E:3.548e-06,    LOSS_initial: 0.2453,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5268.516535758972\n",
      "loss_compared with real:0.078599,   miu_train:0.001934,    lossmean:-0.069\n",
      "Epoch [70400/100000], Loss: 552.5,   LOSS_function: 224.4,   LOSS_E:3.404e-06,    LOSS_initial: 0.2413,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5275.929505825043\n",
      "loss_compared with real:0.077812,   miu_train:0.001872,    lossmean:-0.06823\n",
      "Epoch [70500/100000], Loss: 531.2,   LOSS_function: 202.8,   LOSS_E:4.29e-06,    LOSS_initial: 0.2406,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5283.021706819534\n",
      "loss_compared with real:0.078729,   miu_train:0.001938,    lossmean:-0.06875\n",
      "Epoch [70600/100000], Loss: 520.4,   LOSS_function: 190.2,   LOSS_E:3.51e-06,    LOSS_initial: 0.2428,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5290.24795126915\n",
      "loss_compared with real:0.077954,   miu_train:0.001964,    lossmean:-0.06881\n",
      "Epoch [70700/100000], Loss: 549.4,   LOSS_function: 218.2,   LOSS_E:3.849e-06,    LOSS_initial: 0.2432,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5297.506146430969\n",
      "loss_compared with real:0.07754,   miu_train:0.001934,    lossmean:-0.06863\n",
      "Epoch [70800/100000], Loss: 531.6,   LOSS_function: 197.9,   LOSS_E:3.371e-06,    LOSS_initial: 0.2456,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5304.657976388931\n",
      "loss_compared with real:0.077084,   miu_train:0.001897,    lossmean:-0.06831\n",
      "Epoch [70900/100000], Loss: 544.7,   LOSS_function: 209.8,   LOSS_E:3.498e-06,    LOSS_initial: 0.2464,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1337,      learn rate:2.557e-05,    time: 5311.8390119075775\n",
      "loss_compared with real:0.077331,   miu_train:0.001871,    lossmean:-0.06749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71000/100000], Loss: 560.3,   LOSS_function: 223.2,   LOSS_E:3.708e-06,    LOSS_initial: 0.2348,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5319.0629024505615\n",
      "loss_compared with real:0.076912,   miu_train:0.001985,    lossmean:-0.06819\n",
      "Epoch [71100/100000], Loss: 524.7,   LOSS_function: 204.2,   LOSS_E:4.17e-06,    LOSS_initial: 0.2225,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5326.332924604416\n",
      "loss_compared with real:0.075249,   miu_train:0.00218,    lossmean:-0.06664\n",
      "Epoch [71200/100000], Loss: 549.4,   LOSS_function: 216.5,   LOSS_E:3.745e-06,    LOSS_initial: 0.2317,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5333.48664689064\n",
      "loss_compared with real:0.074199,   miu_train:0.002095,    lossmean:-0.06607\n",
      "Epoch [71300/100000], Loss: 531.4,   LOSS_function: 209.3,   LOSS_E:5.043e-06,    LOSS_initial: 0.2227,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5340.679939508438\n",
      "loss_compared with real:0.073938,   miu_train:0.002133,    lossmean:-0.06608\n",
      "Epoch [71400/100000], Loss: 524.8,   LOSS_function: 190.2,   LOSS_E:4.337e-06,    LOSS_initial: 0.2323,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5347.92701125145\n",
      "loss_compared with real:0.073136,   miu_train:0.002085,    lossmean:-0.06602\n",
      "Epoch [71500/100000], Loss: 525.1,   LOSS_function: 196.8,   LOSS_E:3.655e-06,    LOSS_initial: 0.2286,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5355.305257797241\n",
      "loss_compared with real:0.073785,   miu_train:0.002097,    lossmean:-0.06599\n",
      "Epoch [71600/100000], Loss: 541.1,   LOSS_function: 215.2,   LOSS_E:4.292e-06,    LOSS_initial: 0.2262,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5362.61040019989\n",
      "loss_compared with real:0.074232,   miu_train:0.002152,    lossmean:-0.06635\n",
      "Epoch [71700/100000], Loss: 538.2,   LOSS_function: 217,   LOSS_E:4.495e-06,    LOSS_initial: 0.2226,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5369.736365318298\n",
      "loss_compared with real:0.072945,   miu_train:0.00205,    lossmean:-0.06535\n",
      "Epoch [71800/100000], Loss: 534.9,   LOSS_function: 209,   LOSS_E:4.539e-06,    LOSS_initial: 0.2259,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5376.959366083145\n",
      "loss_compared with real:0.072059,   miu_train:0.002106,    lossmean:-0.06499\n",
      "Epoch [71900/100000], Loss: 548.4,   LOSS_function: 239.6,   LOSS_E:5.409e-06,    LOSS_initial: 0.2129,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1411,      learn rate:2.434e-05,    time: 5384.065585374832\n",
      "loss_compared with real:0.074385,   miu_train:0.002088,    lossmean:-0.06598\n",
      "Epoch [72000/100000], Loss: 482.5,   LOSS_function: 189.8,   LOSS_E:4.455e-06,    LOSS_initial: 0.2303,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5391.1796875\n",
      "loss_compared with real:0.071456,   miu_train:0.00197,    lossmean:-0.06386\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5318, -0.5391, -0.3083, -0.9689, -0.0873, -0.3410,  0.4446, -0.8373,\n",
      "         0.9118,  0.3169,  0.7795,  0.5307,  0.6504, -0.0343,  0.6899, -0.3142,\n",
      "         0.8757,  0.0376,  0.8018, -0.7950, -0.2820, -0.9598, -0.5119, -0.3316,\n",
      "        -0.2963, -0.3996,  0.6962, -0.6640, -0.2487,  0.3854, -0.3147, -0.1898,\n",
      "         0.1076,  0.6404, -0.7270, -0.7962, -0.7199, -0.5722, -0.2657, -0.0498,\n",
      "        -0.8223, -0.9058, -0.0656,  0.7905, -0.6110,  0.8612, -0.6721,  0.8856,\n",
      "         0.5993, -0.9515, -0.7584, -0.3706,  0.8547, -0.5811,  0.9257, -0.1150,\n",
      "        -0.8797,  0.4176, -0.2728, -0.8576,  0.7878, -0.3309,  0.2652, -0.1112,\n",
      "        -0.5495, -0.0671, -0.0340,  0.4168, -0.4241, -0.3495,  0.6046, -0.4493,\n",
      "        -0.5088,  0.8761,  0.8029, -0.4365, -0.4564,  0.0120, -0.3391, -0.5495,\n",
      "        -0.7811, -0.7342,  0.9622,  0.0091,  0.1147,  0.8147,  0.7066,  0.2401,\n",
      "        -0.0324, -0.0787,  0.6678,  0.6923, -0.6783,  0.9044,  0.2279,  0.5591,\n",
      "        -0.6498, -0.1429,  0.6151,  0.0198, -0.8636,  0.0902, -0.0039, -0.2010,\n",
      "         0.4263,  0.4904,  0.6848,  0.0532,  0.2609,  0.6542, -0.6011, -0.2577,\n",
      "         0.5884,  0.7803,  0.7384, -0.0077, -0.9599,  0.9130, -0.3147, -0.8680,\n",
      "        -0.9538,  0.8850, -0.2205,  0.3755, -0.2413,  0.4237, -0.2075,  0.1845],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1080, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0207, -0.0249,  0.0245,  0.0811, -0.0577, -0.0342, -0.0268,  0.0279,\n",
      "        -0.0618,  0.0378, -0.0103, -0.0995,  0.0505, -0.0527,  0.0592,  0.0043,\n",
      "        -0.0252, -0.0282, -0.0377,  0.0690, -0.0624,  0.0564,  0.0253, -0.0148,\n",
      "         0.0189, -0.0045,  0.0678, -0.0461, -0.0166, -0.0752,  0.0185, -0.0813,\n",
      "         0.0832, -0.0308,  0.0618, -0.0018, -0.0526,  0.0535,  0.0491, -0.0523,\n",
      "        -0.0817, -0.0617,  0.0238,  0.0834,  0.0593,  0.0723, -0.0180,  0.0666,\n",
      "        -0.0322, -0.0199,  0.0610,  0.0160, -0.0229,  0.0076,  0.0058,  0.0057,\n",
      "         0.0529,  0.0549,  0.0595,  0.0344,  0.0123, -0.0496, -0.0404,  0.0436,\n",
      "         0.0655,  0.0044,  0.0447,  0.0252,  0.0521,  0.0258,  0.0615, -0.0092,\n",
      "        -0.0269, -0.0221, -0.0657,  0.0244, -0.0526,  0.0525, -0.0179,  0.0176,\n",
      "         0.0108, -0.0261, -0.0124,  0.0501,  0.0408, -0.0389, -0.0184, -0.0215,\n",
      "         0.0791,  0.0989,  0.0169,  0.0443, -0.0688, -0.0802,  0.0743, -0.0675,\n",
      "         0.0574,  0.0298,  0.0301,  0.0889,  0.0782,  0.0592,  0.0445,  0.0670,\n",
      "         0.0757,  0.0073, -0.0853, -0.0683,  0.0176, -0.0521,  0.0290,  0.0183,\n",
      "        -0.0494, -0.0494, -0.0003,  0.0427,  0.0574, -0.0813, -0.1170,  0.0406,\n",
      "         0.0635,  0.0234,  0.0255, -0.0224, -0.0031,  0.0238, -0.0612,  0.0726],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1245, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 4.9112e-02, -5.2060e-02, -4.7997e-02,  4.8926e-02, -3.1095e-02,\n",
      "        -3.3836e-02, -1.1143e-01,  1.6334e-03, -2.8749e-02,  6.2409e-02,\n",
      "        -2.9093e-02, -6.5297e-02, -1.8599e-02,  5.0626e-03, -4.2644e-02,\n",
      "        -8.7257e-02, -6.0070e-02,  5.5400e-02, -9.4178e-03, -8.1456e-02,\n",
      "         1.0710e-02, -2.2311e-02, -5.4940e-02, -3.2170e-02,  2.5802e-02,\n",
      "         2.1137e-02,  4.8530e-02,  5.0840e-02, -5.4126e-02, -6.6666e-02,\n",
      "        -4.2559e-02,  3.8727e-02,  4.5400e-02, -3.5216e-02,  5.7734e-02,\n",
      "         5.1123e-02,  7.1660e-02, -1.4246e-02,  1.3060e-02,  8.6296e-02,\n",
      "        -6.5137e-02,  4.7028e-02,  2.9250e-02, -2.3873e-02,  4.5536e-02,\n",
      "         1.2971e-02, -7.4379e-02, -5.5953e-02, -3.3154e-02, -4.0804e-02,\n",
      "        -6.5840e-02,  3.9780e-02,  8.2196e-02, -7.1354e-02,  5.1406e-02,\n",
      "        -2.0693e-02,  2.0433e-02, -7.1338e-02,  2.1335e-02, -7.3331e-02,\n",
      "         4.0867e-02,  5.0500e-02, -1.5969e-02,  1.0937e-01,  7.6156e-02,\n",
      "        -3.8172e-02,  8.9914e-05, -1.3375e-02, -2.2233e-04,  1.7372e-02,\n",
      "        -7.8665e-02, -1.2366e-02,  1.7330e-02,  4.7129e-02, -2.0829e-02,\n",
      "         2.7104e-02,  7.4994e-02,  2.6115e-02,  5.4175e-03, -8.0303e-03,\n",
      "         7.9995e-02, -4.8808e-02, -7.4868e-02,  9.1645e-02,  2.0380e-02,\n",
      "        -7.8174e-03,  2.9764e-02,  8.5880e-02, -1.2661e-02, -7.9378e-02,\n",
      "         1.2360e-02, -9.6506e-02,  4.0305e-02, -2.1320e-02, -7.5874e-02,\n",
      "         2.5295e-02, -4.2859e-02, -5.6888e-02, -6.7393e-02,  6.8060e-02,\n",
      "        -7.9139e-02,  2.4498e-02, -1.1676e-02,  4.2501e-02, -3.0477e-02,\n",
      "        -5.7879e-02,  2.0599e-02, -7.6981e-02, -9.5936e-02, -2.0157e-02,\n",
      "        -4.5938e-02,  1.3627e-02,  6.2168e-02, -1.0799e-01, -5.5190e-02,\n",
      "        -3.1253e-02, -4.8839e-02, -4.5303e-02,  8.6378e-02, -3.8520e-02,\n",
      "        -4.3901e-02,  4.1325e-02,  6.1391e-02,  8.1616e-02, -5.5638e-02,\n",
      "        -8.4227e-02, -1.4571e-02, -5.3683e-02], requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1044, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0390, -0.0793,  0.0114,  0.0792, -0.0850,  0.0298, -0.0189, -0.0142,\n",
      "         0.0778,  0.0424,  0.0240,  0.0622,  0.0274, -0.0607, -0.0508,  0.0630,\n",
      "        -0.0036,  0.0172, -0.0128, -0.0225,  0.0049,  0.0013,  0.0593,  0.1003,\n",
      "        -0.0041, -0.0285, -0.0089, -0.0246, -0.0073,  0.0682,  0.0030,  0.0489,\n",
      "         0.0037, -0.0076, -0.0374,  0.0475, -0.0635, -0.1054, -0.0724,  0.0120,\n",
      "         0.0973, -0.0852,  0.0351,  0.0332,  0.0701, -0.0539,  0.0791,  0.0050,\n",
      "        -0.0842, -0.0593,  0.0090, -0.0317,  0.0054,  0.0764,  0.0293,  0.0131,\n",
      "        -0.0292, -0.0613,  0.0606,  0.0209,  0.0207, -0.0629, -0.0246, -0.0309,\n",
      "         0.0108, -0.0509, -0.0383, -0.0324,  0.0391, -0.0790, -0.0478, -0.0279,\n",
      "        -0.0465,  0.0494, -0.0752, -0.0248, -0.0318, -0.0139,  0.0877, -0.0275,\n",
      "        -0.0383,  0.0729,  0.0035,  0.0470,  0.0157, -0.0516, -0.0089, -0.0373,\n",
      "         0.0045,  0.0156, -0.0181, -0.0950,  0.0717,  0.0428, -0.0212,  0.0698,\n",
      "        -0.0584, -0.0782,  0.0509, -0.0576, -0.0386,  0.0310, -0.0648, -0.0377,\n",
      "         0.0234,  0.0428,  0.0448, -0.0923,  0.0209, -0.0695,  0.0420,  0.0707,\n",
      "        -0.0633, -0.0702,  0.0607, -0.0140, -0.0978,  0.0338, -0.0364,  0.0437,\n",
      "         0.0352, -0.0380,  0.0427, -0.0826, -0.0120,  0.0497, -0.0121,  0.0584],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0798, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0392,  0.0623,  0.0900], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72100/100000], Loss: 504.6,   LOSS_function: 198.8,   LOSS_E:3.929e-06,    LOSS_initial: 0.2415,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5398.389005184174\n",
      "loss_compared with real:0.080042,   miu_train:0.001831,    lossmean:-0.06986\n",
      "Epoch [72200/100000], Loss: 510.6,   LOSS_function: 211,   LOSS_E:3.513e-06,    LOSS_initial: 0.237,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5405.474062919617\n",
      "loss_compared with real:0.080087,   miu_train:0.001893,    lossmean:-0.0697\n",
      "Epoch [72300/100000], Loss: 504.6,   LOSS_function: 197.4,   LOSS_E:4.586e-06,    LOSS_initial: 0.2418,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5412.7598440647125\n",
      "loss_compared with real:0.079625,   miu_train:0.001811,    lossmean:-0.06924\n",
      "Epoch [72400/100000], Loss: 491.6,   LOSS_function: 172.8,   LOSS_E:4.565e-06,    LOSS_initial: 0.2512,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5420.301646232605\n",
      "loss_compared with real:0.078273,   miu_train:0.001836,    lossmean:-0.06902\n",
      "Epoch [72500/100000], Loss: 527.2,   LOSS_function: 228.2,   LOSS_E:4.283e-06,    LOSS_initial: 0.2356,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5428.200710773468\n",
      "loss_compared with real:0.079042,   miu_train:0.001868,    lossmean:-0.06892\n",
      "Epoch [72600/100000], Loss: 505.2,   LOSS_function: 186,   LOSS_E:9.719e-06,    LOSS_initial: 0.2452,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5436.01592373848\n",
      "loss_compared with real:0.079971,   miu_train:0.001866,    lossmean:-0.06977\n",
      "Epoch [72700/100000], Loss: 483.9,   LOSS_function: 166.4,   LOSS_E:4.572e-06,    LOSS_initial: 0.2501,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5443.776720046997\n",
      "loss_compared with real:0.078102,   miu_train:0.001846,    lossmean:-0.06836\n",
      "Epoch [72800/100000], Loss: 502.8,   LOSS_function: 184.5,   LOSS_E:7.342e-06,    LOSS_initial: 0.2474,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5451.536668300629\n",
      "loss_compared with real:0.077011,   miu_train:0.001783,    lossmean:-0.06795\n",
      "Epoch [72900/100000], Loss: 495,   LOSS_function: 178.1,   LOSS_E:4.818e-06,    LOSS_initial: 0.2494,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1241,      learn rate:2.317e-05,    time: 5459.370279073715\n",
      "loss_compared with real:0.077834,   miu_train:0.001882,    lossmean:-0.06816\n",
      "Epoch [73000/100000], Loss: 526.3,   LOSS_function: 203.3,   LOSS_E:4.13e-06,    LOSS_initial: 0.2441,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5467.276596546173\n",
      "loss_compared with real:0.078125,   miu_train:0.001859,    lossmean:-0.06864\n",
      "Epoch [73100/100000], Loss: 487,   LOSS_function: 172.1,   LOSS_E:3.918e-06,    LOSS_initial: 0.238,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5475.146461963654\n",
      "loss_compared with real:0.076548,   miu_train:0.001899,    lossmean:-0.06774\n",
      "Epoch [73200/100000], Loss: 533.6,   LOSS_function: 231.8,   LOSS_E:4.353e-06,    LOSS_initial: 0.2274,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5482.851729631424\n",
      "loss_compared with real:0.074863,   miu_train:0.001959,    lossmean:-0.06645\n",
      "Epoch [73300/100000], Loss: 492.7,   LOSS_function: 183.3,   LOSS_E:4.016e-06,    LOSS_initial: 0.2337,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5490.661077737808\n",
      "loss_compared with real:0.074883,   miu_train:0.001944,    lossmean:-0.06657\n",
      "Epoch [73400/100000], Loss: 508.6,   LOSS_function: 213.5,   LOSS_E:6.008e-06,    LOSS_initial: 0.2203,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5498.519705533981\n",
      "loss_compared with real:0.074817,   miu_train:0.002037,    lossmean:-0.06651\n",
      "Epoch [73500/100000], Loss: 518.6,   LOSS_function: 207.9,   LOSS_E:4.505e-06,    LOSS_initial: 0.2341,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5506.396361351013\n",
      "loss_compared with real:0.075047,   miu_train:0.001904,    lossmean:-0.06609\n",
      "Epoch [73600/100000], Loss: 522.7,   LOSS_function: 194.8,   LOSS_E:1.532e-05,    LOSS_initial: 0.2347,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5514.282143831253\n",
      "loss_compared with real:0.073463,   miu_train:0.001921,    lossmean:-0.06557\n",
      "Epoch [73700/100000], Loss: 505.8,   LOSS_function: 201.7,   LOSS_E:3.639e-06,    LOSS_initial: 0.2301,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5522.109698295593\n",
      "loss_compared with real:0.075046,   miu_train:0.002024,    lossmean:-0.06671\n",
      "Epoch [73800/100000], Loss: 501.1,   LOSS_function: 214.6,   LOSS_E:4.387e-06,    LOSS_initial: 0.2156,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5529.8940505981445\n",
      "loss_compared with real:0.074176,   miu_train:0.00204,    lossmean:-0.06621\n",
      "Epoch [73900/100000], Loss: 517.9,   LOSS_function: 199.8,   LOSS_E:3.898e-06,    LOSS_initial: 0.2405,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1297,      learn rate:2.206e-05,    time: 5537.692337751389\n",
      "loss_compared with real:0.072424,   miu_train:0.001925,    lossmean:-0.06473\n",
      "Epoch [74000/100000], Loss: 434,   LOSS_function: 168.3,   LOSS_E:4.643e-06,    LOSS_initial: 0.2289,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5545.560275793076\n",
      "loss_compared with real:0.072904,   miu_train:0.001883,    lossmean:-0.0649\n",
      "Epoch [74100/100000], Loss: 447,   LOSS_function: 160.8,   LOSS_E:2.821e-06,    LOSS_initial: 0.2495,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5553.5069835186005\n",
      "loss_compared with real:0.080651,   miu_train:0.001742,    lossmean:-0.0699\n",
      "Epoch [74200/100000], Loss: 468.4,   LOSS_function: 177.9,   LOSS_E:3.101e-06,    LOSS_initial: 0.2529,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5561.245745420456\n",
      "loss_compared with real:0.080522,   miu_train:0.001711,    lossmean:-0.0696\n",
      "Epoch [74300/100000], Loss: 459.1,   LOSS_function: 170.2,   LOSS_E:3.55e-06,    LOSS_initial: 0.2508,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5568.946704387665\n",
      "loss_compared with real:0.083091,   miu_train:0.0017,    lossmean:-0.07155\n",
      "Epoch [74400/100000], Loss: 457,   LOSS_function: 173.1,   LOSS_E:4.228e-06,    LOSS_initial: 0.2455,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5576.549432039261\n",
      "loss_compared with real:0.079796,   miu_train:0.001723,    lossmean:-0.06926\n",
      "Epoch [74500/100000], Loss: 439.7,   LOSS_function: 169.9,   LOSS_E:2.947e-06,    LOSS_initial: 0.2347,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5583.761629581451\n",
      "loss_compared with real:0.082419,   miu_train:0.001959,    lossmean:-0.07179\n",
      "Epoch [74600/100000], Loss: 455.2,   LOSS_function: 172.3,   LOSS_E:3.141e-06,    LOSS_initial: 0.246,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5590.992881536484\n",
      "loss_compared with real:0.079619,   miu_train:0.00172,    lossmean:-0.06924\n",
      "Epoch [74700/100000], Loss: 456.3,   LOSS_function: 185.8,   LOSS_E:3.395e-06,    LOSS_initial: 0.2347,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5598.195539474487\n",
      "loss_compared with real:0.080655,   miu_train:0.001873,    lossmean:-0.07063\n",
      "Epoch [74800/100000], Loss: 463.3,   LOSS_function: 178.6,   LOSS_E:3.45e-06,    LOSS_initial: 0.2473,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5605.282311916351\n",
      "loss_compared with real:0.080177,   miu_train:0.00172,    lossmean:-0.06941\n",
      "Epoch [74900/100000], Loss: 463,   LOSS_function: 164.1,   LOSS_E:3.112e-06,    LOSS_initial: 0.2604,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1129,      learn rate:2.1e-05,    time: 5612.570200204849\n",
      "loss_compared with real:0.079166,   miu_train:0.001646,    lossmean:-0.06866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75000/100000], Loss: 484.1,   LOSS_function: 186.5,   LOSS_E:7.834e-06,    LOSS_initial: 0.2365,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5619.844811916351\n",
      "loss_compared with real:0.079659,   miu_train:0.001882,    lossmean:-0.06969\n",
      "Epoch [75100/100000], Loss: 496.4,   LOSS_function: 201,   LOSS_E:3.188e-06,    LOSS_initial: 0.2406,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5627.130358695984\n",
      "loss_compared with real:0.07413,   miu_train:0.001806,    lossmean:-0.06561\n",
      "Epoch [75200/100000], Loss: 477.2,   LOSS_function: 200.1,   LOSS_E:3.352e-06,    LOSS_initial: 0.2252,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5634.43616437912\n",
      "loss_compared with real:0.075829,   miu_train:0.001887,    lossmean:-0.06645\n",
      "Epoch [75300/100000], Loss: 461.8,   LOSS_function: 175.3,   LOSS_E:4.23e-06,    LOSS_initial: 0.2319,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5642.1121571063995\n",
      "loss_compared with real:0.075672,   miu_train:0.00193,    lossmean:-0.06705\n",
      "Epoch [75400/100000], Loss: 481.7,   LOSS_function: 196.6,   LOSS_E:3.663e-06,    LOSS_initial: 0.2314,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5649.312837839127\n",
      "loss_compared with real:0.075618,   miu_train:0.001944,    lossmean:-0.06683\n",
      "Epoch [75500/100000], Loss: 483.3,   LOSS_function: 210.9,   LOSS_E:3.862e-06,    LOSS_initial: 0.2207,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5656.647638559341\n",
      "loss_compared with real:0.07444,   miu_train:0.001914,    lossmean:-0.06566\n",
      "Epoch [75600/100000], Loss: 494.5,   LOSS_function: 199.2,   LOSS_E:7.078e-06,    LOSS_initial: 0.2355,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5663.81498670578\n",
      "loss_compared with real:0.073186,   miu_train:0.001849,    lossmean:-0.06493\n",
      "Epoch [75700/100000], Loss: 475.1,   LOSS_function: 187,   LOSS_E:8.506e-06,    LOSS_initial: 0.2278,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5671.045561313629\n",
      "loss_compared with real:0.075087,   miu_train:0.002033,    lossmean:-0.06652\n",
      "Epoch [75800/100000], Loss: 441.1,   LOSS_function: 163,   LOSS_E:3.04e-06,    LOSS_initial: 0.2265,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5678.316946983337\n",
      "loss_compared with real:0.075103,   miu_train:0.002036,    lossmean:-0.0665\n",
      "Epoch [75900/100000], Loss: 471.9,   LOSS_function: 202.7,   LOSS_E:3.251e-06,    LOSS_initial: 0.2187,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1207,      learn rate:1.999e-05,    time: 5685.591011762619\n",
      "loss_compared with real:0.074633,   miu_train:0.001984,    lossmean:-0.06611\n",
      "Epoch [76000/100000], Loss: 455.9,   LOSS_function: 182.9,   LOSS_E:3.003e-06,    LOSS_initial: 0.2414,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5692.828844070435\n",
      "loss_compared with real:0.07276,   miu_train:0.00179,    lossmean:-0.06451\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5314, -0.5389, -0.3085, -0.9689, -0.0875, -0.3409,  0.4444, -0.8370,\n",
      "         0.9114,  0.3168,  0.7787,  0.5306,  0.6502, -0.0343,  0.6899, -0.3138,\n",
      "         0.8755,  0.0377,  0.8013, -0.7949, -0.2815, -0.9599, -0.5120, -0.3314,\n",
      "        -0.2961, -0.3994,  0.6965, -0.6640, -0.2487,  0.3846, -0.3144, -0.1898,\n",
      "         0.1076,  0.6402, -0.7263, -0.7956, -0.7200, -0.5714, -0.2662, -0.0497,\n",
      "        -0.8217, -0.9054, -0.0657,  0.7908, -0.6108,  0.8610, -0.6720,  0.8855,\n",
      "         0.5987, -0.9513, -0.7585, -0.3706,  0.8551, -0.5813,  0.9258, -0.1152,\n",
      "        -0.8799,  0.4177, -0.2727, -0.8575,  0.7874, -0.3305,  0.2653, -0.1111,\n",
      "        -0.5493, -0.0667, -0.0342,  0.4168, -0.4238, -0.3492,  0.6045, -0.4492,\n",
      "        -0.5086,  0.8762,  0.8027, -0.4362, -0.4568,  0.0118, -0.3389, -0.5493,\n",
      "        -0.7809, -0.7338,  0.9619,  0.0091,  0.1145,  0.8141,  0.7062,  0.2401,\n",
      "        -0.0322, -0.0785,  0.6672,  0.6922, -0.6782,  0.9044,  0.2278,  0.5589,\n",
      "        -0.6498, -0.1428,  0.6158,  0.0194, -0.8636,  0.0902, -0.0039, -0.2007,\n",
      "         0.4264,  0.4897,  0.6846,  0.0531,  0.2611,  0.6538, -0.6011, -0.2579,\n",
      "         0.5885,  0.7801,  0.7374, -0.0080, -0.9599,  0.9130, -0.3148, -0.8676,\n",
      "        -0.9535,  0.8849, -0.2204,  0.3752, -0.2411,  0.4239, -0.2074,  0.1843],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1105, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0209, -0.0250,  0.0242,  0.0809, -0.0577, -0.0343, -0.0279,  0.0279,\n",
      "        -0.0610,  0.0377, -0.0102, -0.0994,  0.0510, -0.0526,  0.0593,  0.0044,\n",
      "        -0.0249, -0.0283, -0.0379,  0.0701, -0.0621,  0.0558,  0.0251, -0.0148,\n",
      "         0.0188, -0.0046,  0.0679, -0.0460, -0.0163, -0.0744,  0.0189, -0.0816,\n",
      "         0.0829, -0.0306,  0.0624, -0.0024, -0.0528,  0.0537,  0.0490, -0.0528,\n",
      "        -0.0819, -0.0617,  0.0235,  0.0833,  0.0593,  0.0722, -0.0180,  0.0665,\n",
      "        -0.0327, -0.0202,  0.0614,  0.0162, -0.0231,  0.0082,  0.0058,  0.0060,\n",
      "         0.0530,  0.0554,  0.0598,  0.0340,  0.0136, -0.0495, -0.0405,  0.0433,\n",
      "         0.0656,  0.0046,  0.0439,  0.0255,  0.0519,  0.0261,  0.0612, -0.0096,\n",
      "        -0.0270, -0.0219, -0.0654,  0.0250, -0.0529,  0.0527, -0.0178,  0.0177,\n",
      "         0.0107, -0.0266, -0.0127,  0.0500,  0.0405, -0.0383, -0.0185, -0.0215,\n",
      "         0.0792,  0.0992,  0.0165,  0.0444, -0.0687, -0.0795,  0.0742, -0.0676,\n",
      "         0.0573,  0.0298,  0.0303,  0.0892,  0.0782,  0.0594,  0.0446,  0.0666,\n",
      "         0.0757,  0.0075, -0.0847, -0.0687,  0.0177, -0.0522,  0.0292,  0.0197,\n",
      "        -0.0491, -0.0495, -0.0004,  0.0426,  0.0574, -0.0821, -0.1174,  0.0406,\n",
      "         0.0633,  0.0233,  0.0254, -0.0216, -0.0034,  0.0233, -0.0614,  0.0710],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1267, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0489, -0.0528, -0.0477,  0.0491, -0.0311, -0.0340, -0.1114,  0.0018,\n",
      "        -0.0288,  0.0625, -0.0291, -0.0651, -0.0177,  0.0055, -0.0421, -0.0879,\n",
      "        -0.0599,  0.0558, -0.0097, -0.0811,  0.0103, -0.0224, -0.0548, -0.0320,\n",
      "         0.0257,  0.0209,  0.0482,  0.0499, -0.0541, -0.0658, -0.0423,  0.0388,\n",
      "         0.0456, -0.0357,  0.0584,  0.0516,  0.0714, -0.0140,  0.0130,  0.0866,\n",
      "        -0.0653,  0.0471,  0.0292, -0.0243,  0.0458,  0.0130, -0.0746, -0.0558,\n",
      "        -0.0324, -0.0409, -0.0652,  0.0400,  0.0829, -0.0715,  0.0512, -0.0206,\n",
      "         0.0202, -0.0713,  0.0215, -0.0739,  0.0409,  0.0506, -0.0160,  0.1090,\n",
      "         0.0763, -0.0383,  0.0005, -0.0138, -0.0006,  0.0170, -0.0791, -0.0124,\n",
      "         0.0176,  0.0471, -0.0209,  0.0275,  0.0750,  0.0254,  0.0053, -0.0083,\n",
      "         0.0799, -0.0489, -0.0745,  0.0919,  0.0204, -0.0077,  0.0298,  0.0860,\n",
      "        -0.0125, -0.0795,  0.0126, -0.0963,  0.0401, -0.0232, -0.0759,  0.0253,\n",
      "        -0.0431, -0.0568, -0.0671,  0.0680, -0.0793,  0.0242, -0.0114,  0.0429,\n",
      "        -0.0304, -0.0578,  0.0207, -0.0769, -0.0956, -0.0202, -0.0447,  0.0138,\n",
      "         0.0622, -0.1079, -0.0549, -0.0313, -0.0489, -0.0453,  0.0867, -0.0381,\n",
      "        -0.0439,  0.0413,  0.0613,  0.0815, -0.0551, -0.0843, -0.0147, -0.0538],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1058, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0390, -0.0788,  0.0098,  0.0792, -0.0855,  0.0295, -0.0189, -0.0107,\n",
      "         0.0776,  0.0425,  0.0239,  0.0612,  0.0285, -0.0608, -0.0506,  0.0639,\n",
      "        -0.0043,  0.0165, -0.0129, -0.0219,  0.0049,  0.0018,  0.0593,  0.1006,\n",
      "        -0.0034, -0.0288, -0.0090, -0.0248, -0.0075,  0.0681,  0.0034,  0.0487,\n",
      "         0.0038, -0.0068, -0.0386,  0.0476, -0.0631, -0.1058, -0.0727,  0.0122,\n",
      "         0.0971, -0.0860,  0.0352,  0.0334,  0.0700, -0.0541,  0.0789,  0.0040,\n",
      "        -0.0842, -0.0584,  0.0088, -0.0317,  0.0056,  0.0763,  0.0293,  0.0130,\n",
      "        -0.0299, -0.0612,  0.0604,  0.0175,  0.0205, -0.0627, -0.0247, -0.0312,\n",
      "         0.0109, -0.0506, -0.0382, -0.0347,  0.0392, -0.0792, -0.0472, -0.0279,\n",
      "        -0.0483,  0.0511, -0.0753, -0.0257, -0.0320, -0.0139,  0.0877, -0.0275,\n",
      "        -0.0382,  0.0726,  0.0040,  0.0472,  0.0157, -0.0508, -0.0090, -0.0371,\n",
      "         0.0033,  0.0159, -0.0183, -0.0950,  0.0716,  0.0427, -0.0215,  0.0696,\n",
      "        -0.0585, -0.0781,  0.0501, -0.0577, -0.0385,  0.0310, -0.0645, -0.0378,\n",
      "         0.0229,  0.0428,  0.0451, -0.0918,  0.0184, -0.0692,  0.0426,  0.0708,\n",
      "        -0.0633, -0.0700,  0.0609, -0.0136, -0.0982,  0.0335, -0.0365,  0.0422,\n",
      "         0.0350, -0.0378,  0.0428, -0.0827, -0.0122,  0.0497, -0.0122,  0.0585],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0802, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0392,  0.0620,  0.0905], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76100/100000], Loss: 447.4,   LOSS_function: 170.5,   LOSS_E:7.38e-06,    LOSS_initial: 0.2389,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5700.114885091782\n",
      "loss_compared with real:0.077543,   miu_train:0.00177,    lossmean:-0.0676\n",
      "Epoch [76200/100000], Loss: 425.9,   LOSS_function: 146.3,   LOSS_E:3.655e-06,    LOSS_initial: 0.2465,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5707.328968048096\n",
      "loss_compared with real:0.078115,   miu_train:0.001746,    lossmean:-0.06805\n",
      "Epoch [76300/100000], Loss: 420.8,   LOSS_function: 144.5,   LOSS_E:3.463e-06,    LOSS_initial: 0.2438,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5714.508059024811\n",
      "loss_compared with real:0.07789,   miu_train:0.001836,    lossmean:-0.0685\n",
      "Epoch [76400/100000], Loss: 467,   LOSS_function: 186.8,   LOSS_E:4.178e-06,    LOSS_initial: 0.2464,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5722.032304525375\n",
      "loss_compared with real:0.0782,   miu_train:0.001744,    lossmean:-0.06765\n",
      "Epoch [76500/100000], Loss: 454.1,   LOSS_function: 158,   LOSS_E:2.999e-06,    LOSS_initial: 0.2623,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5729.8378801345825\n",
      "loss_compared with real:0.075046,   miu_train:0.001676,    lossmean:-0.06563\n",
      "Epoch [76600/100000], Loss: 461.8,   LOSS_function: 194.1,   LOSS_E:5.646e-06,    LOSS_initial: 0.233,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5737.720780134201\n",
      "loss_compared with real:0.078345,   miu_train:0.001777,    lossmean:-0.06768\n",
      "Epoch [76700/100000], Loss: 434.6,   LOSS_function: 164.3,   LOSS_E:3.355e-06,    LOSS_initial: 0.2385,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5745.4421763420105\n",
      "loss_compared with real:0.076,   miu_train:0.001812,    lossmean:-0.06685\n",
      "Epoch [76800/100000], Loss: 445.3,   LOSS_function: 182.9,   LOSS_E:4.391e-06,    LOSS_initial: 0.23,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5753.362680673599\n",
      "loss_compared with real:0.076763,   miu_train:0.001847,    lossmean:-0.06678\n",
      "Epoch [76900/100000], Loss: 447.6,   LOSS_function: 181,   LOSS_E:4.124e-06,    LOSS_initial: 0.2341,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1111,      learn rate:1.903e-05,    time: 5761.132051706314\n",
      "loss_compared with real:0.078494,   miu_train:0.001878,    lossmean:-0.06856\n",
      "Epoch [77000/100000], Loss: 468.7,   LOSS_function: 188.7,   LOSS_E:5.632e-06,    LOSS_initial: 0.2348,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5768.867954730988\n",
      "loss_compared with real:0.077576,   miu_train:0.001827,    lossmean:-0.06715\n",
      "Epoch [77100/100000], Loss: 455.5,   LOSS_function: 205.6,   LOSS_E:3.631e-06,    LOSS_initial: 0.2114,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5776.503131151199\n",
      "loss_compared with real:0.074848,   miu_train:0.001992,    lossmean:-0.06618\n",
      "Epoch [77200/100000], Loss: 430.4,   LOSS_function: 162.4,   LOSS_E:4.099e-06,    LOSS_initial: 0.2265,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5784.408012866974\n",
      "loss_compared with real:0.075628,   miu_train:0.002001,    lossmean:-0.06663\n",
      "Epoch [77300/100000], Loss: 444.2,   LOSS_function: 178.4,   LOSS_E:3.674e-06,    LOSS_initial: 0.2251,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5792.2059943675995\n",
      "loss_compared with real:0.074454,   miu_train:0.001958,    lossmean:-0.06582\n",
      "Epoch [77400/100000], Loss: 416.8,   LOSS_function: 154.2,   LOSS_E:2.941e-06,    LOSS_initial: 0.2233,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5799.992949724197\n",
      "loss_compared with real:0.074945,   miu_train:0.002059,    lossmean:-0.06621\n",
      "Epoch [77500/100000], Loss: 453.6,   LOSS_function: 171,   LOSS_E:3.704e-06,    LOSS_initial: 0.2396,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5807.708020925522\n",
      "loss_compared with real:0.073277,   miu_train:0.001809,    lossmean:-0.06499\n",
      "Epoch [77600/100000], Loss: 435.8,   LOSS_function: 166.9,   LOSS_E:4.746e-06,    LOSS_initial: 0.2265,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5815.521905422211\n",
      "loss_compared with real:0.074675,   miu_train:0.001893,    lossmean:-0.06545\n",
      "Epoch [77700/100000], Loss: 463.7,   LOSS_function: 185,   LOSS_E:4.151e-06,    LOSS_initial: 0.2357,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5823.395430803299\n",
      "loss_compared with real:0.073517,   miu_train:0.001902,    lossmean:-0.06504\n",
      "Epoch [77800/100000], Loss: 445.2,   LOSS_function: 190.4,   LOSS_E:3.684e-06,    LOSS_initial: 0.2156,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5831.155909538269\n",
      "loss_compared with real:0.076243,   miu_train:0.00203,    lossmean:-0.06675\n",
      "Epoch [77900/100000], Loss: 460.3,   LOSS_function: 174.3,   LOSS_E:4.792e-06,    LOSS_initial: 0.2412,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1155,      learn rate:1.812e-05,    time: 5838.860926628113\n",
      "loss_compared with real:0.072686,   miu_train:0.001828,    lossmean:-0.06417\n",
      "Epoch [78000/100000], Loss: 414,   LOSS_function: 168.2,   LOSS_E:4.212e-06,    LOSS_initial: 0.2298,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5846.60218334198\n",
      "loss_compared with real:0.072168,   miu_train:0.001836,    lossmean:-0.06376\n",
      "Epoch [78100/100000], Loss: 396.1,   LOSS_function: 131.3,   LOSS_E:3.67e-06,    LOSS_initial: 0.2489,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5854.5166137218475\n",
      "loss_compared with real:0.080853,   miu_train:0.001836,    lossmean:-0.06964\n",
      "Epoch [78200/100000], Loss: 405.1,   LOSS_function: 155.2,   LOSS_E:4.055e-06,    LOSS_initial: 0.234,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5862.321437835693\n",
      "loss_compared with real:0.07967,   miu_train:0.001898,    lossmean:-0.06923\n",
      "Epoch [78300/100000], Loss: 398.2,   LOSS_function: 145.7,   LOSS_E:3.811e-06,    LOSS_initial: 0.2368,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5870.170266151428\n",
      "loss_compared with real:0.080571,   miu_train:0.001901,    lossmean:-0.06977\n",
      "Epoch [78400/100000], Loss: 419.1,   LOSS_function: 149.3,   LOSS_E:4.398e-06,    LOSS_initial: 0.2526,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5877.892609357834\n",
      "loss_compared with real:0.07869,   miu_train:0.001711,    lossmean:-0.06769\n",
      "Epoch [78500/100000], Loss: 427.7,   LOSS_function: 181.7,   LOSS_E:3.223e-06,    LOSS_initial: 0.2314,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5885.1545877456665\n",
      "loss_compared with real:0.079009,   miu_train:0.001811,    lossmean:-0.06827\n",
      "Epoch [78600/100000], Loss: 420.5,   LOSS_function: 150.5,   LOSS_E:5.57e-06,    LOSS_initial: 0.2511,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5892.306058883667\n",
      "loss_compared with real:0.078219,   miu_train:0.001743,    lossmean:-0.06741\n",
      "Epoch [78700/100000], Loss: 426.1,   LOSS_function: 166.4,   LOSS_E:5.194e-06,    LOSS_initial: 0.2417,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5899.53900885582\n",
      "loss_compared with real:0.079278,   miu_train:0.001797,    lossmean:-0.06859\n",
      "Epoch [78800/100000], Loss: 423.1,   LOSS_function: 169.9,   LOSS_E:4.43e-06,    LOSS_initial: 0.2365,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5906.921844959259\n",
      "loss_compared with real:0.078993,   miu_train:0.00178,    lossmean:-0.06787\n",
      "Epoch [78900/100000], Loss: 444.9,   LOSS_function: 180.1,   LOSS_E:3.32e-06,    LOSS_initial: 0.2493,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1041,      learn rate:1.725e-05,    time: 5914.141658306122\n",
      "loss_compared with real:0.078637,   miu_train:0.00169,    lossmean:-0.06761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79000/100000], Loss: 367.6,   LOSS_function: 137.8,   LOSS_E:5.405e-06,    LOSS_initial: 0.2374,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5921.365507602692\n",
      "loss_compared with real:0.078332,   miu_train:0.001911,    lossmean:-0.06835\n",
      "Epoch [79100/100000], Loss: 390.6,   LOSS_function: 148.8,   LOSS_E:3.601e-06,    LOSS_initial: 0.2532,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5928.594958305359\n",
      "loss_compared with real:0.086238,   miu_train:0.001658,    lossmean:-0.07253\n",
      "Epoch [79200/100000], Loss: 387.7,   LOSS_function: 136,   LOSS_E:3.916e-06,    LOSS_initial: 0.2633,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5935.866690158844\n",
      "loss_compared with real:0.084368,   miu_train:0.00158,    lossmean:-0.07135\n",
      "Epoch [79300/100000], Loss: 385.5,   LOSS_function: 147.2,   LOSS_E:3.891e-06,    LOSS_initial: 0.249,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5943.087789773941\n",
      "loss_compared with real:0.083618,   miu_train:0.001659,    lossmean:-0.07113\n",
      "Epoch [79400/100000], Loss: 400.6,   LOSS_function: 150.6,   LOSS_E:3.765e-06,    LOSS_initial: 0.2618,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5950.442653894424\n",
      "loss_compared with real:0.084173,   miu_train:0.001598,    lossmean:-0.07146\n",
      "Epoch [79500/100000], Loss: 383.4,   LOSS_function: 137.9,   LOSS_E:3.652e-06,    LOSS_initial: 0.2571,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5957.779048442841\n",
      "loss_compared with real:0.086006,   miu_train:0.001688,    lossmean:-0.07272\n",
      "Epoch [79600/100000], Loss: 393.7,   LOSS_function: 144.4,   LOSS_E:6.037e-06,    LOSS_initial: 0.2573,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5964.941828966141\n",
      "loss_compared with real:0.084048,   miu_train:0.001611,    lossmean:-0.07154\n",
      "Epoch [79700/100000], Loss: 400.4,   LOSS_function: 154.9,   LOSS_E:3.527e-06,    LOSS_initial: 0.2573,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5972.168134689331\n",
      "loss_compared with real:0.084358,   miu_train:0.00168,    lossmean:-0.07174\n",
      "Epoch [79800/100000], Loss: 383.5,   LOSS_function: 148.2,   LOSS_E:4.049e-06,    LOSS_initial: 0.2455,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5979.355973482132\n",
      "loss_compared with real:0.085122,   miu_train:0.001749,    lossmean:-0.07187\n",
      "Epoch [79900/100000], Loss: 387.2,   LOSS_function: 140.9,   LOSS_E:3.948e-06,    LOSS_initial: 0.2575,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:932.4,      learn rate:1.642e-05,    time: 5986.546432733536\n",
      "loss_compared with real:0.085136,   miu_train:0.001654,    lossmean:-0.07185\n",
      "Epoch [80000/100000], Loss: 372,   LOSS_function: 139.7,   LOSS_E:6.164e-06,    LOSS_initial: 0.2573,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 5993.721624851227\n",
      "loss_compared with real:0.083551,   miu_train:0.001633,    lossmean:-0.07126\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5312, -0.5388, -0.3085, -0.9690, -0.0876, -0.3408,  0.4444, -0.8369,\n",
      "         0.9111,  0.3168,  0.7785,  0.5306,  0.6502, -0.0342,  0.6899, -0.3137,\n",
      "         0.8754,  0.0378,  0.8012, -0.7950, -0.2814, -0.9598, -0.5121, -0.3313,\n",
      "        -0.2961, -0.3994,  0.6967, -0.6640, -0.2486,  0.3842, -0.3143, -0.1898,\n",
      "         0.1076,  0.6401, -0.7261, -0.7953, -0.7200, -0.5709, -0.2664, -0.0496,\n",
      "        -0.8214, -0.9055, -0.0656,  0.7910, -0.6106,  0.8609, -0.6720,  0.8854,\n",
      "         0.5985, -0.9510, -0.7586, -0.3706,  0.8553, -0.5814,  0.9260, -0.1152,\n",
      "        -0.8801,  0.4178, -0.2726, -0.8575,  0.7873, -0.3303,  0.2653, -0.1111,\n",
      "        -0.5492, -0.0665, -0.0342,  0.4168, -0.4236, -0.3491,  0.6044, -0.4492,\n",
      "        -0.5085,  0.8762,  0.8026, -0.4361, -0.4569,  0.0118, -0.3389, -0.5490,\n",
      "        -0.7808, -0.7336,  0.9619,  0.0091,  0.1145,  0.8139,  0.7061,  0.2400,\n",
      "        -0.0322, -0.0786,  0.6670,  0.6922, -0.6782,  0.9043,  0.2278,  0.5588,\n",
      "        -0.6498, -0.1427,  0.6162,  0.0193, -0.8636,  0.0902, -0.0039, -0.2005,\n",
      "         0.4260,  0.4896,  0.6844,  0.0531,  0.2613,  0.6536, -0.6011, -0.2579,\n",
      "         0.5886,  0.7801,  0.7372, -0.0080, -0.9600,  0.9130, -0.3148, -0.8675,\n",
      "        -0.9531,  0.8848, -0.2204,  0.3751, -0.2411,  0.4240, -0.2074,  0.1842],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1120, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0209, -0.0248,  0.0240,  0.0803, -0.0579, -0.0343, -0.0286,  0.0280,\n",
      "        -0.0606,  0.0377, -0.0102, -0.0993,  0.0513, -0.0527,  0.0594,  0.0044,\n",
      "        -0.0248, -0.0283, -0.0380,  0.0704, -0.0620,  0.0555,  0.0251, -0.0148,\n",
      "         0.0188, -0.0047,  0.0679, -0.0460, -0.0162, -0.0743,  0.0190, -0.0816,\n",
      "         0.0828, -0.0306,  0.0625, -0.0024, -0.0527,  0.0535,  0.0489, -0.0529,\n",
      "        -0.0820, -0.0617,  0.0231,  0.0833,  0.0593,  0.0720, -0.0181,  0.0664,\n",
      "        -0.0334, -0.0202,  0.0617,  0.0163, -0.0232,  0.0086,  0.0058,  0.0061,\n",
      "         0.0533,  0.0551,  0.0596,  0.0338,  0.0137, -0.0494, -0.0405,  0.0432,\n",
      "         0.0655,  0.0046,  0.0440,  0.0256,  0.0518,  0.0267,  0.0611, -0.0098,\n",
      "        -0.0269, -0.0218, -0.0653,  0.0254, -0.0530,  0.0526, -0.0177,  0.0178,\n",
      "         0.0107, -0.0268, -0.0129,  0.0500,  0.0406, -0.0381, -0.0183, -0.0215,\n",
      "         0.0792,  0.0994,  0.0162,  0.0443, -0.0688, -0.0792,  0.0739, -0.0677,\n",
      "         0.0572,  0.0299,  0.0305,  0.0894,  0.0782,  0.0595,  0.0447,  0.0665,\n",
      "         0.0757,  0.0070, -0.0839, -0.0688,  0.0177, -0.0524,  0.0293,  0.0198,\n",
      "        -0.0491, -0.0496, -0.0003,  0.0426,  0.0574, -0.0824, -0.1177,  0.0406,\n",
      "         0.0631,  0.0233,  0.0254, -0.0215, -0.0035,  0.0228, -0.0614,  0.0705],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1280, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0488, -0.0529, -0.0476,  0.0493, -0.0311, -0.0340, -0.1114,  0.0020,\n",
      "        -0.0288,  0.0626, -0.0290, -0.0650, -0.0173,  0.0055, -0.0419, -0.0880,\n",
      "        -0.0598,  0.0559, -0.0097, -0.0812,  0.0102, -0.0224, -0.0547, -0.0320,\n",
      "         0.0256,  0.0209,  0.0481,  0.0498, -0.0541, -0.0653, -0.0422,  0.0391,\n",
      "         0.0456, -0.0358,  0.0589,  0.0518,  0.0712, -0.0139,  0.0131,  0.0870,\n",
      "        -0.0655,  0.0470,  0.0291, -0.0241,  0.0459,  0.0130, -0.0750, -0.0559,\n",
      "        -0.0320, -0.0409, -0.0652,  0.0401,  0.0832, -0.0715,  0.0515, -0.0206,\n",
      "         0.0202, -0.0713,  0.0215, -0.0739,  0.0408,  0.0506, -0.0159,  0.1089,\n",
      "         0.0763, -0.0382,  0.0004, -0.0139, -0.0003,  0.0170, -0.0791, -0.0124,\n",
      "         0.0177,  0.0471, -0.0207,  0.0276,  0.0750,  0.0250,  0.0053, -0.0085,\n",
      "         0.0799, -0.0489, -0.0742,  0.0921,  0.0204, -0.0077,  0.0298,  0.0861,\n",
      "        -0.0125, -0.0795,  0.0130, -0.0961,  0.0399, -0.0236, -0.0759,  0.0252,\n",
      "        -0.0432, -0.0567, -0.0670,  0.0681, -0.0794,  0.0242, -0.0112,  0.0430,\n",
      "        -0.0302, -0.0579,  0.0209, -0.0768, -0.0955, -0.0202, -0.0447,  0.0139,\n",
      "         0.0624, -0.1079, -0.0548, -0.0313, -0.0490, -0.0454,  0.0870, -0.0373,\n",
      "        -0.0439,  0.0414,  0.0613,  0.0815, -0.0548, -0.0844, -0.0146, -0.0537],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1064, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0390, -0.0786,  0.0096,  0.0792, -0.0855,  0.0293, -0.0188, -0.0081,\n",
      "         0.0775,  0.0427,  0.0241,  0.0601,  0.0290, -0.0609, -0.0506,  0.0640,\n",
      "        -0.0043,  0.0160, -0.0129, -0.0221,  0.0049,  0.0019,  0.0590,  0.1006,\n",
      "        -0.0028, -0.0289, -0.0092, -0.0246, -0.0075,  0.0679,  0.0035,  0.0485,\n",
      "         0.0040, -0.0064, -0.0394,  0.0477, -0.0629, -0.1060, -0.0730,  0.0125,\n",
      "         0.0971, -0.0860,  0.0352,  0.0334,  0.0700, -0.0542,  0.0790,  0.0038,\n",
      "        -0.0842, -0.0577,  0.0087, -0.0317,  0.0058,  0.0762,  0.0294,  0.0130,\n",
      "        -0.0302, -0.0612,  0.0603,  0.0172,  0.0204, -0.0626, -0.0248, -0.0315,\n",
      "         0.0108, -0.0506, -0.0383, -0.0357,  0.0391, -0.0791, -0.0472, -0.0279,\n",
      "        -0.0488,  0.0518, -0.0753, -0.0264, -0.0321, -0.0139,  0.0878, -0.0276,\n",
      "        -0.0386,  0.0724,  0.0031,  0.0472,  0.0158, -0.0502, -0.0090, -0.0369,\n",
      "         0.0030,  0.0159, -0.0183, -0.0950,  0.0715,  0.0427, -0.0216,  0.0694,\n",
      "        -0.0585, -0.0781,  0.0495, -0.0578, -0.0384,  0.0311, -0.0643, -0.0378,\n",
      "         0.0228,  0.0427,  0.0453, -0.0915,  0.0167, -0.0690,  0.0431,  0.0709,\n",
      "        -0.0633, -0.0702,  0.0609, -0.0133, -0.0985,  0.0324, -0.0365,  0.0411,\n",
      "         0.0349, -0.0377,  0.0428, -0.0823, -0.0121,  0.0496, -0.0122,  0.0585],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0804, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0406,  0.0619,  0.0910], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80100/100000], Loss: 378.7,   LOSS_function: 148.1,   LOSS_E:3.91e-06,    LOSS_initial: 0.2593,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6000.936195611954\n",
      "loss_compared with real:0.088721,   miu_train:0.001592,    lossmean:-0.07439\n",
      "Epoch [80200/100000], Loss: 374.6,   LOSS_function: 129.4,   LOSS_E:3.754e-06,    LOSS_initial: 0.2765,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6008.184942245483\n",
      "loss_compared with real:0.088447,   miu_train:0.00155,    lossmean:-0.07354\n",
      "Epoch [80300/100000], Loss: 374.6,   LOSS_function: 126.7,   LOSS_E:3.647e-06,    LOSS_initial: 0.2797,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6015.466613769531\n",
      "loss_compared with real:0.088602,   miu_train:0.001466,    lossmean:-0.0741\n",
      "Epoch [80400/100000], Loss: 386,   LOSS_function: 141.2,   LOSS_E:5.475e-06,    LOSS_initial: 0.2729,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6022.880579471588\n",
      "loss_compared with real:0.090205,   miu_train:0.001462,    lossmean:-0.07482\n",
      "Epoch [80500/100000], Loss: 372.2,   LOSS_function: 127.9,   LOSS_E:3.52e-06,    LOSS_initial: 0.2758,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6030.706321239471\n",
      "loss_compared with real:0.08916,   miu_train:0.00152,    lossmean:-0.07408\n",
      "Epoch [80600/100000], Loss: 379,   LOSS_function: 139.8,   LOSS_E:4.669e-06,    LOSS_initial: 0.2679,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6038.587830781937\n",
      "loss_compared with real:0.089993,   miu_train:0.001586,    lossmean:-0.07514\n",
      "Epoch [80700/100000], Loss: 369.9,   LOSS_function: 130.9,   LOSS_E:5.209e-06,    LOSS_initial: 0.2666,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6046.326118469238\n",
      "loss_compared with real:0.089503,   miu_train:0.001546,    lossmean:-0.07493\n",
      "Epoch [80800/100000], Loss: 386.2,   LOSS_function: 136.8,   LOSS_E:4.083e-06,    LOSS_initial: 0.2806,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6054.157858848572\n",
      "loss_compared with real:0.089159,   miu_train:0.001422,    lossmean:-0.07415\n",
      "Epoch [80900/100000], Loss: 375,   LOSS_function: 124.6,   LOSS_E:3.215e-06,    LOSS_initial: 0.2833,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:865.8,      learn rate:1.563e-05,    time: 6062.022558689117\n",
      "loss_compared with real:0.086853,   miu_train:0.001456,    lossmean:-0.07357\n",
      "Epoch [81000/100000], Loss: 446.9,   LOSS_function: 172.9,   LOSS_E:4.594e-06,    LOSS_initial: 0.2469,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6069.9073276519775\n",
      "loss_compared with real:0.089295,   miu_train:0.001728,    lossmean:-0.07462\n",
      "Epoch [81100/100000], Loss: 438.3,   LOSS_function: 197.8,   LOSS_E:5.103e-06,    LOSS_initial: 0.2152,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6077.635986566544\n",
      "loss_compared with real:0.076079,   miu_train:0.001899,    lossmean:-0.06678\n",
      "Epoch [81200/100000], Loss: 420.7,   LOSS_function: 172.4,   LOSS_E:4.131e-06,    LOSS_initial: 0.2238,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6085.600222110748\n",
      "loss_compared with real:0.075648,   miu_train:0.001972,    lossmean:-0.0666\n",
      "Epoch [81300/100000], Loss: 458.2,   LOSS_function: 202.5,   LOSS_E:4.945e-06,    LOSS_initial: 0.2294,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6093.242857933044\n",
      "loss_compared with real:0.074796,   miu_train:0.001783,    lossmean:-0.06588\n",
      "Epoch [81400/100000], Loss: 434.7,   LOSS_function: 171.4,   LOSS_E:3.372e-06,    LOSS_initial: 0.2387,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6101.013000011444\n",
      "loss_compared with real:0.074993,   miu_train:0.001827,    lossmean:-0.0661\n",
      "Epoch [81500/100000], Loss: 437.6,   LOSS_function: 165.9,   LOSS_E:4.665e-06,    LOSS_initial: 0.2448,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6108.841125011444\n",
      "loss_compared with real:0.074894,   miu_train:0.001741,    lossmean:-0.0655\n",
      "Epoch [81600/100000], Loss: 443.3,   LOSS_function: 190.9,   LOSS_E:4.506e-06,    LOSS_initial: 0.2271,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6116.572667837143\n",
      "loss_compared with real:0.075263,   miu_train:0.001872,    lossmean:-0.0656\n",
      "Epoch [81700/100000], Loss: 422.9,   LOSS_function: 142.5,   LOSS_E:6.119e-06,    LOSS_initial: 0.2507,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6124.30545091629\n",
      "loss_compared with real:0.074634,   miu_train:0.001759,    lossmean:-0.06524\n",
      "Epoch [81800/100000], Loss: 459.2,   LOSS_function: 201.3,   LOSS_E:3.629e-06,    LOSS_initial: 0.2334,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6132.069376468658\n",
      "loss_compared with real:0.074954,   miu_train:0.001824,    lossmean:-0.06564\n",
      "Epoch [81900/100000], Loss: 450.2,   LOSS_function: 192.9,   LOSS_E:4.747e-06,    LOSS_initial: 0.2312,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1081,      learn rate:1.488e-05,    time: 6139.828741073608\n",
      "loss_compared with real:0.075024,   miu_train:0.001834,    lossmean:-0.06551\n",
      "Epoch [82000/100000], Loss: 402.4,   LOSS_function: 160.6,   LOSS_E:3.652e-06,    LOSS_initial: 0.2365,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6147.712591648102\n",
      "loss_compared with real:0.073789,   miu_train:0.001862,    lossmean:-0.06463\n",
      "Epoch [82100/100000], Loss: 411.7,   LOSS_function: 169.9,   LOSS_E:3.15e-06,    LOSS_initial: 0.2373,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6155.467104434967\n",
      "loss_compared with real:0.08001,   miu_train:0.001768,    lossmean:-0.06859\n",
      "Epoch [82200/100000], Loss: 402.5,   LOSS_function: 156.9,   LOSS_E:3.888e-06,    LOSS_initial: 0.2399,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6163.156736135483\n",
      "loss_compared with real:0.079428,   miu_train:0.001764,    lossmean:-0.06861\n",
      "Epoch [82300/100000], Loss: 383.4,   LOSS_function: 117.6,   LOSS_E:3.633e-06,    LOSS_initial: 0.2606,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6170.829005479813\n",
      "loss_compared with real:0.078577,   miu_train:0.001758,    lossmean:-0.06798\n",
      "Epoch [82400/100000], Loss: 427.9,   LOSS_function: 176.3,   LOSS_E:3.615e-06,    LOSS_initial: 0.2463,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6178.557787179947\n",
      "loss_compared with real:0.079498,   miu_train:0.001658,    lossmean:-0.06809\n",
      "Epoch [82500/100000], Loss: 412.8,   LOSS_function: 161.5,   LOSS_E:4.34e-06,    LOSS_initial: 0.2449,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6185.866022825241\n",
      "loss_compared with real:0.07898,   miu_train:0.001689,    lossmean:-0.06813\n",
      "Epoch [82600/100000], Loss: 421.9,   LOSS_function: 176,   LOSS_E:4.252e-06,    LOSS_initial: 0.2397,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6193.156119823456\n",
      "loss_compared with real:0.080551,   miu_train:0.001758,    lossmean:-0.06904\n",
      "Epoch [82700/100000], Loss: 393,   LOSS_function: 144.1,   LOSS_E:5.825e-06,    LOSS_initial: 0.2402,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6200.4064881801605\n",
      "loss_compared with real:0.078159,   miu_train:0.001762,    lossmean:-0.06728\n",
      "Epoch [82800/100000], Loss: 403.1,   LOSS_function: 171,   LOSS_E:5.007e-06,    LOSS_initial: 0.2247,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6207.612341165543\n",
      "loss_compared with real:0.081242,   miu_train:0.001895,    lossmean:-0.0701\n",
      "Epoch [82900/100000], Loss: 407.9,   LOSS_function: 156.4,   LOSS_E:4.258e-06,    LOSS_initial: 0.2453,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:998.2,      learn rate:1.417e-05,    time: 6214.99374461174\n",
      "loss_compared with real:0.079191,   miu_train:0.001702,    lossmean:-0.06796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83000/100000], Loss: 364,   LOSS_function: 142.3,   LOSS_E:4.788e-06,    LOSS_initial: 0.2397,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6222.240947723389\n",
      "loss_compared with real:0.079283,   miu_train:0.00178,    lossmean:-0.0679\n",
      "Epoch [83100/100000], Loss: 394.1,   LOSS_function: 157.5,   LOSS_E:3.37e-06,    LOSS_initial: 0.2588,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6229.472244501114\n",
      "loss_compared with real:0.084363,   miu_train:0.001645,    lossmean:-0.07125\n",
      "Epoch [83200/100000], Loss: 386.4,   LOSS_function: 147.9,   LOSS_E:3.658e-06,    LOSS_initial: 0.2604,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6236.601950883865\n",
      "loss_compared with real:0.085932,   miu_train:0.001588,    lossmean:-0.07235\n",
      "Epoch [83300/100000], Loss: 388.6,   LOSS_function: 137.6,   LOSS_E:3.998e-06,    LOSS_initial: 0.2738,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6243.845632791519\n",
      "loss_compared with real:0.084637,   miu_train:0.001499,    lossmean:-0.07117\n",
      "Epoch [83400/100000], Loss: 374.6,   LOSS_function: 140.2,   LOSS_E:3.063e-06,    LOSS_initial: 0.2569,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6251.059109210968\n",
      "loss_compared with real:0.086676,   miu_train:0.001667,    lossmean:-0.07304\n",
      "Epoch [83500/100000], Loss: 398.2,   LOSS_function: 158.6,   LOSS_E:4.386e-06,    LOSS_initial: 0.2603,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6258.374868631363\n",
      "loss_compared with real:0.084147,   miu_train:0.001582,    lossmean:-0.07114\n",
      "Epoch [83600/100000], Loss: 389.8,   LOSS_function: 157.4,   LOSS_E:3.236e-06,    LOSS_initial: 0.2544,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6265.609909772873\n",
      "loss_compared with real:0.085084,   miu_train:0.001551,    lossmean:-0.07196\n",
      "Epoch [83700/100000], Loss: 377.9,   LOSS_function: 136.8,   LOSS_E:4.23e-06,    LOSS_initial: 0.2623,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6272.90948677063\n",
      "loss_compared with real:0.084573,   miu_train:0.001631,    lossmean:-0.07159\n",
      "Epoch [83800/100000], Loss: 389.3,   LOSS_function: 158.4,   LOSS_E:3.329e-06,    LOSS_initial: 0.2524,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6280.200502157211\n",
      "loss_compared with real:0.085333,   miu_train:0.001645,    lossmean:-0.07201\n",
      "Epoch [83900/100000], Loss: 390.7,   LOSS_function: 158.2,   LOSS_E:3.725e-06,    LOSS_initial: 0.2536,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:893.8,      learn rate:1.349e-05,    time: 6287.399776935577\n",
      "loss_compared with real:0.086257,   miu_train:0.001626,    lossmean:-0.07254\n",
      "Epoch [84000/100000], Loss: 432.9,   LOSS_function: 169.8,   LOSS_E:3.429e-06,    LOSS_initial: 0.255,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6294.6948664188385\n",
      "loss_compared with real:0.085107,   miu_train:0.001643,    lossmean:-0.07208\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5310, -0.5389, -0.3085, -0.9691, -0.0876, -0.3407,  0.4444, -0.8369,\n",
      "         0.9111,  0.3169,  0.7786,  0.5307,  0.6502, -0.0342,  0.6900, -0.3137,\n",
      "         0.8754,  0.0378,  0.8011, -0.7952, -0.2814, -0.9598, -0.5121, -0.3312,\n",
      "        -0.2962, -0.3994,  0.6968, -0.6641, -0.2487,  0.3841, -0.3142, -0.1898,\n",
      "         0.1076,  0.6400, -0.7260, -0.7952, -0.7200, -0.5708, -0.2665, -0.0495,\n",
      "        -0.8213, -0.9056, -0.0656,  0.7911, -0.6105,  0.8610, -0.6721,  0.8853,\n",
      "         0.5985, -0.9507, -0.7586, -0.3707,  0.8555, -0.5814,  0.9260, -0.1152,\n",
      "        -0.8803,  0.4179, -0.2725, -0.8575,  0.7873, -0.3303,  0.2653, -0.1112,\n",
      "        -0.5491, -0.0665, -0.0343,  0.4168, -0.4234, -0.3491,  0.6045, -0.4491,\n",
      "        -0.5085,  0.8762,  0.8026, -0.4360, -0.4570,  0.0118, -0.3389, -0.5487,\n",
      "        -0.7807, -0.7336,  0.9620,  0.0091,  0.1145,  0.8138,  0.7061,  0.2399,\n",
      "        -0.0321, -0.0787,  0.6669,  0.6922, -0.6782,  0.9043,  0.2278,  0.5588,\n",
      "        -0.6498, -0.1427,  0.6163,  0.0193, -0.8636,  0.0902, -0.0039, -0.2005,\n",
      "         0.4256,  0.4897,  0.6845,  0.0531,  0.2615,  0.6535, -0.6012, -0.2580,\n",
      "         0.5888,  0.7801,  0.7372, -0.0080, -0.9601,  0.9130, -0.3149, -0.8674,\n",
      "        -0.9528,  0.8847, -0.2204,  0.3750, -0.2410,  0.4240, -0.2074,  0.1843],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1127, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0209, -0.0246,  0.0239,  0.0801, -0.0580, -0.0343, -0.0288,  0.0280,\n",
      "        -0.0604,  0.0376, -0.0102, -0.0993,  0.0514, -0.0527,  0.0594,  0.0043,\n",
      "        -0.0248, -0.0283, -0.0381,  0.0706, -0.0620,  0.0554,  0.0251, -0.0148,\n",
      "         0.0188, -0.0047,  0.0678, -0.0461, -0.0163, -0.0743,  0.0192, -0.0816,\n",
      "         0.0828, -0.0307,  0.0625, -0.0023, -0.0527,  0.0531,  0.0489, -0.0530,\n",
      "        -0.0820, -0.0617,  0.0229,  0.0833,  0.0593,  0.0718, -0.0181,  0.0664,\n",
      "        -0.0338, -0.0200,  0.0618,  0.0164, -0.0234,  0.0088,  0.0058,  0.0062,\n",
      "         0.0534,  0.0547,  0.0594,  0.0335,  0.0139, -0.0493, -0.0404,  0.0431,\n",
      "         0.0655,  0.0047,  0.0441,  0.0255,  0.0517,  0.0271,  0.0611, -0.0099,\n",
      "        -0.0269, -0.0218, -0.0654,  0.0256, -0.0531,  0.0524, -0.0175,  0.0178,\n",
      "         0.0108, -0.0268, -0.0130,  0.0500,  0.0407, -0.0379, -0.0181, -0.0215,\n",
      "         0.0792,  0.0996,  0.0161,  0.0443, -0.0688, -0.0790,  0.0737, -0.0677,\n",
      "         0.0572,  0.0299,  0.0305,  0.0895,  0.0782,  0.0594,  0.0447,  0.0661,\n",
      "         0.0759,  0.0061, -0.0833, -0.0688,  0.0177, -0.0526,  0.0292,  0.0198,\n",
      "        -0.0491, -0.0497, -0.0001,  0.0424,  0.0575, -0.0826, -0.1179,  0.0404,\n",
      "         0.0631,  0.0232,  0.0253, -0.0216, -0.0035,  0.0226, -0.0614,  0.0701],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1286, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0488, -0.0528, -0.0476,  0.0493, -0.0311, -0.0341, -0.1114,  0.0023,\n",
      "        -0.0287,  0.0626, -0.0290, -0.0650, -0.0170,  0.0053, -0.0419, -0.0882,\n",
      "        -0.0597,  0.0562, -0.0098, -0.0812,  0.0102, -0.0225, -0.0546, -0.0320,\n",
      "         0.0254,  0.0208,  0.0481,  0.0497, -0.0541, -0.0649, -0.0422,  0.0392,\n",
      "         0.0456, -0.0359,  0.0591,  0.0519,  0.0710, -0.0138,  0.0133,  0.0874,\n",
      "        -0.0657,  0.0469,  0.0291, -0.0238,  0.0459,  0.0130, -0.0751, -0.0559,\n",
      "        -0.0320, -0.0409, -0.0654,  0.0402,  0.0835, -0.0716,  0.0521, -0.0205,\n",
      "         0.0203, -0.0713,  0.0216, -0.0739,  0.0408,  0.0506, -0.0158,  0.1089,\n",
      "         0.0764, -0.0381,  0.0005, -0.0139,  0.0002,  0.0170, -0.0788, -0.0124,\n",
      "         0.0177,  0.0473, -0.0205,  0.0277,  0.0750,  0.0247,  0.0052, -0.0086,\n",
      "         0.0800, -0.0488, -0.0740,  0.0921,  0.0204, -0.0077,  0.0298,  0.0861,\n",
      "        -0.0125, -0.0796,  0.0132, -0.0959,  0.0397, -0.0237, -0.0758,  0.0252,\n",
      "        -0.0433, -0.0565, -0.0669,  0.0681, -0.0793,  0.0243, -0.0111,  0.0431,\n",
      "        -0.0301, -0.0580,  0.0209, -0.0766, -0.0954, -0.0202, -0.0448,  0.0140,\n",
      "         0.0625, -0.1079, -0.0549, -0.0313, -0.0490, -0.0454,  0.0872, -0.0366,\n",
      "        -0.0438,  0.0413,  0.0613,  0.0815, -0.0547, -0.0843, -0.0146, -0.0536],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1066, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0390, -0.0781,  0.0094,  0.0792, -0.0856,  0.0292, -0.0187, -0.0067,\n",
      "         0.0774,  0.0430,  0.0245,  0.0596,  0.0300, -0.0609, -0.0508,  0.0641,\n",
      "        -0.0042,  0.0159, -0.0127, -0.0220,  0.0049,  0.0016,  0.0588,  0.1005,\n",
      "        -0.0025, -0.0290, -0.0092, -0.0244, -0.0074,  0.0678,  0.0037,  0.0483,\n",
      "         0.0041, -0.0062, -0.0399,  0.0478, -0.0627, -0.1061, -0.0732,  0.0129,\n",
      "         0.0972, -0.0861,  0.0352,  0.0334,  0.0700, -0.0544,  0.0790,  0.0037,\n",
      "        -0.0842, -0.0572,  0.0084, -0.0318,  0.0059,  0.0762,  0.0295,  0.0129,\n",
      "        -0.0303, -0.0613,  0.0603,  0.0170,  0.0204, -0.0626, -0.0247, -0.0317,\n",
      "         0.0107, -0.0505, -0.0380, -0.0360,  0.0391, -0.0787, -0.0474, -0.0278,\n",
      "        -0.0490,  0.0522, -0.0753, -0.0269, -0.0327, -0.0140,  0.0879, -0.0278,\n",
      "        -0.0391,  0.0723,  0.0018,  0.0472,  0.0157, -0.0500, -0.0088, -0.0369,\n",
      "         0.0029,  0.0158, -0.0185, -0.0950,  0.0714,  0.0428, -0.0217,  0.0693,\n",
      "        -0.0584, -0.0781,  0.0492, -0.0578, -0.0383,  0.0311, -0.0643, -0.0380,\n",
      "         0.0227,  0.0426,  0.0457, -0.0913,  0.0156, -0.0689,  0.0434,  0.0711,\n",
      "        -0.0634, -0.0706,  0.0609, -0.0131, -0.0986,  0.0315, -0.0366,  0.0405,\n",
      "         0.0347, -0.0376,  0.0428, -0.0813, -0.0117,  0.0495, -0.0122,  0.0584],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0804, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0424,  0.0623,  0.0912], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84100/100000], Loss: 403.8,   LOSS_function: 161.2,   LOSS_E:3.058e-06,    LOSS_initial: 0.2352,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6301.882886171341\n",
      "loss_compared with real:0.077452,   miu_train:0.001818,    lossmean:-0.06738\n",
      "Epoch [84200/100000], Loss: 404.4,   LOSS_function: 162.6,   LOSS_E:3.63e-06,    LOSS_initial: 0.2335,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6309.043587684631\n",
      "loss_compared with real:0.0787,   miu_train:0.001842,    lossmean:-0.06785\n",
      "Epoch [84300/100000], Loss: 409.4,   LOSS_function: 162.1,   LOSS_E:4.459e-06,    LOSS_initial: 0.2377,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6316.208721399307\n",
      "loss_compared with real:0.078199,   miu_train:0.001807,    lossmean:-0.06799\n",
      "Epoch [84400/100000], Loss: 423.9,   LOSS_function: 191.1,   LOSS_E:3.693e-06,    LOSS_initial: 0.2246,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6323.560065746307\n",
      "loss_compared with real:0.078365,   miu_train:0.001833,    lossmean:-0.06817\n",
      "Epoch [84500/100000], Loss: 414.1,   LOSS_function: 162.5,   LOSS_E:4.041e-06,    LOSS_initial: 0.2427,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6331.381009340286\n",
      "loss_compared with real:0.078662,   miu_train:0.001732,    lossmean:-0.0678\n",
      "Epoch [84600/100000], Loss: 399.3,   LOSS_function: 155.4,   LOSS_E:3.811e-06,    LOSS_initial: 0.2354,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6339.132212877274\n",
      "loss_compared with real:0.077614,   miu_train:0.001791,    lossmean:-0.06702\n",
      "Epoch [84700/100000], Loss: 404.8,   LOSS_function: 162,   LOSS_E:4.353e-06,    LOSS_initial: 0.2335,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6347.01830124855\n",
      "loss_compared with real:0.076962,   miu_train:0.001856,    lossmean:-0.0672\n",
      "Epoch [84800/100000], Loss: 404.8,   LOSS_function: 154.8,   LOSS_E:3.804e-06,    LOSS_initial: 0.2415,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6354.915875196457\n",
      "loss_compared with real:0.07795,   miu_train:0.00178,    lossmean:-0.06777\n",
      "Epoch [84900/100000], Loss: 409.6,   LOSS_function: 161.1,   LOSS_E:3.731e-06,    LOSS_initial: 0.24,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:1011,      learn rate:1.284e-05,    time: 6362.7695372104645\n",
      "loss_compared with real:0.077394,   miu_train:0.001819,    lossmean:-0.06725\n",
      "Epoch [85000/100000], Loss: 383,   LOSS_function: 147.8,   LOSS_E:3.816e-06,    LOSS_initial: 0.2409,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6370.697203397751\n",
      "loss_compared with real:0.077161,   miu_train:0.001734,    lossmean:-0.06715\n",
      "Epoch [85100/100000], Loss: 393.8,   LOSS_function: 151.6,   LOSS_E:3.09e-06,    LOSS_initial: 0.2496,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6378.565035820007\n",
      "loss_compared with real:0.080926,   miu_train:0.001688,    lossmean:-0.06959\n",
      "Epoch [85200/100000], Loss: 391.8,   LOSS_function: 144.4,   LOSS_E:3.866e-06,    LOSS_initial: 0.2537,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6386.402315616608\n",
      "loss_compared with real:0.082495,   miu_train:0.001685,    lossmean:-0.07054\n",
      "Epoch [85300/100000], Loss: 403.6,   LOSS_function: 166.7,   LOSS_E:4.126e-06,    LOSS_initial: 0.2423,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6394.149749279022\n",
      "loss_compared with real:0.082084,   miu_train:0.001687,    lossmean:-0.0698\n",
      "Epoch [85400/100000], Loss: 415.9,   LOSS_function: 165,   LOSS_E:3.959e-06,    LOSS_initial: 0.2573,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6401.9321937561035\n",
      "loss_compared with real:0.079535,   miu_train:0.001587,    lossmean:-0.06809\n",
      "Epoch [85500/100000], Loss: 393.1,   LOSS_function: 140.5,   LOSS_E:4.282e-06,    LOSS_initial: 0.2586,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6409.894159317017\n",
      "loss_compared with real:0.080525,   miu_train:0.001651,    lossmean:-0.0686\n",
      "Epoch [85600/100000], Loss: 421.3,   LOSS_function: 183.5,   LOSS_E:4.787e-06,    LOSS_initial: 0.2421,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6417.79049539566\n",
      "loss_compared with real:0.081414,   miu_train:0.001676,    lossmean:-0.06928\n",
      "Epoch [85700/100000], Loss: 388.8,   LOSS_function: 156.4,   LOSS_E:3.537e-06,    LOSS_initial: 0.2385,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6425.525602579117\n",
      "loss_compared with real:0.080986,   miu_train:0.001772,    lossmean:-0.06963\n",
      "Epoch [85800/100000], Loss: 405.5,   LOSS_function: 165.4,   LOSS_E:3.954e-06,    LOSS_initial: 0.246,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6433.296059131622\n",
      "loss_compared with real:0.081076,   miu_train:0.001678,    lossmean:-0.06953\n",
      "Epoch [85900/100000], Loss: 396.1,   LOSS_function: 161.3,   LOSS_E:4.328e-06,    LOSS_initial: 0.2397,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:951.2,      learn rate:1.222e-05,    time: 6441.115649938583\n",
      "loss_compared with real:0.082808,   miu_train:0.001785,    lossmean:-0.07081\n",
      "Epoch [86000/100000], Loss: 371.1,   LOSS_function: 144,   LOSS_E:4.25e-06,    LOSS_initial: 0.2376,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6448.990749120712\n",
      "loss_compared with real:0.081208,   miu_train:0.001766,    lossmean:-0.06977\n",
      "Epoch [86100/100000], Loss: 411.3,   LOSS_function: 177.4,   LOSS_E:5.036e-06,    LOSS_initial: 0.2436,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6456.646758556366\n",
      "loss_compared with real:0.082744,   miu_train:0.001691,    lossmean:-0.07022\n",
      "Epoch [86200/100000], Loss: 372.7,   LOSS_function: 147.2,   LOSS_E:3.093e-06,    LOSS_initial: 0.2378,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6464.508190393448\n",
      "loss_compared with real:0.084087,   miu_train:0.001817,    lossmean:-0.07161\n",
      "Epoch [86300/100000], Loss: 387.8,   LOSS_function: 146.3,   LOSS_E:4.38e-06,    LOSS_initial: 0.2529,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6472.233720064163\n",
      "loss_compared with real:0.083302,   miu_train:0.001671,    lossmean:-0.07095\n",
      "Epoch [86400/100000], Loss: 396,   LOSS_function: 161.6,   LOSS_E:3.987e-06,    LOSS_initial: 0.2459,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6480.171703577042\n",
      "loss_compared with real:0.080831,   miu_train:0.001629,    lossmean:-0.06984\n",
      "Epoch [86500/100000], Loss: 402.9,   LOSS_function: 156.5,   LOSS_E:3.801e-06,    LOSS_initial: 0.2592,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6487.4333164691925\n",
      "loss_compared with real:0.082644,   miu_train:0.001606,    lossmean:-0.07038\n",
      "Epoch [86600/100000], Loss: 382,   LOSS_function: 140.2,   LOSS_E:3.628e-06,    LOSS_initial: 0.2545,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6494.68107676506\n",
      "loss_compared with real:0.083133,   miu_train:0.001618,    lossmean:-0.07125\n",
      "Epoch [86700/100000], Loss: 386.3,   LOSS_function: 150.6,   LOSS_E:3.486e-06,    LOSS_initial: 0.2481,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6501.836284160614\n",
      "loss_compared with real:0.082911,   miu_train:0.001706,    lossmean:-0.07121\n",
      "Epoch [86800/100000], Loss: 397.9,   LOSS_function: 147.4,   LOSS_E:4.418e-06,    LOSS_initial: 0.2626,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6509.0647785663605\n",
      "loss_compared with real:0.08131,   miu_train:0.001593,    lossmean:-0.06933\n",
      "Epoch [86900/100000], Loss: 391.9,   LOSS_function: 151.2,   LOSS_E:3.483e-06,    LOSS_initial: 0.2535,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:927.7,      learn rate:1.164e-05,    time: 6516.234429597855\n",
      "loss_compared with real:0.082212,   miu_train:0.001701,    lossmean:-0.06972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87000/100000], Loss: 354.3,   LOSS_function: 136.8,   LOSS_E:4.049e-06,    LOSS_initial: 0.2523,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6523.48251914978\n",
      "loss_compared with real:0.081618,   miu_train:0.001669,    lossmean:-0.06973\n",
      "Epoch [87100/100000], Loss: 370,   LOSS_function: 135.2,   LOSS_E:3.786e-06,    LOSS_initial: 0.2734,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6530.630918502808\n",
      "loss_compared with real:0.08772,   miu_train:0.00149,    lossmean:-0.0732\n",
      "Epoch [87200/100000], Loss: 365.9,   LOSS_function: 132.9,   LOSS_E:3.769e-06,    LOSS_initial: 0.2713,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6537.864635229111\n",
      "loss_compared with real:0.089795,   miu_train:0.001531,    lossmean:-0.07465\n",
      "Epoch [87300/100000], Loss: 380.9,   LOSS_function: 151.6,   LOSS_E:3.672e-06,    LOSS_initial: 0.2671,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6545.216099500656\n",
      "loss_compared with real:0.086722,   miu_train:0.001487,    lossmean:-0.07296\n",
      "Epoch [87400/100000], Loss: 360.7,   LOSS_function: 121.9,   LOSS_E:3.505e-06,    LOSS_initial: 0.2787,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6552.463319301605\n",
      "loss_compared with real:0.087362,   miu_train:0.001461,    lossmean:-0.07317\n",
      "Epoch [87500/100000], Loss: 358.6,   LOSS_function: 129.6,   LOSS_E:3.161e-06,    LOSS_initial: 0.2676,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6559.787249803543\n",
      "loss_compared with real:0.088129,   miu_train:0.001502,    lossmean:-0.07363\n",
      "Epoch [87600/100000], Loss: 374.7,   LOSS_function: 139.1,   LOSS_E:3.539e-06,    LOSS_initial: 0.2748,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6567.0040447711945\n",
      "loss_compared with real:0.086538,   miu_train:0.001424,    lossmean:-0.07297\n",
      "Epoch [87700/100000], Loss: 362.9,   LOSS_function: 129.6,   LOSS_E:3.658e-06,    LOSS_initial: 0.2719,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6574.162987232208\n",
      "loss_compared with real:0.088285,   miu_train:0.001486,    lossmean:-0.07428\n",
      "Epoch [87800/100000], Loss: 361.2,   LOSS_function: 123.8,   LOSS_E:3.629e-06,    LOSS_initial: 0.2769,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6581.459987401962\n",
      "loss_compared with real:0.087803,   miu_train:0.001478,    lossmean:-0.07348\n",
      "Epoch [87900/100000], Loss: 367.2,   LOSS_function: 147.7,   LOSS_E:5.13e-06,    LOSS_initial: 0.2528,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:836.9,      learn rate:1.108e-05,    time: 6588.668334722519\n",
      "loss_compared with real:0.089431,   miu_train:0.001603,    lossmean:-0.07459\n",
      "Epoch [88000/100000], Loss: 376.8,   LOSS_function: 143.5,   LOSS_E:4.016e-06,    LOSS_initial: 0.2799,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6595.926911115646\n",
      "loss_compared with real:0.086612,   miu_train:0.001429,    lossmean:-0.07282\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5310, -0.5389, -0.3084, -0.9692, -0.0876, -0.3406,  0.4444, -0.8370,\n",
      "         0.9110,  0.3169,  0.7787,  0.5308,  0.6502, -0.0342,  0.6900, -0.3138,\n",
      "         0.8755,  0.0379,  0.8011, -0.7954, -0.2814, -0.9598, -0.5121, -0.3312,\n",
      "        -0.2963, -0.3995,  0.6968, -0.6641, -0.2487,  0.3840, -0.3141, -0.1898,\n",
      "         0.1076,  0.6400, -0.7260, -0.7952, -0.7200, -0.5706, -0.2666, -0.0494,\n",
      "        -0.8211, -0.9057, -0.0656,  0.7911, -0.6103,  0.8610, -0.6721,  0.8852,\n",
      "         0.5985, -0.9504, -0.7587, -0.3708,  0.8557, -0.5814,  0.9261, -0.1152,\n",
      "        -0.8804,  0.4180, -0.2725, -0.8575,  0.7873, -0.3303,  0.2654, -0.1113,\n",
      "        -0.5490, -0.0665, -0.0342,  0.4169, -0.4233, -0.3490,  0.6045, -0.4491,\n",
      "        -0.5085,  0.8763,  0.8026, -0.4360, -0.4571,  0.0118, -0.3389, -0.5486,\n",
      "        -0.7806, -0.7336,  0.9622,  0.0091,  0.1145,  0.8138,  0.7061,  0.2399,\n",
      "        -0.0321, -0.0788,  0.6668,  0.6922, -0.6781,  0.9043,  0.2279,  0.5588,\n",
      "        -0.6498, -0.1428,  0.6164,  0.0193, -0.8636,  0.0901, -0.0040, -0.2005,\n",
      "         0.4253,  0.4899,  0.6845,  0.0532,  0.2616,  0.6535, -0.6012, -0.2580,\n",
      "         0.5889,  0.7801,  0.7372, -0.0079, -0.9603,  0.9131, -0.3149, -0.8674,\n",
      "        -0.9526,  0.8847, -0.2204,  0.3749, -0.2409,  0.4241, -0.2073,  0.1843],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1133, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 2.0817e-02, -2.4486e-02,  2.3932e-02,  7.9873e-02, -5.8093e-02,\n",
      "        -3.4257e-02, -2.8871e-02,  2.7953e-02, -6.0310e-02,  3.7526e-02,\n",
      "        -1.0233e-02, -9.9266e-02,  5.1511e-02, -5.2617e-02,  5.9470e-02,\n",
      "         4.2715e-03, -2.4775e-02, -2.8258e-02, -3.8110e-02,  7.0770e-02,\n",
      "        -6.2059e-02,  5.5234e-02,  2.5118e-02, -1.4723e-02,  1.8866e-02,\n",
      "        -4.6536e-03,  6.7821e-02, -4.6303e-02, -1.6386e-02, -7.4335e-02,\n",
      "         1.9262e-02, -8.1609e-02,  8.2757e-02, -3.0711e-02,  6.2572e-02,\n",
      "        -2.1977e-03, -5.2661e-02,  5.2824e-02,  4.8907e-02, -5.3015e-02,\n",
      "        -8.2078e-02, -6.1601e-02,  2.2678e-02,  8.3292e-02,  5.9252e-02,\n",
      "         7.1747e-02, -1.8103e-02,  6.6363e-02, -3.4152e-02, -1.9811e-02,\n",
      "         6.1934e-02,  1.6432e-02, -2.3536e-02,  9.0205e-03,  5.8471e-03,\n",
      "         6.1720e-03,  5.3378e-02,  5.4457e-02,  5.9335e-02,  3.3238e-02,\n",
      "         1.4124e-02, -4.9302e-02, -4.0321e-02,  4.3029e-02,  6.5411e-02,\n",
      "         4.6851e-03,  4.4180e-02,  2.5414e-02,  5.1545e-02,  2.7402e-02,\n",
      "         6.1038e-02, -1.0018e-02, -2.6922e-02, -2.1958e-02, -6.5548e-02,\n",
      "         2.5704e-02, -5.3147e-02,  5.2248e-02, -1.7362e-02,  1.7828e-02,\n",
      "         1.0804e-02, -2.6902e-02, -1.3026e-02,  4.9967e-02,  4.0746e-02,\n",
      "        -3.7682e-02, -1.7996e-02, -2.1572e-02,  7.9129e-02,  9.9729e-02,\n",
      "         1.6072e-02,  4.4306e-02, -6.8851e-02, -7.8835e-02,  7.3471e-02,\n",
      "        -6.7745e-02,  5.7168e-02,  2.9929e-02,  3.0575e-02,  8.9584e-02,\n",
      "         7.8249e-02,  5.9428e-02,  4.4665e-02,  6.5891e-02,  7.6069e-02,\n",
      "         5.0739e-03, -8.2805e-02, -6.8713e-02,  1.7628e-02, -5.2722e-02,\n",
      "         2.9169e-02,  1.9811e-02, -4.9147e-02, -4.9767e-02,  1.0411e-05,\n",
      "         4.2160e-02,  5.7491e-02, -8.2687e-02, -1.1810e-01,  4.0230e-02,\n",
      "         6.2985e-02,  2.3233e-02,  2.5289e-02, -2.1766e-02, -3.5180e-03,\n",
      "         2.2533e-02, -6.1352e-02,  6.9863e-02], requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1290, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0488, -0.0526, -0.0477,  0.0493, -0.0311, -0.0341, -0.1114,  0.0024,\n",
      "        -0.0287,  0.0626, -0.0288, -0.0650, -0.0168,  0.0051, -0.0420, -0.0884,\n",
      "        -0.0597,  0.0565, -0.0098, -0.0812,  0.0102, -0.0225, -0.0546, -0.0319,\n",
      "         0.0253,  0.0207,  0.0482,  0.0497, -0.0542, -0.0646, -0.0422,  0.0392,\n",
      "         0.0457, -0.0359,  0.0592,  0.0520,  0.0708, -0.0136,  0.0135,  0.0879,\n",
      "        -0.0658,  0.0468,  0.0290, -0.0237,  0.0460,  0.0131, -0.0751, -0.0559,\n",
      "        -0.0319, -0.0409, -0.0656,  0.0402,  0.0836, -0.0716,  0.0526, -0.0205,\n",
      "         0.0203, -0.0714,  0.0216, -0.0739,  0.0407,  0.0506, -0.0159,  0.1089,\n",
      "         0.0765, -0.0379,  0.0005, -0.0138,  0.0006,  0.0171, -0.0786, -0.0124,\n",
      "         0.0178,  0.0474, -0.0203,  0.0278,  0.0751,  0.0245,  0.0052, -0.0086,\n",
      "         0.0800, -0.0488, -0.0737,  0.0921,  0.0203, -0.0077,  0.0299,  0.0861,\n",
      "        -0.0125, -0.0796,  0.0133, -0.0958,  0.0396, -0.0238, -0.0757,  0.0252,\n",
      "        -0.0433, -0.0564, -0.0669,  0.0682, -0.0793,  0.0244, -0.0110,  0.0432,\n",
      "        -0.0300, -0.0581,  0.0209, -0.0764, -0.0954, -0.0203, -0.0449,  0.0140,\n",
      "         0.0625, -0.1078, -0.0549, -0.0313, -0.0490, -0.0453,  0.0873, -0.0358,\n",
      "        -0.0436,  0.0413,  0.0613,  0.0815, -0.0546, -0.0843, -0.0145, -0.0535],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1068, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0389, -0.0774,  0.0094,  0.0792, -0.0857,  0.0291, -0.0186, -0.0056,\n",
      "         0.0774,  0.0433,  0.0249,  0.0591,  0.0310, -0.0610, -0.0510,  0.0643,\n",
      "        -0.0042,  0.0160, -0.0126, -0.0219,  0.0049,  0.0014,  0.0585,  0.1004,\n",
      "        -0.0024, -0.0291, -0.0091, -0.0242, -0.0073,  0.0677,  0.0039,  0.0481,\n",
      "         0.0041, -0.0061, -0.0402,  0.0480, -0.0626, -0.1061, -0.0733,  0.0133,\n",
      "         0.0972, -0.0862,  0.0352,  0.0334,  0.0700, -0.0546,  0.0790,  0.0035,\n",
      "        -0.0842, -0.0569,  0.0082, -0.0319,  0.0060,  0.0762,  0.0296,  0.0129,\n",
      "        -0.0303, -0.0614,  0.0603,  0.0169,  0.0203, -0.0626, -0.0247, -0.0318,\n",
      "         0.0105, -0.0505, -0.0377, -0.0363,  0.0391, -0.0785, -0.0476, -0.0278,\n",
      "        -0.0491,  0.0524, -0.0753, -0.0273, -0.0332, -0.0140,  0.0879, -0.0281,\n",
      "        -0.0397,  0.0722,  0.0006,  0.0472,  0.0157, -0.0499, -0.0087, -0.0369,\n",
      "         0.0028,  0.0158, -0.0188, -0.0951,  0.0713,  0.0428, -0.0218,  0.0693,\n",
      "        -0.0583, -0.0781,  0.0490, -0.0579, -0.0382,  0.0312, -0.0643, -0.0381,\n",
      "         0.0227,  0.0426,  0.0460, -0.0912,  0.0144, -0.0687,  0.0435,  0.0711,\n",
      "        -0.0635, -0.0709,  0.0609, -0.0129, -0.0987,  0.0310, -0.0367,  0.0400,\n",
      "         0.0344, -0.0376,  0.0428, -0.0806, -0.0113,  0.0494, -0.0123,  0.0584],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0805, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0438,  0.0626,  0.0914], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88100/100000], Loss: 351.5,   LOSS_function: 127.7,   LOSS_E:2.806e-06,    LOSS_initial: 0.2705,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6603.29444694519\n",
      "loss_compared with real:0.088906,   miu_train:0.001516,    lossmean:-0.07397\n",
      "Epoch [88200/100000], Loss: 354,   LOSS_function: 123.8,   LOSS_E:3.36e-06,    LOSS_initial: 0.2774,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6610.5856392383575\n",
      "loss_compared with real:0.089729,   miu_train:0.001427,    lossmean:-0.0746\n",
      "Epoch [88300/100000], Loss: 367.7,   LOSS_function: 137.9,   LOSS_E:3.893e-06,    LOSS_initial: 0.2759,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6617.851647138596\n",
      "loss_compared with real:0.089856,   miu_train:0.001456,    lossmean:-0.07479\n",
      "Epoch [88400/100000], Loss: 356.1,   LOSS_function: 135,   LOSS_E:3.78e-06,    LOSS_initial: 0.2653,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6625.262881755829\n",
      "loss_compared with real:0.091998,   miu_train:0.001562,    lossmean:-0.07604\n",
      "Epoch [88500/100000], Loss: 358.6,   LOSS_function: 126.8,   LOSS_E:2.958e-06,    LOSS_initial: 0.2801,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6633.0081396102905\n",
      "loss_compared with real:0.090418,   miu_train:0.001465,    lossmean:-0.07519\n",
      "Epoch [88600/100000], Loss: 368.1,   LOSS_function: 145.8,   LOSS_E:3.058e-06,    LOSS_initial: 0.2682,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6640.833085536957\n",
      "loss_compared with real:0.090594,   miu_train:0.00145,    lossmean:-0.07558\n",
      "Epoch [88700/100000], Loss: 358.1,   LOSS_function: 130.9,   LOSS_E:2.943e-06,    LOSS_initial: 0.2745,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6648.672836303711\n",
      "loss_compared with real:0.090172,   miu_train:0.00149,    lossmean:-0.07509\n",
      "Epoch [88800/100000], Loss: 345.8,   LOSS_function: 119.9,   LOSS_E:2.68e-06,    LOSS_initial: 0.2734,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6656.421076059341\n",
      "loss_compared with real:0.090774,   miu_train:0.001541,    lossmean:-0.07602\n",
      "Epoch [88900/100000], Loss: 355,   LOSS_function: 125.5,   LOSS_E:2.58e-06,    LOSS_initial: 0.278,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:810.9,      learn rate:1.055e-05,    time: 6664.284651517868\n",
      "loss_compared with real:0.088697,   miu_train:0.00147,    lossmean:-0.07392\n",
      "Epoch [89000/100000], Loss: 363,   LOSS_function: 131.7,   LOSS_E:3.728e-06,    LOSS_initial: 0.2859,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6672.067450284958\n",
      "loss_compared with real:0.088265,   miu_train:0.001389,    lossmean:-0.07353\n",
      "Epoch [89100/100000], Loss: 340.9,   LOSS_function: 116.3,   LOSS_E:3.343e-06,    LOSS_initial: 0.2782,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6679.848271608353\n",
      "loss_compared with real:0.091267,   miu_train:0.001404,    lossmean:-0.07549\n",
      "Epoch [89200/100000], Loss: 339.9,   LOSS_function: 113.3,   LOSS_E:3.33e-06,    LOSS_initial: 0.2807,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6687.674917221069\n",
      "loss_compared with real:0.092253,   miu_train:0.001436,    lossmean:-0.07644\n",
      "Epoch [89300/100000], Loss: 351.7,   LOSS_function: 134.4,   LOSS_E:3.146e-06,    LOSS_initial: 0.2692,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6695.463565587997\n",
      "loss_compared with real:0.091033,   miu_train:0.00147,    lossmean:-0.07598\n",
      "Epoch [89400/100000], Loss: 349.3,   LOSS_function: 121.1,   LOSS_E:4.607e-06,    LOSS_initial: 0.2803,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6703.254822731018\n",
      "loss_compared with real:0.091202,   miu_train:0.001463,    lossmean:-0.07564\n",
      "Epoch [89500/100000], Loss: 344.2,   LOSS_function: 118.2,   LOSS_E:3.519e-06,    LOSS_initial: 0.2796,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6711.14742565155\n",
      "loss_compared with real:0.092175,   miu_train:0.001482,    lossmean:-0.07585\n",
      "Epoch [89600/100000], Loss: 339.9,   LOSS_function: 113.5,   LOSS_E:3.409e-06,    LOSS_initial: 0.2804,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6718.952132463455\n",
      "loss_compared with real:0.092687,   miu_train:0.001446,    lossmean:-0.077\n",
      "Epoch [89700/100000], Loss: 367.1,   LOSS_function: 136.7,   LOSS_E:3.735e-06,    LOSS_initial: 0.2847,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6726.698441982269\n",
      "loss_compared with real:0.091179,   miu_train:0.001396,    lossmean:-0.07567\n",
      "Epoch [89800/100000], Loss: 345.2,   LOSS_function: 107.1,   LOSS_E:3.186e-06,    LOSS_initial: 0.2956,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6734.460290193558\n",
      "loss_compared with real:0.090356,   miu_train:0.001338,    lossmean:-0.07491\n",
      "Epoch [89900/100000], Loss: 357.1,   LOSS_function: 123,   LOSS_E:3.052e-06,    LOSS_initial: 0.2907,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:788.5,      learn rate:1.004e-05,    time: 6742.359247684479\n",
      "loss_compared with real:0.091823,   miu_train:0.001394,    lossmean:-0.07583\n",
      "Epoch [90000/100000], Loss: 316.8,   LOSS_function: 111.4,   LOSS_E:3.2e-06,    LOSS_initial: 0.2797,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6750.202429533005\n",
      "loss_compared with real:0.091653,   miu_train:0.001438,    lossmean:-0.07619\n",
      "Epoch [90100/100000], Loss: 335.4,   LOSS_function: 129.2,   LOSS_E:2.829e-06,    LOSS_initial: 0.2814,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6758.097754240036\n",
      "loss_compared with real:0.097991,   miu_train:0.001402,    lossmean:-0.07942\n",
      "Epoch [90200/100000], Loss: 318.1,   LOSS_function: 103.1,   LOSS_E:3.128e-06,    LOSS_initial: 0.2932,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6765.964732646942\n",
      "loss_compared with real:0.097227,   miu_train:0.001333,    lossmean:-0.07934\n",
      "Epoch [90300/100000], Loss: 321.6,   LOSS_function: 110.5,   LOSS_E:2.65e-06,    LOSS_initial: 0.2887,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6773.73432970047\n",
      "loss_compared with real:0.098273,   miu_train:0.001415,    lossmean:-0.08011\n",
      "Epoch [90400/100000], Loss: 331,   LOSS_function: 105.4,   LOSS_E:2.881e-06,    LOSS_initial: 0.3084,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6781.6685655117035\n",
      "loss_compared with real:0.097302,   miu_train:0.001258,    lossmean:-0.0793\n",
      "Epoch [90500/100000], Loss: 329.9,   LOSS_function: 109.8,   LOSS_E:2.554e-06,    LOSS_initial: 0.3015,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6789.102044343948\n",
      "loss_compared with real:0.096003,   miu_train:0.001289,    lossmean:-0.07874\n",
      "Epoch [90600/100000], Loss: 322.5,   LOSS_function: 108.1,   LOSS_E:2.702e-06,    LOSS_initial: 0.2932,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6796.25367975235\n",
      "loss_compared with real:0.097522,   miu_train:0.001349,    lossmean:-0.08013\n",
      "Epoch [90700/100000], Loss: 319.3,   LOSS_function: 93.38,   LOSS_E:2.806e-06,    LOSS_initial: 0.3091,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6803.477286815643\n",
      "loss_compared with real:0.096861,   miu_train:0.001263,    lossmean:-0.07913\n",
      "Epoch [90800/100000], Loss: 312.6,   LOSS_function: 95.72,   LOSS_E:2.525e-06,    LOSS_initial: 0.2971,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6810.945517778397\n",
      "loss_compared with real:0.098776,   miu_train:0.001393,    lossmean:-0.08018\n",
      "Epoch [90900/100000], Loss: 329.2,   LOSS_function: 112,   LOSS_E:2.889e-06,    LOSS_initial: 0.2967,\n",
      "lamda1:1.001,    lamda2:1.524e+06,    lamda3:716.7,      learn rate:9.559e-06,    time: 6818.096933841705\n",
      "loss_compared with real:0.09799,   miu_train:0.001299,    lossmean:-0.07964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91000/100000], Loss: 287.6,   LOSS_function: 96.89,   LOSS_E:2.537e-06,    LOSS_initial: 0.3106,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6825.360821723938\n",
      "loss_compared with real:0.096263,   miu_train:0.001211,    lossmean:-0.07903\n",
      "Epoch [91100/100000], Loss: 293.9,   LOSS_function: 91.25,   LOSS_E:2.549e-06,    LOSS_initial: 0.3305,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6832.535342216492\n",
      "loss_compared with real:0.10801,   miu_train:0.001061,    lossmean:-0.08525\n",
      "Epoch [91200/100000], Loss: 307.1,   LOSS_function: 106.1,   LOSS_E:2.351e-06,    LOSS_initial: 0.3283,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6839.7431762218475\n",
      "loss_compared with real:0.10841,   miu_train:0.001061,    lossmean:-0.08565\n",
      "Epoch [91300/100000], Loss: 295.8,   LOSS_function: 92.38,   LOSS_E:2.455e-06,    LOSS_initial: 0.332,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6846.962171316147\n",
      "loss_compared with real:0.10781,   miu_train:0.001103,    lossmean:-0.08521\n",
      "Epoch [91400/100000], Loss: 282.5,   LOSS_function: 82.31,   LOSS_E:2.642e-06,    LOSS_initial: 0.3262,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6854.22956776619\n",
      "loss_compared with real:0.10962,   miu_train:0.001137,    lossmean:-0.08614\n",
      "Epoch [91500/100000], Loss: 288.5,   LOSS_function: 80.99,   LOSS_E:2.183e-06,    LOSS_initial: 0.3396,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6861.529758214951\n",
      "loss_compared with real:0.10746,   miu_train:0.001018,    lossmean:-0.08495\n",
      "Epoch [91600/100000], Loss: 288.6,   LOSS_function: 85.45,   LOSS_E:2.313e-06,    LOSS_initial: 0.3319,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6868.741874933243\n",
      "loss_compared with real:0.10864,   miu_train:0.00111,    lossmean:-0.08594\n",
      "Epoch [91700/100000], Loss: 300.8,   LOSS_function: 99.28,   LOSS_E:2.975e-06,    LOSS_initial: 0.3275,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6876.072715759277\n",
      "loss_compared with real:0.10867,   miu_train:0.001085,    lossmean:-0.08593\n",
      "Epoch [91800/100000], Loss: 295.6,   LOSS_function: 95.56,   LOSS_E:2.19e-06,    LOSS_initial: 0.327,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6883.285284042358\n",
      "loss_compared with real:0.10954,   miu_train:0.001121,    lossmean:-0.08657\n",
      "Epoch [91900/100000], Loss: 291.7,   LOSS_function: 91.87,   LOSS_E:2.182e-06,    LOSS_initial: 0.3267,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:600.9,      learn rate:9.1e-06,    time: 6890.5013880729675\n",
      "loss_compared with real:0.10931,   miu_train:0.001105,    lossmean:-0.08689\n",
      "Epoch [92000/100000], Loss: 269.8,   LOSS_function: 83.51,   LOSS_E:2.577e-06,    LOSS_initial: 0.3377,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6897.609939575195\n",
      "loss_compared with real:0.10847,   miu_train:0.001057,    lossmean:-0.08574\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5309, -0.5390, -0.3083, -0.9693, -0.0875, -0.3406,  0.4444, -0.8370,\n",
      "         0.9110,  0.3170,  0.7790,  0.5309,  0.6502, -0.0342,  0.6900, -0.3139,\n",
      "         0.8755,  0.0379,  0.8011, -0.7956, -0.2814, -0.9598, -0.5122, -0.3311,\n",
      "        -0.2965, -0.3995,  0.6968, -0.6641, -0.2488,  0.3839, -0.3141, -0.1898,\n",
      "         0.1076,  0.6399, -0.7262, -0.7953, -0.7200, -0.5707, -0.2667, -0.0492,\n",
      "        -0.8211, -0.9057, -0.0656,  0.7911, -0.6102,  0.8611, -0.6721,  0.8851,\n",
      "         0.5985, -0.9503, -0.7588, -0.3709,  0.8558, -0.5813,  0.9262, -0.1151,\n",
      "        -0.8805,  0.4180, -0.2724, -0.8576,  0.7874, -0.3304,  0.2654, -0.1114,\n",
      "        -0.5489, -0.0666, -0.0342,  0.4169, -0.4231, -0.3490,  0.6046, -0.4490,\n",
      "        -0.5085,  0.8763,  0.8026, -0.4360, -0.4571,  0.0118, -0.3389, -0.5485,\n",
      "        -0.7806, -0.7337,  0.9624,  0.0092,  0.1146,  0.8138,  0.7061,  0.2399,\n",
      "        -0.0321, -0.0789,  0.6669,  0.6922, -0.6781,  0.9043,  0.2280,  0.5589,\n",
      "        -0.6498, -0.1428,  0.6164,  0.0194, -0.8636,  0.0900, -0.0040, -0.2005,\n",
      "         0.4250,  0.4900,  0.6845,  0.0533,  0.2618,  0.6534, -0.6012, -0.2580,\n",
      "         0.5891,  0.7801,  0.7372, -0.0079, -0.9606,  0.9131, -0.3149, -0.8673,\n",
      "        -0.9524,  0.8846, -0.2205,  0.3749, -0.2409,  0.4241, -0.2073,  0.1844],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1134, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 2.0769e-02, -2.4386e-02,  2.4068e-02,  7.9742e-02, -5.8175e-02,\n",
      "        -3.4231e-02, -2.8778e-02,  2.7903e-02, -6.0286e-02,  3.7469e-02,\n",
      "        -1.0255e-02, -9.9278e-02,  5.1591e-02, -5.2544e-02,  5.9521e-02,\n",
      "         4.1638e-03, -2.4749e-02, -2.8272e-02, -3.8126e-02,  7.0868e-02,\n",
      "        -6.2112e-02,  5.5125e-02,  2.5177e-02, -1.4701e-02,  1.8952e-02,\n",
      "        -4.6050e-03,  6.7787e-02, -4.6548e-02, -1.6524e-02, -7.4422e-02,\n",
      "         1.9277e-02, -8.1553e-02,  8.2752e-02, -3.0764e-02,  6.2585e-02,\n",
      "        -2.0993e-03, -5.2623e-02,  5.2536e-02,  4.8934e-02, -5.3006e-02,\n",
      "        -8.2083e-02, -6.1495e-02,  2.2572e-02,  8.3288e-02,  5.9194e-02,\n",
      "         7.1695e-02, -1.8118e-02,  6.6374e-02, -3.4350e-02, -1.9562e-02,\n",
      "         6.2020e-02,  1.6453e-02, -2.3693e-02,  9.1459e-03,  5.8914e-03,\n",
      "         6.1474e-03,  5.3383e-02,  5.4239e-02,  5.9287e-02,  3.2984e-02,\n",
      "         1.4295e-02, -4.9298e-02, -4.0201e-02,  4.2954e-02,  6.5329e-02,\n",
      "         4.6984e-03,  4.4268e-02,  2.5097e-02,  5.1465e-02,  2.7677e-02,\n",
      "         6.1001e-02, -1.0054e-02, -2.6923e-02, -2.2207e-02, -6.5688e-02,\n",
      "         2.5751e-02, -5.3190e-02,  5.2169e-02, -1.7269e-02,  1.7830e-02,\n",
      "         1.0893e-02, -2.6904e-02, -1.3061e-02,  5.0039e-02,  4.0789e-02,\n",
      "        -3.7536e-02, -1.7864e-02, -2.1609e-02,  7.9076e-02,  9.9849e-02,\n",
      "         1.6088e-02,  4.4327e-02, -6.8902e-02, -7.8792e-02,  7.3215e-02,\n",
      "        -6.7768e-02,  5.7221e-02,  2.9971e-02,  3.0611e-02,  8.9646e-02,\n",
      "         7.8272e-02,  5.9421e-02,  4.4643e-02,  6.5632e-02,  7.6276e-02,\n",
      "         3.9076e-03, -8.2473e-02, -6.8601e-02,  1.7585e-02, -5.2816e-02,\n",
      "         2.9106e-02,  1.9686e-02, -4.9194e-02, -4.9873e-02,  1.0482e-04,\n",
      "         4.1980e-02,  5.7508e-02, -8.2744e-02, -1.1829e-01,  4.0048e-02,\n",
      "         6.2945e-02,  2.3256e-02,  2.5280e-02, -2.1993e-02, -3.5463e-03,\n",
      "         2.2497e-02, -6.1304e-02,  6.9679e-02], requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1291, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0488, -0.0525, -0.0477,  0.0492, -0.0312, -0.0341, -0.1113,  0.0024,\n",
      "        -0.0287,  0.0626, -0.0287, -0.0650, -0.0166,  0.0047, -0.0421, -0.0886,\n",
      "        -0.0596,  0.0567, -0.0099, -0.0812,  0.0102, -0.0224, -0.0546, -0.0319,\n",
      "         0.0251,  0.0207,  0.0482,  0.0497, -0.0542, -0.0643, -0.0423,  0.0393,\n",
      "         0.0457, -0.0359,  0.0593,  0.0520,  0.0707, -0.0135,  0.0136,  0.0883,\n",
      "        -0.0660,  0.0467,  0.0291, -0.0235,  0.0460,  0.0131, -0.0750, -0.0559,\n",
      "        -0.0319, -0.0410, -0.0657,  0.0403,  0.0837, -0.0716,  0.0532, -0.0204,\n",
      "         0.0203, -0.0716,  0.0216, -0.0738,  0.0407,  0.0507, -0.0159,  0.1089,\n",
      "         0.0766, -0.0378,  0.0006, -0.0138,  0.0009,  0.0172, -0.0783, -0.0123,\n",
      "         0.0179,  0.0476, -0.0201,  0.0280,  0.0752,  0.0243,  0.0051, -0.0087,\n",
      "         0.0801, -0.0488, -0.0735,  0.0921,  0.0203, -0.0077,  0.0299,  0.0861,\n",
      "        -0.0124, -0.0795,  0.0134, -0.0958,  0.0396, -0.0238, -0.0756,  0.0252,\n",
      "        -0.0433, -0.0562, -0.0669,  0.0683, -0.0792,  0.0245, -0.0110,  0.0433,\n",
      "        -0.0300, -0.0582,  0.0209, -0.0761, -0.0954, -0.0203, -0.0451,  0.0140,\n",
      "         0.0626, -0.1077, -0.0550, -0.0313, -0.0490, -0.0452,  0.0874, -0.0350,\n",
      "        -0.0435,  0.0412,  0.0613,  0.0815, -0.0545, -0.0843, -0.0144, -0.0533],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1067, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0389, -0.0766,  0.0093,  0.0793, -0.0858,  0.0291, -0.0185, -0.0047,\n",
      "         0.0775,  0.0436,  0.0254,  0.0585,  0.0318, -0.0610, -0.0511,  0.0643,\n",
      "        -0.0041,  0.0160, -0.0127, -0.0219,  0.0048,  0.0014,  0.0584,  0.1004,\n",
      "        -0.0025, -0.0291, -0.0091, -0.0240, -0.0073,  0.0676,  0.0042,  0.0477,\n",
      "         0.0042, -0.0060, -0.0404,  0.0481, -0.0626, -0.1062, -0.0734,  0.0136,\n",
      "         0.0972, -0.0861,  0.0352,  0.0334,  0.0700, -0.0546,  0.0790,  0.0034,\n",
      "        -0.0842, -0.0565,  0.0080, -0.0321,  0.0060,  0.0762,  0.0296,  0.0130,\n",
      "        -0.0304, -0.0613,  0.0603,  0.0169,  0.0203, -0.0627, -0.0247, -0.0319,\n",
      "         0.0105, -0.0505, -0.0375, -0.0363,  0.0388, -0.0781, -0.0479, -0.0277,\n",
      "        -0.0491,  0.0525, -0.0753, -0.0276, -0.0336, -0.0141,  0.0879, -0.0283,\n",
      "        -0.0402,  0.0721, -0.0002,  0.0473,  0.0157, -0.0499, -0.0087, -0.0369,\n",
      "         0.0028,  0.0158, -0.0190, -0.0952,  0.0712,  0.0429, -0.0220,  0.0693,\n",
      "        -0.0583, -0.0782,  0.0489, -0.0580, -0.0380,  0.0312, -0.0644, -0.0381,\n",
      "         0.0226,  0.0426,  0.0463, -0.0910,  0.0134, -0.0685,  0.0436,  0.0711,\n",
      "        -0.0636, -0.0710,  0.0610, -0.0128, -0.0987,  0.0307, -0.0369,  0.0397,\n",
      "         0.0342, -0.0376,  0.0428, -0.0801, -0.0111,  0.0494, -0.0124,  0.0583],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0805, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0452,  0.0626,  0.0918], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92100/100000], Loss: 282.8,   LOSS_function: 91.24,   LOSS_E:2.135e-06,    LOSS_initial: 0.3488,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6904.82258272171\n",
      "loss_compared with real:0.11483,   miu_train:0.0009684,    lossmean:-0.08886\n",
      "Epoch [92200/100000], Loss: 274.6,   LOSS_function: 86.37,   LOSS_E:1.999e-06,    LOSS_initial: 0.343,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6912.172363996506\n",
      "loss_compared with real:0.11529,   miu_train:0.0009956,    lossmean:-0.08975\n",
      "Epoch [92300/100000], Loss: 267.9,   LOSS_function: 78.71,   LOSS_E:2.765e-06,    LOSS_initial: 0.3426,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6919.366873502731\n",
      "loss_compared with real:0.11473,   miu_train:0.0009965,    lossmean:-0.08973\n",
      "Epoch [92400/100000], Loss: 281.8,   LOSS_function: 89.61,   LOSS_E:1.948e-06,    LOSS_initial: 0.3505,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6926.536287307739\n",
      "loss_compared with real:0.11506,   miu_train:0.0009475,    lossmean:-0.08943\n",
      "Epoch [92500/100000], Loss: 273.8,   LOSS_function: 86.18,   LOSS_E:2.306e-06,    LOSS_initial: 0.3411,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6934.3191549777985\n",
      "loss_compared with real:0.11475,   miu_train:0.0009765,    lossmean:-0.08973\n",
      "Epoch [92600/100000], Loss: 271.9,   LOSS_function: 76.75,   LOSS_E:2.079e-06,    LOSS_initial: 0.3557,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6942.19212436676\n",
      "loss_compared with real:0.11385,   miu_train:0.0009313,    lossmean:-0.08899\n",
      "Epoch [92700/100000], Loss: 263.6,   LOSS_function: 68.68,   LOSS_E:2.204e-06,    LOSS_initial: 0.355,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6949.970306634903\n",
      "loss_compared with real:0.11518,   miu_train:0.0009414,    lossmean:-0.08993\n",
      "Epoch [92800/100000], Loss: 263.5,   LOSS_function: 71.06,   LOSS_E:2.121e-06,    LOSS_initial: 0.3505,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6957.773423194885\n",
      "loss_compared with real:0.11535,   miu_train:0.0009906,    lossmean:-0.09021\n",
      "Epoch [92900/100000], Loss: 267.5,   LOSS_function: 72.27,   LOSS_E:2.534e-06,    LOSS_initial: 0.3545,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:539.4,      learn rate:8.663e-06,    time: 6965.612110853195\n",
      "loss_compared with real:0.11572,   miu_train:0.0009608,    lossmean:-0.0901\n",
      "Epoch [93000/100000], Loss: 256.1,   LOSS_function: 73.64,   LOSS_E:1.741e-06,    LOSS_initial: 0.3574,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 6973.487090110779\n",
      "loss_compared with real:0.11441,   miu_train:0.0009235,    lossmean:-0.08987\n",
      "Epoch [93100/100000], Loss: 262.9,   LOSS_function: 78.75,   LOSS_E:1.847e-06,    LOSS_initial: 0.3604,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 6981.3769364356995\n",
      "loss_compared with real:0.11826,   miu_train:0.0009078,    lossmean:-0.09123\n",
      "Epoch [93200/100000], Loss: 258.9,   LOSS_function: 69.43,   LOSS_E:2.074e-06,    LOSS_initial: 0.3704,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 6989.5039002895355\n",
      "loss_compared with real:0.1184,   miu_train:0.0008676,    lossmean:-0.09144\n",
      "Epoch [93300/100000], Loss: 247.8,   LOSS_function: 59.18,   LOSS_E:1.918e-06,    LOSS_initial: 0.3691,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 6997.382949829102\n",
      "loss_compared with real:0.11947,   miu_train:0.0008934,    lossmean:-0.09184\n",
      "Epoch [93400/100000], Loss: 257.4,   LOSS_function: 72.22,   LOSS_E:2.216e-06,    LOSS_initial: 0.3614,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 7005.272388458252\n",
      "loss_compared with real:0.11933,   miu_train:0.0009137,    lossmean:-0.09224\n",
      "Epoch [93500/100000], Loss: 262,   LOSS_function: 77.54,   LOSS_E:1.659e-06,    LOSS_initial: 0.3617,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 7013.066757440567\n",
      "loss_compared with real:0.11899,   miu_train:0.0008993,    lossmean:-0.0923\n",
      "Epoch [93600/100000], Loss: 266.8,   LOSS_function: 80.11,   LOSS_E:1.915e-06,    LOSS_initial: 0.3652,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 7020.875818490982\n",
      "loss_compared with real:0.11828,   miu_train:0.0008587,    lossmean:-0.09184\n",
      "Epoch [93700/100000], Loss: 258.8,   LOSS_function: 69.47,   LOSS_E:2.329e-06,    LOSS_initial: 0.3693,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 7028.685245513916\n",
      "loss_compared with real:0.11958,   miu_train:0.0008634,    lossmean:-0.09242\n",
      "Epoch [93800/100000], Loss: 266,   LOSS_function: 87.62,   LOSS_E:2.557e-06,    LOSS_initial: 0.3466,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 7036.428081274033\n",
      "loss_compared with real:0.1204,   miu_train:0.0009525,    lossmean:-0.09292\n",
      "Epoch [93900/100000], Loss: 256.3,   LOSS_function: 65.94,   LOSS_E:1.697e-06,    LOSS_initial: 0.3732,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:502.7,      learn rate:8.248e-06,    time: 7044.167892456055\n",
      "loss_compared with real:0.12004,   miu_train:0.0008794,    lossmean:-0.09263\n",
      "Epoch [94000/100000], Loss: 258.1,   LOSS_function: 72.22,   LOSS_E:1.676e-06,    LOSS_initial: 0.367,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7052.031457662582\n",
      "loss_compared with real:0.12004,   miu_train:0.0008851,    lossmean:-0.09246\n",
      "Epoch [94100/100000], Loss: 255.5,   LOSS_function: 70.81,   LOSS_E:2.108e-06,    LOSS_initial: 0.3633,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7059.769386768341\n",
      "loss_compared with real:0.11946,   miu_train:0.0008729,    lossmean:-0.09264\n",
      "Epoch [94200/100000], Loss: 264.3,   LOSS_function: 81.51,   LOSS_E:2.163e-06,    LOSS_initial: 0.3592,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7067.491273641586\n",
      "loss_compared with real:0.12118,   miu_train:0.000893,    lossmean:-0.09332\n",
      "Epoch [94300/100000], Loss: 253.4,   LOSS_function: 66.25,   LOSS_E:1.799e-06,    LOSS_initial: 0.3693,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7075.333554029465\n",
      "loss_compared with real:0.12083,   miu_train:0.0008853,    lossmean:-0.09338\n",
      "Epoch [94400/100000], Loss: 253.6,   LOSS_function: 71.02,   LOSS_E:2.069e-06,    LOSS_initial: 0.3591,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7083.160159111023\n",
      "loss_compared with real:0.12149,   miu_train:0.0008923,    lossmean:-0.0937\n",
      "Epoch [94500/100000], Loss: 253.7,   LOSS_function: 66.17,   LOSS_E:1.799e-06,    LOSS_initial: 0.37,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7090.5126848220825\n",
      "loss_compared with real:0.12026,   miu_train:0.0008652,    lossmean:-0.09285\n",
      "Epoch [94600/100000], Loss: 255.2,   LOSS_function: 70.71,   LOSS_E:2.126e-06,    LOSS_initial: 0.3629,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7097.791225671768\n",
      "loss_compared with real:0.12061,   miu_train:0.0008836,    lossmean:-0.09344\n",
      "Epoch [94700/100000], Loss: 266.8,   LOSS_function: 88.63,   LOSS_E:3.094e-06,    LOSS_initial: 0.3472,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7104.90456867218\n",
      "loss_compared with real:0.12004,   miu_train:0.0009278,    lossmean:-0.09327\n",
      "Epoch [94800/100000], Loss: 261.2,   LOSS_function: 78.19,   LOSS_E:2.074e-06,    LOSS_initial: 0.3601,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7112.166083574295\n",
      "loss_compared with real:0.12095,   miu_train:0.0008874,    lossmean:-0.0938\n",
      "Epoch [94900/100000], Loss: 261.2,   LOSS_function: 80.1,   LOSS_E:1.723e-06,    LOSS_initial: 0.3573,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:499.2,      learn rate:7.852e-06,    time: 7119.312434434891\n",
      "loss_compared with real:0.11995,   miu_train:0.000904,    lossmean:-0.09308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95000/100000], Loss: 230.7,   LOSS_function: 63.92,   LOSS_E:1.957e-06,    LOSS_initial: 0.3638,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7126.555033922195\n",
      "loss_compared with real:0.12103,   miu_train:0.0009006,    lossmean:-0.09325\n",
      "Epoch [95100/100000], Loss: 234.7,   LOSS_function: 65.63,   LOSS_E:1.573e-06,    LOSS_initial: 0.3702,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7133.683512687683\n",
      "loss_compared with real:0.12693,   miu_train:0.0008484,    lossmean:-0.09664\n",
      "Epoch [95200/100000], Loss: 229.2,   LOSS_function: 50.44,   LOSS_E:1.824e-06,    LOSS_initial: 0.391,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7141.0602560043335\n",
      "loss_compared with real:0.12533,   miu_train:0.0007679,    lossmean:-0.09572\n",
      "Epoch [95300/100000], Loss: 246.6,   LOSS_function: 69.11,   LOSS_E:1.619e-06,    LOSS_initial: 0.3886,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7148.236302852631\n",
      "loss_compared with real:0.12701,   miu_train:0.0007598,    lossmean:-0.09635\n",
      "Epoch [95400/100000], Loss: 233.5,   LOSS_function: 59.62,   LOSS_E:1.613e-06,    LOSS_initial: 0.3808,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7155.625203132629\n",
      "loss_compared with real:0.12642,   miu_train:0.0007848,    lossmean:-0.09673\n",
      "Epoch [95500/100000], Loss: 228.2,   LOSS_function: 57.42,   LOSS_E:1.357e-06,    LOSS_initial: 0.3747,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7162.768952846527\n",
      "loss_compared with real:0.12867,   miu_train:0.0008446,    lossmean:-0.09814\n",
      "Epoch [95600/100000], Loss: 236.7,   LOSS_function: 59.23,   LOSS_E:1.737e-06,    LOSS_initial: 0.3882,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7170.080101490021\n",
      "loss_compared with real:0.12673,   miu_train:0.000777,    lossmean:-0.09666\n",
      "Epoch [95700/100000], Loss: 237,   LOSS_function: 61.92,   LOSS_E:1.694e-06,    LOSS_initial: 0.383,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7177.379102468491\n",
      "loss_compared with real:0.12703,   miu_train:0.0007889,    lossmean:-0.09696\n",
      "Epoch [95800/100000], Loss: 229.4,   LOSS_function: 56.04,   LOSS_E:1.515e-06,    LOSS_initial: 0.38,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7184.608136415482\n",
      "loss_compared with real:0.12756,   miu_train:0.0008049,    lossmean:-0.09719\n",
      "Epoch [95900/100000], Loss: 247.7,   LOSS_function: 74.01,   LOSS_E:1.605e-06,    LOSS_initial: 0.3803,\n",
      "lamda1:1.002,    lamda2:1.524e+06,    lamda3:449.9,      learn rate:7.475e-06,    time: 7191.7652451992035\n",
      "loss_compared with real:0.12586,   miu_train:0.0007856,    lossmean:-0.09636\n",
      "Epoch [96000/100000], Loss: 210.5,   LOSS_function: 52.37,   LOSS_E:1.647e-06,    LOSS_initial: 0.3881,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7198.9998960494995\n",
      "loss_compared with real:0.12665,   miu_train:0.0007615,    lossmean:-0.09664\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5309, -0.5391, -0.3082, -0.9693, -0.0875, -0.3406,  0.4444, -0.8371,\n",
      "         0.9111,  0.3170,  0.7793,  0.5310,  0.6503, -0.0341,  0.6901, -0.3140,\n",
      "         0.8756,  0.0379,  0.8012, -0.7957, -0.2814, -0.9598, -0.5122, -0.3310,\n",
      "        -0.2966, -0.3995,  0.6968, -0.6640, -0.2488,  0.3838, -0.3141, -0.1898,\n",
      "         0.1076,  0.6398, -0.7263, -0.7955, -0.7200, -0.5710, -0.2668, -0.0491,\n",
      "        -0.8210, -0.9058, -0.0655,  0.7911, -0.6101,  0.8612, -0.6720,  0.8851,\n",
      "         0.5985, -0.9502, -0.7588, -0.3709,  0.8559, -0.5813,  0.9262, -0.1150,\n",
      "        -0.8806,  0.4181, -0.2724, -0.8577,  0.7875, -0.3305,  0.2653, -0.1115,\n",
      "        -0.5489, -0.0666, -0.0341,  0.4169, -0.4230, -0.3490,  0.6046, -0.4490,\n",
      "        -0.5085,  0.8763,  0.8027, -0.4360, -0.4571,  0.0119, -0.3390, -0.5485,\n",
      "        -0.7807, -0.7338,  0.9628,  0.0093,  0.1147,  0.8140,  0.7062,  0.2399,\n",
      "        -0.0322, -0.0791,  0.6669,  0.6922, -0.6781,  0.9043,  0.2281,  0.5589,\n",
      "        -0.6498, -0.1428,  0.6164,  0.0194, -0.8637,  0.0899, -0.0041, -0.2005,\n",
      "         0.4247,  0.4902,  0.6846,  0.0533,  0.2620,  0.6535, -0.6012, -0.2579,\n",
      "         0.5892,  0.7802,  0.7372, -0.0078, -0.9608,  0.9132, -0.3150, -0.8673,\n",
      "        -0.9524,  0.8846, -0.2205,  0.3749, -0.2409,  0.4241, -0.2072,  0.1845],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1132, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0207, -0.0243,  0.0243,  0.0797, -0.0582, -0.0342, -0.0286,  0.0278,\n",
      "        -0.0603,  0.0374, -0.0103, -0.0993,  0.0516, -0.0525,  0.0596,  0.0040,\n",
      "        -0.0247, -0.0283, -0.0381,  0.0709, -0.0622,  0.0551,  0.0252, -0.0147,\n",
      "         0.0190, -0.0045,  0.0678, -0.0468, -0.0167, -0.0746,  0.0192, -0.0815,\n",
      "         0.0828, -0.0308,  0.0626, -0.0020, -0.0526,  0.0523,  0.0490, -0.0530,\n",
      "        -0.0821, -0.0614,  0.0225,  0.0833,  0.0591,  0.0717, -0.0181,  0.0664,\n",
      "        -0.0345, -0.0193,  0.0621,  0.0165, -0.0238,  0.0092,  0.0059,  0.0061,\n",
      "         0.0533,  0.0541,  0.0593,  0.0328,  0.0145, -0.0493, -0.0401,  0.0429,\n",
      "         0.0653,  0.0047,  0.0443,  0.0247,  0.0514,  0.0279,  0.0610, -0.0100,\n",
      "        -0.0269, -0.0225, -0.0658,  0.0257, -0.0532,  0.0521, -0.0172,  0.0178,\n",
      "         0.0110, -0.0269, -0.0131,  0.0501,  0.0408, -0.0374, -0.0178, -0.0216,\n",
      "         0.0790,  0.0999,  0.0161,  0.0444, -0.0689, -0.0788,  0.0730, -0.0678,\n",
      "         0.0573,  0.0300,  0.0306,  0.0897,  0.0783,  0.0594,  0.0446,  0.0654,\n",
      "         0.0765,  0.0029, -0.0823, -0.0685,  0.0175, -0.0529,  0.0291,  0.0195,\n",
      "        -0.0492, -0.0500,  0.0002,  0.0418,  0.0575, -0.0828, -0.1185,  0.0399,\n",
      "         0.0629,  0.0233,  0.0253, -0.0222, -0.0036,  0.0225, -0.0613,  0.0695],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1290, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0489, -0.0524, -0.0477,  0.0491, -0.0312, -0.0341, -0.1113,  0.0024,\n",
      "        -0.0287,  0.0626, -0.0285, -0.0650, -0.0165,  0.0043, -0.0423, -0.0887,\n",
      "        -0.0596,  0.0569, -0.0099, -0.0811,  0.0102, -0.0223, -0.0546, -0.0319,\n",
      "         0.0250,  0.0206,  0.0483,  0.0497, -0.0541, -0.0642, -0.0424,  0.0393,\n",
      "         0.0457, -0.0358,  0.0595,  0.0520,  0.0706, -0.0134,  0.0137,  0.0887,\n",
      "        -0.0661,  0.0467,  0.0292, -0.0234,  0.0459,  0.0131, -0.0748, -0.0559,\n",
      "        -0.0319, -0.0411, -0.0658,  0.0403,  0.0837, -0.0716,  0.0538, -0.0204,\n",
      "         0.0203, -0.0717,  0.0215, -0.0737,  0.0407,  0.0509, -0.0159,  0.1090,\n",
      "         0.0768, -0.0377,  0.0007, -0.0138,  0.0013,  0.0172, -0.0779, -0.0123,\n",
      "         0.0180,  0.0477, -0.0199,  0.0281,  0.0752,  0.0242,  0.0051, -0.0088,\n",
      "         0.0801, -0.0487, -0.0733,  0.0920,  0.0203, -0.0077,  0.0300,  0.0861,\n",
      "        -0.0124, -0.0795,  0.0133, -0.0958,  0.0397, -0.0238, -0.0755,  0.0252,\n",
      "        -0.0433, -0.0560, -0.0670,  0.0684, -0.0791,  0.0246, -0.0110,  0.0435,\n",
      "        -0.0300, -0.0583,  0.0209, -0.0759, -0.0954, -0.0203, -0.0453,  0.0140,\n",
      "         0.0626, -0.1076, -0.0550, -0.0313, -0.0490, -0.0451,  0.0874, -0.0345,\n",
      "        -0.0434,  0.0411,  0.0613,  0.0815, -0.0545, -0.0843, -0.0144, -0.0530],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1065, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0388, -0.0760,  0.0094,  0.0793, -0.0859,  0.0291, -0.0184, -0.0041,\n",
      "         0.0775,  0.0440,  0.0259,  0.0580,  0.0325, -0.0611, -0.0512,  0.0645,\n",
      "        -0.0041,  0.0162, -0.0128, -0.0220,  0.0048,  0.0014,  0.0583,  0.1004,\n",
      "        -0.0027, -0.0291, -0.0090, -0.0239, -0.0074,  0.0676,  0.0045,  0.0473,\n",
      "         0.0042, -0.0060, -0.0404,  0.0483, -0.0626, -0.1062, -0.0734,  0.0139,\n",
      "         0.0971, -0.0860,  0.0351,  0.0333,  0.0699, -0.0547,  0.0791,  0.0033,\n",
      "        -0.0842, -0.0563,  0.0078, -0.0322,  0.0060,  0.0762,  0.0297,  0.0130,\n",
      "        -0.0304, -0.0612,  0.0603,  0.0168,  0.0202, -0.0628, -0.0247, -0.0319,\n",
      "         0.0104, -0.0506, -0.0373, -0.0363,  0.0386, -0.0778, -0.0481, -0.0276,\n",
      "        -0.0490,  0.0525, -0.0753, -0.0277, -0.0339, -0.0142,  0.0878, -0.0284,\n",
      "        -0.0407,  0.0720, -0.0007,  0.0473,  0.0157, -0.0499, -0.0086, -0.0369,\n",
      "         0.0029,  0.0157, -0.0193, -0.0953,  0.0711,  0.0429, -0.0222,  0.0693,\n",
      "        -0.0582, -0.0782,  0.0489, -0.0582, -0.0378,  0.0312, -0.0645, -0.0381,\n",
      "         0.0225,  0.0426,  0.0465, -0.0909,  0.0130, -0.0684,  0.0435,  0.0711,\n",
      "        -0.0636, -0.0712,  0.0610, -0.0127, -0.0987,  0.0305, -0.0371,  0.0395,\n",
      "         0.0340, -0.0376,  0.0428, -0.0798, -0.0107,  0.0495, -0.0125,  0.0583],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0804, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0464,  0.0626,  0.0923], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96100/100000], Loss: 215,   LOSS_function: 49.71,   LOSS_E:1.649e-06,    LOSS_initial: 0.406,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7206.425799608231\n",
      "loss_compared with real:0.13299,   miu_train:0.0006883,    lossmean:-0.09968\n",
      "Epoch [96200/100000], Loss: 217.4,   LOSS_function: 58.87,   LOSS_E:1.373e-06,    LOSS_initial: 0.3901,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7213.615270614624\n",
      "loss_compared with real:0.13574,   miu_train:0.0007437,    lossmean:-0.1016\n",
      "Epoch [96300/100000], Loss: 214.4,   LOSS_function: 46.36,   LOSS_E:1.395e-06,    LOSS_initial: 0.4138,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7220.8709235191345\n",
      "loss_compared with real:0.13308,   miu_train:0.0006563,    lossmean:-0.1002\n",
      "Epoch [96400/100000], Loss: 217.1,   LOSS_function: 52.43,   LOSS_E:1.471e-06,    LOSS_initial: 0.4051,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7228.166857719421\n",
      "loss_compared with real:0.13381,   miu_train:0.0007001,    lossmean:-0.1008\n",
      "Epoch [96500/100000], Loss: 215,   LOSS_function: 53.86,   LOSS_E:1.294e-06,    LOSS_initial: 0.3971,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7235.947279453278\n",
      "loss_compared with real:0.13365,   miu_train:0.0007109,    lossmean:-0.1009\n",
      "Epoch [96600/100000], Loss: 225.1,   LOSS_function: 60.52,   LOSS_E:1.617e-06,    LOSS_initial: 0.4044,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7243.7728950977325\n",
      "loss_compared with real:0.13296,   miu_train:0.0006896,    lossmean:-0.1\n",
      "Epoch [96700/100000], Loss: 220.5,   LOSS_function: 59.31,   LOSS_E:1.302e-06,    LOSS_initial: 0.3972,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7251.592785835266\n",
      "loss_compared with real:0.13507,   miu_train:0.0007074,    lossmean:-0.1015\n",
      "Epoch [96800/100000], Loss: 217.8,   LOSS_function: 53.95,   LOSS_E:1.298e-06,    LOSS_initial: 0.4038,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7259.395313739777\n",
      "loss_compared with real:0.13326,   miu_train:0.0006987,    lossmean:-0.1004\n",
      "Epoch [96900/100000], Loss: 218.5,   LOSS_function: 54.83,   LOSS_E:1.359e-06,    LOSS_initial: 0.4029,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400.6,      learn rate:7.116e-06,    time: 7267.1358234882355\n",
      "loss_compared with real:0.13289,   miu_train:0.000696,    lossmean:-0.1002\n",
      "Epoch [97000/100000], Loss: 201.3,   LOSS_function: 46.92,   LOSS_E:1.911e-06,    LOSS_initial: 0.4101,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7275.0403344631195\n",
      "loss_compared with real:0.1317,   miu_train:0.0006664,    lossmean:-0.09975\n",
      "Epoch [97100/100000], Loss: 205.2,   LOSS_function: 53.13,   LOSS_E:1.238e-06,    LOSS_initial: 0.4068,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7282.805755376816\n",
      "loss_compared with real:0.13783,   miu_train:0.0006654,    lossmean:-0.1027\n",
      "Epoch [97200/100000], Loss: 201.1,   LOSS_function: 42.36,   LOSS_E:1.483e-06,    LOSS_initial: 0.4238,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7290.638808012009\n",
      "loss_compared with real:0.13837,   miu_train:0.0006331,    lossmean:-0.1032\n",
      "Epoch [97300/100000], Loss: 208.2,   LOSS_function: 51.21,   LOSS_E:1.434e-06,    LOSS_initial: 0.4191,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7298.391957521439\n",
      "loss_compared with real:0.13775,   miu_train:0.0006324,    lossmean:-0.1024\n",
      "Epoch [97400/100000], Loss: 205.4,   LOSS_function: 47.56,   LOSS_E:1.468e-06,    LOSS_initial: 0.4215,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7306.244468450546\n",
      "loss_compared with real:0.1388,   miu_train:0.0006247,    lossmean:-0.1033\n",
      "Epoch [97500/100000], Loss: 204.8,   LOSS_function: 51.57,   LOSS_E:1.172e-06,    LOSS_initial: 0.4101,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7313.947992801666\n",
      "loss_compared with real:0.13905,   miu_train:0.0006605,    lossmean:-0.1037\n",
      "Epoch [97600/100000], Loss: 203.3,   LOSS_function: 46.39,   LOSS_E:1.338e-06,    LOSS_initial: 0.4194,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7321.80957198143\n",
      "loss_compared with real:0.13909,   miu_train:0.0006415,    lossmean:-0.1035\n",
      "Epoch [97700/100000], Loss: 206.2,   LOSS_function: 51.28,   LOSS_E:1.376e-06,    LOSS_initial: 0.4139,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7329.612237215042\n",
      "loss_compared with real:0.1387,   miu_train:0.0006457,    lossmean:-0.1033\n",
      "Epoch [97800/100000], Loss: 202.4,   LOSS_function: 40.8,   LOSS_E:1.18e-06,    LOSS_initial: 0.4329,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7337.526349306107\n",
      "loss_compared with real:0.13722,   miu_train:0.0006,    lossmean:-0.1024\n",
      "Epoch [97900/100000], Loss: 208.8,   LOSS_function: 53.39,   LOSS_E:1.225e-06,    LOSS_initial: 0.4157,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:369,      learn rate:6.774e-06,    time: 7345.369503736496\n",
      "loss_compared with real:0.1395,   miu_train:0.0006428,    lossmean:-0.1037\n",
      "Epoch [98000/100000], Loss: 210.1,   LOSS_function: 46.03,   LOSS_E:1.484e-06,    LOSS_initial: 0.4192,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7353.257926225662\n",
      "loss_compared with real:0.13732,   miu_train:0.0006347,    lossmean:-0.1028\n",
      "Epoch [98100/100000], Loss: 213.9,   LOSS_function: 56.68,   LOSS_E:1.405e-06,    LOSS_initial: 0.4016,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7361.039589643478\n",
      "loss_compared with real:0.13716,   miu_train:0.0006835,    lossmean:-0.103\n",
      "Epoch [98200/100000], Loss: 209.5,   LOSS_function: 49.49,   LOSS_E:1.536e-06,    LOSS_initial: 0.4083,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7368.864492893219\n",
      "loss_compared with real:0.13749,   miu_train:0.0006751,    lossmean:-0.1032\n",
      "Epoch [98300/100000], Loss: 211.4,   LOSS_function: 50.82,   LOSS_E:1.591e-06,    LOSS_initial: 0.4097,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7376.72797703743\n",
      "loss_compared with real:0.13589,   miu_train:0.0006637,    lossmean:-0.1022\n",
      "Epoch [98400/100000], Loss: 213.3,   LOSS_function: 51.52,   LOSS_E:1.273e-06,    LOSS_initial: 0.4139,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7384.736516714096\n",
      "loss_compared with real:0.13719,   miu_train:0.0006409,    lossmean:-0.1027\n",
      "Epoch [98500/100000], Loss: 215.5,   LOSS_function: 50.42,   LOSS_E:1.127e-06,    LOSS_initial: 0.4231,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7392.1486093997955\n",
      "loss_compared with real:0.1358,   miu_train:0.0006155,    lossmean:-0.1022\n",
      "Epoch [98600/100000], Loss: 206.1,   LOSS_function: 43.27,   LOSS_E:1.157e-06,    LOSS_initial: 0.4172,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7399.403157949448\n",
      "loss_compared with real:0.137,   miu_train:0.0006508,    lossmean:-0.1029\n",
      "Epoch [98700/100000], Loss: 214.2,   LOSS_function: 52.62,   LOSS_E:1.124e-06,    LOSS_initial: 0.4141,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7406.742694377899\n",
      "loss_compared with real:0.13604,   miu_train:0.000645,    lossmean:-0.1023\n",
      "Epoch [98800/100000], Loss: 213.3,   LOSS_function: 51.95,   LOSS_E:1.313e-06,    LOSS_initial: 0.4126,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7413.9547390937805\n",
      "loss_compared with real:0.13743,   miu_train:0.0006518,    lossmean:-0.1034\n",
      "Epoch [98900/100000], Loss: 214.9,   LOSS_function: 51.92,   LOSS_E:1.307e-06,    LOSS_initial: 0.417,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:385.8,      learn rate:6.449e-06,    time: 7421.170909643173\n",
      "loss_compared with real:0.13623,   miu_train:0.0006364,    lossmean:-0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99000/100000], Loss: 216.3,   LOSS_function: 53.07,   LOSS_E:1.347e-06,    LOSS_initial: 0.4038,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7428.439827203751\n",
      "loss_compared with real:0.13676,   miu_train:0.0007009,    lossmean:-0.1028\n",
      "Epoch [99100/100000], Loss: 216.3,   LOSS_function: 51.22,   LOSS_E:1.186e-06,    LOSS_initial: 0.409,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7435.714047193527\n",
      "loss_compared with real:0.13528,   miu_train:0.0006659,    lossmean:-0.1022\n",
      "Epoch [99200/100000], Loss: 225,   LOSS_function: 60.5,   LOSS_E:1.254e-06,    LOSS_initial: 0.4072,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7443.041531801224\n",
      "loss_compared with real:0.13399,   miu_train:0.0006733,    lossmean:-0.101\n",
      "Epoch [99300/100000], Loss: 215.9,   LOSS_function: 53.35,   LOSS_E:1.551e-06,    LOSS_initial: 0.4013,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7450.308265924454\n",
      "loss_compared with real:0.13456,   miu_train:0.0006895,    lossmean:-0.1018\n",
      "Epoch [99400/100000], Loss: 214.4,   LOSS_function: 46.45,   LOSS_E:1.1e-06,    LOSS_initial: 0.4166,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7457.612525224686\n",
      "loss_compared with real:0.13365,   miu_train:0.0006473,    lossmean:-0.1014\n",
      "Epoch [99500/100000], Loss: 220.6,   LOSS_function: 58.73,   LOSS_E:1.265e-06,    LOSS_initial: 0.4005,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7464.819389104843\n",
      "loss_compared with real:0.13533,   miu_train:0.0006903,    lossmean:-0.1022\n",
      "Epoch [99600/100000], Loss: 219.2,   LOSS_function: 55.07,   LOSS_E:1.259e-06,    LOSS_initial: 0.4064,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7472.190902471542\n",
      "loss_compared with real:0.13493,   miu_train:0.0006667,    lossmean:-0.1018\n",
      "Epoch [99700/100000], Loss: 206.7,   LOSS_function: 39.69,   LOSS_E:1.448e-06,    LOSS_initial: 0.413,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7479.339203834534\n",
      "loss_compared with real:0.13425,   miu_train:0.0006716,    lossmean:-0.1016\n",
      "Epoch [99800/100000], Loss: 213.9,   LOSS_function: 46.26,   LOSS_E:1.303e-06,    LOSS_initial: 0.415,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7486.671912193298\n",
      "loss_compared with real:0.13303,   miu_train:0.0006583,    lossmean:-0.101\n",
      "Epoch [99900/100000], Loss: 211.9,   LOSS_function: 46.25,   LOSS_E:1.314e-06,    LOSS_initial: 0.41,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:398.8,      learn rate:6.14e-06,    time: 7493.851330041885\n",
      "loss_compared with real:0.13423,   miu_train:0.0006677,    lossmean:-0.1015\n",
      "Epoch [100000/100000], Loss: 217.6,   LOSS_function: 50.14,   LOSS_E:1.254e-06,    LOSS_initial: 0.4135,\n",
      "lamda1:1.003,    lamda2:1.524e+06,    lamda3:400,      learn rate:5.845e-06,    time: 7501.163850069046\n",
      "loss_compared with real:0.13355,   miu_train:0.0006451,    lossmean:-0.1013\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5309, -0.5392, -0.3081, -0.9694, -0.0874, -0.3406,  0.4444, -0.8372,\n",
      "         0.9111,  0.3171,  0.7795,  0.5311,  0.6503, -0.0341,  0.6901, -0.3140,\n",
      "         0.8757,  0.0379,  0.8012, -0.7959, -0.2814, -0.9598, -0.5122, -0.3309,\n",
      "        -0.2967, -0.3995,  0.6968, -0.6640, -0.2489,  0.3838, -0.3141, -0.1899,\n",
      "         0.1076,  0.6398, -0.7265, -0.7956, -0.7200, -0.5712, -0.2668, -0.0490,\n",
      "        -0.8210, -0.9058, -0.0655,  0.7911, -0.6100,  0.8613, -0.6720,  0.8850,\n",
      "         0.5984, -0.9501, -0.7589, -0.3710,  0.8560, -0.5813,  0.9263, -0.1150,\n",
      "        -0.8806,  0.4181, -0.2724, -0.8578,  0.7875, -0.3306,  0.2653, -0.1115,\n",
      "        -0.5488, -0.0667, -0.0341,  0.4169, -0.4229, -0.3490,  0.6047, -0.4490,\n",
      "        -0.5086,  0.8763,  0.8027, -0.4360, -0.4570,  0.0119, -0.3391, -0.5485,\n",
      "        -0.7807, -0.7338,  0.9631,  0.0093,  0.1147,  0.8141,  0.7062,  0.2399,\n",
      "        -0.0322, -0.0792,  0.6670,  0.6922, -0.6781,  0.9043,  0.2281,  0.5589,\n",
      "        -0.6498, -0.1428,  0.6164,  0.0195, -0.8637,  0.0898, -0.0041, -0.2004,\n",
      "         0.4244,  0.4903,  0.6847,  0.0534,  0.2622,  0.6535, -0.6013, -0.2579,\n",
      "         0.5893,  0.7802,  0.7373, -0.0078, -0.9610,  0.9132, -0.3150, -0.8673,\n",
      "        -0.9524,  0.8845, -0.2206,  0.3749, -0.2409,  0.4241, -0.2072,  0.1846],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1130, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0207, -0.0243,  0.0245,  0.0797, -0.0583, -0.0342, -0.0284,  0.0278,\n",
      "        -0.0604,  0.0374, -0.0103, -0.0993,  0.0517, -0.0524,  0.0596,  0.0040,\n",
      "        -0.0247, -0.0283, -0.0381,  0.0710, -0.0622,  0.0550,  0.0252, -0.0147,\n",
      "         0.0191, -0.0045,  0.0677, -0.0470, -0.0168, -0.0747,  0.0192, -0.0815,\n",
      "         0.0828, -0.0308,  0.0626, -0.0019, -0.0526,  0.0521,  0.0490, -0.0529,\n",
      "        -0.0820, -0.0613,  0.0225,  0.0833,  0.0591,  0.0717, -0.0181,  0.0664,\n",
      "        -0.0345, -0.0191,  0.0621,  0.0165, -0.0239,  0.0093,  0.0059,  0.0061,\n",
      "         0.0533,  0.0539,  0.0593,  0.0326,  0.0146, -0.0493, -0.0400,  0.0428,\n",
      "         0.0652,  0.0047,  0.0444,  0.0244,  0.0514,  0.0280,  0.0609, -0.0100,\n",
      "        -0.0269, -0.0227, -0.0659,  0.0257, -0.0532,  0.0521, -0.0172,  0.0178,\n",
      "         0.0110, -0.0269, -0.0131,  0.0502,  0.0408, -0.0373, -0.0177, -0.0217,\n",
      "         0.0790,  0.1000,  0.0162,  0.0444, -0.0689, -0.0788,  0.0728, -0.0678,\n",
      "         0.0573,  0.0300,  0.0307,  0.0897,  0.0783,  0.0594,  0.0446,  0.0652,\n",
      "         0.0766,  0.0021, -0.0822, -0.0684,  0.0175, -0.0529,  0.0290,  0.0194,\n",
      "        -0.0493, -0.0500,  0.0002,  0.0417,  0.0575, -0.0827, -0.1186,  0.0397,\n",
      "         0.0629,  0.0233,  0.0253, -0.0224, -0.0036,  0.0225, -0.0612,  0.0694],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1288, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0489, -0.0524, -0.0477,  0.0489, -0.0312, -0.0341, -0.1113,  0.0025,\n",
      "        -0.0287,  0.0626, -0.0284, -0.0650, -0.0165,  0.0039, -0.0425, -0.0888,\n",
      "        -0.0596,  0.0570, -0.0100, -0.0811,  0.0102, -0.0222, -0.0545, -0.0319,\n",
      "         0.0249,  0.0205,  0.0484,  0.0496, -0.0541, -0.0640, -0.0424,  0.0393,\n",
      "         0.0457, -0.0358,  0.0595,  0.0520,  0.0706, -0.0133,  0.0137,  0.0892,\n",
      "        -0.0662,  0.0467,  0.0292, -0.0234,  0.0459,  0.0131, -0.0746, -0.0558,\n",
      "        -0.0320, -0.0411, -0.0659,  0.0403,  0.0838, -0.0716,  0.0543, -0.0204,\n",
      "         0.0203, -0.0719,  0.0215, -0.0736,  0.0407,  0.0510, -0.0159,  0.1090,\n",
      "         0.0769, -0.0376,  0.0007, -0.0138,  0.0017,  0.0173, -0.0776, -0.0123,\n",
      "         0.0180,  0.0478, -0.0198,  0.0282,  0.0753,  0.0241,  0.0051, -0.0088,\n",
      "         0.0801, -0.0487, -0.0731,  0.0919,  0.0203, -0.0078,  0.0300,  0.0861,\n",
      "        -0.0124, -0.0794,  0.0132, -0.0958,  0.0398, -0.0238, -0.0754,  0.0252,\n",
      "        -0.0433, -0.0559, -0.0670,  0.0685, -0.0790,  0.0246, -0.0110,  0.0435,\n",
      "        -0.0300, -0.0584,  0.0208, -0.0758, -0.0953, -0.0203, -0.0454,  0.0140,\n",
      "         0.0626, -0.1075, -0.0551, -0.0313, -0.0490, -0.0451,  0.0874, -0.0342,\n",
      "        -0.0433,  0.0410,  0.0614,  0.0815, -0.0544, -0.0842, -0.0144, -0.0529],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1064, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0388, -0.0757,  0.0095,  0.0793, -0.0860,  0.0292, -0.0184, -0.0037,\n",
      "         0.0775,  0.0443,  0.0264,  0.0576,  0.0330, -0.0612, -0.0512,  0.0647,\n",
      "        -0.0041,  0.0163, -0.0128, -0.0220,  0.0048,  0.0013,  0.0582,  0.1004,\n",
      "        -0.0029, -0.0291, -0.0090, -0.0238, -0.0074,  0.0676,  0.0048,  0.0470,\n",
      "         0.0042, -0.0061, -0.0404,  0.0484, -0.0626, -0.1061, -0.0734,  0.0141,\n",
      "         0.0971, -0.0859,  0.0351,  0.0333,  0.0699, -0.0548,  0.0791,  0.0032,\n",
      "        -0.0842, -0.0561,  0.0076, -0.0324,  0.0060,  0.0762,  0.0297,  0.0130,\n",
      "        -0.0304, -0.0612,  0.0604,  0.0168,  0.0202, -0.0628, -0.0247, -0.0318,\n",
      "         0.0104, -0.0506, -0.0371, -0.0363,  0.0385, -0.0775, -0.0483, -0.0276,\n",
      "        -0.0490,  0.0525, -0.0753, -0.0278, -0.0342, -0.0142,  0.0878, -0.0285,\n",
      "        -0.0411,  0.0719, -0.0008,  0.0473,  0.0157, -0.0500, -0.0086, -0.0369,\n",
      "         0.0029,  0.0157, -0.0195, -0.0954,  0.0711,  0.0430, -0.0223,  0.0694,\n",
      "        -0.0582, -0.0782,  0.0488, -0.0582, -0.0376,  0.0312, -0.0646, -0.0382,\n",
      "         0.0225,  0.0426,  0.0467, -0.0908,  0.0127, -0.0683,  0.0435,  0.0711,\n",
      "        -0.0637, -0.0712,  0.0611, -0.0127, -0.0986,  0.0304, -0.0373,  0.0395,\n",
      "         0.0339, -0.0375,  0.0428, -0.0794, -0.0103,  0.0495, -0.0126,  0.0583],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0803, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0474,  0.0627,  0.0927], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()#计时\n",
    "epochs = 100000  #训练次数\n",
    "opt = torch.optim.Adam(u.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    lpde=LOSS(u)[0]\n",
    "    lE=LOSS(u)[1]\n",
    "    l0=LOSS(u)[2]\n",
    "  \n",
    "    if (i+1)%1000== 0:\n",
    "        gradient_lpde=funcweight(lpde)\n",
    "        gradient_lE=funcweight(lE)\n",
    "        gradient_l0=funcweight(l0) \n",
    "\n",
    "    if (i+1)%1000== 0 and lpde>1e-5:\n",
    "        lamda1=0.2*lamda1+0.8*(  (gradient_lpde+gradient_l0+gradient_lE)/gradient_lpde  )\n",
    "    if (i+1)%1000== 0 and l0>1e-5:\n",
    "        lamda3=0.2*lamda3+0.8*(  (gradient_lpde+gradient_l0+gradient_lE)/gradient_l0  )\n",
    "    if (i+1)%1000== 0 and lE>1e-5:\n",
    "        lamda2=0.2*lamda2+0.8*(  (gradient_lpde+gradient_l0+gradient_lE)/gradient_lE  )\n",
    "        \n",
    "    l_total=lamda1*lpde+lamda3*l0+lamda2*lE\n",
    "    l_withoutweight=lpde+l0+lE\n",
    "    l_total.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    \n",
    "    if (i+1)%1000 == 0:\n",
    "        learnr = opt.param_groups[0]['lr']\n",
    "        \n",
    "        #更新学习率\n",
    "        learning_rate *=0.952\n",
    "        for param_group in opt.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "    if (i+1)%(n_epoch*40)==0:\n",
    "        Save()\n",
    "    \n",
    "    \n",
    "\n",
    "    if (i+1)%n_epoch == 0 or i==0:\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        learnr = opt.param_groups[0]['lr']\n",
    "        time_test =torch.arange(interval*jump, interval*(n_all+1+jump), interval*int(n_all/n_test))\n",
    "        t_test = time_test.view(-1, 1).requires_grad_(True)\n",
    "        x_test = u(t_test)[:, 0].view(-1, 1)\n",
    "        y_test = u(t_test)[:, 1].view(-1, 1)\n",
    "        z_test = u(t_test)[:, 2].view(-1, 1)\n",
    "        vx_test = gradients(x_test,t_test,1)\n",
    "        vy_test = gradients(y_test,t_test,1)\n",
    "        vz_test = gradients(z_test,t_test,1)\n",
    "        loss_test = loss(x_test,x_real)+loss(y_test,y_real)+loss(z_test,z_real)\n",
    "        miu_train=funcmiu(x_test,y_test,z_test,vx_test,vy_test,vz_test)\n",
    "        #lcq=lE+lmiu_test#注意这里！！\n",
    "        lossmean_test = torch.sum(x_test-x_real+y_test-y_real+z_test-z_real)/n\n",
    "        print(f'Epoch [{i+1}/{epochs}], Loss: {l_total.item():.4g},   LOSS_function: {lpde.item():.4g},   LOSS_E:{lE.item():.4g},    LOSS_initial: {l0.item():.4g},')\n",
    "        print(f'lamda1:{lamda1:.4g},    lamda2:{lamda2:.4g},    lamda3:{lamda3:.4g},      learn rate:{learnr:.4g},    time: {total_time}' )\n",
    "        print(f'loss_compared with real:{loss_test:.5g},   miu_train:{miu_train.mean():.4g},    lossmean:{lossmean_test.item():.4g}') \n",
    "        loss_list.append(l_total.item())\n",
    "        lpde_list.append(lpde.item())\n",
    "        l0_list.append(l0.item())\n",
    "        lE_list.append(lE.item())\n",
    "#         lamda1_list.append(lamda1)\n",
    "#         lamda2_list.append(lamda2)\n",
    "#         lamda3_list.append(lamda3)\n",
    "#         l_withoutweight_list.append(l_withoutweight.item())\n",
    "#         time_list.append(total_time)\n",
    "        loss_test_list.append(loss_test.item())\n",
    "        lossmean_test_list.append(lossmean_test.item())\n",
    "#         miu_train_list.append(miu_train.mean())\n",
    "    \n",
    "    if (i+1)%4000 == 0:\n",
    "        for name, param in u.named_parameters():\n",
    "            if 'a' in name:  # 筛选出包含'a'的参数\n",
    "                print(name, param)\n",
    "        \n",
    "        \n",
    "    if l_total <= stop_condition:#刚才写成loss_test了，感觉不妥，毕竟应该不知道真实数字是多少\n",
    "        print(f'Training stopped at No.{i+1} time. Loss ({l_total}) is below the specified threshold ({stop_condition}).')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "932983a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_uname='hh.pth'\n",
    "#保存神经网络\n",
    "torch.save(u.state_dict(), new_prefix + old_uname[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41a2718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算神经网络的轨迹\n",
    "output_history= []#想要缩短周期，就调大Bz\n",
    "for i in range(jump,(n_all+1+jump)):\n",
    "        # 将当前状态输入神经网络得到下一时刻的状态\n",
    "        next_state = u.forward(torch.tensor([interval*i]) )#+torch.rand(1) * interval )\n",
    "\n",
    "        # 记录输出值\n",
    "        output_history.append(next_state)\n",
    "\n",
    "import numpy as np\n",
    "x_coordinates = np.array([x[0].item() for x in output_history])\n",
    "y_coordinates = np.array([x[1].item() for x in output_history])\n",
    "z_coordinates = np.array([x[2].item() for x in output_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22d89d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.loadtxt('通行x_real.txt')\n",
    "\n",
    "# 将所选数据转换为PyTorch张量\n",
    "\n",
    "\n",
    "ydata = np.loadtxt('通行y_real.txt')\n",
    "\n",
    "\n",
    "zdata = np.loadtxt('通行z_real.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#全500点，用于后续绘图\n",
    "x_plt=xdata[jump:(n_all+1+jump):1]\n",
    "y_plt=ydata[jump:(n_all+1+jump):1]\n",
    "z_plt=zdata[jump:(n_all+1+jump):1]\n",
    "x_real_plt=torch.tensor(x_plt, dtype=torch.float32).view(-1,1)#真实值的0~500点，\n",
    "y_real_plt=torch.tensor(y_plt, dtype=torch.float32).view(-1,1)\n",
    "z_real_plt=torch.tensor(z_plt, dtype=torch.float32).view(-1,1)\n",
    "vxdata = (np.loadtxt('通行vx_real.txt'))*1e-6\n",
    "vydata = (np.loadtxt('通行vy_real.txt'))*1e-6\n",
    "vzdata = (np.loadtxt('通行vz_real.txt'))*1e-6\n",
    "vx_real_plt=torch.tensor(vxdata[jump:(n_all+1+jump):1], dtype=torch.float32).view(-1,1)\n",
    "vy_real_plt=torch.tensor(vydata[jump:(n_all+1+jump):1], dtype=torch.float32).view(-1,1)\n",
    "vz_real_plt=torch.tensor(vzdata[jump:(n_all+1+jump):1], dtype=torch.float32).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dab0c957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制轨迹，2维\n",
    "plt.plot(x_coordinates,y_coordinates,linestyle='--', label='PINN')\n",
    "plt.plot(x_real_plt, y_real_plt,label='VPA')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "# plt.title('PINN results VS classic results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1f7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = [x_coordinates, y_coordinates, z_coordinates]\n",
    "file_names = ['hh_outputx.txt', 'hh_outputy.txt', 'hh_outputz.txt']\n",
    "\n",
    "for file_list, old_name in zip(file_lists, file_names):\n",
    "    new_name = new_prefix + old_name[2:]  # 保留原始文件名中的后缀部分\n",
    "    with open(new_name, 'w') as f:\n",
    "        for item in file_list:\n",
    "            f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf8262b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAADvCAYAAAD/yxH8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABjSklEQVR4nO29eXxU9b0+/pxZsk32yUL2BEISyEpCAK2ileKugCjqbe/lFmu1X22r3lqxVqu2Vqq9KtVWf7eWqm3VIotgUai4YasIsmRPyL6TWTJZZt8+vz+Sz+HMZJYz+wTmeb3ygszMmTlncs5z3p/3+3k/b4YQgggiiCACewhCvQMRRBBBeCJCDhFEEIFDRMghgggicIgIOUQQQQQOESGHCCKIwCFEbp6PlDIiiCDwYEK9A44QiRwiiCACh4iQQwQRROAQEXKIIIIIHCJCDhFEEIFDuEtIRhBBQGEymTA0NAS9Xh/qXQk4YmJikJubC7FYHOpd4QXGTW9FpFoRQUDR29uLhIQESKVSMExYJu39AkIIlEolpqenUVRUZP90WB54ZFkRQUih1+vPe2IAAIZhIJVK51WEFCGHCEKO850YKObbcUbIIYIIInCICDlEcMFDKBSipqYGFRUVuOWWW6DVagEA8fHxAIC+vj4wDIMXX3yR3ebee+/Fa6+9BgD47//+b+Tk5MBgMAAAFAoFCgsLg3oMgUCEHCK44BEbG4vTp0+jubkZUVFReOWVV+a8JiMjA9u3b4fRaHT4HkKhEDt27Aj0rgYVEXKIIAIOLr30UnR1dc15PD09HWvWrMHrr7/ucLv77rsPzz//PMxmc6B3MWiI6BwiCBs88V4LWkem/PqeS7MT8Ysbynm91mw244MPPsDVV1/t8PmtW7fimmuuwZYtW+Y8l5+fj0suuQR/+ctfcMMNN/i0z+GCSOQQwQUPnU6HmpoaLF++HPn5+bjjjjscvq6oqAgrVqzAm2++6fD5n/3sZ3j22WdhtVoDubtBQyRyiCBswPcO72/QnAMf/OxnP8PNN9+M1atXz3muuLgYNTU12Llzp5/3MDSIRA4hACEEFosFEefv+YeysjIsXboU//jHPxw+/8gjj+C3v/1tkPcqMIiQQ5BBCIHJZIJarcbk5CTUajUMBkOELOYRHnnkEQwNDTl8rry8HLW1tUHeo8Ag0lsRRFitVhiNRhBCYDabQQhhf4AZBZ1IJGJ/BALBvFPVeYq2tjYsWbIk1LsRNDg53rD8I0dyDkEAJQOz2QyGYdgLnvt/7utMJhOAmey51WpFUlLSBUMWEYQPIuQQYBBCYDQaYbVaWTKg0YL9hW5PFpOTk1AoFIiKimKfv9AiiwhChwg5BBAWiwUmk4klAk8vZLqNUCgEcC5fQSMLShZisRhCoXDekoUjojwfMd9yShFyCADslxECgfd5X+4JxSUK+pw9WYjFYohEonlDFjExMVAqled92zb1c4iJiQn1rvBGhBz8DKvVCpPJZLOM8BbutnVEFkajkW0AEggEEIvFbGTh6/4EArm5uRgaGoJcLg/1rgQc1AlqviBCDn4C1S5w7+LOLkRu7sHVxerNMsQZWdAIhrsMCQeyEIvFjpyRIggDRMjBDyCEYHJyEhqNhld4TF8fExOD6Ohot6/1Fvb5CgAwGo1sZ6E9Wfiy/Ing/EOEHHwE1S5MT09DpVIhLS3N5evNZjNaWlrYXIHVakVycjJSUlKQnJwMkSgwfxJKWBGyiIAvIuTgJbjLCHqHdneXn5ycREtLCwoLC5GWlgZCCKxWKyYmJqBSqdDX1wcASElJQUpKCrv0CAQckQVdhhiNRphMJmi1WmRkZNgkOCO4cBAhBy/gSLvg6kImhGBgYAAjIyOorq6GRCJh79ZCoRBSqRRSqRTATGQxMTEBpVIJpVIJs9mM3t5eJCcnIykpKWAXqH3+QavVYnR0FElJSXMSnBGyuDAQIQcPwZVA26sdHZGDyWRCc3MzoqOjsWLFCpuEoSOIRCKkpaUhLS0NCxYsQH9/PyQSCWQyGTo7OyEWi5GSkoLU1FTEx8cH9AIVCARzIguDwcCShVAoZJcgIpEo5MnNCPyLCDnwhDvtgkAgmEMOKpUKra2tWLRoERYsWODV5wqFQmRkZCAjIwMAYDAYoFKpMDw8jOnpacTExLD5ivj4+IBdoI6k3lar1cZqnZIFjSwiZDG/ESEHHnC0jLAHwzCsyQchBL29vZDL5Vi2bBni4uK8+lxH0Uh0dDQWLFiABQsWgBACvV4PlUqFgYEBqNVqxMXFsTmLuLg4ry9QPmXWCFmc34iQgxtwG6HcaRcoiTQ1NSE+Ph719fUBDfsZhkFsbCxiY2ORnZ0NQgi0Wi1UKhV6enqg1WoRHx/PkkVsbGxA9yVCFucXIuTgBM46KZ2BYRjo9XocP34cJSUlSE9P93kfPK1WMAwDiUQCiUSC3NxcEEKgVquhUqlw5swZGAwGJCQksGThSmPha7+DM7LQ6XQ2lZIIWYQvIuTgAJ5KoGk1Qq1W4+KLLw4b/TzDMEhISEBCQgLy8/NhtVpZPUZrayvMZjMSExNZsgjkgFf6PdJIyhFZcDtOI2QRekTIgQOqXRgYGIDFYkF+fr7bbfR6PZqamiCRSJCcnMybGPhEBf7WOQgEAiQlJSEpKQmFhYWwWCyYmpqCSqXC0NAQLBYLK8gKtLTaEVlwdSMmkwkWiwUpKSmR9vQQIUIOs6AdjhaLBQB4OQjL5XKcOXMGZWVlkEgkaGlpCfRu+hVCoZCNGoCZ/Mrk5CRUKhWUSiVMJhP7mqSkJLdlWF9gTxaTk5NsFyMhhC2r0mVIhCwCjwg5YK52QSAQuCQHq9WKzs5OTE9PY/ny5YiOjobBYJh3/fr2EIlErCBLKpVCJpMhMTERCoUC3d3dNmSSmJgY0GQrlxDo7xaLhR0aEzG+CTwuaHJwpl1wpFmg0Ol0aGxsRHp6Ourq6tyKoHxBIOXTfCAQCJCens4mV41GI1QqFcbGxnDmzBlERUWxZJGQkODXi9NqtdqQjztLvQhZ+B8XLDm40i44ixzGxsbQ1dWFpUuXsqE4d5v5Hjlw4ahaERUVhczMTGRmZgIAq7EYGhqCWq1mBVkpKSmQSCQ+XZze6CzOR5esUOKCJAcaLTizb+MKmoCZu1h7ezv0ej3q6+tZT0f7bc63yMEdYmJikJWVhaysLBBCoNPpMDExgf7+fqjVakgkEhuNhScXp33k4A7no0tWqHFBkQNf+zZu5KDRaNDU1ISsrCwsWbLEpQjqfBmDBniuc2AYBnFxcYiLi5sjyOru7oZWq2U1FsnJyW4FWf7QWfBxyaLLkHAwvgk3XDDk4Il2gd6xR0ZG0NfXh/LyciQlJbl8f0/u8jqdDs3NzRAIBEhNTXV6Zw33yMEVfBVkeRo58NkfVy5ZNLIIJ5esUOO8Jwd7+zY+Jxw1AzWZTFixYgUvAxa+JxItf5aUlEAoFEKlUqGrqwt6vR4JCQksWThaugQT/naE5iPISkpKYnUWtFoRKPBxyRIKhYiKirpg29PPa3Kg62Cu54I7TE9Po7W1FSKRCFVVVX67QAgh6OzsxNTUFOrr69llSHx8PPLy8tiLZXx8HMPDw7BYLEhISIDBYIDZbA6YQ1So4EqQNTg4CL1eD4lEgqioqIA6ZAHOXbK6u7sRExODjIyMC9Il6/w64zig2oWjR4/i4osv5iWBHh4exsDAABYvXoyzZ8/6jRgMBgMaGxuRkpLClj9pJEPBvViKiopgsVigUCgwPj6O06dPQyAQBE1jAAR/loS9IKu3t5d1yerr6wPDMGxUEQxBFoVYLGa/a/vI4nw3vjnvyMFRw5S7k5z6OgoEAqxYsQJGoxEjIyN+2Z/x8XG0tbWhtLTUxl/S3T4JhUKkpqZiZGQEy5YtYzUGZ8+exZkzZxAdHc0uQXwtG4YrEhMTWY2FyWTCxMREUAVZFovFpqrhyvjmfCSL84oc+Pgu2GNqagrNzc0oLCxEdnY2ALBlTl/3paenBwqFAnV1dT43Y9lrDHQ6Hes7qdFo2Nbs1NRUvzR+hXoKlX3OQSwWOxRkUbIMhCDLarU6jFAcaSzsyWLHjh3YtGnTvJpTYY/zhhw8HT3nyNeRwp182h385engqlph7+NAKwHt7e0wGo1ISkoKSrdloEAJ3hmCIciikYM7OCKLTz75BOvXr/f4M8MJ854c3GkXaOKP+7g7X0dfNAsTExNoaWnB4sWLWWu3QMNRJYA2UA0ODoIQguTkZKSmpvJer4dD5ODJ5zsSZHEjK28EWRaLxavcBsMw0Gq1Njec+Yh5TQ58tAs0CqDkQC9eV76O3kih6ZKmvb2dtzVcoC5AbvISOOdoTdfrIpGIXYI4C8FDTQ6+6By4gqycnBwQQqDRaNiysU6ns9FYOFuGOVtW8IFarUZCQoJX24YL5iU5eDJ6jpIDIQR9fX2QyWRuL15PlxVmsxnNzc2wWCyor6/3WybdXyIorqM1cM6kdmhoCNPT037znfQn/CmCYhgG8fHxbNmYuwzr6OiAwWCwMb2hGhO+ywpHMBqNbqeZhTvmHTl4at8mEAhYQxa+OQBPLsrp6Wk0NTWhsLAQWq02oCU2f8HepFan02F8fBw9PT3Q6XSs5X0oT+5ARi7OBFnj4+MYGRlhBVkGgwEWi8WrnE2gRVzBwLwiB2czI1zBbDajoaEBZWVlfvF15GJoaAiDg4OoqqpCfHw8O7HKXwiGfJobglOZ8/T0NPr7+6FSqaBQKJCUlITU1NSAi5G4CObFxdWYAGAFWTKZDC0tLWzOhmos3H0H81Xybo95QQ72FmJ8JdDd3d3QaDSorq5mJ0r5AxaLBa2trSCEoL6+3uZkCfVa3VcwDIPExERIpVKkpKQgKyuLTW5SMRINvwM5gctdtSKQoBqK6Oho1NXV2Thk9fb22nwHiYmJTqPF+XweAPOAHGii78SJE6itreX1hdNlRHJyMtLT0/1aytNoNGhsbERubi5yc3Nt9ofe6f11UoRD4xUVY6WmpgKYqfSoVCp2AldUVBQrxvLnUJ1wCsu5DlnAOUGWXC5HV1cXSyY0wct338fHx3Hrrbfi8OHDnQD6AGwihKjsX8cwTB+AaQAWAGZCyPLZx2sAvAIgBoAZwP8jhBybfe5hAHfMbvMjQsghj4/b0w2CCe4yQq/X8zrxuL6OUqkUra2trC+krxgdHUVvby8qKiqQmJg45/lwuJj9BWckJxaLbSZw6fV6jI+Ps+7btGSYmprq05yMUEYO7uBMkDU6OopTp07hqaeegslkwokTJ1BTU+M0sti2bRvWrFmDDz/8cDHDMFsBbAXwkJOP/SYhRGH32DMAniCEfMAwzLWzv1/OMMxSALcBKAeQDeAwwzAlhBCPLoSwJAdH2gV3d2VHvo6A74Im+t7t7e0wGAyor693Gol4Qg58TvxwvTi4iImJQXZ2NivGoiVD2pbtqArAB/5u2Q4kuIKssrIyxMbG4sEHH8Tvfvc7iMVivPrqqw6327dvHz799FP66+sAPoVzcnAEAoDepZIAUM3/OgBvE0IMAHoZhukCsALAl54cV9iRgzMJtCtycObrCPhODvS9MzMzXZq90M/iQw5UnanT6SCVSgO6dvcW3oT19iVD+05Tq9XKJvaSk5NdVnZCnbvxJQJMT09HUVERXn/9dZevGxsbQ1ZWFv28UYZhnKnmCIB/MgxDAPx/hJD/m338PgCHGIb5LQABgItnH88BcJSz/dDsYx4hrMjB1eg5oVDosO7sytcR8I0c6Lra2Xvbg0/kYDab0dTUhOjoaCQkJLCfQRupUlNTw0Zr4CvsO01pYo+WTe3X6ty/bagjB18+ny6vAOBb3/oWzp49O+c1Tz31lCdv+Q1CyMgseXzIMEw7IeQIgB8AuJ8QspthmE0A/gTgWwAcnTwes11YkAMf7QIlBxrSW61WdHR0QKfTOfV1BLwjBzrjcWBgwOV728Od7FqtVqOxsRFFRUXIyMiAyWSyaaSiF41Wq2XD8VBZzwXizm2f2KNr9ZGREZuJ4ampqSGPHLyVTgNg5doAcPjwYaevy8zMxOjoKLKyssAwTBYAmaPXEUJGZv+VMQyzFzNLhCMANgP48ezL3gFA1y9DAPI4b5GLc0sO3gh5LEuTju5ETUKh0MbX8dixY4iLi8OyZctcXryekoNer8fXX38NhmHcvrc9XEUOo6OjaGxsRGVlJRtKchEbG4ucnBxUVlZixYoVyMnJgU6nY/enq6sL4+PjfkuuhgPoWn3JkiWor69HcXExBAIBent7odVq0dLSgtHRUZthvMGCr5FDfHy829fdeOON3KXHZgD77F/DMIyEYZgE+n8AVwJonn16BMBls/+/AkDn7P/3A7iNYZhohmGKACwGcMzT4whZ5OCpfZtAIIDFYvHI15G7HR8olUq0t7ejrKwMXV1dvLbhwhE5WK1WnDlzho1w+JRVqdaADpSpqamx6Y0Qi8XsEiRQXg7BvnPb90McO3YM+fn5GB8ft+k0pWKsQHea+hI50Onm7rB161Zs2rQJDz/8cCeAAQC3AADDMNkAXiWEXAsgE8De2b+FCMCbhJCDs29xJ4DtDMOIAOgBfB8ACCEtDMPsBNCKmRLnPZ5WKuiHBR3UNtxisfBWOjIMg87OTtaQha9STygUznFdcrQ/PT09UCqVrPdCT0+Px4039lGKwWBAQ0MD0tLSUFpa6vXFZt8bQcuHXC8HShbzXc9PwZU4FxQUsJ2mtGxKCLERY/lbtu6vnIMrSKVSfPTRR8DMnZ3F7DLi2tn/9wCodrQ9IeRfAOqcPPcUAI8SG/YIOjl4I4FWq9WQy+XIzs72+CJzt6wwGo1obGxEQkICli9fzp4Q3rRtcyMHapxK9Rb+hH35UK1WQ6lUskattD3bXUXAFUK95reHfaepvTOUSCRixVj+MHvxNefAJ3IIdwSNHOhJbDAY2MYePttQX8eMjAxIpVKP/+iuyMGV94I3bduUUPr7+zE6Oora2lqfhEB8P5PeYalR68TEBJvcpBdNamqqXxWMoYa9EMlgMGB8fNym09SV7b87+EoONNE8nxEUcqDahfHxcUxPT2Px4sVut7H3dezv7/cqGeeIHAgh6O/vx9mzZ522b3tT5aAO07GxsVixYkVISnFCodCmIkAvGq6CkZKFKzu5cIsc3CE6OtrG7IUO1OHa/tNKCJ8ksy/LCr45h3BHwMmBO3pOJBLxuuAc+Tp6q1ew387eBcrZCeDpskKj0UChUCA3NxclJSVuXx+sC8/+otFoNGySz2QyhaTjMtBgGNuBOtwZGS0tLezSi4qxHB23v0qZ8xkBOxscSaCFQiE7Qt3ZNs58HanOwVNwyYGSTlFRkcNyov12fJcVVMgklUr93hbuT3AVjPn5+bBYLGySr6+vj53AlZqaGtLeBn/3pziakcE9btplmZqayjpZB6OUGe4ICDk4s28TiUROL3B3vo58qg6OQEuZg4ODGBoaYr0X3IFP5ECXEdPT06ivr2crHPMF9h2XdOk3NDSE8fFxxMTEwGg0+txE5SkCvaRx1mnKtf2nuRxv9iWyrHAAd9oFZ3d/vr6O3l544+PjAOCQdJyBb5UjKSmJbSWf712ZUVFRrENUd3c3oqOjWZ2GwWBglyApKSkBXYIEO99h32mq0+nQ1dUFpVIJmUzG2v7T5KY7RKoVduCjXbAnB098Hb1ZVqjVajQ3N0MsFqOystKjbV2Rw+TkJJqbm+dUOeY7OXDBMAxiYmKQlpbGNlHRULy/vx8Mw7B3X/u+CF8R6r6K2NhYSCQSZGVlQSqVsnkabqcpJUlHYqwIOdiBhuHuJND0Avd0tgNXPs0H1HuhtLQU/f39/A9kFs4udLo8cURm3pQ/wxX2d29HOgP7vghKFt6UDl19dihACco+T2O1WjE1NYXx8XGntv8ajcat8zQ1eunr60NXV9eH8JPRC8MwhQDaAHTMvsVRQsjd3nwHfo0N3V3AlBzoiLiSkhLeCTy+Mmir1Yq2tjZ2QrbVavVLlcNisaCtrQ1Wq9Xp8sQb4dR8BTcU55rU0tKhu7urK4Q6cgCcVysEAgGSk5ORnJwM4Jztv1KpRHd3N7Zv384qY5cvX+7W6GXr1q1gGOYj+MnoZfa5bkJIjWdHPBdBr10ZDAZ0dXV5PCKOz7JCq9WisbERWVlZyM/PB8MwMJvNPpMDfd/s7Gzk5eU5vat5sqwYHR2FXC6HVCpFampq2E2l8uTuze2LoKVD7t0VgEe+k+EQOfAtZdpL23/9619j06ZNeOWVV3DmzBl8/vnnDo83gEYvfkPQyIH6OhJCbGTKfOEucqDlxPLycpbV6XbekgMhhLWds39fR+BDDrTVXK/Xs+atQ0NDAGYuIKlU6vc1fLBhf3elUme+3hXhEDl4uw95eXkQi8XYsWOHS4ILoNELABQxDHMKwBSAnxNCPvf4QOBncnD2ZXB9HTs6Orz60p0tWag9nFqtdui94Ese4OzZszCbzTa2c67gjhyMRiMaGhoglUpRUlICs9mM1NRUFBUVzVnDx8bGsnqDUMCfd297qbMj7wq6BImKigqLyMGXaVc07xYio5dRAPmEECXDMHUA3mUYppwQMuXpcQQ0cnDm6+gNHC0r9Ho9GhsbIZVKeTtT84HJZMLw8DBiYmJQV1fHm8xcERGtcNA8i/1Fb7+G12q1UCqV0Ov1OH78uF+aqcIF1LsiJyfHoZVcXFwcq5MJVQTh7bQr7nahMHqZ9Y00zP7/BMMw3QBKAHzt6bEEjByc+TrSpJ03ywruBaVQKNDR0YElS5awYhZ/gE6wot19nuyns4TkyMgI+vv7UVNTw0tWy5X/jo2Noba21qaZ6nzyc3BkJTc8PIyzZ8/ixIkTQTlWR/BWPq3VannNSaVGL1u3bgVcGL0AEBBCpjlGL0/OPk2NXj4Fx+iFYZh0AOOEEAvDMAsx0w7e4/GBIEDk4MrX0ZkXpDvQ7eiwGpVK5XM0Yg9qJFNVVYXJyUmPFZn25MDNL9gPv/EE9s1UXD8HrVaLhIQEdghNuCU2PYVIJEJiYiKMRiMWL148x7siISGBXYIE0rvCW3Lk6+VAjV7+9Kc/AcBa+MnoBcBqAE8yDGPGTPnzbkLIuMcHAj+TAy0juvJ1tPeC5At64Z04cQKJiYkehft89pu6DVEjmenpaa9atuk2NL+QmpqKsrIyhyeatyegvZ/D1NQUlEqlTWVAKpUiMTHR6zttKNf93M+2P1a6BPGnd4UzeHP8fKXTHKMXAFhD/+Or0QshZDeA3R7vuAP4lRzGxsYQGxvr9GIA4Lb5yhlUKhW0Wi1KS0v92tyk1+vR0NAwx3remyoHJYepqSk0NTW51XH44+JjGMZmziM3sdne3s67RTuc4GzZybXPC1fvCr6Rw3yAX8khOzvb7YXvqvnKEbgS67i4OK+JwdGdkHpGOspbeCNoEggEmJiYwOjoqNv8QqBOXPvEpn2LNt87bbhEDq7gzrsiFPZ5EXJwAr5/UL7kQDs1Y2JiUF9fj6NHj7rfyMl+cU84LuE4E2N5GjlYrVaMjIxAo9HgoosuCgtvBEct2o4Sm1KpNKxmZXhbpbD3rlCr1VCpVKxiNhjeFedLXwUQAoUkX3KYnJxES0sLFi5c6LRT05PPpCec2WxGc3MzoqKiXPZ0eKJ2pPkFarUeDsTgCM4Sm1y9AU1shjJy8EcJk2uf5867wt5z0pf+GJogDjcwDLMBwC/sHq4CcB0h5ANH24QdORBCMDg4iOHh4TmGL76UQS0WC6uL4DpMudqGr2tVU1MTFi9eDIZhoFLN6Z3xGYG6ULnJPqo3oIlNrVYLhmGQlZXlU2LTGwTieF15V0xPT9sMABaLxT65QPEpZQYbhJC9APbS3xmG+T6AbwNwOn07rJYV1DdSKBQ6bG7y1qFHIBBgbGwMQ0NDqKys5MXsfMiBdn7S/IJSqfTorhMOSkAKrt4AAJqbmxEbGzsnsSmVSgO+fg/G98L1rqC5GToAWK/Xw2w2Qy6Xe+xdoVarHU5gDycwDFMC4DEAFxNCnJ7kYRM50FFxBQUFyMlxPPOTbuvJH8tqtUKtVsNsNvMeKgO4VjtS5adWq7WZoeFpEjNciMERBAIBpFIpCgoKbBKb3BIiHQIciJkRwVyacXMzeXl50Gg0aG9vx9TUlMfeFVqt1un5Gw5gGEYM4E0APyGEDLh6bUjIwWAw2DxGxUfu7uqeGr4YDAY0NjZCKBSirKzMI22FswudOkAlJyejpqbG5gIPhNmLfTI1WOB+prPEJncCF+0u9UdiMxwiqpiYGCxatAjA3JmesbGx7BLEfgkxD8xlfwmghRDytrsXBn1ZIRKJoNFoAMxIVGmJjc8UK08qCHSoTGlpKc6ePevxRevos6i0uri4eM6cC+D8coJyBfvEJreRSqfT+eTlAIS+K9NeOk0TzZmZmQ5t7+nxJicn86pWcI1eCgsLcfjw4RQPjV6qMWP0Eg+gD8C3aWMVwzAPA7hjdpsfEUIOcd7vcgAbAdTy+R5CtqzQarVoaGhATk6OS48ER9u6Ak1ojoyMsENlZDKZV5oF7oVO8wuuDGr5kgMhBF1dXRgeHmblwFKp1GFJNVSE48nd276Ryt7LgR4f30lUoSYHV5/P7Xux96749a9/jU8++QR6vR5RUVFYtWqVQ3LkGr1s27YNhw8f9tTo5VXMLAs+YxhmC4AHATzKMMxSALcBKAeQDeAwwzAls30WKQD+DOA/CCHTfL4Hv5ODu5NZKBRienoap06dQkVFBa9huNxtXV3kFouFHYRTX1/Psr+nFnPAuWUFIQRnzpyBRqNxG93wiWzMZjOampoQGxuLVatWQafTsWIsk8nESp/5mKKEI+y9HGhIzq0KuEtshnpZ4UnTFfd4X3jhBfzXf/0XKisr8eabb6KgoAD5+flztuEavWzevBkPP/zwenhm9FKKmc5MAPgQMxWHRwGsA/D2bGdmL8MwXZjp4vwSwN0AMgC8bPfdPk0I+bujDwlq5GC1WjEwMACNRoNvfOMbHoecrgxfaCSSl5eH3Nxc3tu5+6wTJ04gOTkZy5Ytc3vCuiNGuo8FBQXIysqC0Whk70J0La9SqVhTFGoNr9Ppgi6s8dcFah+S2yc26dqdm9gM58jBHQwGAzZs2ICCggKnr+Eavcz+66nRSzOAGzHTyXkLgLzZx3MAcJWCQ7OPgRDyNICnPTmWoDpBNTQ0IDk5GYmJiV6tRZ0tK+jF5CwS8aZPQqPRYGpqCtXV1Q7zC47gihyobyZ1lHL0OqFQyFqO0bVtQ0MDOjs7bSoEycnJ8zKqcJTYVKlUUCgU6OrqYh2ijEZjSPfTH0N0A2z0sgXA7xiGeQzAfgD0C3PE5l6vSYOyrOB6L0gkEjQ2Nnr13o6s7bu6ujA5Oem0CxTwnBzOnj2Lnp4exMbG8iYGwLVj9fDwsEe+mXRtGxsbi4qKCggEApsLKSYmhq0QBGLgTDBCey4ZAucSm5OTk5iammKjitTU1KCWNn0hB9qVydfoZXR0FPDQ6IUQ0o4ZbweqWbhudpMhnIsiACAXPnhLBvQbpxfvxMQE671gsVi8GmsH2F7k3KEyXDMZd9u521+uc9XXX3tmnmOfxKSt4CaTySYH4g3sLyTqFNXR0cE2VPk7qgj2up8mNqemptgWbaVSiYGBAdYa35PEprfwRWdhNpvdDurlGr28/vrrgIdGLwzDZMwShgDAzzFTuQBmoog3GYZ5DjMJycUAjnl1IAggOVCNQXJyMpYvX+5TKzQFjRycDZVxBj6faTKZ0NjYiMTERK8t5xz5OUilUptWcH+Buj3n5eXZ6A5oeE5Ljd5GFaEsydKLUyKR2CQ2uXLnQHZcWiwWr9+Tz/fGNXqZTVhuAzwyermdYZh7Zv+/BzNVCBBCWhiG2QmgFTOzLO4hhHh3J0aAlhWu5lL4cpEIBAIoFAqMjIzwtlwDZkjF1TqW6hcWLVqEzMxMr/ePVjjc6SE8fU93J5y97kCr1dpMaKLhuaeGKOHUsm0vd1ar1Q4Tm/6InLxNSNK/k7vvzc7oBQDGZ7fna/SyHcB2J889BcCjxIYz+J0cBgYGMDQ05PFcCnewWq0YHh6GwWDARRdd5NFJ7qpaQfMLfAfsugLDMDAYDGhqavLL+9H39BTcGRI0qqBDV/hGFaGOHFxdnNyOy4KCAqeJTXqMnn6HvuQcQq3s9Cf8Tg5paWnIysryazZdp9OhoaEBiYmJSEhI8PgP52hZwc0veNJz4QyEEPT390Ov12P16tVu152evre3cKRmVCqVbFTBzVVwv9f5YPZC4SyxSRWMng4A9jZyMJvN87KK5Ax+JweJRMLLBo7vCUArHUuXLgUhBGNjYx7vkz05+CO/wIXFYmEH9kokEr8Sg78v0NjYWOTm5rJRxeTkJJRKJXp6ehAVFcXecUMJX3UO9opN7gBgVz4OFN5GDvOgr8IjhMSVhE8zESEEPT09UCqVbKVjcnLSq0oHlxxo96c/TGSAGf3G6dOnkZOTg9zcXHz55Zc+v6c9AhXi23sc0Kiiq6sLU1NT6O7uRnp6etBnZfgzarEfAMwnsektOVFruvMFISEHkUjksuRjMpnQ1NSEuLg4m9F53siggXPkMDY2hu7ubr/lAyYmJtDS0uL32RmhAjeqOHHiBKRSqY2lHF2eyHRAQapvk7RdIZAKSVeJTYvFguTkZOj1+oA6T88XhIQcXDVQ0Uy/ozu7NzJoYCZSmZiYYOdHeJJfcHYXGx4exsDAANvc5Q2sVisYhnGbfAtVcjA1NXXOCLujjWfwwMdTKE4V47+WL8C1NXl+FygFK99hn9ikE7PPnj2LpqYmNnnrqDXbEc4nc1kgQKVMd3BGDtyhMo4Y2FM/B2AmCmlvb4fVavU4v+Bo+UMIQUdHBzubw5sLgxDCHgdXFCYQCNySRahA1/HSjAX4qXAUf/5yEI8cGsQrXwzhppIYXLk0069GtaFIhtKJ2TExMaitrWU9NvkmNiPk4AfYX+TcyVCuOh89JQeaX8jNzYVSqfT4hLNXPNJEZlJS0hyjF76gxEAIgVgsBiEEhBBYrVYbwqAkEW4t2zFiIf6jPhe31GbjgxY5/vjvAWw/ocOBvhFsWCRHaeK5HpCUlJR5OdeTEAKBQGBTEnaW2JRKpeyMDD7LCnsvh507d86ZCgd47uXAMEwhgDYAHbNvcZQQcrcv30PIyYE2ZGVkZLgchgN4pq6k+YXKykpERUVBJnMoX3cJKmoSCoXQaDRoaGjwKZFJCGErOTQ6oMcrFAohFotZkqCvNRgMMJvNNoQRDhALBbixKhPXVWTgQLMMf/i8H88e06AmNxF3rYiHcGICvb29EIlEbK4inOzvPYWzxCadkSGXy/H555+79Y+093LYtm0bfvOb3zh7OW8vh9nnugkhNd4eoz38fqZ5sqwYHx/HiRMnUFxcjKKiIrfbuvJ1pKD6hcHBQdTX17Oef94mMgkhUCgUOH36NCoqKrwiBhotmM1mhxf4308MY8tfTuPZD7vwQascg5NGgBGgo6MDKSkpiIuLY0nDZDLBbDZ7LUH3ZJ95/S0FDG6sysR7dy/Ho9cUY0ilxw/2dOP/mk3ILanEkiVLIBKJ0NPTg+PHj6OjowNyudyrqWfhBJrYLC8vx4oVK1BcXAy5XI7du3dj1apV+Pjjjx1ut2/fPmzevBnAjJfDu+++6+lH23s5bPTuCNwjJJGDQCDA6OgodDqdX5WUtMohkUhsmrG8JQeGYdDf3+/T0F66ZKDJR0cXnEjAYFpvxl+PDcFkmSE/sQBYmBqD8twYlKnkKMuMx+L0OMSJGZZsaIQhFApDHlWIhQJsqs3GdeUZ+NOXg3jjq2F8ekaJey4rxH+uyGHt76muoq+v77yJKhiGQVlZGZYvX46rrroKmzZtcrr8tfdycBHReurlAABFDMOcAjAF4OeEkM99Oa6gk4PZbMbY2BjEYrHLoTKewpV+wRtyoD0SQqHQppzqCfgQAwBsXJaNjcuyYbJY0dgnwyenu6AVJ6Nv0oxPziiw5/Qo+9qc5BiUZMSjJCMOizMkWCSNQW5SNIQChlXo0R9f4c3FKokW4UeXF+HmZVn49cEu/PZwD450KvHLG0qRnRRjE5obDAZWgEW9J6VS6bz14dRqtSgoKMBNN90UCi+HUQD5hBAlwzB1AN5lGKacekt6g6BWK+gFTIeh+osYZDIZurq6nLpXe3qSGwwGnD59GlFRUVi0aJHXxEDv7K6IgYuJcSVM8j78v2tq2dIZIQRytRFtZ9VoPzuNTpkGHTI1PutUwDp7DUUJBViYFoeFabFYlBaLRdI4FKfHYkFiNEQhiiqyk2Lw4qZy7G04i2cP9+DWP53ECzeXoy7/nBlPdHS0zVAdOi1cq9Xi1KlTbMJPIpEELarwZblGFZKeeDk4a8zz1Mth1hrOMPv/EwzDdAMoAeCZ7wAHQYscxsbG2AtYo9FAp9P5/J6EEHR3d7N+Ef6QLdN28LKyMgwPD3u9X/aJR3evHxgYgEKhQF1dnY0Og2EYZCREIyMhGpctPidrNpgt6JZr0TGmRqdMgy65BicHp/B+i5x9TYxYgKLUWCyUxmJhWhwWpcdhYZoEealxEAmCoyO4qSYLdfnJuHdnM+56qwn/9x+VqM1z7NZFvRjHx8exdOlSdvlhP6ovkMYvNAHtDfg4T9t7Oaxbt27Oa7zxcmAYJh3A+KyZ7ELMeDn0eHUgswjIt8wtv9EBMGq1GitWrIBYLIZer/fa8AU4d1dubGyck1/wBdRhetmyZYiLi8Po6KhHdxJaljQYDBCJRLydljs6OmC1WrFs2TLed/hokRBLsxKwNMs2UprSm9At16JTpkGPQoNOmQZfD07hQOu5pLdIwCA3OQZF0lgUpsUhPyUWBamxyEuJRUZCFAR+vksXpMbi9f+sxn+90YAH97bhn/euhNAJOdHzxllUQcuINFfh76jCF3LgU8q093J45513APju5QBgNYAnGYYxY6b8eTchZNyrA5lFQCMHaviSkpJiI0DyRsxEIRQKMTU1hZaWFhQVFbHJHV9AHaumpqZsdBae5CpofiE7OxsnT56EWCxGeno60tLSnCooaQI1JSUFhYWFfjnJE2PEWJaXhGV2d+dpvRk9Cg165DOk0avUok+pw796VGwSFABiRALkJMdAAgOWKruQnRSNrKRoLEiMQWZCFNLioyAWer5ESZVEYVVRMv5+YhRqgxlJsY5Vqo6qJPaO1gaDgR2Iq9Fo2KjCH3ZyFovF6yUYn94KB14OAHz3ciCE7Aaw2/O9do6AkQPtO3Bk+CIUCr0uZVFr9+rqar9MM6bvJ5FI5igo+QqQuInHvLw85OfnQ6fTQaFQsOPfU1NTkZaWxlrO63Q6dqivLwYzfJEQI0J1bhKqc8+RhtVqhdlixciEDn1KDQZVevSP6zEyZUDXqA4HmscwbZhL4ilxYkglYkglUUiOFSMhRojEmJl/48RCdsmiM1uh0powOqlH66gafeM6rCxMdkoMdJ/cXZzR0dHIyspCVlaWzQBgaidnL07yBP4wlz1fEBByGBwcxODgIBue28ObyIHmFwwGA5YvX+4XYuBaxTuaus0ncnCWeIyNjUVeXh5r46ZUKjE6Oor29nZERUVBo9GgvLw8pO3RAoEAUQIBCtMTUJiewGopJicnceaMBrW1tZjSm6DQmHF2ygi5xgTZtAFKjQlytRFKjRFj0wZM682Y1Jlhts4lUpGAQXp8FEozJfjOihysr3atE/G0r4I7AHjhwoUwGo3s8oMbVfCdvuVL05dGo/HLeRkuCAg5REdHO5ySzX6oSOQROdC7e1xcHFJSUrz+43FPPDpIxtVgHXfkwDfxKBQKkZGRgYyMDDavkZmZie7ubvT29rJGJcHMyjuCQCBgHaOqq6shFouRLBAgMUaMhdKZpRGtfNgfLyEEBrMVWqMFllmSiBYLER8t9CiH4WtHZlRUFBtVEELYXAXfqMJX5+lIb4UbZGZmuryoPIkcqGyZ5heampp8atsWCoUYGBjA6OioWwGWK0WmxWJxq1/gghCC3t5eTE5O2uQ1aK2/u7sbWq0WKSkpSE9P94kEvcXw8DA7RpBWfriDZugxO2sWixELESP2rZeCfqf+AMMwc6IKruQ5ISGBzVXQqMIXcvJ0Any4I2DVClfgSw50WE1lZSWrWfc2mUnzHO3t7bBYLFi+fLnbOwTtreCCr7CJC6vVitbWVohEIlRXV9ucfPZZeeqFSCde0aSmvx2W7Y+pt7cXU1NTqK2tdfi9cKMFOiaQkgUwE935Q6lJm54CAXsvBxpVDA0NAZhJFnq7//NVuOUKIZNPuwvXe3p6MD4+PmdYjS/W9qdOnUJmZibvyoD9Z3lDDHS+RkZGhsO5ifafR0t0ZHbilVwuR3NzMywWC6RSKdLS0pCYmOi3uyshBO3t7SCEoKqqiteFwTXfAWyjCm53KX3ek4stmF4ONKoAzjVSDQ8PQ6fTQafTzYkq+L7v+YKQ2cQ5A3fQbF1d3ZwTy5vIYXp6GpOTkygrK5szR9MVuMsKbxSPGo2Gtby3r9i4A8Ocm+ZcWFgIk8kEpVKJwcFBTE9PIzExEenp6T6V76j3ZXx8PBYuXOj1iW0fVXBJgn5ffL0qQjUnk0YVdJ8TExNtogo+k8LPJ2IAQrSscAaaXygsLHRYPQA8t4qjrdspKSlsnZwv6LLCU8UjAHZuRHl5uV8y2GKx2CYknpychEKhQG9vL8RiMZvU5ONYBMxoLBoaGrBgwQKPCNMdHC0/7AnDWVITCOyygg/oQB0q8S8qKmKJmfpOJiQksGRBowqj0Xhe5RuAEEUOjiCXy3HmzBmb/IIj8LWKo0sTlUqF+vp61g3KEwgEAhiNRrbVmi/pjYyMYGhoCMuWLQtIroBhGFYUVFxczGoqOjo6YDAYWHs3qqmwB/XQWLhwoccRjSdwtfxwltT0Z0LSGziadmVPzFRXQWe+Jicno6Ojwy0xe2D0kowZ34YKzHRnbiGEfMkwTCqAvwMoxIzRyyZCiGp2m4cB3IEZdeSPCCGHvP8WZhBS5xAqN+7u7kZfXx/q6+vdmmXwWVZYLBY0NDTAaDSitrYWYrHY41wFbYU+e/YsxsbGeNvtd3V1QS6Xo66uLqBJRC6opmLZsmWor69HSkoKRkdH8dVXX6GxsRGjo6PsxC+1Wo1Tp06htLQ0oMTgCAKBAGKxGNHR0YiKirL5u1CvCpPJFHJycJWoZhiGjSjq6upQVVUFQgh27NiBpqYmfOc738GhQ46vS2r00tnZiTVr1mDbtm3OPmY7gIOEkDLMKCXbZh/fCuAjQshiAB/N/g6GYZYCuA1AOYCrAfyBYRifLbgYN1lWr1KwVqsVJpPJ5WuOHj2KZcuWobW1FTExMSgtLeUVTo6MjMBgMKCoqMjh83QADnVRpmhra0NmZiYvl2gaCpvNZmg0GigUCiiVSnZ4Snp6+py7hMViQUtLC2JjY1FcXBwW60/qriyXy6FUKmE2m2E0GrFkyRKkp6eHxT5S0HOmvb0dSUlJrGo02F4VnZ2dSEtLc3hHd4X29nY8++yz2Lp1K6ampnD55ZfPeU1paSk+/fRTtiPz8ssvR0dHBwCwfwiGYRIBNABYSOwuToZhOgBcTggZZRgmC8CnhJDS2agBhJCnZ193CMDjhBCf5iSEdFnx9ddfo6ioyGl+wRFcRQAqlQqtra1YunTpnD+uJ8sRrokKzWgvWrQIer3eJnyXSqVIT09HTEwMmpqakJ2djZycHN7HEmgwHHdliUSC3t5eFBYW4uzZs+ju7kZycjKrqQgHr0dKDPn5+Q5Lpf70qnAGXwbaxMfHo7a21ulreBq9LAQgB/DnWb/IEwB+TAjRAMgkhIwCwCxB0H7vHABHOe8xNPuYTwgJOcjlcqjValRVVXk8aNbZsmJoaAiDg4NOreL5Wsy5qkjExMTYTIuiLcVKpZJtJTabzWGXmBoYGGCXOlyxz8TEBORyObq6uhATE8MmNf0545QP6DIwPT0deXnnjI08yVX4C74OtPnWt77lq9GLCEAtgB8SQr5iGGY7ZpYPj7rYxlEI6LPwIqhnMRXbKJVK3rMA7GEfAVitVpw5c4Z1rnbG+u5yFVzFI5+TQygUQiAQQK/XY+XKlbBYLJDL5ejr62M7MmlUESrQfI5Wq53TDs4dCweAXT61tLTAbDazUZE/NRWOQKsmOTk5Tjts3QmwaCelP4jC18jBD0YvQwCGCCFfzf6+C7O5BQBjDMNkcZYVMs42XLu4XAAjHh+EHYJWyjSbzWhubkZ0dDTq6urYCUOeglvKpCdWSkoKSktLvXKu9kbYBMw0l42NjdlIjZOSktjqgVwuR2trK0wmU9AuNC6sViva2togEolQWVnp9nOppqKgoAAmkwnj4+M2moq0tDRIpVK/RkVGoxGnT59GYWEh7wgykAIs+n7eEAyfOZl8jF4IIWcZhhlkGKaUENIBYA2A1tmn9wPYDGDb7L/7OI+/yTDMcwCyMWP0cszjg7BDUCIH2v2Yn5/Prsm9bdumEQC1nFu0aBGvlmdnk7Y9JQZCCM6cOcNWQhydSLGxscjPz0d+fj7MZrONeCkpKYkVLwVqnU+FZNQnwlOIxWJkZmYiMzOTlRnTqIgOfnGUlPUEtJxaXFzsU2eqKwEW4HlU4Wvk4Ao8jV4A4IcA/sYwTBRm3Jy+O/v4NgA7GYa5A8AAZgxmQQhpYRhmJ2ZIxAzgHkKI925KswhItYIQwpbOaALPvvuxs7MTSUlJHuccNBoNmpubYTabUVVVxVtgNDQ0BIvFgoKCAnYfPVU80ugnISHBK0UhdV+Wy+UYHx9HdHQ0u/zwV9mT3o3z8vL8YoRjD5qUlcvlMBgMbKNYcnIy7zuuVqtFY2MjysrKPBam8QVXgMWNUF0JsICZJLkz0neF3//+98jIyMCWLVu82d3wKRtxEFCbuN7eXigUCoe27t56OoyMjECtVuPSSy/1yDNSIBCw5VVviEGv16OxsdGni85+MApd59NOU3pH9sakBDh30S1evDhgPhH2Sdnx8XGMjY2ho6MDEomETWo6+9uo1Wo0NTWhvLzcrabFF3CXH/bDglwlNb1VaJ5vRi9AgMjBarWisbERYrHYqa27p+RAdQS0POepmSxdVnDvJHxPAmpLt2TJEr/e6ezX+VQOrdFo2DJjamoqr/2k+xjoi44LoVDIRj5UU6FQKNDQ0AAALFFQsqP7WFlZGfQLiU9Sk6/zlyPwyTnMNwQscsjPz3cpJPGEHOj6NCsrCzk5OTh+/LjH+yQQCGzGyvG9M8tkMvT29qK6utqnNbY7iMViG+szWmbs7OxEXFwc27rtiBSVSiU6OzsDvo+uwNVUFBUVsY5MlOxiY2OhVqtRU1MT8juss6Tm1NQUGIaByWTyeFhQJHLgCYZhkJqa6pKFhUIhm5dwBa5VPG1l9rRHghCCqKgojI2NwWq1IiMjA0lJSS4JghCC/v5+jI+PsxLsYIFbZiSEQKPRQC6X29yR09PTIZFIcPbsWQwNDdlUTcIBXEcmmndKTU1lK1b0GEJZ6qUQCARQq9Wsd4hYLPZYgMXHeXq+IWRqHT7VitHRUfT19dl4UXq6FqdkIpFIsHLlSrZnv62tzWnlwGq1or29HQBQU1MT0i5BhmEQHx+P+Ph49o6sUCjQ1dWFyclJCAQClJWVhZ3wikImk7F9M5S8tFrtHE0FNd8NhaR7amoKra2tqK6uZgV0ngqwIssKD+Bu/eZqWUFmh+Gq1WrU19d7feLbJx5FIhHr5UgIYUP37u5uxMbGsln39vZ2pKamoqCgIKz6D4Bzd+SpqSmIRCJkZmayZCGRSNjlRzAjHWcYGRnByMgIli1bZrM/cXFxc0q9lLATEhJYTUUwjsERMXDBV4BFbefOJ4TsduPMZNZsNqOxsRHx8fFYtmyZ1xenOw8GhmHYygEN3UdGRtDe3o6YmBgwDAOdTheyNbwzWK1WNDc3Iy4ujhV+cROCcrkcp06dgkAgYIkiFHe0wcFByOVyLFu2zKVugBIcV1OhUCgwMDDANroF6hjcEYM9uLkKLjmMj4/j5MmT551VXEiXFfbkQMVShYWFXpcLvRE2MQzD3sFo2VUul7MNVnR9HEyFoyOYTCbWco7bgwDYJgQXLlwIg8HAemTw8XjwJ6gfpadLMq51G7fRrbOzE3q9HikpKWzHpK/H4Ckx2IN+/vT0NL797W/j//7v//xqmhMOCIgICgBbGXAGnU6HtrY2touNj1U8xRdffIGLLrpozoXqrRR6dHQUg4ODqKqqmpMgo6Qhl8tZhWNGRgbvEqO/QCs2RUVFHgvH6N1NLpdjcnISCQkJSE9P97scmvpZGAwGLF261K/fj8ViYc13VSqV2wqOK/hKDBTT09O4+eab8cMf/hCbNm3y+n1wIYmg+IAbOVCreEdiKUegHZbci99bKXRPTw/ruuzoQuGGvY5KjBkZGQFf41PhUFlZmcc+A8BcPQJXDk0t5tLT0326UAgh1JsA5eXlfo+wuEsMugxUKBRobGxkBWRpaWkuPR4B/xGDRqPBrbfeirvuustXYghbhCxysFgs+Oqrr5CUlASr1Yry8nLed5pjx47ZJLm8UTxSu3ixWIySkhKvqiAajQYymQwKhcLmAvTlpLPHxMQE2traAiYcohZzcrnc6yYx+l1GR0eHxOiGCsgUCgXUajWSkpLYpCY33+EvYtBqtbj11lvxne98B9/97nfdb+AeYRk5BIwcLBaLy1KlwWDAkSNHsHjxYo+rAidOnEB5eTliYmK8Mn+ldvGZmZlz1u7eQq/XQy6X21xkGRkZbu9krsAVYAVDD2C/hKIO1/YXGRdWqxVNTU2sdVqoQftXqHtXVFQUq6egk7x8IQa9Xo/bb78dN910E77//e/7iwgj5EAxPT2NxsZGWCwWrF692uP3Pn36NIqLixEbG+txfoHaxRcXFyMtLc3jz+YDepHJZDKo1WokJycjIyPDo0Ta0NAQzp49y46lCzaowzW1mKNNYlwzGGcmLeEEnU6HwcFBDA0NITY2ll1CeaOpMBgM+M53voOrr74a9957rz8jpAg5AOes4quqqtDY2IiLL77Y4/dubGxEfn4+O1uS7x+J2sVXVFQETc1G8xQymQwqlcqtFoHmQdRqNSoqKsLCvg0AO2BHoVDAYrEgJSUFSqUSeXl5YWWNZw/uUkIsFmN8fBwKhQKTk5OIj49nIyN3BGwymbB582ZceumleOCBB/y9dLqwyMHeZJZrFU//UF988YXH5EAnNBmNRmRnZ/NuFaZzIKuqqoLmCm0PqkWQyWSsYS03T0GVmQKBwK15TSih1Wpx8uRJREdHw2w2Izk5GWlpaQH1qPAGrnIM1GKeRkYCgcDpQGOz2YwtW7agrq4OW7duDcTfJSz/0EEhB+qDQF2m6ZfrrCTpdGc47bb0bjw5OYnExES2vGh/ctLymk6nQ3l5eVidvPZ5CiolLikpCalk2xVoSXXRokVIS0uzqeCoVKqgzfd0B0+TjwaDgU1q0oHG1PTmvvvuQ2lpKR577LFAEfaFSQ46nY41H7EXiRw9ehT19fW8LlhniUe6NpbJZBgfH0dsbCxbXhQIBGhuboZEIsGiRYvC9k5MDVoSEhJgMpmg0WhCOm3bGajtf2lpqcOSKne+p0KhACFkTtt2MOBrVYIONH7rrbfw4osvIi4uDj/96U+xcePGQJnThOWJGdDeCldW8cA5rYM7cnA17p47/YlbXjxx4gR0Oh3S09ORm5sbtsRALzhugpSenFThSNfGaWlpIWuw0mg0aGxsdOkXwdjN96RNYrRtOxiE549yJTXl6ezsxC233ILvfe97eP/996FUKgPmXBWOCFjkoNVqcfz4cdTU1Dgtw9HJS876F7xVPE5PT6OlpYU9QeVyOSuUycjICJvuuenpaTQ3N2Pp0qVOVaHctbFCoQiJs7U/TFq4hMdNzEqlUr+1mvtLx2C1WvHQQw9BIBBg+/btwYjcwvLOFTByIITAYDC4vKAbGxtRVFTksJuN6/9H22P5gHZZVlZW2pAAvYvJZDLo9fqQ90vQyklVVZVHzV3U2Voul8NisfhsLecOExMTaG9v93g/XYHrGqVQKMAwjI1HhTfwJzE8+uij0Ol0+MMf/hCsJd2FRw7uzFxaWlqQk5MzJ1TzRvEIzMiwZTIZqqqqXN6NLBYLqwqcnp5GSkoKMjIyPDJJ9QVnz57FwMAAqqurfUraUWWgXC6HRqNhm6v8dRxKpRJdXV0BF2HRZKBcLoder0dqairS0tJ4H4e/iIEQgieffBIymQyvvvpqMJPXFxY5ADN/dFdob29nQ0v2A72UQp85cwZms9njhh8a7spkMkxMTCAhIQEZGRkuVYG+oL+/H0qlElVVVX7NH1itVra5ih6HL81V1KSlpqYmqA5T9k1i7rQI/iSGbdu2obe3F6+//nqwq1oXHjkYjUaXPe729vSuEo/OQGc0JCUloaioyKfQmjYlUR0CNYBJT0/3WaVIDWyMRqPfOxYdfRZtruJKiPla4I+OjmJ4eDhk6kwKey0C1YWkpaUhLi7Or8Tw/PPPo6mpCX/7299CkfSNkIM9enp6EBsbiwULFniVeNTpdGhsbERBQQEWLFjgy646BDVPkcvl7ImZkZHhcYhttVrR0tKCmJiYkDQm2asbKVHYi32AGdm2TCZDdXV1WGlCgHO6EIVCAZ1OB5PJhLKyMmRkZPhkCvT73/8eX375JXbu3BkqMoyQgz36+/shEAiQnZ3tMTFMTk6itbXV73bxzkBPTJlMZnOBucveU2ertLQ05OfnB3w/3YEmZuVyOXQ6nU2+pb+/H5OTk6isrAwbbYUj0OpJXl4eJicnMTU15dXIPkII/vjHP+Kjjz7Crl27QinauvDIwWQyuXSKHhoagl6vZ7sy+RLD2NgY+vr6UFVV5df2aL4wmUxsRKHT6dgOTPvKh8FgYMcABiKy8RXc9b1MJoNIJEJxcTHS09PDLmqgcLSUoEI42onJp9xLCMFrr72G9957D++++26oXbAj5GDzxrPryfb2dlgsFtb41VW5jGsXTy3EQw2LxcJ2YE5PT7MdmFFRUWhpaUFJSQk7yTocQU1arFYrsrOz53Rh+nNUn6/gm2PglnudTQz/61//ip07d2L//v3h4BMaIQcK+8QjFSrJZDIYjUZWrMSt3dOp0bQpKRzDXtpnMDQ0BLlcjtTUVGRnZyMtLS0s78SEELS2tiIqKmpOLkSr1bJGNlQGHUoBmbfJR3uPikOHDsFiseDYsWM4ePBguAjiIuTAR/FoNptZoqAhe2pqKnp7e5Geno78/PywlUIDMyKsnp4eVFZWsssPhUKBmJgYtucjHIbPUBdrOqHKFewFZKmpqbwGA/kL/hQ4/e///i/+/ve/Izo6GoWFhdi1a1c4EHdYntABJQeuVZw3UmiLxYKRkRF0dXXZzJxITk4OS4KgbeE1NTVzljxcSzlqG+9vSzm+sFgsaGxshFQq9ThJSvMUMpmMTQS6c4vyBf4iBgD4xz/+gRdeeAEHDhxASkoKBgcHw8WkJvxOZgSJHLxVPKpUKrS3t6O8vBzx8fHsSTk5OYmkpCRkZmaGRdcinSg+NTWFyspKtxcJt1XbbDbbhOyBJj2z2czOHc3Ozvbpvezdomi7dnp6ul+iI38Sw6FDh/Cb3/wGBw4c8GgC+cGDB/HjH/8YFosF3/ve97B161ab5/ft24dHH30UAoEAIpEIL7zwAi655BLo9XqsXr0aBoMBZrMZN998M5544gkAM05md999N/R6PUQiEU6cOLGSEHLMpwMMAAJODlyC8JddPCGEVTWqVKqAqxpdgZrPEEJQVlbmMVFRCTRdRgUyZDcajWz1JDMz06/vDYCd6SmXy33ul/AnMXz88cd44okn8P777yM9PZ33dhaLBSUlJfjwww+Rm5uL+vp6vPXWW1i6dCn7GrVazZJ6Y2MjNm3axJ4PdLiuyWTCJZdcgu3bt2PVqlW48sorcf/99+Oaa67B+++/j+uuu+4zQsjlPh1kABBQKdjAwACbjON70VDHqOnpaad28XRQLx00S1WNPT09NnbxgVa6WSwWm3W7Nxczd7o2Ddm5szz9NSPDYDDg9OnTrElLIMBt16b9EnSoDq0Y8CE9fxLDkSNH8Itf/AIHDhzwiBiAGZfz4uJiLFy4EABw2223Yd++fTbkwNW5aDQa9tjojFNg5gZgMplsnpuamgIwo9cBMOLt8QUSAb16/vCHP+DQoUNYvXo11q9fj1WrVrm8s1ssFtbivLq6mve0Kjolqbi4mLVh6+/vR1RUFDIzM/0if7aHyWRCQ0MDFixY4LdJR1zbOPsZGfHx8Wx05CnpuTNpCQSio6ORk5ODnJwcttzrboAx4F9i+OKLL/Czn/0M7733nlc6k+HhYZucRG5uLr766qs5r9u7dy8efvhhyGQyHDhwgH3cYrGgrq4OXV1duOeee7By5UoAwAsvvICrrroKP/nJT2jC/mGPdy4ICOiyApi5Y3344YfYtWsXvv76a1x88cXYsGEDvvGNb9ic5DTkzcrK8tvFRpOAVP5ME5q+1u2pbHvhwoUe3428AdWE0J6PqKgoZGRk8FrbU7ftJUuWuJ0kFgxwBxhT5y7aL6HX6/1GDMePH8ePf/xjvPfee14nHd955x0cOnQIr776KgDgL3/5C44dO4YXX3zR4euPHDmCJ598EocPH7Z5fGJiAhs2bMCLL76IiooK/OhHP8Jll12GjRs3YufOnbj11ls/IoR8y6udDCACTg5cmEwmfPLJJ9i1axe++OILrFixAuvWrUNiYiIaGhqwceNGj5JFnkCn07FEQQhhicLTk5AatARLtu0IVINA1/a058P+WOi+Bmogjq+g63K5XI6zZ89Cp9MhPz8f2dnZPgmTTp06hXvuuQd79+71aZbGl19+iccffxyHDh0CADz99NMAgIcfdn6jLyoqwvHjx+cs3Z544glIJBL85Cc/QVJSEiYmJthJ9AKBYJoQ4theK4QIavuZWCzGlVdeiSuvvBJmsxmff/45nn/+efz73//G2rVrkZubiyuuuCIgUtbY2FgUFBSgoKCAHTLb1tYGs9nMXlzuEmdcg5ZQimfi4uJQWFjIru3psZhMJrbyYTab0dHRgerq6nBQADoEXZdbrVaMjY2hrq4O09PT6OjogNFo9Gr6VlNTE37wgx9g9+7dPg/Zqa+vR2dnJ3p7e5GTk4O3334bb775ps1rurq6WH/SkydPsvstl8shFouRnJwMnU6Hw4cP46GHHgIAZGdn47PPPsPll1+Ojz/+GAA6fdrRACFkszJFIhGKioowNTWF5uZmdHV1Yffu3XjyySexZMkSrF+/HmvXrg3IiR0dHY3c3Fzk5uayQiU6yTktLQ2ZmZlznJXGxsbQ39+PZcuWhY2cGJh7LHQg8dTUFLKysmAwGBAbGxuWuhBgbo4hKSkJubm5rLJxcHCQlaXTPIWz5GxrayvuvPNO7Ny5E4sXL/Z530QiEV566SVcddVVsFgs2LJlC8rLy/HKK68AAO6++27s3r0bb7zxBsRiMWJjY/H3v/8dDMNgdHQUmzdvZtXAmzZtwvXXXw8A+OMf/4gf//jHMJvN9Eb4fZ93NgAI6rLCEaxWq80f22q14vjx49i1axf++c9/ori4GOvXr8dVV10V8NDYbDazZUWtVsuWFWlTT3V1dcgMXvlCLpejt7cXVVVVrBcC1YVQsVKodSEUfJOP9vb33AnbNNHc0dGBzZs3480330RFRUWwDsFfCEvmDjk5uILVasXp06exa9cuHDx4ELm5uVi3bh2uvfbagCfXaIadjpRfsGABMjMzg2Yl5w1GR0cxNDQ0R6FJk4DUvl8ikQSt3OsM3lYl7AcYHz9+HMPDwzh06BDeeust1NTUBG6nA4cIOfgCQgiam5uxa9cuvP/++0hLS8O6detw/fXXB6TrkTuFu7i4mL24JiYm/Ko/8BeoSYs7+znu1C3qZk0rH8FaLvmzXHn06FFs3bqVHXPw4osvsiXDeYQIOfgLtM14165d+Mc//oGEhATceOONuOGGG5Cenu7z+poatKSmpqKwsHDOZ3PvwvHx8cjMzAyJOpOiv78fKpWKl3TbHtQlilZxaHI2UElMfxLD0NAQNm3ahFdeeQWrVq3C1NQUGIZx6GYe5oiQQyBAFZW7du3Cvn37EB0djRtuuAHr1q3DggULPCYKOn0qLy8PWVlZbj/b3nOS3oWDEa7TY9dqtSgvL/c5ijEajWyJ1FnrvC/wJzGMjo7i5ptvxvbt2z2e1B6IfgkAePHFF/HSSy9BJBLhuuuuwzPPPMN3lyLkEGgQQjAwMIA9e/Zg7969IITg+uuvx/r163lNvdJqtWhsbMTixYs91lvQtfDY2BgUCoVHQiVvQAjBmTNnYLFYsGTJEr9XI7jJWWp770tHrD+JYWxsDBs3bsRvf/tbXHHFFR5tG6h+iU8++QRPPfUUDhw4gOjoaMhkMtY4mQfCkhzCO/XuIRiGQUFBAe6//37cd999GB0dxZ49e/CDH/wAOp0O119/PdatW+ewD4J6Uroa9+bus+Pj4xEfH49FixaxQqWGhgYIBAKWKPyh4SCEoK2tDSKRKCDEAMyU8RYsWMCa/46Pj2N0dBTt7e0uBxc7gj+JQaFQ4JZbbsHTTz/tMTEAgeuXePnll7F161Y2b+MBMYQtwiObFgAwDIPs7Gzce++9+Oijj7Bv3z6kpaXhf/7nf/DNb34TzzzzDDo6OkAIwalTp9DW1oaamhqviMERqFCpvr4e5eXlbEL1+PHj6Ovrg06n8+p9rVYrmpqaEBMTg8WLFwdFv0DH0y9duhSrVq1CTk4OVCoVjh8/joaGBoyOjrIT1e3hT2IYHx/HLbfcgieeeAJXXXWVV+/hqF9ieHh4zuv27t2LsrIyXHfdddixYwf7uMViQU1NDTIyMrB27Vo2+XnmzBl8/vnnWLlyJS677DIcP37cq/0LJ5xXkYMzMAyDjIwM3HXXXbjrrrugVCqxb98+/PznP0d3dzcIIXj11VcDlq2PiYlBfn4+8vPz2XU9VWdy1/Xu4ItJi7/gbHDxqVOnIBKJ2IRmdHQ0Jicn0dbW5hdimJiYwC233IKtW7fiuuuu8/p9HC2jHRHshg0bsGHDBhw5cgSPPvoo2y8hFApx+vRptl+iubkZFRUVMJvNUKlUOHr0KI4fP45Nmzahp6cnbMVnfHBBkIM9pFIptmzZAo1GgwMHDuDmm2/Gc889h76+PnzrW9/Chg0bUFVVFZAyZVRUlI2iUaFQoLu7GzqdjiWKhISEOScVNWlZsGABcnJy/L5f3oC7lFq4cCFr7NrU1ASTyQSj0YjKykqfiWFqagqbNm3C/fffjw0bNvj0Xrm5uRgcHGR/Hxoacml6s3r1anR3d0OhUNj0SyQnJ+Pyyy/HwYMHUVFRgdzcXNx0001gGAYrVqyAQCCAQqEISmNeoHBeJSQ9RXt7O4qLi9nKwvT0NA4cOIDdu3fjzJkzuOKKK7B+/XrU1dUFXM9A53fKZDKo1WqkpqYiMzMTSUlJMJvNbAUlHC3u7TE5OYmWlhZkZ2dDpVLBYDC4JD5XUKvV2LRpE+688058+9vf9nnfzGYzSkpK8NFHHyEnJwf19fV48803UV5ezr7Gvl/ihhtuwNDQEKsLof0SV155JR566CFcf/31eOWVVzAyMoInn3wSZ86cwZo1azAwMMD3WMMyvLigycEVdDodPvjgA+zevRuNjY247LLLsH79eqxcuTLgegar1cra3U9OTsJkMiEvLw+FhYVhI7pyBkdLCdonQYmP7+BirVaLW2+9Fd/5znfw3e9+12/7+P777+O+++5j+yUeeeQRm36J3/zmNzb9Es8++ywuueQSNDY2zumXeOyxxwDMlIG3bNmC06dPIyoqytNKSoQc5iv0ej3rSXHixAl84xvfwIYNG3DxxRcHVM+g0+lw+vRpZGVlQafTYWJigq0UhFOPBAWfHIP94GJnBrV6vR633347Nm7ciDvvvHNer915ICwPLkIOHsJoNLKeFF9++SVWrlyJdevWYfXq1X7VMzgyaaGGrlR0JZFIWHVmqBvCvEk+2hvUxsbGwmAwICsrCw888ACuueYa3HPPPec7MQARcjj/YDabceTIEbzzzjv4/PPPUVtbi3Xr1uGKK67wqfJBTVoqKiqcSoG57lDcuRiBsMRzB39UJWjl46233sILL7wAsViMH/3oR7jtttsC5nkZRghLcuAdlx48eBClpaUoLi7Gtm3b5jz/7LPPoqamBjU1NaioqIBQKMT4+DgAYPv27aioqEB5eTleeOEFdpvx8XGsXbsWixcvxtq1a6FSqQDM3J2/+93vorKyEtXV1fj00099O8oAQSQS4YorrsDLL7+MhoYGfO9738ORI0ewevVqbNmyBfv374dWq/XoPWkyr6qqymWPAMMwSExMRHFxMVatWoXi4mLo9XqcOnUKJ0+exNDQEIxGo6+HyGt//VGuZBgGMTEx+Ne//oW77rqLLR3KZDJ/7WoEnoIQ4uqHEEKI2WwmCxcuJN3d3cRgMJCqqirS0tJCnGH//v3km9/8JiGEkKamJlJeXk40Gg0xmUxkzZo15MyZM4QQQh588EHy9NNPE0IIefrpp8lPf/pTQgghL730Evnv//5vQgghY2NjpLa2llgsFqefF26wWCzkyy+/JP/zP/9DqqqqyE033UT+8pe/kLGxMaLRaJz+DA4Oko8++ogoFAqXr3P3o1AoSEtLC/n000/JZ599Rtra2ohSqfTpPR39jIyM+GV/NRoNmZqaIrfffjt5/PHHidVq9fg7/+CDD0hJSQlZtGgRe05x8e6775LKykpSXV1N6urqyOeff04IIUSn05H6+npSVVVFli5dSh577LE52z777LMEAJHL5Z6fDPzg7joMyQ+vyIErOY2KimIlp87w1ltv4fbbbwcAtLW1YdWqVYiLi4NIJMJll12GvXv3AphpcNm8eTMAYPPmzXj33XcBzDj6rFmzBgDYrPbXX3/tLf8FHQKBAKtWrcJvf/tbnDp1Co888ghaWlpw1VVX4fbbb8fbb79NLclZyOVydHV1YdmyZT7rAmJjY1l1ZkVFBRiGQUtLC44dO4a+vj6PoxlH8KfAyWKx4Ic//CGKiorw2GOPeZxjsFgsuOeee/DBBx+gtbUVb731FlpbW21es2bNGjQ0NOD06dPYsWMHvve97wGYcdL6+OOP2ecOHjyIo0ePstsNDg7iww8/DJnoLJTgRQ58JafATPnp4MGD2LhxIwCgoqICR44cgVKphFarxfvvv8+KUMbGxtjOx6ysLDaErK6uxr59+2A2m9Hb24sTJ07YCFfmEwQCAWpra/H000/j5MmT+NWvfoW+vj7ccMMNuPnmm/GXv/wFL730Evbv3x8QC7qYmBjk5eWhrq6ONYHp6OjAV199he7ubqjVaoeqQVfwJzFYrVbcf//9SEtLwy9/+Uuvko98bl7czlK+/RIAcP/99+OZZ565EJKic8Arxe3o5HH2Zb333nv4xje+wRqwLFmyBA899BDWrl2L+Ph4XlZrW7ZsQVtbG5YvX46CgoKAlwyDBYZhUFlZicrKSjzxxBNob2/Hww8/jGPHjqGyshIMw+CGG25AWlpaQE7GqKgodpYEHVhM1ZlSqRQZGRluzVz9TQw//elPERsbi2eeecbr0myg5kvs378fOTk5qK6u9mq/5jt4XXGeSE7ffvttdklBcccdd+COO+4AAPzsZz9j51JkZmZidHQUWVlZGB0dZTvZRCIRnn/+eXb7iy++2C+GoeEEhmEgFovBMAy6u7sxPDyMXbt24fbbb0dMTAzrSZGZmRmwrkvupC2umauz9mx/E8Ojjz4Kq9WKl156ySfNBt+blyf9EgsXLsRTTz2Ff/7zn17v13wHr78I16LbaDTi7bffxo033jjndZOTk/jss8+wbt06m8fpcoF6LVDyuPHGG/H6668DAF5//XV2O61WC41GAwD48MMPIRKJbFpqzxcUFxdjz549iI2NRXFxMbZu3Yp///vf2LFjBwgh2Lx5M66++mq89NJLGBoa8jj85ws68KeiogIrV66EVCrF6Ogojh49itbWViiVSqhUKr8RAyEEv/zlLzExMYHf//73Pou5fOmX4ILbL9Hd3Y3e3l5UV1ejsLAQQ0NDqK2txdmzZ33a1/kE3joHd5JTAHjttddw8OBBvP322zZvcumll0KpVEIsFuO5555jk41KpRKbNm3CwMAA8vPz8c477yA1NRV9fX246qqrIBAIkJOTgz/96U8oKCjw75HPAxBCMDo6it27d2PPnj0wGAysJ0VhYWHA18FkdmDx0NAQ5HI50tLSkJWV5ZMlHiEE27ZtQ19fH1577TW/SNED1S/BRWFhIb7++utAaS7CMqEREUHNExBCIJPJsHfvXuzZsweTk5O49tprsW7duoD6OtClRFVVFUwmE6vO9GZgMSEEzz33HJqbm/G3v/3Nr3mkQPRLcBEhh7mIkEOYQqlU4t1338Xu3bshk8lwzTXXYN26dX51hnKWYyB2DtZ8BhYTQvDSSy/hq6++wt///vegqzj9BUIILr30UjzyyCO45pprAAA7d+7Ejh07cPDgQW/fNkIOEQQGExMT2L9/P/bs2YP+/n6sXbsWGzZsQGVlpdfreU+Sj+4GFhNC8Mc//hEfffQRdu/eHRBPzWCiubkZt9xyC06dOsU6Qx08eBCLFi3y9i0j5OAL3DkGP/vss/jb3/4GYGYN2tbWBrlcjtTUVGzfvh1//OMfQQjBnXfeifvuuw/AzBTlxx9/HG1tbTh27BiWL1/Ovt/TTz+NP/3pTxAKhfjd737ntS1ZsDE1NYUDBw5gz549rK/A+vXrUVtby5sofKlKcAcWW61WfPrppxCLxfjXv/6FvXv3BmQOaijw05/+FBKJBBqNBgkJCXj00Ud9ebuwJAde8ulQI1Dy7dbWVtLe3k4uu+wycvz4cXb7lpYWUlVVRfR6Penp6SELFy4kZrM5sAcZAGg0GrJr1y5y++23k4qKCnLvvfeSDz/8kExNTQVFEj02NkY2b95MsrKyyMqVK8lzzz0X6q/Eb1Cr1aSkpIRUVFQQvV7v69uFXCrt6Ce8DAGcIFDy7SVLlqC0tHTO9vv27cNtt92G6OhoFBUVobi4GMeOHQvMwQUQcXFx2LhxI958800cP34cV155Jd544w1cdNFFeOCBB3DkyBGYzWb29f7UMQDAgQMH0NfXh87OTrz//vsezbB01+i3b98+VFVVoaamBsuXL8e//vUvADM+ECtWrEB1dTXKy8vxi1/8gt3mwQcfRFlZGaqqqrBhwwZMTEx4fWwSiQS33nor/vM//zOsBiv7E/OCHAIl3/bH580XUGHVG2+8gZMnT2L9+vXYtWsXLr74YvzoRz/CK6+8gp/85Cd+I4Y9e/bgz3/+M9577z1IJBKkpqZi7dq1vLYNVK/E2rVr0dzcjMbGRpSUlODpp5/26RgFAkHYGe74E/PiyIif5NtXX301L/m2J583HxEVFYWrr74ar776Kk6fPo26ujps27YNHR0deOCBB3Dw4EEYDAav3/8f//gHXn75Zezfv9+r0XSB6pW48sor2b/9qlWrMDQ05PUxXgiYF+TgD/n2yZMnceTIEaSmprqVYnuquJvPEAqF+Oqrr3Ds2DF89dVX2LJlCz799FOsXr0ad9xxB9577z2PZmwcOnQIzz33HPbv34/k5GSv9ilQsyW42LFjB1uKjMAJ3CQlwgImk4kUFRWRnp4eNiHZ3Nw853UTExMkJSWFqNVqm8fHxsYIIYT09/eT0tJSMj4+bvO8fUKyubnZJiFZVFQ0LxOSvsBisZB///vf5IEHHiBVVVVk48aN5K9//atLT4r9+/eT+vp6IpPJfPrsnTt3kjvuuIP9/Y033iD33nuv09d/9tlnZM2aNXMeV6lU5PLLLydNTU02j//qV78i69ev98o3IkAIefLR0c+8IAdCCDlw4ABZvHgxWbhwIfnVr35FCCHk5ZdfJi+//DL7mj//+c/k1ltvnbPtJZdcQpYsWUKqqqrI4cOH2cf37NlDcnJySFRUFMnIyCBXXnkl+9yvfvUrsnDhQlJSUkLef//9AB5Z+MNisZCvv/6aPPTQQ6S6upqsW7eO7Nixg4yOjrLE8MEHH5C6ujoyOjrq8+d98cUXNn+LX//61+TXv/61y20KCwsdmrE8/vjj5Nlnn2V/f+2118iqVauIRqPxeT/9iJATgaOfeUMOEYQHLBYLaWhoID//+c9JbW0tufbaa8mDDz5IqquryfDwsF8+g0+k2NnZyd75T5w4QbKzs4nVaiUymYyoVCpCCCFarZZccskl5L333iOEzLhFLVmyxOfIJgAIORE4+omQQwRew2q1kpaWFrJhwwZy+vRpv763u0hx27ZtZOnSpaS6upqsWrWKtX1raGggNTU1pLKykpSXl5MnnniCfc9FixaR3NxcUl1dTaqrq8ldd93l1332ASEnAkc/EXLgCXcehc888wx70pWXlxOBQECUSiUhhJAXXniBlJeXk6VLl5Lnn3+e3Wbnzp1k6dKlhGEYm5yHQqEgl19+OZFIJOSee+4J+LFFEHKEnAgc/UTIgQeCrdBUq9Xk888/Jy+//HKEHC4MhJwIHP3Mi1JmqBFshaZEIsEll1xy3vQhRDA/ESEHHgi2QjOCCMIB89+1NQggJLgGuxFEEA6IRA48EGyF5vmGQDRROZuWFoEf4SYpEQEJvkKT4s9//vO8T0jySeZOT0+zmoWGhgZSWlpKCJkplU5PTxNCCDEajWTFihXkyy+/JIQ4n5Y2TxHy5KOjnwg58ESwFZoFBQUkJSWFSCQSkpOT47I6Es7wVO34xRdfkLKysjmPazQasmzZMnL06FFCCCElJSVkZGSEEELIyMgIKSkp8fOeBxUhJwJHPxFyiCCgeOedd+b0STiKhvbs2UNKS0tJSkoK+eKLL9jHzWYzqa6uJhKJxCY6SEpKstk+OTnZ/zsfPIScCBz9RHIOEQQUhPAfONPe3o53333XxnKNDpwZGhrCsWPH0NzcHND9jeAcLnhyGBwcRFFREcbHxwEAKpUKRUVF6O/vD/GenR8IxMAZ4Ny0NAA209Ii8B8ueHLIy8vDD37wA9awduvWrfj+979/QQ7RCQT4TEvr6upiI4yTJ0/CaDRCKpVCLpezVm46nQ6HDx9GWVkZAOfT0iLwI9ysOy4IGI1GUllZSZ5//nmydOlSYjAYQr1LDhHM/o5//vOfpLa2llRUVJDa2lry0Ucfeb3fgWiiUigU5IorriDFxcXkiiuuYI9zniLk+QVHPyHfgXD5AXAVZqz414Z6X5zsnxBAN4CFAKIANABY6uL1NwD4ePb/FQCaAcRhRvh2GMDi2eeWACgF8CmA5ZztlwHI5mw/HOrvIPIT3J8LflnBwTUARjFzIYQjVgDoIoT0EEKMAN4G4CqWvh3AW7P/XwLgKCFESwgxA/gMwAYAIIS0EUI67DcmhJwihIzM/toCIIZhmPPTZjkCh4iQAwCGYWoArAWwCsD9DMNkhXaPHCIHALcpY2j2sTlgGCYOwNUAds8+1AxgNcMw0tnnrgWQ52hbJ9gI4BQhxHvX2QjmHS54cmBm6movA7iPEDIA4FkAvw3tXjmEo2YOZxPJbgDwb0LIODATHQD4DYAPARzEzJLE7GRb2w9lmPLZbe/ydIcjmN+44MkBwJ0ABgghH87+/gcAZQzDXBbCfXKEIdje7XMBjDh57W04t6QAABBC/kQIqSWErAYwDqDT3QcyDJMLYC+A/yKEdHu11xHMW7iblRlBmIBhGBGAMwDWABgGcBzAfxBCWuxelwSgF0AeIUTDeTyDECJjGCYfwD8BXEQIUXGe/xTATwghX8/+noyZ3MSThJDdiOCCQyRymCeYTSTeC+AQgDYAOwkhLQzD3M0wzN2cl24A8E8uMcxiN8MwrQDeA3APJQaGYTYwDDME4CIABxiGOTT7+nsBFAN4lGGY07M/EaXRBYRI5BBBBBE4RCRyiCCCCBwiQg4RRBCBQ0TIIYIIInCICDlEEEEEDhEhhwgiiMAhIuQQQQQROESEHCKIIAKH+P8BNI94wijELlQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制轨迹 3维\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(x_plt[::int(n_all/50)], y_plt[::int(n_all/50)] ,z_plt[::int(n_all/50)],color='red',label='VPA')\n",
    "#ax.plot(x_coordinates[::int(n_all/100)],y_coordinates[::int(n_all/100)],z_coordinates[::int(n_all/100)],label='neural network')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "# ax.set_title('Particle Motion in Electromagnetic Field')\n",
    "plt.show()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.plot(x_plt[::int(n_all/100)], y_plt[::int(n_all/100)] ,z_plt[::int(n_all/100)],label='classic computation')\n",
    "ax.plot(x_coordinates[::int(n_all/50)],y_coordinates[::int(n_all/50)],z_coordinates[::int(n_all/50)],label='PINN')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "# ax.set_title('Particle Motion in Electromagnetic Field')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "572d448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_prefix +'_loss.txt', 'r') as file2:\n",
    "    loss_list = [float(line.strip()) for line in file2.readlines()]\n",
    "with open(new_prefix +'_lpde.txt', 'r') as file3:\n",
    "    lpde_list = [float(line.strip()) for line in file3.readlines()]\n",
    "with open(new_prefix +'_l0.txt', 'r') as file4:\n",
    "    l0_list = [float(line.strip()) for line in file4.readlines()]\n",
    "with open(new_prefix +'_lE.txt', 'r') as file5:\n",
    "    lE_list = [float(line.strip()) for line in file5.readlines()]\n",
    "with open(new_prefix +'_loss_test.txt', 'r') as file6:\n",
    "    loss_test_list = [float(line.strip()) for line in file6.readlines()]\n",
    "with open(new_prefix +'_lossmean_test.txt', 'r') as file6:\n",
    "    lossmean_test_list = [float(line.strip()) for line in file6.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8ed937d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAGoCAYAAABbtxOxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAADPB0lEQVR4nOzdd3yTVdsH8N/J7J60dFCghUJpKYWylyCKTAERZYgTRVzI4+ZBUJShj4oo4AIRwdeFoKIgG9mrLRTKKBRa6N47OznvH2nSpE0nCWnD9f18EHrnTnJae3Jf9znXuQ7jnIMQQgghhBCiJ7B3AwghhBBCCGlJKEAmhBBCCCHEBAXIhBBCCCGEmKAAmRBCCCGEEBMUIBNCCCGEEGJCZO8G2EObNm14x44d7d0MQgghhNzB4uPjCzjnfvZuB6ntjgyQO3bsiLi4OHs3gxBCCCF3MMbYDXu3gVhGKRaEEEIIIYSYoACZEEIIIYQQExQgE0IIIYQQYoICZEIIIYQQQkxQgEwIIYQQQogJCpAJIYQQQggxcUeWeSOEEEIIacni4+MlAoHgOaFQ+CTn3BMAs3ebHAhnjJVqtdrvdDrdl71791bVPIECZEIIIYSQFkYkEq318PAYHBQUVCmRSAoZo/jYWjjnUKlU4qysrJfKyspiATxe8xxKsSCEEEIIaXmGdOjQoVQqlaopOLYuxhikUqm6Q4cOpQCGWDqHAmRCCCGEkJZHKBAIuL0b4ciqfr5Ci4/d5rYQQgghhBDSolGATAghhBBCiAkKkAkhhBBCCDFBATIhhBBCCCEmKEC2AVVGBioOHgRXq+3dFEKIDXCNBsrUVHs3gxBCHEppaanA39+/x8GDB11qPrZmzRqf8PDwKKlUGhsVFdXt5MmTzgAwY8aMDrNnz25n7bZQgGwD5Xv2Iv3ZOdApFPZuCiHEBvI++gjXx4yFOjvb3k0hhJAWa+TIkZ0GDhzYpbHnL1q0KCA6Orpy2LBhshrH27799tsh77zzTubp06cveHp6aqdPnx4GAEuXLs3atGmT38WLFyXWbDsFyLZgKFfIqToLIY6o8tRpAIC2uNjOLSGEkJbr/Pnzrj179qxszLkymYxt3LjRb/bs2QWmxxMSEpyWLVsWvGrVqhszZ84s6dGjh3LBggVZqampTklJSdLQ0FD1wIEDy1euXOlvzbZTgGwDxoLeFCAT4tA49XFCCLEoMzNTlJubK+7bt6+s4bOBLVu2eCoUCsHkyZNLTY8vX748IDQ0VDlz5swSw7HAwEANAOTm5ooAYOLEicVbt271tWLzaatpm6AAmRDHZpwlsmsrCCF3mNd/Swy5klNeKz/X1roEuMs+mhKT3pTnHD582BUABg0a1KgR5H///dc9MjJSJhaLjcc0Gg127tzpNXv27FzTc2UymQAAvL29tQAwZMiQysLCQlFCQoJTbGysVfJbHWIEmTE2nDF2mDH2FWNsuL3bA6b/sdLoEiGOiYG2fSWEkPqcPn3axcvLSxMREaFqzPk3btyQBAQEmFU3OHnypHNFRYVw9erVgS4uLr0Mf0aOHNlVLBbzyMhIJQCEhoaqAODKlStSa7W/xY4gM8bWAxgPII9z3t3k+GgAn0G/NeA6zvkH0I/jVABwApBhh+aaoxFkQgghhFhZU0dx7enMmTOuUVFRjUqv0Gg0UCgUAg8PD7MA+cKFC04AcOzYsYtSqdQYVM2fPz8oKytL4uTkxAHAxcWFA4BcLrfawG+LDZABbACwGsBGwwHGmBDAGgAjoQ+ETzPGtgE4zDk/yBhrC2AFgEduf3NN0CI9Qu4M1McJIcSipKQkl6lTpxbW9fj48ePDgoKCVKdPn3YbPHhwua+vr6akpMQsLi0tLRW6urrqevfubUyb0Gg0OHXqlPvcuXNzDMfy8vKEAODv72+1+rotNsWCc34IQFGNw/0ApHDOr3POVQB+BjCRc66rerwYgMXhdcbYbMZYHGMsLj8/32btrnoz/d908STEMTFKsSCEkLqkpaWJ8/PzxX379q0z//jSpUvOEomEnzlz5vLq1asze/XqJbty5Yqz6Tl+fn4ahULB5HK58UN3xYoVfjqdDi+99JKx2kV8fLyLUCjEwIEDGzVi3RgtNkCuQzAA0+mFDADBjLHJjLGvAWyCftS5Fs75N5zzPpzzPn5+fjZtJFWxIIQQQsid6siRI64A4Orqqjt9+rST6R9DwFtUVCT6+OOPswzPmTBhQmlmZqYkJSXFuEpvzJgx5VKplM+bNy84OTlZ8tlnn/kuWbIkeO3atakeHh6GwVHs37/fPTY2tsLHx0cHK2nJKRaWWBq24ZzzrQC23u7G1KkqQKZFeoQQQgi508TFxbkAwJQpU8JNjwuFQpSUlCScPXvWOTo6WmbIIQaA2NhYRb9+/crXrVvn+8EHH+QAQNu2bbVr1669/uabb4Zs2LDBPyoqSrZ58+aUUaNGVRiep9PpsHXrVp9FixZlWvN7aG0jyBkAQky+bgcgq45z7aeqigWVgCLE0VEnJ4SQmlauXJnFOY+v+Uej0cS7ubnxhIQEZ0sL+BYvXpy1fv16//LycmN8OmPGjNL09PQkpVKZkJCQcNk0OAaA9evXe7u6umpnzZpVMy33lrS2APk0gHDGWChjTAJgGoBtdm5TbcZFelYb6SeEtCSURkUIIc12/vx55x49eshrHh89enTFG2+8kZWcnNzobaOVSiVbt25dmkhk3aSIFptiwRj7CcBwAG0YYxkA3uGcf8sYexHALujLvK3nnF+wYzMto4snIY6NFukRQkizrV27ts6SvK+99lpBXY9Z8sILL1h15NigxQbInPPpdRzfAWDHbW5Ok5y4XoSOACoUanjbuzGEEKsrV6ghBqBQa+Hc4NmEEEJam9aWYtEqqHX6kWOdjkaQCXFE2aX6kpyZxVarKEQIIaQFoQDZBqjMGyGEEEJI60UBsi1UVbHgtEiPEEIIIaTVoQDZFgRVdZC1NIJMiCOjSSJCCHFMFCDbgCHFglONVEIcEqc0KkIIcWgUINuAIUDW6SjFghDHZCx2btdWEEIIsQ0KkG3BcO2k+JgQh0YDyIQQ4pgoQLYFWqRHCCGEENJqUYBsA8ZNtmh4iRCHxqmPE0KIQ6IA2RYE+h+rTksjyIQ4JNpqmhBCbKa0tFTg7+/f4+DBgy41H1uzZo1PeHh4lFQqjY2Kiup28uRJ44amM2bM6DB79ux21mgDBcg2QFUsCLkz0AAyIYTUbeTIkZ0GDhzYpanPW7RoUUB0dHTlsGHDZDWOt3377bdD3nnnnczTp09f8PT01E6fPj3M8PjSpUuzNm3a5Hfx4kXJrbadAmRbMATItNU0IQ6O+jghhNTl/Pnzrj179qxsynNkMhnbuHGj3+zZswtMjyckJDgtW7YseNWqVTdmzpxZ0qNHD+WCBQuyUlNTnZKSkqQAEBoaqh44cGD5ypUr/W+17RQg24BxBJmGlwhxSJzWGRBCSL0yMzNFubm54r59+8oaPrvali1bPBUKhWDy5MmlpseXL18eEBoaqpw5c2aJ4VhgYKAGAHJzc0WGYxMnTizeunWr7y02nwJkm6AAmRAHRznIhBBSn8OHD7sCwKBBg5o0gvzvv/+6R0ZGysRisfGYRqPBzp07vSZMmFBkeq5MJhMAgLe3t9ZwbMiQIZWFhYWihIQEp1tpv6jhU0hTMUqxIOSOQPfAhJDb6o8XQpB3sdbCNZvzj5Rh0pr0pjzl9OnTLl5eXpqIiAiVpcdXrFjRZtmyZcFt2rRRG459+eWXaTdu3JAEBASoTc89efKkc0VFhXD16tWBX375ZYDhOOccYrGYR0ZGKg3HQkNDVQBw5coVaWxsrKIpbTZFAbItVFWxoACZEEIIIXeiM2fOuEZFRdWZXnHu3DnnN998M/P11183yzVeuHChwMPDwyxAvnDhghMAHDt27KJUKjUGV/Pnzw/KysqSODk5GY+5uLhwAJDL5beUJUEBsk1UTb/SRiGEODbq44SQ26mJo7j2lJSU5DJ16tTCuh6/ePGiy2OPPVZU87ivr6+mpKTELD4tLS0Vurq66nr37m0cEdZoNDh16pT73Llzc0zPzcvLEwKAv7+/WZDdVJSDbANVG+nRCDIhjorqIBNCSJ3S0tLE+fn54r59+9aZf3z16lWnOXPmdIiIiIiMiIiIXLJkiT8A9OrVS3blyhVn03P9/Pw0CoWCyeVy44fvihUr/HQ6HV566SWzEej4+HgXoVCIgQMHNmlxYE00gmwDzLDVNJWAIsShUQ4yIYTUduTIEVcAcHV11Z0+fdpssVx0dLQyMzNT5OXlpbly5crFms+dMGFC6eLFi9ulpKSIO3furAaAMWPGlEulUj5v3rzgV155JW/nzp3uS5YsCd64ceM1Dw8Ps6m8/fv3u8fGxlb4+Pjc0hQfBcg2YFikp9PR9CshDo0iZEIIqSUuLs4FAKZMmRJuelwoFKKkpCQhLi7OJSwszOICutjYWEW/fv3K161b5/vBBx/kAEDbtm21a9euvf7mm2+GbNiwwT8qKkq2efPmlFGjRlWYPlen02Hr1q0+ixYtyrzV74FSLGyBUpAJcWjckGJBATIhhNSycuXKLM55fM0/Go0m3s3NjScmJjqHh4cr63r+4sWLs9avX+9fXl5ujFNnzJhRmp6enqRUKhMSEhIu1wyOAWD9+vXerq6u2lmzZtXKbW4qCpBtQWD4sVKETIhjowCZEEKaKikpyXnr1q0+hvzjiIiIyJycHKHh8dGjR1e88cYbWcnJyU3aMlqpVLJ169aliUS3niBBKRY2YEixgJYCZEIcGc0SEUJI023bti21oXNee+21gobOqemFF1645ZFjAxpBtoHqRXqEEEdUvdM0RciEEOKIKEC2AUOZN1qkR4hj4qAcZEIIcWQUINsEXTwJuSNQFyeEEIdEAbINMIE+QKaNQghxUIxK1RBCiCOjANkWqqpYcBpBJsSh0U0wIYQ4JgqQbYDBMIJMo0uEOCTjZqcUIBNCiCOiANkGDCkWdO0kxLHRLBEhhDgmCpBtoSo/kUpAEeLgKEAmhBCHRAGyDRg2CqH8REIcG6NpIkIIcUgUINuAMUCmiychDslYB5kmiQghxCFRgGwLVOaNEIdGO+kRQohjowDZBoxbTVN+4h2jZOvvyPt0pb2bQW4TzmgzoDtN6d/bkfu/j+zdDELuKKWlpQJ/f/8eBw8edKn52Jo1a3zCw8OjpFJpbFRUVLeTJ086Gx6bMWNGh9mzZ7e7lfemANkWDFUsqMzbHSP7v/9F4ddf27sZ5Haj+PiOkfXaayhav97ezSCkVRk5cmSngQMHdmnu8xctWhQQHR1dOWzYMFmN423ffvvtkHfeeSfz9OnTFzw9PbXTp08PMzy+dOnSrE2bNvldvHhR0tz3pgDZBhhtNX3H4lqtvZtAbiNKsbjz6JRKezeBkFbj/Pnzrj179qxsznNlMhnbuHGj3+zZswtMjyckJDgtW7YseNWqVTdmzpxZ0qNHD+WCBQuyUlNTnZKSkqQAEBoaqh44cGD5ypUr/ZvbdgqQbUBgyEFuAQFy+f79uBTRDaqbN+3dlDuCtqjI3k0gt4PxHtj+fbzyxAlciugGRfIVezfljqDJz7d3EwhpFTIzM0W5ubnivn37yho+u7YtW7Z4KhQKweTJk0tNjy9fvjwgNDRUOXPmzBLDscDAQA0A5ObmigzHJk6cWLx161bfZjafAmSbsHOZN21FBfLXrAHXalH6118AAEVSkl3acqdR5+XZuwnktrBvH9fJ5chftRpcpUL57t0AAFncabu05Y4hFgMANLm5dm4IIa3D4cOHXQFg0KBBzRpB/vfff90jIyNl4qq+BwAajQY7d+70mjBhgtlolEwmEwCAt7e3cRp3yJAhlYWFhaKEhASn5ry/qOFTSFMZy7zZaXQp7+OPUfLzL5CGhtrl/e9ETCoFVyr1F8+oKHs3h9wm9irlWPD11yj86muI2jR7cIQ0kcjHB5rcXKhzcuzdFHIHW3h0YUhKcUqtBWu21tm7s+z9we+nN+U5p0+fdvHy8tJERESoLD2+f/9+1z/++MPz888/z7L0+I0bNyQBAQFq02MnT550rqioEK5evTrwyy+/DDAc55xDLBbzyMhIYw5UaGioCgCuXLkijY2NVTSl7QAFyLYhsG8VC12lfjZDp7L4O0lsQBwUBFVqKlSpafZuCrmNmL1GkGVVfVxB+bC3izgwEJrcXKjS0uzdFEJahTNnzrhGRUXVmV4xYsSIyhEjRtQ5uqxQKAQeHh5mAfKFCxecAODYsWMXpVKp8QN4/vz5QVlZWRInJyfjMRcXFw4Acrm8WdkSFCDbgGEEuTlVLLhKheKffoL3jBlgJtMKTWtA855Gmk/g6goAUKak2Lkl5La4he3kuVaL4h9+gNe0aRBIpc18e+rktxsT6S+X1MeJPTV1FNeekpKSXKZOnVpY1+Pjx48PmzNnTn50dLRizpw5IWlpaU4KhYKtXr36xrhx4yp8fX01JSUlZnFqaWmp0NXVVde7d2/jiLBGo8GpU6fc586daza9k5eXJwQAf39/syC7sSgH2QaYsOrH2ozRpeJffkXu8g9QtHHTrbeDLqK3DddoAADKa9ea9LyKo0cpb7kVMvRsrm16Hy/bvh25yz9AwZovbr0h1MVvG0MfV6U0rY9XnjgBdXa2LZpESIuVlpYmzs/PF/ft27fOEeLLly879+rVSz5q1KjwadOmFV26dOnihQsXLg4YMEAOAL169ZJduXLF2fQ5fn5+GoVCweRyufHTb8WKFX46nQ4vvfSSWbWL+Ph4F6FQiIEDBzZrkSAFyDbAhPobnuaU/OIq/ZSppqCggTMb8VotYIX9HUNruHimNPrnzjlH+qyncWP6DABA5utvoPzAAZs1kVgPr0qjQnP6uFr/u6Kxxo0RdfHbxvB5rkxLA1c3bkCKc46bTzyJ6xMmAgCyFixA2c5dNmsjIS3FkSNHXAHA1dVVd/r0aSfTP4YAVy6XC/bs2ePWqVMnxeOPP14C6NMifH19tQAwYcKE0szMTElKSopxOn3MmDHlUqmUz5s3Lzg5OVny2Wef+S5ZsiR47dq1qR4eHmZTevv373ePjY2t8PHxaVY9TgqQbaFqBJnrmn7xZE76xZY6hbzBc1U3b1r8sKWRY3Pl//6LnGXLbPoehqBHJ5M1OvDJ++ADAIA6MxNcq0XZX38h47nnbdZGYj2cGWaJmt7HBc6GPt7wmhF1ZiZKt2+38Aj1cVOVx44he/Fim76HYQQZajXUmZmNek7hV18BAHTl5QCA0i1bkTlvni2aR0iLEhcX5wIAU6ZMCe/Xr1+U4c/AgQOjNBoN4uPjnTt37iw/d+6cS58+fSyOMsfGxir69etXvm7dOuNq5LZt22rXrl17fceOHV49evTo/v333/tt3rw5ZdKkSeWmz9XpdNi6davPrFmzml2XkQJkG2C3MLokqAqQubzhi2fqpAdu6cM289XXcCmiW7Of31pkzHkOxRs32XREnWu1EHp6AgDUmRYX5NZS9P3G6ufT5gOtiiFA5s1YZ8Ak+o2duLzhm+C0R2Yi69XXqoOzJspe9M4d0cdvPjULJT/93OyfU6NoNBB6eQEA1FmN6+PFP/1s/HdzflcIaa1WrlyZxTmPr/lHo9HEu7m58YSEBOeoqCh5QECA+sKFC8Y0iszMTLOc48WLF2etX7/ev7y83BivzpgxozQ9PT1JqVQmJCQkXB41alRFzfdfv369t6urq3bWrFnN3pyAAmQbMCzmaNZW0wIhADRqhMKwkp3XqFZhKRC0dKzM4siU4+KyZqUhNe61NRqI27cH0PiLpynanat14YZZGk0zUiyqgjh1VsN9XFNVUkxX63e3cTd7Jb/+2qS2tXba0tKGT2qm5vRx035d83OakDvZ+fPnnXv06CF/7rnnCktKSoSdOnWKioiIiNy1a5e76XmjR4+ueOONN7KSk5ObtGW0Uqlk69atSxOJml+LgqpY2IBhkR7XNn00w/Ahqrh8udHP0clkEEos/O6YLhK05chKK6EpLoakqtqE9V9cA0lICBTnzzd48bR4A0MBcqtizEFuRoqFoY8rrza+GoJOJoPQw6PJ72V8T52uembLAQlcXaGrrIS2qAgiX9vUhuZaLcTBQVAkJTW6j3OTNBqzfzv4/w9CGrJ27doMw7/37t1b78rX1157rcmLsl544YVb3taWeqgtVI0CQ9u8Mm+APmdNW17ewNl6mvx8qG7cMH5tyEEu/PZbaAv0FVZyFr8HVbrl6jCOPvVnmBZVXb/e6OdUHjvWpDrSXKOBwNMDEIuRv2IF8tesQcXhI1Dn5aHg628gP3cOgD5Iv9wtEpe7RZo9P23adOO/G5ObSuyrOge5+X0caPxiXE1BIZTXU02OVPdxTaH+OpD7/pI6a/RyB/+dEvn7A0CNn1H9Kk+cgK4RaS4GXKOGwMkZQg8PFHzxJfJXrUbFoUNQ5+ah8Nv1kMXHA9DvZGro46Y3vmlVi3EB2450E0KswyFGkBlj3QC8DKANgH2c8y/t2h5jikXzR5cAoPLYcXiMug/qzEyUH/gXAjdX/agDE5jl2l2/fwIAwOepp6AtK0XliZMAANW1a1BVlR3TyWS4NvI+RCSdr26f4T0VCjCX274xz20jjYiA7MQJlGzeDNehQxtcxKi4cgU3n5oFr+nTEPjOOwD0QWvlsWMQenqi4vBh6MrK4BTdAy59ekMcHAxteTmE7h4I/vADZL29EAWrVpu9Zv6nAIRCCL29Lb6nxmR3Ll1lpTEXnbRMxhSLZqwzML3xqjx6FJ4TJ0Kdm4fy3bshcHer7uMmM1BpU6YAALwfexQ6mQzyM2f1b19QgPJd1Qt1r40eg4jz52rVUNcpFBA4ch/v3Amq1FSU/PYb3O8b2WAfV2dm4uYTT8Jj3DgEf/IxAP3/l8rDhyH08kLlsePQFBXCOboHnHv1hDQ0FLrSMgg93BG45H1kvfkWCtassfja4pAQi8dVqdXBu65SBtTxWUAIaRlabIDMGFsPYDyAPM55d5PjowF8BkAIYB3n/APO+SUAcxhjAgBr7dJgE4apM96EEeT8L76AyMcHqvSbAAChry9yP/wA8oR4yBLOQHH+fIOvUbR+PQRubvWOCF/uHg2Rvz8C3llkPKZTKh364mkIFsr37MW1e+6F67C74HbXXXDp0wdC9+p0J3VODgQuLlBn6Gd+Sn76GcqLl6CtrIA6I9PCKNxPELi6wrlPb0CjgcjfHx5jx8Jj7Fhoy8qguHgJyuTLkMUnQJV6HcqrKdA2YsRQV1EB2GiamFhHc1IsCr5Zq//9MvRxb2/kfbIC8gsXoDifBPmZMw2+RvHGTcZNaepyOboHhL6+CFj4dnV7HXwE2TCiXnn4MFJG3AO3oUPhNqyqj1ctngUAdW4eBFKJccatbPt2qLOyoC0rgyYnB7pK88X0JT/9DObsDLdhw6CrrITIzw/u996LrvFx0JaXQ3HpEpSXL0N+NhGKK8lQpVyDuo6ZOlO6ylprigghLUyLDZABbACwGoBxqT9jTAhgDYCRADIAnGaMbeOcX2SMTQDwVtVz7EogNKRYaHHzqaegzs1Dp+1/13k+5xwFn68yOxa8YgVyl7yPks2/gWs08Bg7Bn7/+Q+g0+kDYM4hbtsWEIn0AblIBK5Wg4nFZqMn2opKVPz7L7Jeew0AIGzTBpq8PGS+/kb1+8vlNh3NUGVkomL/Pvg89pjN3qM+XKWCc+/e8Bw/DuX79qP0z20o+elngDFIO3cGE4shCgpExd59ELi4wHXwIACAwN0d8sRESDp3gktsLzBnF3hOnAAwBpdevVB5/DhKfvkVlQcPAQCk4eHG9xR6eMB1QH+4DugPn8cfNx5XZWSCifX/ryqPHEXptm2QJySYtVdbQRfPls4wgsy1OqS/+CIUFy4i/MD+ep+Tv2KF2dfBK1cid9kylG7ZCq7Vwm3ECLSd/1Z1H9fpIGrbVt+nq/o41GqgRh/XyWSoOHIEmXNfBgAI/dpAm1+ArDffqj7HxgGyOjcPZX//DZ+nnrRLmUmuUsEpMhLeM6ajbPdulG3frl+gyBgkncIgkDpBFBiAir37AJEIHveNBAAwqRTyM2cgCQ2FU49oCKRO8Jz8AADAJTYWslOnUPzrZpTv3AmgRh93d4drv35w7dcPMPloU2dlAQIBuEaLymNHUfbPP5AdP2HWXh31cUJaPNaSN5NgjHUE8LdhBJkxNhDAu5zzUVVfzwcAzvlyk+ds55yPs/BaswHMBoD27dv3vmGSs2ttSVeyIJxwD4offw7e3+uzPbpdvlTn+VytxuXoHpCEhkIa0RXud98NzwkTbNY++blzyPtkBWQn9akYHX/7Dc7do6z6HmnTZ8Bz4gR4T5uGa+PGQ3XtGsKPHrHZApp62zLjETCpBB2++w6AfipVHheHyhMnoUg6D215BdQ52dDmV4/uMhcX/ShRcTFEPj71vr6muBiavDw4de3arPap0tJQcewYFImJKP1zGwBA3KE9XPv1h/cjMyBuFwKhm37UUJOfDwiFDbaJ2NavD81G9PnDKHj4CbT5dQOA+vs4AFyK6AZxSAicukfBbcgQeD34oM3ap7h0Cbn/+58xMOvwwya49Olj1fe4+dRTcL3rLvg+8QTSZjwCeUICwv7ZAWloqFXfp3FtmQWdTIaOP/8EQB8wyxISUHniBBRJF6AtLYUmJ0fffwwYQ8TFC9CWlEDo5VVvYK8tKYE6OxvSiIhm3QCo0tNRefQo5OfPo3TLVgD6Pu7SKxY+jz0KcUiIcTZLU1gIcA5RmzZNfh/S+jDG4jnnFjtnYmJiWkxMzK3vGkbqlZiY2CYmJqZjzeMteQTZkmAApvNXGQD6M8aGA5gMQApgh6Uncs6/AfANAPTp08e2dwWCpi3gMezK5PXgZPg+/bStWmXk3KMHOny/AYrkZKROnAT1zRtWD5DlZ85AfuYMvKdNg7a4GADAm1ESyxq4Wg2BW/W0tEAigeugQXAdNKjWucqUFJTv3QtJWBgYY40KREXe3hDdwgi8pGNH+HTsCP7ww+A6jrK//oL6xk2U3LiJks2bzc5lLi7gMhkiLl6gVfB2xJvax6vO85wwAX4vvWirZhk5deuGDt99B9WNG7g2ajRUN25aPUCuPHYclceOw/eJJ6oXndlpwa9h9syASSRwHTAArgMG1DpXmZqK8l27IQ5pp+/jjei7Qi8v42Lf5pCEhEAybRq8Hn4YgH7DEPWNmyi9cROlf/xhdq7A3R268nJEnEs01swmhNx+re0Ka+nWnXPO/+Wcz+WcP8s5t7xy4jZioqZtFGJccHcL9fqaQ1JV0zPzlVetWqOzrm1YubL+aV7OOXKWLoOsRspBcyiSk5Hctx/UWVlVF8/GXWiknTujzZw58LjvvltuQ1MxkQjBH/0P3S5fQtfEswjbsR1eDz1kdo6hlnPJli0OX32kVWhsgFzVx2sunrM1cXAwACB7wQLbplkYypo14iY4938fofLEiQbPa4gyNRXJffpCVbX1c2N/ttLQULSZ8yw8x9WaaLQ5JhAgaOlSfR8/l4iwf3bAe8b06kEVVO+6V/zzz8btrQkht19rC5AzAJguEW4HoOm7MtgYE+oDXdbIBTzGi6fo9l48Bc7GzWuQ3KcvSrdtq24T5yjdtq3WopWayvfvr1Vaqa4Lsa6B3QHzV36G4k2bcOPRW89VLt22DbrycqSMuAfKy5fNFuO1BgKpFNKwMAS+/x66Xb6EzocOmj2es3ARLkdGIeW+UVBlZIJzDq7RNPj/i1hZY2udV900MvHtvQk2rViTHNsbxTVmJEq3b4e2rKze16g4dAjKq1fNjtV1Q93QTXDB2rUoWr8eN594st7zGqNi3z7oKipwbfQYyM+eheAW6kTbg0AigTQ0FAGLFqHbxQsIP37M7PHcZctxOao7rg6/G8rUVH0f12qpjxNym7S2FIvTAMIZY6EAMgFMAzCj/qfcfkykX6RnaYSPq9WAUGg2Pc7VhgD59v/vCN26BaXb/kLRhg0o27nLmPssj4tD1htvwmvaVAS++26dz894/gUA1fmX8rNnkffZZ2bnaIv0dVq5ou6ao1yjQeHXX1c9QQtF8hU4de3S3G8Lko4dzb4Wt7dceqm1EPv7G3/GZTt3Ifudd6ArLYX65k1cu/des3Nd+vWD18MPQ+TjDebkDKG3Fwq++BJcoUD5nj1ot2Y13O+5hzYruAXGqSxLfVyjAQQC8z6usWMf//NPlP7xB4q++w7l//wD76pZCUXyFWS9+ho8xo5BcI0FhKbSZz8LwKSPX7iA/M8/NzvHUGO8vptgzjnyP6l+H3nShVtK7TKMjhtIQto1+7VaApG3t/FnXH7gALL/uwDa4mJocnJwfcxYs3OdY2Lg/eijEHp6QuDmCpGPD/LXrAE0WpTt2IHgT1fAY8wY6uOE3IIWGyAzxn4CMBxAG8ZYBoB3OOffMsZeBLAL+jJv6znnF+zYTIsETAANmMWNQi5H94DXQw8h8P33jMe4cXTp9o4gA4BTZCScIiOhuHwZFVWjwdKwUKhz8wAA2uKSOp9bcxRJJ5ebbXgB6BewGWQvegehv2+1+IFdc1OU7LffRuhm62yT63rXUHhOmGiV12oJPEaPgsfoUQCArDffNC7sM5CdOgXZqVN1Pj/jhRchDg6G0NMTHX/9RX/DZofKA62aYXGzSR/nnIMxhsvdo+ExdiyCV3xS/Zid0qgAwKlrFzi9+QZUN27o+/jVq5CGh0NToF+wpqnaTMiSmou4dSoV0h6cYn7MZBvs7AUL0GnnPxZvBGqWmsucNw+d9+5p8vdjfD2TdA7XQYPgOXlys1+rpXG/+264V40oZy96p9aW4fLERMgTE+t8fuZ/XkHex59A4OKM0C1balU+IYQ0rMUGyJzz6XUc34E6FuK1FIwBWiYwm37lnBtzkks2bzYLkKGxz/SrKXFwEADg+tix8Jn1FCTt9KMxpovbairff8D478xXXoUqM6PWOelz5hj/rUxORt6H/9OXsqrBUPYocMn7yH57IdTZ2Sj980+U7tgBLldAW1qKkC/WmI0aqW7cgLa4GE4xMQBgdgEwBO/2qpxxuwR9+CECP/gA4Bzlu3ejZOtWVB46bPFct+HDIQ4OhiYvD+V79kCdmYnL3aMBxuD3yn+gvHIVTCBA4AfL6WLaAONPxyRHlKtUYFIpAOhH8SwEyLc7jcqUODAQgH5jIZ/HH4dTZDcAgMDNrc7nVB6tnvbPfPU1qLOza52TPuc547/VGRnIfucdBC1dWus8Qx9v+/bbyF2yBNqyMpT88QfKd++BTiaDpiAfIWvWQNKhg/E5qowMaPLy4dwzBmDMYh/vtHcvJO3MR5MdSeB7ixGw+F19H9+3D6VbtqLi338tnut611BI2oVAU1CA8t27AQCXe+g/H/3mzYPqxg3oFHIEf/IJjSwT0oAWGyC3ZgyAjjGIM6pLyWlycsDq2B3NntOvBm3feAPOMTEo3bIVRd+uNx4XuFgOkFU3byJz3jzj12U7dujrCnfrho4//h+uDhsOXVkZFIn6LZaDP/8MmXNfhjo31+LrGRamCDw9EfzZZ8j+73/N6rgCQPHmzWjz3HNIfWAymEQC5eXLxscknTuh09/Vtaa5quqmw06rwFUaHSSi23MBYowBjMFj9Gh4jB5tPK6Ty8GEQos/A51KhaxXX0X5nr1Ajanv0j//NP7b97k5YCIR2jz3HMAYNNnZEAUGUgBdRVxUXTZMnZkFcUBbi+fZM43KwG/ey3CK7IaSrb+j6PvvjcfruglW5+Yi3aSqTtn27YBAAEmnTuj4yy9InTAB6qws42xFu9WrkPHiS9BUzT7VpC3XB8hCTw+0+/ILZL3xJrLfmm92TvGPP8H/9deQ+uAUQKeF8mqK8TFxu3botGe38XePq/UBMpPY56bDLn185Eh4jBxpPK5TKACBAAILfZxrNMh64039ZzOA/JUrjY9d/men8d9tnn8OnHP4vfACIBBAk5urr79NATS5DUpLSwXh4eHdN2/enDJs2DDjdNSaNWt8Vq5cGXjz5k1p586d5evXr0/r37+/HABmzJjRwc3NTfvNN9/UHpWzIgqQbYAxQMcEcIurHn1JuXsEpBERFs+35/SrgdDTE94PPwzn6GikPlA9VVnXDlyaqkDXdehQuA7oD7cRIyBq0wYCZ2cwkQhdjhyGMjUVJb9tgceYMXCJ7YW8Du2hzra8ptJ48XR3h+uAAXAfcTfKduyAtrQU3tOn43J0DxR+9TWg0RjzHQF9ioji4kWoUq4h46W58H16FpxjYoyjS7c7QM4vV2LG2hO4mqf/fiIC3PHk4I6Y2DMYTmLhbW2L6SLMWo9JJGi3Sr85jU4uR/n+/ch69bVa5xV++RUA1No6W9y+PcL+/gtMKIQ6PR1MIrnDAmd96oHn6SPGI9fHjq27j9s5mAP0fcvrwQfhHBtrntNaR9FLTZ4++Hfp2xduw4fBbdgwiAICIJBKwcRidNq1E6q0NJT89hvcRtwD1/79IO3aFZq8PGO6iSldRdVNsJsb3O++G12OH0PZzl3Q5OXB57FHkdy3H4q+/x7MyQnK5GTj86Th4VBevQp1RgYynn8Bvk89CZe+fY193FJwaEslMhVmfnsSSZn6xY2d/d3w5OCOeKBXMFwkt/czvL4t6ZlIhOAVnyB4xSfQKRSoOHTIuJmMqYIv9LX6DX3dQOTvr0+XcXKC6sYNCKTSO6yPE2sYOXJkp4qKCuHx48evWHp80aJFAdHR0ZWmwfGiRYvarlq1KmDVqlU3evToIZ8zZ06H6dOnh12/fv0CACxdujQrMjKy+7x58/IiIyOtV4KrBgqQbYAxBrlICmet/v+buF07iAMDITt92niOtqISTCwCq9oBD7BPDnJN0q5d4TpoECqP6YP7ks2b4dyzJ0Rt20KTmwNRQACcY3oaV777zXsZzlG1F9owiQROXbsiYMF/jcfUN25CfeMmijZuhMf995vVH62+eOqrTTCxGJ4Tq/OGnfv0hjwuHoXrvgUAdDlxHAIXFzCJBCW//YbstxeifM8elO/Zg66JZ+32M/3q4DVczatAGzcppCIBLueU480t5/HmFv1W4R9N6YGH+rSsBYMCZ2d4jhsHz3HjID+fhOIfftDfWAgE0JaVotxktMlAffMm8ld+Bvm5RMjj4gHob7I8J0+GuF0wxEFB4Co1mFgE9xEj6nxvVXq6cZS7NW2MwGrk5grc3ODco4ex3wBVfVwk1P8OtoBZIgNJx45wH3mvfvYAQNlff8GldywkHUOhzkiHKCAQzjE9oC3T1zb2m/cyXHr3rvU6TCyGNDwcbedXjwKrMzOhq6hA4ddfVy0Ura4jblhnYKgow0QieI6vLrXm0qcPKg8fNi7W7XzwIETeXmASCUr/+htZr7+OigMHUHHgALqeSbBbH193OBVJmWXwdhHDw1mMlLwKLPg9CQt+TwIAvDcxCo8O6NCiAkmBkxM87rsPHpcvQXH5Moq+3wgIBWBCEbhSWasWMwBo8vKQ+7//QZ2Ricoj+htBJhbD5/HHIAoIhKitv/75ajU8RtVdFlOdmakfNRKJIPb3t9W3SFqo8+fPuz7wwAMWFzrIZDK2ceNGv6+++irNcCwhIcFp2bJlwRs2bLg+c+bMEgBYsGBB1vjx47smJSVJu3fvrgwNDVUPHDiwfOXKlf62HEW2/6e1A2IAip3c4aPUXxDcRtwNSXCwWYB8papoP5NK4fWgfsTWnvmJBkwgQPv1+iD05tPPoPLIEWQvWGB2jsjf31gVQujp2eT3yF22HLnLlpvtPFZ98bScD9lu1SoUrlsHgbMLpOHhZkX7pZ07m51b/ONP+lJIhm24bUir48gtU2DJ9osY2KkNjlwtwPCuftjwZD8AwNXccqQWVGL2Jn0Q+fpv5/D6b/q0k69mxmJ090Cbtq+pnKO7w/nDD4xfc50ORTExELp7QJF8GUIPTzhFRiLj+edRtH692XO1paUoqtqt0FTQhx8g+93FCFq2FB5jxhiP5yxbhuKNm4xfB3+6Aq6DB0Po4QGdSoWSn3+G66BBkHbuDM45tAUFEPn52eC7brqaoY/b3XfrAzyTANnYxyUSeE2dqj/YAgJkxphx9iDj5Xko37ULOe8uNjtH6OMDaVUVGWETyqcZ8ozzV36G/JWfIeLSRWOgqKuaJRLUUXIx+OOPUPjten3g3SkM4rbVwZS0cyezc4s2bKgOkG08gqzVcRRWKLFk+yX0aOeJwykF6B/qg1+eHQgASMmrwM2iSjy1IQ4AsOjPC1j0p37t+MqpPTGpV8vKj3aKiEDQ8mXGrznncIqMhMDdHcrLlyBwdYVzbG+kP/00Sn7+xey5XK02DlKY0i1fjtz330fbRQvhNWmS8XjeZ5+ZjUwHffwxXAcPgsjbG1ytRvFPP8FlwADjFt4tqY+TW5eZmSnKzc0V9+3bV2bp8S1btngqFArB5MmTSw3Hli9fHhAaGqo0BMcAEBgYqAGA3NxcUffu3ZUAMHHixOL333+/HQXIrQxjDLkuPuhUqk8nkLRrB+9p0+AUFQVNYRHkCQmoOHQIqvR0cKUSxT/+pM/ta2Flivxffx05FRUQBQbAOSYGbkOGIHfZclQeO6bfWjk6ukkjAr5PzzL7cFVev46SLVvMc57ruHiKvL3R9vXXLT7m3LMnOmzaiLLde1C8aRPyPvzQ+FhhhRK+btJGt9FAptJAIhRAJKwdYGeVyLHnYi4KK1X4fF91fdgd53PgJBZgaHj1SGh4W3eEt3XHhcWj8OKPCcgskeNKrj5QmPND9YYor4/qihfu1geCcrX2tk/V1oUJBPB94gmzY9qyMki7doVOLofPIzPg9dBD+unbef+x+BqGXPLM/7yC8r370GbOs5CEhZkFx4bHAcBzyoNQXU2pc5W+U48ecBsyBL7PPF1vGsntJOnQAV6TH4C0cydoCgshP5uIioMH9RvVyOUo3rQJYMy4OU9L4ffyXGgLCyH09oJzr1i4DR2CvBWfouLAAciOn4A0IgLido3/XGoz9yUUfL7K+LXi4kVU7NuPgi++MB4T1rEoUOjpCf9XLP8OOXXrhg4//ojyXTtR9P1G5H9WXWauUKFFm2aMIstVWggFzGIecW6ZArsu5KBcocFHu6rTPbYlZsHbRYxxPapvbDv7u6Gzvxsuvz8aL/10BjcLZUjO1d/wz/vlLOb9chYA8PzwTnhjdETL6+OMweexR6u+mgRAX5lEGtkNuvIKeE99GN4zZqDy2DFkvPiSxdfIrppFyH5rPioPHYbvM09D2qVLrbSNrNf0aVyekyZBk5eLymPHLb6eU1QUXIcMQZvZz0DgWvdC8TtR1n8XhCivXnW53e8rDQ+XBS1bmt7wmdUOHz7sCgCDBg2yWLz733//dY+MjJSJq/qvRqPBzp07vWbPnm22WEkmkwkAwNvb27gqesiQIZWFhYWihIQEp9jYWJvsgsRqlvG5E/Tp04fHxcXZ7PXTCiox+f0/8b9wDWI9BfB+ZEadI5nqzExoy8og9PCAODgYWh3H3+eycH+PIAgELWeKzpRhI5D68t8s4ZxDk52N/M8+N1sIZupWt1fNee89/Q1HlTGTPsb2uUMQFdT4kW7OOYZ//C88nMTY8GRf7LyQg6wSOdYcuNao5786sgteuie83nOySuRY+EcS9l22vKAJAO7q4odHB3TAZ/uuIK1ABm9XMQ6+dneL/b3QVlRCnZkJp65doLx+HdqSEqTPftY4qmiJwNUVIWvX4saM5pczd+7dGy6xveDSrx+coqKguHABztHRt7Q1cEO2PPQ0wi6eQvYzr2CAjwDeM2bUmT6hzsqCtrQUAnd3SNq1A+cc2xKzMC460OINWEugUygAzsGcnJqcKqDOzUXBl1/WGn006BJ3us4guTFyP/yf2UzFmEkfY/OcgejbseFt4U2NXnkIOs7x8+yB2JmUg9wyBT7bd7XB54kEDM8OC8ProyznmxvklSmw4I8k7LloeWEyAPQL9cFzwzvho53JyCtXgHPgxH/vgbil/l7IZFDdvAmniAiobtyAprAQGXNfhragoN7ndfztN6RNmVLvOfVxjo2Fc8+ecO3fT7/u5MoVOEVEOESFIsZYPOfc4j7wiYmJaTExMWY/3NYUIL/66quB69ev9y8uLrY42nHvvfd2kkqlfPv27dcB4OjRo85DhgyJlEgkXCgUGoNTzjm0Wi0rKys74+TkxAGgqKhI4Ovr2+unn35KmTZtWqml12+sxMTENjExMR1rHm8Zt7AORsAYipw9UTowBj696x99EQcHm5Uu+/n0TSz4PQllcjUeHdjRxi1tnqYGxgaMMYiDghC4dAkEri6QnT0LoYcnAt99B6Xbt0PSvv0tT5f6v/EGfGfNgk6pwuvHC4Hzufg3OR/BXs7wcqn/tRVqLd77+yJ+PHnTeKz3kr21zhsdFYAHYoOxKykH90UFYHT3ACzfcQlfH9IvHvRwbng0K8jLGd8+0Recc/RduhcFFbXXGRy6ko9DV6qrJFQoNRj7+WGM6R6I54Z3um0r6BtL6OYKYdW0vDQsDADQ5fgxQCRC1muvo2z7dki7dYPyUnVqTeDyZXCJ7YXO/x6A7PRpZL+9EFypBACEfPM13O66C5UnT+m3E1apkLt0KYReXtCWlBhfQx4fD3l8PArXrjNrT5eTJ5qVAtQYjAPFUncUDbgbPgM61HuuOCgI4qAg49fbz2fj5Z/PIr1IhhdH1H8jZS/N7eMAIG7bFgGLFoFJJJDFxUHo7oGARfo1AiI//1sKjgHA7z/z4P3IDHC1GsvPlAGnMrD3Yi46+bnBx7X+Pq7UaLF8x2VsOJZmPBb7fu1azCMj2+LB2HbYeykXd3Xxw4SYIHy65wo+23cVGh2Hh1PDfdzfwwlrH9PHPSM++RfX82sPop1KLcKp1CKzY6NWHsL4HkF4fnin276wtyECFxc4VS1ElXToAEmHDgg/sB8QiZCzaBFKNv9mvEk1CPxgOZy7RyH8yGFUHDmCvI8+hrZQn5Jq2LRIlpCgX5gpFCJn0Ttgzs7g8uqNpeQJCZAnJNRK6wo/fsxsLcudoKlBqj2dOXPGNSoqymJ6BQAoFAqBh4eH2vD1hQsXnADg2LFjF6VSqTFAnj9/flBWVpbEEBwDgIuLCwcAuVxuswshBcg2YBhw0TVjdL5Epv9dySq1yYxBi8BEIgQsWmR2zO+FF6zy2gInJwiqbjj4yRIAwEe7kvHRrmSkfTCuzuedTivCQ1+ZT/fNvisMm47fgFytxYSYIEzrG4IBYb7GEdxRUQHGc92k1V3Jw7nx3Yoxhri3RyKvTIEyhRpXcytwLb8CfyVmo7O/GzKKZUjMqL45vpxTjss55VjzbwqS3x8NtZa3uEDZlGEBVfAnHyPo44/qHI0UBwTA8/774X7vvQDnELhUD5C49u8H1/76nG6fR2cCACpPnoI6MxNMLIY8MRGy+HizwBsArvQfAAAIXLoEXg8+aN3vC1z/32b08TK5fsFeRnHdO0u2dkwgQMB//2t2TNqpUx1nN41AIjHWaefn9Avjvj50HV8ful5vHz+bXoJJa46aHXv2rjD8eOomyhUaTIgJwuTYYNwV7mfs46O7V/dxdyeRyb+bltKx/9XhyC9XokSmQmpBJZJzyrH9fDY6+rqiWKbCSZMg+Xp+JT7fdxWf77uK1OVjodLqIBW1rEDZlKGPB77/PgLee6/OPi5q0wZekybpS1FqtWapEy6xsXCJjQUAeD/8MABAlpAAVWoamEQMxcVLqDx5AsqL5n386sBBAPS1tX1mPmL1743cmqSkJJepU6fWuRORr6+vpqSkxNixSktLha6urrrevXsbAyCNRoNTp065z507N8f0uXl5eUIA8Pf3V8NGKEC2oeYkr4iF+g8Xtab2LnytWW6ZAtfyKzCo0+2pVMA5x1+JlkvKmcopVWDUykMolev7mJeLGM8MDcPM/h3g6SLGW6P1oyUNpTV4mYxc+bg2PefZ38MJ/h5O6Oyvz8E2HVmUq7S4WSRDYkYJ3qha4KfS6BA6X1/f1F0qwrLJ0bg/Jqj2C9fAOYeOA0I7pGk0Zqq+sTnFhoAZADzvH2/8N1eroUxNRarJzonZC95G9qJ3ELBwIbymPmzV6gK30sdVFnbabM3yy5VIzinHkPDb08cB4PvjNxo8p7BCiVErDxlnadykIsy+KwwzB3SAj6sEb46OAEfDfcLTZGaooZFqS/zcpfBzlyK8rTvuiwowS8NSqLVIK9QHzi//fNZ43NjHnURYND6y0RVwdDpul1SsRvXxRs5OmAbNnvffbzzO1WqoMzNxbXT1gt/cJUuQu2QJ2v53PrwffbRFVRC5U6WlpYnz8/PFffv2tZh/DAC9evWSrVu3zriQyc/PT6NQKJhcLmfOzs4cAFasWOGn0+nw0ksvmaWaxMfHuwiFQgwcOLDOEepbRQGyDRj7JgeKK1VQ63Twd2/ch4Ih90ztYBfPMZ8dRlGlCqcX3As/96YHkE1VLKt9U2lam1Wl0eHVzYlmQfTqGb0wpnug2YWysReZmHbVU/kh3tZdOOYsEaJrgDu6Brjj4T4huJ5fgRGfHDQ+Xq7U4KWfzmBnUg76hfpgaHgbhPm5Ib9cianfHMeU3u1w9mYJugV6IDGjBMk55djy3CBUKDXo0tbyosjWionFcOrSxVgh5epdw6DJywO0WuS8+y5y3n0XvrNnw/uRRyA/lwiniAgwiQTa0lI4denS+DfiAGf6HadLZWooNFq09WhcHzeM+Ku1jrX+48Evj+FmkQyH37gbIT62T5GUq7S1jmm0OmNet1qrw5tbzmFrQqbx8U8eisGkXsHN6uM9Q7yM/w7xsW4fdxILERHggYgAD0zsGYz0IhmG/q96p9JyhQav/3YO+y7loU9Hb4yI8EeYnxuKK1WY9s0JjOsRiOSccoT5ueJSdjnOphfjzxeHoEyuRrfAxlchaQ2YWAxJx47GPn5t3HiorunXhxgqJPk+PQvejz4KRVISpOHhYFInaIuLjOkhxPaOHDniCgCurq6606dPm304RkdHK52cnPiECRNKFy9e3C4lJUXcuXNn9ZgxY8qlUimfN29e8CuvvJK3c+dO9yVLlgRv3LjxmoeHh1lQtH//fvfY2NgKHx8fmwVLFCDbgHGnJ3D0qspvq2/qz5QhQFY52MWzqFI/evPQV8fw7+t32/z9lJraF89KlRZuUhGUGi26vq2v7Tuoky9m9G+P8T0aHn2tT3SwJ54eEoqMYjna2zg4CPNzw6kF9+CBNceQWVI9Tb/9fDa2n6+9FfD/dupX4e82WSw06IP9APRlqPzcpRjcufXUIG6KsL+2QXntGhQXLiK3avvjwm++QeE339Q6t83zz8ProSnQlpXBqWvXel+XgYNXpVj0W7YXSo2uyX3c0WaJbhbpB3JGrTyEi++NbuDsW2epj5fI1WjjJoVGq0PM4t2QqbTo29EbMwd0wISYoFsaWQxv644X7u6ES9nlCPe37Y1liI8LziwciUlfHMWNwuoBsp0XcrDzQg6WbDdPNUjeU17rNQZX9fHPp/eCu1SEuyMcswZxx59+hDLlGpRXko3lCgvXfWuxHJ3vM0/D+5FHoCkstFi/n1hPXFycCwBMmTLFbKGFUChESUlJAgDExsYq+vXrV75u3TrfDz74IKdt27batWvXXn/zzTdDNmzY4B8VFSXbvHlzyqhRo8xWeut0OmzdutVn0aJFmbChlpu82IoZBiSaUyBEYsMRZKVGi9/PZODp7+Pwz/lsrDmQgqlfWy6zY02meZpphXXPhshUGiRlluJavnnVg8IKJYorm7ZZjlJd/fObHKvPSS6uVCGzRI5H1p4EAHTwdcEPs/rfcnAM6G+K3h4fia8e7X1bKhP4uzvh6Fsj8FADi0AtCfaqHv2a98tZPLLuJM5nlOKf89lIuFlsFngcupKPnu/tRlJmKYorVfjx5E1UKDVW+R5uB6GnJ1xiY+Hz6Ex0u3wJXU4ch8uAARbPLfjiC6TcPQKpEydBJ5OBa2sHYJxz4yY5vOqPsomBrqjqA8IWfVyt1WFbYhae2RiHP89m4tsjqZi4+kjDT7QimYWRXQOFWouLWWW4mmse0BVXqlBYoWzS+5j+3A39oKhShdwyBR799hRkKi3auEnw8+yBmNgz2CrT7q+PisD6J/relrx/b1cJDr5+N54Y1LHJzzW9SZ/70xk8ueE0kjJLsTMpB6fTiqDUaI2fy6dSixD9zi4kppegsEKJX0+no9TCDFxLJfTwgEtsL3hPm6bv46dOwm34cIvnFq5dh5ThdyPtwSnQyeXVu9jWYOjjpPlWrlyZxTmPr/lHo9HEu7m5GYOCxYsXZ61fv96/vLxcAAAzZswoTU9PT1IqlQkJCQmXawbHALB+/XpvV1dX7axZs4pqPmZNNIJsA6xqGwFdMwJkkdA2F0/OOSasOmqsz7n3UvVoolbHrZaTuv1cNtYduY4zN0sAAJfeG42jKfWXADKYsPooUqq2aE5dPtZ4QTNUkmjsCB1QffFcMyMWbT2k2JqQia0JmdhwLBXFMjWWPRCNaX1DWmzJtMb66KEYfPRQDLQ6jkV/JsHPXYqVe81LVd3bzR9jowPRsY0rugV4wFkiRG6ZAv2X7TOec38DQdT4VdWP//f381j/RB+MiGgLQH/jlZJX0aRSevYi9PJChw3fQSeXm+U7Xxs/HqqU6jJ+ybG9IfT2RrvVq+AUEYGi//sRFfv3g6tUUFy8iK4ANEyAm83o44bPBVvkIE/56jgS00sAwKy8mEKttVpFhN0XcvDVwWtIqOrjZxeNxMXsxgUUU78+blx0em3ZWOPnTlNn2oDqm+BPHopB1wB3bI7PwN+JWfjxVDoKKpR49/5IPDqwo13y7a3p3QlReHdCFDjneHfbBXg6i/H5/hSzc+7t5o/7IgPQNcAdnf3d4CoVoaBCiT4mVXhM+7AlE00WML6x5Ry+frS3cSGyWqtDck45uge3gj7u4YGQr76ETi43K1OYNm065GfPGs9L7hULgYcH2n3+GZx79EDxTz+jfP9+cIXCWIUjeOVKuI+6j3KabWj06NEVb7zxRlZycrKkT58+japOoFQq2bp169JENt54iQJkGzD0Jd6MJTzaqquntQPk02nFSM4th6ez2LggzSCzWI72vtZJC3jhxwSzr+9dcdAsDaAuJTKVMTgG9JtujOsRiNX7G65LaolhFFQqEiC2vTeCvZzx6d4rEAoYNjzZF8O7OtZ0o1DAsPSBaABAnw4+cJYI8eCXxxDm54p1j/etdX5bDyf8+HR/zFh3slnv99SGOKQsHYO0QhnuXaHPh44K8sCmWf2xNSEDK/ZcQcLCkfUGZfnlSoz7/DBGRPgjup0nHulff7k0a6q5GLDT339DJ5OhbPduZL+l3/RAW1yMG4/MrPM11AJRs6pYaHT6vm3tPn4+oxSJ6SVwl4pQXmOU/2aRzGr55oZdIQ36L9vXqFH0CqXGrCLLb/HpmNq3PdYfSW1WOwx9XCISICrIA2F+rvh8fwoEDGbBnaNgjGHxxO4AgEGd20DAGB7++jj83aUW+3gbNyk2zxlYqzpPYz27KR6X3x+NvDIl7vpInw/dztsZf74wGDuScvD+XxeRsGikWQWfmoorVRj7+WHcFe6HiEB3PDk4tFltaY6afbzjzz9BJ5ej4uAhZM6bBwDQlZXh5hNP1vkamfPmIeJcImDj3RrvdK+99lrjRtGqvPDCCzYdOTagANkGjGv0mjG6VB0gWzcH+a/ELLhKhDgx/x7I1Vqz2p+n04qsFiDX1JjgGACSc/Qj214uYpTI1Fi1/yrG9QjEx7uvGM9Ze+g6JvYKMlvwqNbq8PGuZEQG6Re3GKiqLthSsQACAcM3j/XG3ot5uKebf6sYBbkVhioCSYtHGafzLRnUuQ1Slo7B+cxS/G9nMo5fr7Maj0W7L+bi+f+rviG6kFVm9nv18NfH0c7bGc8MDQMH0KWtu9nFdMbaE8grV+Ln0+n4+XQ6HuodYjZ1nZhegolrjuKvF4ega4A7fj59E1P7hkAiFNhkREfg4gLPiRPhdtddEPn4IGfJUhT/8gukoaHwuH88xAGBcOoWAUmnTlj59hf4RhGAV5vxPoY+rrF2Hz+XBYlIgKPzR4BzIGbxbuNjp9OKbLYgs7EpJteqboCDPJ2QVarAx7uvYGrf9njv74vGc746eA2TegYjwLO6j2t1HCv3XkE7b2dM7Vu9E6HhfaUi/e/Dl4/0xj9J2bi7qz9iTBbUOaIBYfoNMi4sHgVBPX2hb0cfXFs2FucySrB6f0q9GxNZsutCjllVjYxiuVlt+KlVAfp/RnaBWqtDeFt3sxrRL/yYgOxSBX6J05fufbhPCFxNPgOu5Jbjvk8PYfOcgegV4oUfT93Ew31CjP9PrU3g7AyP0aPgcuwoRD4+yPv4YxRu+F7fx8eOgbh9e0g7d4a0SxeU//MPxCEhNt/KnLRcFCDbgnEEuen+OqevqqCy8gKek6mFCPZ2hrNECGeJEAdeG46l2y9h76VclMjtn29mmG7+5tE+ePjr47icU25c2GewdMcl7EjKxu/PDwYAZBTLMOTD6pXeY6MDjQugDBdPQ053VJBnq0gBsKb6RnYMREIBerX3xk+z9Xm5hp0cfV2l8PeQIrNYju+OpZltWGJgGhxbci6jFOcySrHjvL585ZjuAfhyZm/j41fzzFPLurz9DwD9RV8oYJi+9gQAYM+lXPwal45NJ25g0Z8XMHdEZ7xyX/2L6JqLMQaRj35HtoC3FyDg7QUWz0uJGgj5uexm3QTvTNL/PKydYnEytQj+7lJjgHL4jbvxwc7L2H4u21hf3Z4M3++HU3rg0W9PIb9cWSuf/YN/LmNzXDr2vTocAGqnAsUEGbdoNvbxqpsqQ6WXO4lrI/q4UMDQq703vn1CP8qs03H8k5QDV6kQIT4uuJ5fiX/OZ2PrmdrrnUyDY0suZJXhAoADyfrPh6HhbbBpVn/j48eumd90R72zCwCQ+M59cJEI8eR3pwEA285m4dCVfKzan4JFf17AU4NDsej+yAa/t+Yy9HH/116Df9X21zV5jB1rs/cnrQMt0rMB4x19M66eR1P0HyjWmn7V6TgOXM7DldwKOEuqP0xD27jii0f0NSblKussujqQ3LTRCQBILahEx7e2I+FGCQDASSzAuOhAAJZ3uEovqh6RXnfYfGrWdLW3McWihe1E1dIJBQwTewZjSHgbdGnrjrsj/LH2seqgtpOfKw6/0bwqJCl5FUjKLDUuAIqoI5iJemcXIhbuNC72+nzfVWw6UV3v9vP9KbiaW96s9AZrqa7k2PQ2/GMIkK10E8w5x5GrBUhML4HUZAQ+xMcFq6f3glDAILNSHz9ytUkzoQD0s0gd39qOY1WfbRKhwLhwtntVwGTKtB//n8mulgDMdqOrTqOiPt4UAgHDuB6BGN7VH5383DAysi3+N6WH8fE2blKcmH9Ps177UnYZLmaVGQc3+na0vMtdzOLdCF/wj3GGcdOJG1hlkle9/mgqLmSV2rWPtxA6nU5HCdA2VPXztfhhTCPINmD4bW7OIj0Da02//njqJt7+Q7/b1OyhYWaPSUQCiAQMlSotVBod3vgtES+OCEdn/6ZvBVsqUxtHAxpy8Eo+1h2+ju+f7IfDV/UjD5tOpAHQl8Bylphf8P54YbBxB6y2HtU1lK/m6dMyXh3ZBZ/suYKpXx/Hv68Ph6tEhEpldQ4yuTVSkRDXl41FXrnSOPW9aHwkooL0C/4CPJxQKldj5KeHAOhL59UcOQL0I8aGhUKfT+8FAOgX6lNrq93GMLzX8K5+6ODjgru6+MFNKkL/qqlnWzNM/95SH7+VJ5v482wW5v1yFgDw7F3mu9UxxuAiFkKm0kKj1eHNLecxa0goIoOaXhu3UqnBzG8bl7N+8nohVu69io2z+iH+RjEA4JtD+kWQYpGg1lbNf780xPi7YZpecSFTn7M8f0wElv9zGQ9/fRxH3xwBT2cxZIY+LqY+fqtEQgFSl49FTpkCgZ763N33J0YhzM8Nns5i+LpJIFdpjfXXuwV64JKFhZkFFfqcY0C/eFKj483u4+M+1/8+DO7si46+rrg3si0kQoHDlqS0hDGWI5fLPV1dXR132007k8vlToyxHEuPUYBsA8Y6yLdw96u8xRFkjVaHCqUGv8VnGI+Nja69aMVFIkRemRKzN8Xh3+R8nMsoxf7XhkOu0uL49QJjpYK6xN8ohr+71KxSxcwB7XEpu9x4YTTVP9QHszachkbHUa7QwNtFn99l2OVKLNQvqvstPgOzhoTilZFd4CoVIfGd+zDkg/24kFWGnu/tNk4ZP3tXGO6NbItP9lxBYaUK0e/uxsAwX2M+rauEfsWtQSBgZoHLU0PMF9v4ezhh7j3h2HY2E+urpnIrlRqzfEVTc386AwAYUs/FzkUixLl37sOTG07jcB0jl/9WTe0adlSbPyYC8TeKMe/eLs0KApvqVga4bnUEWaPVoVKlxeb4dOOxKRbK/rlIhcgvV+KVXxOxLTEL+y/n4syi+6DUaHHoSgFGRtbfx8+ml8DLWYyzVdUxAGBqnxDklClw0ELqTXSwJ1786Qzyy5XIK1fCq2oHusqqGQGJUICYEH2604z+7TF/TATcncRIWjwKwz86gIxiuVkff3xgB4yKCsDyfy5DptKi1/t7MDKyrbFKB/Vx62CMGYNjAHh0YMda57wxuiv+78RNbJ4zECIBg0qrQ493d9c6DwBe3ZwIwHwTJUuuLRuLuT+fwfZztWu4A/pZ1aMphcbZhLfHdcPptCI8P7yzw+eaazSaxWlpaas7duwIZ2dnhUAguOOH1K1Fp9MxuVzulJaWJtFoNIstnUOfLDZgspFeszVnEwG1VocjKQXYcDSt1oVrxcMxFhc9lCk02JJQHUQXVk2Nvff3Bfx0Kh3/vDy0zp2YSmVqPPjlsVrHnxocijA/N1zMKkOJXIUZVXWHTQNXAJCpNcacYQOJUIBpfUPwcJ92ZvWEPZ3FWPNILB5bf8p44ezTwRuv3NcFxZXm+ZWm7+EqpenX2+WVkV3wysjq3egMFSz6hfrg0QEd8NJPZ/BAr2D8bpLreCSlAGcWjjSW+Trw2nBsTcjAydQi/HdsN4iEAmya1R+lMjVSCyvRM8QLV3LL8dm+qxYvqMv/uQxAv4Dwg8nRmNavfa1zrKk5KRYGzUmj0uo4jqYUYOPxNOy9ZJ7S9MHkaItlC4sr1fjb5Gdl2GVyxe4r+PrQdfwye0CdI++VSo1x9sbUY4M6ICrIE5eyy6DVcePo74gIf+w3WQim0uigq3EXIRYKMKlnMMb3CDLr/25SEVbPiMW0b04Y+3hMO0+8OSYCao35a5iWsKM+fvs8P7wznh/e2fi1oY9HBnrglZFd8PTGOIzrEWjWNxMzSnF20UgM/mA/KlVa7Jw3FDuTcnD8WiFeG9UVQgHDmhmx+GCyGldyK9C7gzdS8irwxYEUi3nRhk1Sdl3IxaLxkbVu1h1JbGzsroSEhBevXbv2Duc8AJQWa006xliORqNZHBsbWzvXCxQg24TAOILc/NewdPFUa3VQa3Uok2uQX67E6bQi/Hk206x0Uk3vTYzCYxZGAgxCfJzN8noNMfS1PH2uX30bdCTXKPbfu4M3JvUKRpifPkUjMsjDbKGdobyVwea4DLPRLwAQixgEAgYBal/o7+rih+Qlo7HvUh66BrijU9X7+LjWnaLVmEUsxHZOzL8Hns5iOEuEuD9GvyHL9H7tMfWb4+Ac+GxaT3i7SuDjKkFRpQoBHk541cICPE8XMXq6eAHQV8NYMyMWh67sQrmi7tza1QdScG9kW3i7SKxeC/dWKtUYWKr+YNrHCyqUiEsrwl/nsi3Oxhi8PqorXri7c52Ph7d1w4Ws2tPhqQX6Pm6YvbGk5qY9MSFemBgTZFzw2i3Qw2zL55o/5q0JGdh1wXz2UixkYIxBLKz9/2RAmC+uLBmD/ZdzEebnZqy8oRPV/YOmEWT7OvXfe+AqFcFVKjLWsZ41pBhTvz4OtZbjwwej4eUiQVsPJ1wvqISPiwTz7u2Cefeav467kxi9O+hzljv7u2HF1J44fr0Q2aV1l8b9YOdlTOwZBE9n8W3ZoMkeqoI3iwEcsS36ZLGFqs/9miMnDdlnsnlHzRXuy3ZcwrrD1xvMeXxjdFf8lZiNS9llCPNzrTc4BoADrw7H/st5uFEow9Idl+AmFeHk9UKcStPnjM1YdxLjewRi9YzYWs997gfzeqiTY4Nr1bI1vQhO79cep9OqL/Qr9lxBTTVHlGuSioQYW7WIz0AiEuD7p/rhvb8u4JrJIh79+Y75odlamKZlGPQL9UHqcvMNIX59dgD2XMyrlX9en2NvjYCAMbhKRVBrdXjs21NmswcZxXL0WbIXfu5SnJx/j1U3haleh9u0Pm46s1OzNSt2J2PNv9eMZeDq8urILjicUoBTqUXwcBLVGxwDwLYXh2DfpVzkliux8I8kuElFSLhZbNx6/IUfE/DH2bZY+1ifWs+dV6OKweiogFojdqZ9fErvELOR7VU1NrTQn19/n5SIBBjd3byPCwQMPz7dHx/svIxzNQYEXGgE2a78PWr38dj23ri61LwKxHdP9sWfZ7Pg5y6tdX5d9rwyDJxzuDuJodVxPLMxrtYMRe8le+EkFuDC4tGtflMY0rJQgGwDzSnfuOtCDp41KcBvul1rfrkS3xy6jmFd/DCwky88nMRwdxIht0yBJdsvIaadJ9Y/0RcioQCezmLMGhKKnUk5mBDT8BbKIqEA91UV1D+SUoCDV/Ix9ZsTZuf8fS4bq2fUfm5hjdFlS5tvmF4MJ8e2w/yt5+utm9rQxbMuw7r4Yd+rw9Hxre1mx2kHpNahs787Ovs3rUSXu8lCL7FQgJ9mD0C5Qo2PdyUbc5IBff8Z89lhfDkz1ji7YS1NiY+PXC3A4+tPGb82zUEulaux+kAKBnbyxZDOfvBwFsHDSYwSuRoL/0hCR18X/P78YDAGeLlI8NzwTvj7XHaj+rhQwIx9/OjVAuy8kIPJX5inRpmmLJi6XmB+wzmme+11DKZByejuAfB1ldT6bDDV3G2aB3Vug20vDkGXBf+YDSBQFYvWoYOvK+beE96k55iWqhQKGNY/0RflCjVW70/B14euGx9TqHUY9tEBfPt43zuu1B+xHQqQbaA506/P1tidSlEVIGeWyPHmb+cAAC+N6Iw+HX3MzhvXIxB+blKz6SWpSGi2aUZj+Tfhzj6vXD/t9erILnhsYEc4S4QWL3w1A95Ns/oj4WYxPqjKFa1JcovTZB19XZBmUiaK3FncncRYPLE7nhwciqnfHEdumRKAPh1oxCcHsWZGLMb1MB+dVGq0UKh18HQWW3rJejVl/LhmBQi5Wt/Hc0oVWPhnEnQcmDOsE4aG+5mdd19Vmohp/xIJBZjUqxl93KPxfbxMoc8Dfn54Jzw7rBOcxAKLwWjNm9C1j/fBqdSiOvt4c2+CDSKDPMwWDJI7i7uTGPPHdsMj/Tvg8e9OGVOFMorlGLXyEFZO7YmJPYPMfi9VGh3kKi08XZrex8mdiwJkGzB0zHJF84vzy9Va3CisxP2rjqCsKs+yYxvXWueZrjq+VeImjOy8+KO+CkFuuaLeD52aU179Qn3QL9QHD/QKNtsAwKC5o0sGjw/qiOX/XMacu8IQ6GW9nw1pXTq2ccU3j/bB8/+XYLab4ws/JkDHe+H+mCD0WbIHMe28UKnS4MT1ImP+ZGMYfqsrb6G+sEbHkV4kw8Q1R425+h19a/fxthamsJvLpZ58XY1WZ3aj/fbv+vKQV/MqmnTzENveG7HtvTGtbwh6vle7lrnTLZZlm9o3BOcySvDyPV3g7UoBz52qva8L1syIxQs/JhiDZACY98tZyFRazOjfHkP/tx/tvFzgKhVi76U8pC4fS7OKpNEoQLYBQ0z4uYX8u8bS6Di+O5oGmUqLcdGB2HspF76utt3y8pH+7ZFWUGm5hm1uOTr7uxk/XAybPYS1adyUddsaI1dtPZzQxk0CzqtTNV6+J/yWc8ieHByKJwZ1pA9BgpgQLxx9awQiFv4Dhbp6Sv7rQ9fw97ksFFSozLbe/Tc5z2KaUH2+Pni94ZPq8e2RVJTIVJgQE4RtiVkItJCzbU1TegfjzM1inLRQlzYpqwwx7TyNfaewUj/6HtXIcnk1A18vFwnaeTujXKFBadVunbOGhNYbpDfG9H7tMa1vCPVxgsggDxx4bTh6v7/HLK1n3ZHrOHglD+lFcrNF6H81Mi2JEABgd+JONX369OFxcXE2e325Sotui3aaHWtodGrUp4dwNa8ckUEeGN7FH6sPpCDYyxmd/N2w8al+NmurJb/FZ2DPxRxcy69Eisl2wCsejsHkWH2d1Se/O4UDyfm4tmxsg0HtqdQidPR1qbWYQ6vjxufKVdomLdAipLHSCiqRU6ZAiUyFOT/UvT32y/eEw9NZjLgbRfjikd51ngcA//nlrFm5OqDhPj5pzVGcTS9BZKAH7otqi5V7ryLYyxnBXs74dc7Axn9DVrD9XDY2x6dDptKabeLw/qTueHSAfqHtcz/E45+kHFxdOqbBtIj4G0UI8nKuNaOl1XEImH5Wjfo4sZX0IhluFsmg1Gjx1Ia6r+1PD9GXIN13Kde49ba9McbiOee1V8gSu6MRZBv4J207XEJXQ5Y2B+CNy/nj4LgvMgBfPdobP1YVRM8skVtcFGNrU3q3w5Te7fDVwWtmeYSv/JqIV35NNH49Kqpto0Z8+4X6WDxu+ly6cBJb6djG1Zie1DPEq8781c/2XW30a5Zpb8Cp3f9BkTETQON+dznnGNbFD98/1Q+/n9HXHs8skWN4V78Gnml943oEYlyPQPxw4oZZgLzwjyQsrNp5E9CXVmxMznDvDtTHif2E+LggxMcFADA0vE2dGwutO5J6O5tFWjmqgWUDJcoiCJ2yAdb4jQA0Wg5hVbkkZ0n1/xZLece3y7N3hWHB2G51Pj6o052z5SdxDMseiG7UFGtqQaVZDW8DtVaH5JxyXNR8A7H7JQikFncotUit5RBVBYzO4upgMdSOffyR/u3x7v2RcHeyPFYyqNPt2bqbEGtZND4SD8bW3lGypuv5FcgvV9Y6rtVxi9tokzsPBcg2UJ0b1/j0FY2OQ2zh4mlp0c7twhjDM3eF4dqy6nqW/7w81JhrOHNAh7qeSkiLFBnkgbn36OsG3x8ThOvLxlpMjbj743/Re0n1ArPt57IhV2nx8e5kjFp5yJhT2xRaHYeo6ibYyaSPd7BzH39icCjOvXOf8djvzw8y1qqd5cC7lBHHFN7WHW+O1m82NKyLn7GP+9RYwzPik4Pou3Sv8eudSdmoUGrw1cFrGPPZYfRfthfkzkYpFjYgZE2/7zBdQe5ssoilKUXVbcV0mrRboAcuvz/Gjq0h5NZ09nfHl4/EYnB4G+PmIYM6+dZanMo5MPXr4wj0dMIfZ7PQ1kNqLBtn1IR1YmpddR93aWF93HTBW6/23ji94N56ziakZfP3cMI3j/ZG344+xj4+sJOvxe3pR688hIGdfPHd0TS4S0UoV+or0+SWKZFXprC4EQq5M1CAbAOs6qrJGG/0GLJax407UpmOIHu3kLqNXz/aGx18XezdDEKsYkyN3RiDq0oCTuoZhD/OZhmPm1Z7MA+OmzFLpLU8S9RS+vj6J/rA352CAeIYDJvjGARWBboP9Ao2W2B7Oaccl3PKAcAYHBvkVygpQL6DUYBsAwLjCHJTLp46iARVI8gmF08vF9uWdmusUVG3f7EgIbfLOxOi0LuDNyb1CjYLkOvEm15izHyWqHqWydvG5Rsba0REW3s3gRCbeW1UV4T5uWFK73a1KtDUZdznR5pUH504FspBtoHm1OfUaKvzE01Xe9/qxhmEkIa5SUWY1q89nMRC/PnCYHw2rafZjaqpxwY2L/febJbIJMXCXUrjFITYmpNYiBn920MiEmD73CH45KEYtPO2vJnUSyM63+bWkZaIPpltQNCMRXpqnc5YTonKIRFiPzEhXvo/7bywan8KtiRkoGtbd7xzfyQCvZyRW6bAb7VTGRtU1ywRbXhByO0VFeSJqCBPDOjki493JeP3M5kI9nLGiodj4OsmgUbHsWp/CoaGU6WmOxkFyDZgTLFgTctPtFQCihBiHx3buOKTh2Mwf2wEnMVCuFaN9HbwcUGApxPya1SB45zXG+yazRJRHyfE7oK9nPHp1J54e1w3SMVCuFX1cc45/js2olHl4ojjogC5BeCcQ6PjJivc6eJJSEvRxs28yoRAwODnLkV+jR3ZOQfqGww2nSWquS0zIcR+fGv0ccYYZt/VyU6tIS0FBcg20NRFehqd/jzDCnepSIBgL2c8OyzMFs0jhFhNdR/XcQ5BPXXfTGeJGGPo5OeKh/uE2LyFhBBCmo4CZBtgTSwBpdHqzzOMIDPGcPStEbZoGiHECpiFQLi+3l5zlggA9r063PoNI4QQYhU0z2cDTV10o9bpt6Q2rHAnhLQ+Ol53iFxzlogQQkjLRgGyDbCMOACAMxSNOl9bNYIspIsnIa2DWg4AEEJrPFRPfAxtVYAspJtgQghpFShAtgGm1O/KI2SmF8+6r56GEWTT6VdCSAtWcgMA0IHlGg/VFyCrtVWzRALq44QQ0hrQp7UNWMpBru/iachBpulXQloHSz213hQL4zoD6uOEENIaUIBsA9UbheiMxxp38aT/HYS0JqxGFYu60CwRIYS0LvRpbRPM5L969a1wp0V6hLR+9fVxmiUihJDWhcq82YChigVj1SPIv5xOx8jIthAwhss5ZXj021MAgHfvj8TATvrtLEWUn0hIq8Bq/A0A3x9Nw8N9QyBgDNfyKzDtmxMAgDdGd8X46CAANIJMCCGtBQXINmDYKMR0+vXtP5Lw9h9Jtc5996+Lxs0DKD+RkNamuo9/sucKPtlzpdYZ/9uZjC8PXANAs0SEENJa0HCGDTBjikX1xfOZoaFm50QFeRj/baiRaigFRQhp6WovxJ3Su53ZGWF+rsZ/lys1AACZSgtCCCEtHwXINmBMsTC5eL42qqvZOdvnDoW7VD+A36WtGwAgq0R+m1pICLEG0/HgdydEmT22/9XhaO/jAgCIaecJAMgolt2uphFCCLkFDhEgM8bCGGPfMsZ+s3dbgNpl3vp19IFUJKx1niF8/s+9XdDGTYpRUQG3p4GEkFtSMwe5s78b3KSiWpv98Kpe/sxdYfBzl+KBXuajzIQQQlqmFhsgM8bWM8byGGNJNY6PZowlM8ZSGGNvAQDn/DrnfJZ9WlpbzUV6vI717YayUN0CPRD39r0IqRptIoS0DqxG3xbVCJCrCtSgk58bTi+4F5393W5X0wghhNyCFhsgA9gAYLTpAcaYEMAaAGMARAKYzhiLvP1Nq1/NEWRDwPzUYPM8ZEPZVGdJ7dFlQkjLZ7j5NcTFc+8Jt3ies5j6OCGEtCYtNkDmnB8CUFTjcD8AKVUjxioAPwOYeNsb14DqHGQ9w6jSs8PCzM4zXFyd6OJJSKtk6OPCqhKNM/t3MHvcsMU8VaghhJDWpcUGyHUIBpBu8nUGgGDGmC9j7CsAvRhj8y09kTE2mzEWxxiLy8/Pt2kjGQxl3vTzq4a8xJrTryMi/AHQ6BIhrU9VX2b6ANhQ3rhmIDw03A8A4C4V37aWEUIIuXWtrQ6ypWEYzjkvBDCnvidyzr8B8A0A9OnTx6b11AwjyIaLp2Hr6ZqbBKx4uCfeGq2ERNTa7lMIIaaEzHIt8/cndcfzd3eCpwsFyIQQ0po0OTJjjIkYYx8zxgJt0aAGZAAIMfm6HYAsO7SjXjXrIBtGkGtuEuAkFqK9Ly3MI6S1qe7J+lkigaGP19gNUyISoIOvKwghhLQuTQ6QOeca6EdrJdZvToNOAwhnjIUyxiQApgHYZod21Muwk17114YUCxopJsQh1JjLMowgCwSUa0wIIY6guRHbXgB9rdmQmhhjPwE4DqArYyyDMTarKjh/EcAuAJcA/Mo5v2DLdjRHdY1UQw6y/mvaZpYQx0SBMSGEOJbm5iBvA7CEMXaNc37Gmg0y4JxPr+P4DgA7bPGe1mNe5s2QYmHMTSaEOARDrfOaC3AJIYS0bs0NkNdCHwWeZIwdBrAfQDyAeM65bUtEtAKCqlQKVmORnsEj/dvf9jYRQqynZjhccwe9ST2Dbl9jCCGEWF1zA2QvAL2q/sQCmArgHQBCxlgW5zyknuc6PFajBJTp6FLaB+Ps0SRCiFWZL8Q1vQmmPk4IIa1fswJkznk5gENVfwAAjDEpgBgAPa3SslaseqMQ8xXuhBBHY55GRQghxDHcUh1kxpgnAAnnPJ9zrgRwqurPHa16oxC9mikWhJDWrbpHW06jIoQQ0ro1q4oFYyyAMXYA+q2gcxhjWYyxDxlj7tZtXutUvRiPFvAQ4siYhTQqQgghrV9zR5BXQ18HeTQAJYBoAC8DGMUYu4tzXmal9rVKNTcKeXZYJ3s2hxBidfo+btiS8z8ju9ivKYQQQqyuuXWQRwCYwznfwzk/xDlfA6A7gBwA71mtda2UcaMQBgwNb4PQNrSTFiGOxFjrnHF0D/ZA1wCaPCOEEEfS3ABZB0BjeoBzrgKwEMCUW21U66e/fI7s5oeNT/Wzc1sIIbbSv6MPtr0wxN7NIIQQYmW3spPeSxaOFwPwbH5zHAOrGkEeHdWWNgchxIHd1cWXqtQQQogDam4O8nzoNwlpA+BjAEkAnKuOn7VO01ovw4p2bsxQJIQ4IurjhBDimJpbBzmVMTYEwDcATqB6rUougPut1LZWyzBqzHU6O7eEEGITVYPGOk59nBBCHFGTA2TGmAjABwA+4ZwPZ4x1hL6KRTmAOM55hXWb2Pow4wp3ungS4sho/JgQQhxTkwNkzrmGMTYHwKqqr9MApFm3Wa2bIQeZc7p8EuLQqI8TQohDupVFen2t2RBHYhhB1tEIMiEOifo4IYQ4tuYGyNsALGGM9bJmYxyFYQQZlJ9IiEMy1K2gWSJCCHFMza1isRb6a8RJxthhAPsBxAOI55znW6txrZUxB5kunoQ4NOrhhBDimJobIHsB6FX1JxbAVADvABAyxrI45yHWaV7rxASUg0zInYDTLBEhhDik5laxeAf6KhaHTI5LAcQA6Gm11rVSgqrMFS3lJxLikIw5yHQTTAghDqnJOciccw2AOQAkNY4rOeenOOffWKtxrZWYCQEAap3azi0hhNiCuCpAVnONnVtCCCHEFqiKhQ1IhPqBebWWAmRCHJEhQFbSTTAhhDgkqmJhAxImBgAodSo7t4QQYgsSwwiyjkaQCSHEEVEVCxuQCPUBsopGlwhxSCLGAE59nBBCHFVzR5C9AAwH8DqADOirWGwDkMMYS7dKy1oxwwiyWqdGhaoCpcpSO7eIEGJNxhQLrkGluhIlihL7NogQQohVNStA5pyXc84Pcc4/45w/zjnvAcAdwEAA71u1ha2QtGoEWalVY8TmERjy85BGP1epVeKbc99ArpHbqnmEkFskrAqQVToNxv8+HkN/Gdro56p1aqw9txaV6kpbNY8QQsgtalKAzBgrYYz5WHqMqlhUEzF95opKp2lyoLvnxh6sOrMKq86sskXTiI3sTtuNTRc32bsZ5DYxFHdT6dQokBc06bnHs47j8zOfY9nJZdZvGLGZAzcPYH3Sens3gxBymzR1BNkDJnnLjLEUxliQyddOjLG7rdW41ooJBJDoeLPyE11FrgCAI5lHrN0sYkOvHnwV/zv9P3s3g9wm1QFy0xfpSYT6CpmHMw5bsUXE1uYemItP4z+1dzMIIbdJc3OQDdoCcDL52hP6EnB3OAYPnQ7F6rImP1OpUwIAUktTIVPLrN0wYmO0e+KdwfB/uVhTnSaha+SuekqNvo8XK4tpfUIrpKHKJYTcEZpbxaI+zAav2bowoL1GjT+yjxoPrT23Fjquw+qzqzGp8yT0DeiLClUF8uX56OrdFSXKEjwQ/oDx4gkAu9J24YHwB+zxHTiUpSeW4ufkn3H+8fM2f68KdQXcJe42fx/SMuwsTDT++4uzX0AqlOLzM59jfNh4DAwaiEp1JXIrcxHhG4EieREeCH8ACq3C+Jzt17djRrcZ9mi6Q/k0/lOsT1p/W/p4saIYfi5+Nn8fQoh92SJApiE0MDxXXIpnAqsH1z8/87nx33+k/IE/Uv6o9SwBqx7Q95B44LsL3+HukLvh5eRly8Y6vJ+TfwagH+Ez/RnbwrWSa+jp39Om70Hsz/Ah5ywQQ16VSvX1ua+Nj/99/W/8ff3vWs9T69TwdvIGALhL3LHx4kaM6jgKvs6+Nm+zIzPkBqu0KmMKi7U5i5wh18hxrfQaBciE3AGaEyC/WVX7OB766wQFxDUxhgEKJfYM+BCHUIGJnSdCo9OAcw6hQIhSZSnUWjVUOhVEAhHkGjke+ushvH+iugDIwoEL8eahNzHs12FwFjnDTeyGGL8YOIucIRaKIRaIwTlHvjwfMX4x8JJ6wUvqBW8nb3hKPSERShDkGgTGaEDfoFxVDk+pp01eu717e9wsv4nkomQKkO8AHECwWoMf+i/AbpEOD3Z50NjHRQIRSpQlUGvVUOvUEAqEUGgUmPLXFHwc97HxNRYNWIT5h+fj7l/vhovYBa4iV8T4x8BF5AKxUGxc7Jsny0OMfwy8pd5mfVwkEKGdWzvq4wAkAglUOhWKFcVo69rWJu8R7hWOcwXnkFyUjAGBA2zyHoSQlqOpAfIWAA8A+A/01wgG4BvG2HHoA+Ys6zavtdJfsAKcvPBwh7EAAKlQanzUWeRc6xnP93weX5z9wvj1iJAR+Hncz/g3/V8UK4txpfgKrhRfgVKrhFqnv/DK1DKodWrsu7nPYiucRc7o3qY7RnYYiXFh4+Ah8ah1TnZFNm6U3zD7wC9XleNm2U0cyzqGWdGzIGAC7EzbCR+pD/oG9G11F2QRE0HDNShSFNksQPZz8cPN8pu4VHTJJq9PWhbOAAaONiI3zOg2HoB5Hw8QBdR6zmt9XjMLkAcGDcQv9/+C/Tf3o1hRjKslV3G1+Kqxj2uqquAotUrsT99vsR1SoRRRvlEY2WEkxoeNtzjblFuZi5SSFAwOHmw8VqmuxM2ymziYcRBPRz8NkUCEfTf2wVnkjIFBA1tdH3eXuKNQUYgiRZHNAmR3qT51ivo4IXeGJgXInPOHAKCq1FtfAH2q/n4KwNuG06zZwFbJcHFpwoKt52Kew6zuszB261jkynIhFojRzbcbuvl2q/d5Oq5DhboCZcoylCpLUawsRrGiGKmlqcioyMCVoitYdnIZ1p1bhy/u/QJdfbqaPX/+kfmIz43Hg+EP4kjmEXhKPXGl+IrxcdPUEADwcfJBpboSYoEY7dzb4cexP0JcVfe5pWrn3g5pZWlILk5GqGeoTd7DsEDrctFlm7w+aVkMowNN+bh7POpxTI+Yjge3PYi0sjS4il3RxbsLunh3qfd5hj5eripHibIEJYoSFCmKkFaWhvTydFwruYYPT3+IdefXYfU9q9G9TXez5797/F0cyTyCsaFjcb7gPEQCEVJLU42Przm7xux8b6k3ZBoZxAIx2rq0xS/3/2IW/LdEIe4hKFQUIrk4ucHPzObS6rQAgMuF1McJuRM0KweZc14EYFfVHwAAYywAQD8Ava3TtNbMMPrStHsFiVCCTWM2gYM3egRHwATwkHjAQ+KBdu7tLJ5zLOsYXtr3Ep7c+STmxs6Fi9gF+27sQ6GiEIn5+kVGW65uAQDkynLrfK8HOj8AHdehUl2JnMocJBUm4cG/HsSLPV+EWqfG2NCxFts97e9pmBw+GQ93fbhR35O1dfLqhLSyNPx25TeM6jDKJqNjhovn1eKr0Og0EAlskd5PWgoO1qzVyBKhBOvuW2dMr2oM0z4e7BZs8Zy4nDg8v+95zNo1C3Nj58JD4oED6QdQIC/AmbwzAIAdqTsafK/7w+6HSCBCuaocRYoiJOQl4P7f78ebfd9EhboC93e632Ie/xM7n8CIkBF4LOqxRn1P1tbeoz3O5p/FlitbMKHTBJusNdByfR9PLUuFXCO3OBNICHEcVruKc85zoN9uepu1XrPVasYIskGgW6CVGwMMChqEjWM3Yt6BeVh6cmmtx/9v7P8hX56PjPIM3NfhPmRXZuNI5hGsPb8WiwYuQo82PWqNPOu4DjEbY5BamopXD74KAPjtym+4r+N9mNp1qvECxTnHhcILuFB4oVaAzLn+RkCmloGDw1Xsesvfq0anwbWSa/B19oWT0AluEjdjKHMy+yQWHFmAhQMXWv3ipuH60k8qnQq5stw6AxnS8mVWZKJCVYFiZTE+jf8UFwsvwt/ZHyM7joSn1BMeEg/8oyuBRChqVh+3RQpAn4A++GHsD5i7fy4+OPVBrcfXj1oPmVqGtLI03NfhPmRVZiEuJw6rz67G2/3fRrRfNCJ9I82ewzlHj409kF2ZjXn/zgMAbL6yGaM7jsa0iGlmAX58bjzic+NrBcimfVzHdXCTuN3y96rVaZFSkgJfZ19IhBJ4SDyMMzhn88/i9YOv4/3B78NF7HLL71XzfQH9Z19WRRY6eXWy6uuT2yenMgdFiiLINXJ8EvcJzhech4+TD8aEjoGnxBMeUg+ImAh9AvrQ/+c7GA1z2UTzRpBtKco3Cjsm78DV4qvIKM9AO/d2cBI6IbsyGz38epidG+gWiNi2sZgbO7fO1xMwARJmJmBF/ArsubEHubJcxOXGIS43Dn+k/IFVI1Zh3819GNVxlPE5MrUM+27ug6fUEyeyT9TaeS5hZgJEAhHy5flIzE/Eve3vrTXayznHF4lfIMwzDKM7jjZ7PDE/ETN3zDQ7//zj56HhGnT17op7OtyDL89+ieTiZCwdshQRPhFN/jnWRcd1EAvEUOvUyJPlUYDcyuRW5mJF/AooNAqL+b558jz836X/MzvWWa1CS+rjXby74O8H/tb38YoMBLoGwlXsivTydPQN6AsAGIZhAPR9vHfb3ng25tk6X48xhjOPnsHnCZ9jZ9pOZFdmIzE/EYn5idhydQu+vPdLHEw/iDFhY4zPkall2J++H25iNyTmJ2Ld+XVmrxk3Mw4SgQRFiiKczj1d54zO14lfI8gtCOPCxpmNBl8qvISH/za/0T732DlodVp08OiAB8MfxMqElUgpScHSIUtrpZvcCi3XGhcD5spyKXBqZQrkBVgRtwIyjcziup0iRVGtPu4t9cbuKbvhJHKqdT5xfOxO3NigT58+PC4uznZvkHYE2DAOeGwbEDbMdu/Tgmh0Giw8utBiaSuDwUGDcTTraJ2PA0CgayCKFcVQaBUY1m4YlgxeAi8nL6i0KiTmJ2LbtW3GEnkdPTpi8aDFiPaLxswdM3Gx8GKt1zvw8AEsOroIRYoi/Dz+ZxzOOIy3j76NUmUpZnabied7Pm+VkaYH/nwAap0aN8pu4KNhH2F0x9G3/JrEukqVpTiedRwXCy/icOZhpJSk1Hv+6I6j8VCXhxDgGoD43HjE+MUguTgZu9J2oUtmEh6+Ho82UzYAkRNvzzdgZzquw3vH3zOmY1lyX4f7sPvG7npfx1vqDcYYihRFGBg4EMuGLkMb5zZQa9U4X3Ae/6T+YyzN2M6tHd4d9C76BvTFEzufMKaLmNoxeQc+jf8U10uu449Jf+Bk9knMPzwfBfICTI+Yjpd6vWSVkesZ22egTFWGG2U38P7g9zGp86Rbfk1iXaXKUpzMPokLhRdwJPOI2XoaS0Z2GImHujyEYLdgJOQloLtvd1wrvYbdabsR5BaEQUGDMDBooE3bzBiL55z3sembkGahEWSbaHkjyLYmEoiwfOjyegPkhoJjAMiuzDb++2DGQQz9ZSjcxe4oV5ebnfd45OPYe3MvHt/5OMaEjjELjt8d+C5+uPQDUkpSkFOZAy3XQigQAgCGthuKbZO24dP4T/H9xe+x+8ZuvNnvTdzT/p6mfstmtFyLANcA3Ci7gbzKvFt6LWI96WXpeG7fc5CpZciX59d77tSuUzEoaBBi/GJq1SVu79EeABDmFYYxoWOAX2YCOl2zUixaKwET4N1B79YbIDcUHAP6HQQNTuac1Je5E7lApjHfOXRmt5k4nHkYT+9+GhM6TTALjhcOWIitV7fiQuEFfR/XVffx/oH98eekP7HqzCr8dPkn7L2xF6/3e/2W1x9odBoEuFT1cRn18ZYiqyILL+5/EcWKYhTIC+o994HOD2BYyDD0aNOjVi1rQx/v7N3ZbOaT3LkaFSAzxroCaAfgFOe83OT4eM553RHRnaqVlUiyps33b8bm5M349cqvdZ6zdcJWHMs6hpndZmLugbk4lHGo1jmze8xGn7Z9MHvPbLPgeOGAhRgXNg6uYldM6DwBD257EP+k/gMAmN9vPqZHTAdjDO092uOpXU+hUl0JrU5rrCkLAJ5ST7w76F1M6DQB7594H/MOzMPQ4KGYFjENg4MGGy+0TaHjOvhIfSAVShsMxIht6bgO5apyvHX4LRzJPGL2mI+TD/531//QL6AfkouT4S5xh1ggRr48H1G+UU14lzvvJtjg9wm/45fkX4yjvJb8OelPHLh5AE92fxLzD8+3uEBwatepGBs6Fo/vfNwsOH6r31uY2Gki3CRueLj0YUz4YwK2XdMvbXm196t4LOoxCJgAkb6RmL59OuQauf4mmFX3W3eJO/7b/7+4P+x+LD6+GK8ffB1bA7diesR0DG03tFmLaHVcBxexCzwkHhQg25mO6yBTyzD/yHz8m/6v2WPuYnd8NOwjDAwaiGsl1+AkdIKz2BlZFVm10gkJqU+DnxKMsRcAvAQgGUAvxtjLnPPfqx5+DwAFyHW5g0aXDCJ8IrBw4EIsHLgQ2RXZ2J++HxnlGfjh0g/Gc8K9wxHuHQ4AeKnXSziUcQjRbaJxvuA8RnccDZFAhKe6PwVXsStGdhiJPTf2ANCnS7RxbmN8nS7eXbBj8g7M3T8X93a412zLXkPaRIWqwrhZQ02xbWPx6/2/Yt25dfgl+Re8sO8FDG83HP/t/188vvNxvDvwXUT6RsJT6tngyJNGp4FQIIS/i3+9lUCIfho0MT8RhfJC9A/sjyC3ILPHG7vjYU5lDkqUJbhUeAmuYlfkVObgVM4p5MvzzWYUHgx/EM/FPAepUGpWJ9g0B93fxb9p38QtLMRt7Tp7d8aCAQuwYMAC5Mny8E/qPyhVlmLt+bXGc8I8wxAWHQZAX8JyR+oO9GnbB3G5cRgSPAQeEg+81OsleEo9MbHTRPx57U8AwL6H9pn9vwj1DMWeKXswd/9c9Avohye6P2F8zEWk7+PlqnKodWqLQW+0XzR+Hv8zvkv6Dj9f/hlzD8zFoKBBWDxoMZ7c+SRe7/s6Yv1jG9XHtVwLkUAEfxd/CpAbUKYqw9m8syhSFKG3f2+EeISYPa7jOjCwBn/mebI8FCmKcKnwEtwkbsiT5eFo5lGUqkpxLv+c8bxxYePwn9j/QCKUGHeqBGC8zgAwu3YQ0hiNuY1+FkBvznklYywUwG+MsVDO+QqgWZWO7gB37uiSqUC3QDzS7RGodWqzANlUhE8E4mbG4buk73C+4DxC3EPMFgeuGL4Cf1//GyImsvgBF+Iegt8n/l7ruKtIXxHDsPq+rp2vxAIxnuv5HJ6OfhrfJn2LLxO/xL9b/gUAPLtXv4DJx8kHQa5B8HH2wb3t74WHxAMDggaYVd3QcR2ErCpArrxzAuQzeWcQ6BqIAFf9xhj7b+5HJ69O6ODRwew8pVaJt4+8jV7+vfDt+W+RJ9cHGJPDJ2PxoMUoVhTjUuElRLWJwpCfhwAAfh3/q7GmbW5lLgoVhYj0jURcThxePfgqihRFDbZvVvdZmBU9C+4Sd2t+26CPPj1/F388HvU4tDqtWYBsqqNnR8TNjMMfV/9AXG4cAl0DsWjgIuPjS4YswdB2Q6HSqizeqAS4BuDX+2vPSBlugt86/BYAoKdfT4vvLxKI8EyPZ/BE9yfww8Uf8FnCZxj520gAwMsHXgagz4sOdguGl5MX7m1/LzylnugX2M9scyWNTgMBE6CtS9s76ib4XP45+Dr7GhceH8o4hGC34FqLFNU6Nd45+g4ifCLw4+UfkVmRCUCfy//RsI9QqtQHtb3b9kb/H/sDAH4c+yOi/aIB6BfR5VTmoHub7jibdxavH3odOZU5DbbvyagnMSt6ls02gSJ3rsYEyCLOeSUAcM5TGWPDoQ+S24GuEpbdwaNLlogF1RuJxPrH1npcKpTivg73Yc3ZNRgdWntx2/iw8U1+z5ol4xpKmxALxZgTMwdDgofg5f0vI0+ehwmdJsBD4oGM8gxUaipxJPOIMR1EyISIahOFcK9w/Kf3f/RpHAIRuvt2xw+XfsCFgguIalM9Zc85R5GiCE4iJ4gFYjAwpJenI0emz588X3AeDAwj2o+oVVKvPqXKUpzJO4OOHh1RripHoFsgtl/fjt+u/IZKdSXeG/we+gf0h1AgtDgqu+fGHmy5ugVhnmHo7tsdx7KOgYNDo9Pgvo734Z7292D79e3GIGRur7mY0mUKRv42Ekqt0vg6x6Yfw3vH38POtJ0AgOPTj+NI1hG8fvB1s/czPG7wb/q/iP4+2uL39vDfD2Nw8GDodDoczz7e4M9iQqcJUGvVmN5tOtq7t6+VR0xsx7R/1bw5AvR93LCT3wOdH6j1eHNyPpvcxwViPNn9SQwMGoh5B+YhsyITozuORhvnNsioyIBcLcfxrOPGtBwGhug20QjzCsMrvV8x3gRHtYnC2nNrcSbvDHr59zK+PuccxcpiSIVSiAQiCCBARkUGsiuywcFxruAcOOcYFjKsSek85apyxOXEoYNnB8jVcvi5+GHvjb346fJPqFBXYNGARRjSbggEEFj8GRzKOIRNFzehq3dXdPXpivjceKh1ami5FsPbDcfo0NHYd2OfcTBhdo/ZeCzyMYzZMsYsve349OP43+n/4fcU/YDEyRkncSTziLHMp8Ff1/8y+/pI5pE6+/iMHTMwIHAAhEzYqDUqYzqOARgwJXwKOnl1oj5ObKrBKhaMsf0AXuGcnzU5JgKwHsAjnPOmJ2zamc2rWNw8Cay/D5i5Beh8r+3epxU5cPMA1p5fi+9Gf3dbduXS6rTouamn8etuPt0sjkLV9dxiZXGtEesKVQXy5Hm4WHgRx7OOG6f0DQuMHuryEF7s9SLG/z4e5apyuIhcIGRCMMZQpipr1HszMPQJ6IMo3yhMDp9scec/HdfhcMZhnCs4h2/OfdOo1w3zDMNd7e7CrrRdeHvA27ir3V14atdTOJ1zulHPt5buvt0R7ReNt/q9hf8c+E+dWyg/1OUhbL6yuc7XCXYLxqfDP4Wvsy9SS1PRP7C/rZps2a+PAxf/AKasB7o/eHvfu4U6mnkUnyV8hg2jN1i9BrElnHMM/WUoSpWlAPQVL/558J9GPVfHdShSFNXq4zK1DLmyXCQXJeNI5hHkyHJwOuc0pEIp5Bo5xoeNx1v93sKEPyagSFEEZ5EzREwExhgq1BXGeswN6d22NyJ9IzG582R09u5s8Xs7knkE5wrO4avErxr1mh08OmBEyAjsvrEbr/R+Bfd1vA8v7nsRBzMONur51hLlG6VPtRuwEAuPLqwVMBvM7DazzplFAPB39sfKu1ciyC0IyUXJGBQ8yFZNtiuqYtFyNWYE+TEAGtMDnHMNgMcYY1/bpFWtnXEE2b7NaEnubn837m5/9217P6FAiHFh47D9+nYAwKWiS016rqV0DjeJG9wkbgjzDDOOap/PP48V8SsQlxsHZ5EzfJx8sOX+Lcbca0B/MdZyLeQaObyl3pBr5JBpZHATu6GrT1e0c2+Hbj7doNKqsPHiRvyZ8idO55zGhgsbAOjL4/UJ6AOZWoYD6QdQqa40q/Zh0MmzE7r6dEWhvBCTwydje+p2Yy7u9dLruF56HQDwwr4X4CX1QomyxPhcL6kXurfpjs5enfFMj2dwNPMo3jj0hvHx6RHTMSNiBu7/437jsfcGvYfUslR8l/Sd8diHQz/Em4ffNGvX8JDh6NO2D8aFjTP7uZoGUdO6TsOk8El4Ztcz2DBmA7p4d0Fnr85Yfmo5ZveYjedjnkeRogg5lTkI9Qw1K9vV5Pxha7iDF+LWZXDwYOMo8e3AGMP9Yfcbg6yMioxGP1fABBb7uIvYBaGeoQj1DDXOZl0svIjPEj7DsaxjcBG5wFPqiV/H/4r96ftxs+wmAPM+7in1hEqrgkwtg5PICZG+kQhyC0KUbxQ0Og1+uPQD/kj5A/G58cZa8P0D+qNPQB9wcOxO2w2FRmHx+wn1DEWkbyTyZHl4MPxB7LmxB2fyzkAsEONG2Q18d0HfF189+Cr8T/kbU5kAfRpJVJsodPToiDkxc5CQm4C5B6rT2SZ2mohnejyD8b9Xz9i9N+g9pJWlYX3SeuOxZUOW4b9H/mvWrqHBQ9EvoB/GhI4x2wjHdJT/gc4P4JFuj+DJnU9i7X1rEdUmCl28u2DRsUV4NPJRvNL7FZQoS5BdkY0Onh3M0lscNTgmLRvVQbaF9NPAt/cCj/wGhI+03fuQer1x6A1jhYtJnSfh/cHv2+R9OOc4nn0c3Xy6mS0QuZXXO5lzEvtu7LNYKUAsEKOTVycsHLAQ6eXpGBc2rsHXPJt3FuvOr0OYZxj+vPanMX/37wf+tjglDujzhnMrc7Hl6ha82OtFiAViyNQyXCy8CA5u3HyCc45cWS5KlCWI8IlAclEyfk3+FQ92eRBKrdJsGtpUbmUuTuacxP1h99tk+2+b2vwEcOF34MFvgegp9m7NHWv5yeX48fKPAIB72t+DlXevtMn7cM5xKucUOnl1sspiL8454nLjsO/mvlqbUwCARCBBiHsI3h/8Pq6XXsfEzg3X2k4qSMLXiV8j1CsU269tNwbHWyZsQRfvLhafo9QqUSgvxE+Xf8JLvV6CRCiBQqPApaJLUGgUxhrAhj5erChGN99uuF56HRsvbMS0iGmoUFWgT4DlAdACeQEOZxzGpM6TWl8fv01oBLnlsmqAXJV6IeScKxs82Y5sHiBnxAHr7gFmbAa63Ge79yH1+uHiD/jw9IfYNGYTevr3tHdzmk2mluHLxC+RXZmN//T+D/xd/M3yupurXFVug8Vrd4jNTwIXtlKAbGd/pPyBhUcX4qt7v7qto9fWptAo8FXiV7hZfhMvx76MILcgY+rGraA+3vJRgNxyWXujkK4AzgCQWPl1WxmqYtESPNLtEfQP7G9W6qc1chG74NU+rzZ8YhPRhfMW0GhYizCx00RE+kbWOULaWjiJnDCv9zyrvy71cUKar+Fio03X6hbtWZ0xPqYA2Z4YY60+OCYtHPVxu2KMtfrgmBDSMtkiQCY0gkyIg6M+TgghjqxJKRaMsT0A4gx/OOc3bNKq1o7qIBPi2KiPE0KIQ2tqDnIFgEcAvAmAM8YKAcRDHzCfBqCwbvMahzEWBmABAE/OeQtYMUOjS4Q4NurjhBDiyJqUYsE5f4Bz3h5AWwD3A1gNQA3gKQB/ANhZ97MtY4ytZ4zlMcaSahwfzRhLZoylMMbeaqBd1znns5r63jZj2LGskUXjCSGtDI0gE0KIQ2tWFQvOeT6AHVV/AACMsUAA/QDU3ku4fhugD7Q3mryWEMAaACMBZAA4zRjbBv0CwOU1nv8U5zwPLYlhu08KkAlxTMzQx7X2bQchhBCbsFqZN855NoA/q/405XmHGGMdaxzuByCFc34dABhjPwOYyDlfDmA8WjrDCLKOLp6EOCSaJSKEEIfWUqtYBANIN/k6o+qYRYwxX8bYVwB6Mcbm13HObMZYHGMsLj8/37qtrfVmNIJMiEMzplhQHyeEEEdk7Y1CrMVSFf46k/0454UA5tT3gpzzbwB8A+h30rul1jWERpcIcWyURkUIIQ6tpY4gZwAIMfm6HYAsO7Wl6QQUIBPi0OgmmBBCHFpLDZBPAwhnjIUyxiQApgHYZuc2NR7lIBPi2IwBMlWxIIQQR2T3AJkx9hOA4wC6MsYyGGOzOOcaAC8C2AXgEoBfOecX7NnOJqEcZEIcG90EE0KIQ7N7DjLnfHodx83KyLUqxtElungS4pDoJpgQQhya3UeQHRIt4CHEsVEOMiGEODQKkG2Bpl8JcWxU5o0QQhyaVQNkxtglxpjGmq/ZKhmnX2kBDyEOidKoCCHEoVk7B3kNAF8rv2brYxxdoosnIQ6JUiwIIcShWTVA5pyvtubrtVqUg0yIY6MAmRBCHFqjA2TGWCKABABnqv4+yzmvsFXDWjXKQSbEsRlugnUUIBNCiCNqygjyDwB6AXgeQGcAYIxdQ3XAfAZAQtW2z3c2KgFFiGOjEWRCCHFojQ6QOecfGf7NGHOFPljuBSAWwCMAlgAQMsYyOeftrd3QVoUW8BByZ6A+TgghDqlZOcic80oAR6r+AAAYY1IAMQB6WqVlrRnlIBNyZ6A+TgghDqnZi/QYYwIAXQCoOefXOOdKAKeq/tzZjDnIdPEkxKHROgNCCHFIzaqDzBiLBpAC4CKAZMZYWNXx9lWB852N8hMJcWyGGufUxwkhxCE1N5hdBeAQAH8AcpPjLwD4/FYb1eoxBoBRfiIhjo4CZEIIcUjNDZB7A1jKOS+ocfxvACNurUkOQiCk6VdCHB0FyIQQ4pCaGyBXApBaOJ4OIKT5zXEgTEAXT0IcVlWKBd0EE0KIQ2pugLwVwBwLx/0AKJrfHAfChJRiQYijo5tgQghxSM2tYrEIQAJjTAh9kM0ZYwEAlgI4ba3GtWpMQFUsCHF0dBNMCCEOqbl1kAsYYwMBrAbgBCAZgBBAHoBR1mteK8YEME7DEkIcC1WxIIQQh9bsOsic80wAD1SNHPcCoAZwinNeZq3GtWqMVV9ECSGOifo4IYQ4pCblIDO95xhjXzDGHgUAznkO5/wfzvleAGLG2NM2aWlrwxhoBJkQR0d9nBBCHFFTF+l9CH0N5IcAbGCMfcUYEzLGHmeM7QWQA+ArazeydWI0/UqIo6M+TgghDqmpAfJ0AE9yzv0AfADgaQC7AXwMfYm3xwAEWLWFrRWlWBDiwLjZX4QQQhxLU3OQAwHsr/r3hwDmQ7/l9GjOudqaDWv1aJEeIXcA6uOEEOKImjqCLIB+MR6qFuPJAHxOwbEllGJBiMOjPk4IIQ6pORuFvMEYG8kYcwWggz5IJjVRigUhjstY5o36OCGEOKKmplhsATAZwCsANNDXPl7CGDsO4ByA85zzYus2sZWiFAtC7gDUxwkhxBE1KUDmnD8EAIwxHwB9AfSp+vstAEHQ76iXxTkPsXZDWx9KsSDE4VEfJ4QQh9TcnfSKAOyq+gMAqNowpB+A3tZpWitHKRaEODBKsSCEEEfW7J30auKc5wDYVvWHUIoFIXcA6uOEEOKImrNIjzQKjSAT4vAoxYIQQhwSBci2QikWhDg+6uOEEOKQKEC2FcZA06+EOChjYEx9nBBCHBEFyDZDVSwIcXjUxwkhxCFRgGwrlGJBiOOjPk4IIQ6JAmRbaSlVLBRlwOFPAB2NdBFiPS2gbxuoZMChjwCtxt4tIYQQh0EBss20kBSL3QuAfe8ByTvs3RJCHE9L6OMHPwD2LwESf7R3SwghxGFQgGwr9kyx4Bwouan/t7Jc/7dWaZ+2EOLI7JliYejjqkr93xrq44QQYi0UINsKE9hvdCn+O2BlNJARZ5/3J+ROYa8+fv43fR+/dsA+708IIQ6OAmSbsWOZt5sn9H8Xptjn/QlxdPYu85YZr/8776J93p8QQhwcBci2QlUsCHF81McJIcQhUYBsK/ZMsTDVEi7gygog/bS9W0GI9VEf11PJqmeuCCHEAVCAbDPM3g1oOX57Evj2XkBeYu+WEGIltJOemb/mAutHASXp9m4JIYRYBQXItmLvKham7bCHK7uA4jT9v7PO6P/WquzTFkJs5U7u4yl7gYKqdQ455/V/qyrs0xZCCLEykb0b4LBYC6mDfCt0OkDQzHuoHx8GhBJgYb5120RIS9Lq+7hWnw7WnCD7hwf1f79bat02EUJIC0AjyDZjxyoWjb3YXdsPHFlp+bHSDOA9byBhU/PbYRgxbgk5koRYk72rWDS2j6cdAQ5+ZPmxykLgPR/g5Fe33h7q44QQB0MBsq20hioWmx4A9r5j+bGCK/q/k367fe0hpLVp6X18wzjgwBLLj5Vl6P8++3+3rz2EENJKUIBsK/asYmGNi7Y1L/z2ypEkxNZaQg6yPV/DgPo4IcTBUIBsM3ZMsbAquvARUjfq44QQ4ogoQLYVJrA8QrNhPHDuVxu/N13wCLktLPXxHx4E4r+37ftSHyeEEJuiANlW6qpikXYY2PqMbd+7pedFEuIoLPXxlL36usA2fV/q44QQYksOESAzxroxxr5ijP3GGHvO3u3Ruw0pFrkXgPgNDbShBaCLOXFYNv7dzr8CnFpbzwnUxwkhxBbsHiAzxtYzxvIYY0k1jo9mjCUzxlIYY2/V9xqc80uc8zkAHgbQx5btbbS6Uiys6ctBwF8v13PCrbx/I5+rrAC06lt4H0JaIUPftnUfX3s3sOO1+hpyCy/ehD6uoU1+CCF3FrsHyAA2ABhteoAxJgSwBsAYAJEApjPGIhlj/9/eeYdLUWR//1v3Xi5BclIkSBQXFQOo6xrXnDGLYc26wbjJuLuyP/Pquq6ru4rhRUUx4OpiRFQQMwKigEgQUZIEkZzvrfeP032npqe7p3pmeqbv3O/neebpmepQVdN9uk6dOnVqV6XUK55PR+ecEwC8D+Dt4hY/gFIuFFII/0S37cx2rds7A8NPjr88hCSRuGU8aGW6gsi4trvW7Z2BRw8PP4YyTggpM0q+kp7WerxSqrsneW8Ac7TWcwFAKfUMgEFa69sBHBdwnVEARimlXgXwdIxFtqSEDUZBrVoW9fhmfAHzI6Q+USTXAq3TldBiy/jiKQXMjxBCkk/JFeQAOgOYb/xeAGCfoIOVUgcDOBlAYwCvBRxzKYBLAaBbt24FKmYIxXCxyF6I0mRb8noTEjdFcrGoy04HWGlpuSWEkDhIqoLs99YPbIm01uMAjAu7oNZ6KIChADBw4MD4WzWlgNqa2LMJpwj+ib6n6vDfhJQLRXOjCpKhEsl4xqUo44SQ8iIJPsh+LADQ1fjdBcCiEpUlD8qg0cjJtzCg3mxESdlRRAtyXBTUf5gWbUJIeZBUBflTAH2UUj2UUtUABgMYVeIyRaNBu1gEWdVK/X8QUmCKJuNB+SRNIaWME0LKg5IryEqpEQA+AtBXKbVAKXWR1norgMsBjAYwA8BzWuvppSxnZJQC1i0DHj4EWPKlpJVcYS4S3nq6Fiqb+m9cBdRsLXyZCCkk7rO8cSXw8KHAos+Kk19SiWKF3riaoSEJIYmn5Aqy1vpMrXUnrXUjrXUXrfWjTvprWusdtda9tNa3lrqc0VHAiq+BhZOA0ddLUikauZI0rHn4S97RDRh1eUFLQ0hsrPwOWDgRGHVFzBmFyE7SlWcvd3QFnj+/1KUghJBQSq4gly3K+GubtHa+1KOGLJ9GN8jFIts13f2fj8g9b0JKQZ2Mx0QcSnApX0dfvVLCzAkhJDtUkOPCHHJs3tH/mJotwLrlxStHEJvWhF0gep65RrEo1cIqhETG80y36OR/WM1WYO2ywudnYiPjG1aG7CzgoiOEEFImUEGODaPRUZWy9TYio64E7uoVrz+eTcM16spCZxox3d3NRpbUUxo19U8ffQNwd2/xrc+HMNmwkZuRF+SXv3WeSZs0SAghuUEFOS5MF4s6xdDTqEz/r2xr85yUlq9iufLb/M73YlqCV8wF1jtW8potwLt/AzavDzqxsOUgpGgEPLuuK0HoKE0e17dlxdw88/dgyvjK+cDymU56DfDuXTIRjxBC6jFUkOPCVJDdxqQUFtKcY5zmWNYZLwN39U79fuLE1PfPhgNjbwXevTMgS7pYkHpChhtRCZ/dYsv4nLeAO3ZI/X7u3NT3r14Fxt4CvPmnHMtECCHJgApyXFQ1Tn3XARbkjP05ku/wa9h5YY2v37VfvxbYujH1e/O61PeaTU7aWvvrEVIfyPbollrG/Y6xkXE/xgwBNhsW8TQZ3yzbTbQgE0LqN1SQ46J6m9T3QAtyofz1vNf1aQynjgS2bMxMz0pEBXnrpuCyuFb1oCW4aUEm9ZXAZ7eIMj7laWDLBsvzTSKWsSZMxp35FkEyTggh9QQqyHHh64McRIzWJdc6NPM14IG988snI18fpcA74dBsKN3/RAc1nrQgk/pKzM+ujYwvmgzc0y/g/AKWxbUSu5gyXuFOSM4x1CMhhCQEKsjFoK6xiMnFIuO6hkXIvHahJ+P51cfbeGof69LsMcAMnziotCCTekOxfZAtZXzDipjLgcxOsFl3txP89Vhg2n8zz6WME0LqCVSQi4HbgAUqwjFakHO/qMUhfhZkr4JsNp5Oo75mMfDs2T7Xo3WJ1FPifnYL3okOSrPARsa3rPMPLUcZJ4TUE6ggx0WTVqnvUSzINVuBTx+VrTUh/ok5z3C3ON934o/HfSJNic5SFlqXSH0lSqSa2lpg4mPA1s3Zj01lEPzbRsZtXDRs8ZY77dqUcUJIeUAFOS72vRzoPND5kcWCbDYaE4YCr/4OmPiofV5B1928Nl6LjU1j5zf8GnxwXsUhpGi4ctXF9evPNkpk8MWzwCu/Bd6/J3p+XuKWcT9CLciUcUJIeUAFOS5adgIueRto1dWiATP2u4tqRAq0H+Cf+OrvLM+PMY5qlMZz5Xc5loOQEtC0LXDxGKBdn2iWUddPOHT552w4Mjv2Vsvj8wz3aJKPgrxqQW7lIISQIkMFOXZUtDjIbmMTZdgzoxGL6mKRa+MZ0YJckeVxe+jA3MpBSClRFjJuUifjEV6/+cp4zvHQo8p4Zfix/9ozt3IQQkiRoYIcN0pF80+sC94f5dbEMGxpVdaIjWfBYsISUmo88b1zkvEo8pDvRF4fWaWME0JIIFSQ40YppBo3GwuyM8ktioK8eV2M7gkRJ+llHGM0nu/cnLl/5uvAqoXRi0VIqalTcC1kHHnK+Jb1wI/zIhXPnogy7lXsTRkffX3m8bPHxFh2QgiJByrIcRNmXXIbGrOBcY/JNlRpMuw44N5d7Y71U6R9Fd0CWZeyXWfEYOCRQy2uk4XaGmD4KcC8D/K/FiFRUBXBoRzrZNzHjSqKjI84E/jnbnbHLpvlk1hIGQ9RkP146lTggX2y55W1LBp4ejDw9Tv5X4sQQrJABTl2bPwTjfTaHKxLy2cG75v+YvrvRZ+F5+8l3zBxYbj/y5rF+V9r7RJgzlvACxflfy1ComDlg2zKeA4+yEumBe/79JH039++75O9X0hGm/kOBeoob81lmXufa8x6XToLhBASM1SQ4ybNxSIA30l6EaxLpSLfmKaMiUrqK2krRNZTGc/VBzlDoWboNkJI+UEFOW6sJvD4NZ4lvjW5NJ6RFjdBylpeCLhCFyk6hg9ysWQ85+e8QC4WtTXhy8kTQkiZQAU5dlT2BsR3kl5Mrg2+Q61h5Yswgcdvgk5oWUIU5Fpal0k9wfRBjmsirt91ohwTmhZBxv3iLuc6ErRpTbTjqYgTQooIFeS4qRcW5ALFSJ39ZrTzwyzIYcqzH26HYs1iLkZAioDHxSJSmDd3kl4uCnKuHccCWZD9JsiFlSmso7tlQ/b80zOSzdaNwI/fRjyXEEKiQQU5bkLDvPlFsYhZQfazTBd02DbK6WEW5IjuGib/2Dn3c0vJslnAh/eXuhTEFleWVAUiyXguE3HrsJA5Wxm3kvs8J+mFyXjU9455/D/7Rzs3KayYC7z/j1KXghBiQVWpC1D2hIWAcvGdwBOTgpxzQ+l3LW/DGNEtpM6C7HNeVAW5HIZfHzkM2LQK2OeXQGWjUpeGWGNhQS6UjFst3GFrLc7FXcNP+Q6zIIcpyFGt4WUg408MklCbe/wC2KZ9qUtDCAmBFuTYMXyQN60OOMZsPHOIg5w3BRp+jeo3HaYo5GNBrq9sWlXqEpBcMDvBm9cFHKQzvxdzkl6uHWMbGc/ZghxRQS6HqDcbnTag1JOwCSFZoZTGjemf+MzZ/seYDVVew685EtZQhim95nmb10ePSjH1efdCmfuiXqsQkxpnvgEs/iL/6+RLOVjDyx1vmDdXxl/6Vfbjc4mDnLpQDucEnWex5HWGjPt0XMMU1xmvhFw7oowXQi7mvAUsnJT/dXIlKVGKCCFZoYtF3Jg+yMtmpNJnvAJsca1NBYqRqnXho1989QqwaS3QuLlPfkbDeFun6Nd+47rM67iUwsVixBmyHVJiS245WMoaBD4+yN9PTe2e9Sawyl25slAyXsBnw5WZ7z4CNqwEmrYOzy9IxsNk77U/Bu+LPEpUABkffopsSyXjdR1/doIJSTrsxsaO8m/UnjWsyWmT9AoQAqoQyqJ5jcBGLsaXfCFW16u3sPGsXyh/2Xv6tNT3Usu47+FG4osBlu84n8XVi6IdXw4jK+69L4e6EFLmUEGOm7QYqQH4TuDJwRIcVwiotd8HnBbjS37owRFPKKMGh41nPcB0sYgaBznmSXr+J/okGWlrApRVq/zCXLRCTht2rMW1zWzKQC5qqSATUl+gghw3KsCCHMT0F53z8vBPjDxZrkATeEpJOTU4SfpfSTB1Yd4irqT36SOyzSUOckOW8XLoBGu6WBBSX6CCHDdpMVIDcBuqNUvyyyuuZWhtQleVmkQ15PmSoP+VZCct1nkArqxsNHxfK3II5VfvZLyAcyKS9L7JlSgLyhBCSgoV5NixsSA7L8vlszLTopDry9evfLQuReOly4D/7B/9vFULMlcUS9T/SnxJk48oMj4nlVSRwxzpnGW8DCzIpS7La38E7tsj+nmrF2WG/yt1XQghWaGCHDdWPsjOy3LzWiMtF4XP4pzFnwMrvvGcVqA4yKWk1BaZKcOBJVOzH+flHzsDI85MTyt1XYglRhSLuslzATJRJ+NrzMR4irVkWroiHphXEWS8oFF1SiwXE4bKSnhRuecnwOPHexIp44QkHSrIcWPjg5x1kQFL3OuENUrv3wPct7v9tcKo2WRVrOKQkAYnF+V27ljPNRLU8SDZSZPxLK4Kpozn8qzYyPjEx4D7B9hfK4yazXblKgZJ6TjW5LCIkTf2MmWckMRDBTlurCbbuSvtGdalnBrPCMOvQ1pFv76XLRvzv0ahSErjaY4CZD12fep7UspPcsDwQQ68ja6Mm6NEOShJucp4rqNEW9ZnPyaUMrIgu2xYYX9s0DuS8k5I4qGCHDu5WpBjcrGwPc/mBZ5341lAktLgrFtuf+zIC1Pf08KAJaQuJARvmLdsMu5s0zpQ9UHG8+wEF9LFIilW1ygy/vKV/ulJqQshJBAqyHGjlEVDVKjh1xxfurlal7bGaEGubBzxhIQolet/sD927rjU97SFJNh41gvSwrxliYNcb2V8Q/ZjikWpO47uO2l9BAX52w8DdiTkfUUICYQKctxECQGVr3XJxj/R/8TgawHA2qX+p3mjL7i06mqX7c4nyXaH/TL3tba8hkuplUo3ZFcUBbkuJio85Q+5948dBQw7LlLRSMyYoRyzhUvLd5QoKTJe1cQu252cZ7Xjzpn7Wna2u0YdJVYqm7aRbRQZDyLsfTX8FGDoz/PPgxCSF1SQY8fGxcKd4Z6ndSlbIx14Whbr0tLp4s84e0z6IUEWZNvGu1l72bbcPrMMtTWZx4dRautS09ayjTL8GmQ1DntevvsImPdepKKRGIga5q3QkWoK8rybCvL3IuPTX0o/JEhBVpV2WTRx/KDb9sjcF1nGS9wJzkXGgwi7f3PeAhZNzj8PQkheUEGOG5swb9DAJ0OBiY8aSblM4InZP/GTh9J/BzWetsWom3BUm9lY6oiNZ2KsSzkqyDaLNpCEYYZ5c9NCXCw+Gw58dH96WlQK6WLhl/bBP9N/5+tGZcp40D7ra5VYLhq3lG2kUaIsLjc5nUsIKQZUkOPGNszbG9d5E6PnlesL1bfxtGi8arbklp83D60zFeJan/xra8W9YPZbwdfKuSye/+DLUdHC7lU5/omFsCCXWtkn0bBZalpr4K2/ZqZFpaCdYBsZzzPMW118aL/8AzrBT54EzHjZ72L5lcXLV6+lr2yYDXdkLJIFOaDja3Mfa3MIJ0cIKRhUkOPGZqlp6MxVtcwX6LQX7PxOCzoEmU+MVMuGzLQuecvuV5dNq8W94KlTMmfX52ttMc+f/ynw3C+AMX+xP99V6NdHCAGVlj8n6dUvzCgW5jyDEIth2Mp5X70GPHKYf8cw7TJFnqQX2AnORcYt3Ki0Br5+B3j2nPSQeO6+QrFsFvDMmcCrv7c/x1VYI1mQg9yobBTkqKNohJBCQgU5diwtyO4QfSox9XXkhZZ+p0UOAVUoCzK0pYuFUaZJw4L35VQWI7+V38o2iqWorvHM0T8xauPJ4dfSU+drb2lBdn1YzTSXkRcACz61WHyn2DKerwXZkHGbTrBpNf3wPs/xBXzmVy+Q7Zrv7c/JRcZzmWdQdwwVZEJKCRXkuKmozG4J0Do1ieXEB1Npfsdlu04u+J5mYXEKajxty2EOv2a4WPj8Z6Z1zZt33i4WxvnujP5mbe3PdxvPXCfwRG08aV1KDlYyXgu06CTfTxrqJvofF3qdArpR+R+Y/jNvGTfdqCwUZLPTvdXbWSiggrx2mWwjybhT3nUFsCDb1IUyTkhJoYIcN6rSQuFxLKg9fw70ODCV5sWmEc4Jy4ba2ygWyro0Y1Sma4Kf9cTML6OxDWhwRt8IfPygfVkAYPlM2TbfLvt5LrkMv6blb5bfxoLMxjMxqErjfoS4WNRuBbr+FOhzuJPkZ0FNmoznO0rk1GfOGGDtkvR9fnXNRcbfvhl4/16LshjnL5kqW9uQlEABXCy0f3rguZRxQkoJFeS4sbUg124VH0V32DbKpJbUATkV0TcvG+tFofwTAeD9e2S721lA1338fTHv2Skkj4A8P7ofeOPa7GUx67v4c9lmHe72Ob8QCnJcFuQP7gMePiT6eSQT83GrqErdjzAXi9qaAsh4AbGS8TznGZguE28Nke2upwHdD/Cv67/2DM4jSC7euxt466bsZTH/74WTw6/ph6kgR7WgZ3y3sSDn0Bma8DDw732jn0cIyYAKctxUVFrMRjYUZDd0lK8FOct14rYu2Q6/Wmdr5OE21p33BDoPSN83d5yPhdnbeObrg2zkt2iKbDOGeD1sXgd8M16+u/dm0+rs5/nxoRFey8oHOQdFasyfgYWTop+Xlq8GPn8W2JygZcZLhiOraZ3gLBbkikqEy3hcFmS/a2Xx8wfyl/FaHxnvtBvQde/0us57X1ybzA5mhhwUUMbnfyLbbGHstmwEvh4r310Zr91iH/3CzPPDf5k7LM7NQcZf+wOw9Mvo53mZOhLYuDr/6xBSj6GCHDcVVdlfdHXWpUon6gVyHH4toI9ePtalfKwr7n/g/mdbNwNPDAL+1iP4XJs8syl0affIuVZQnGeXl68CHj8eWDJdFlpwiRI6ysUbfzYbpfJP/PYD4MVLgdE3lCb/JFJhuFiEWpAtRokSJ+MBnXJrGa/J/K4qMl3Phh0L3N0nPI9seW5aY18WV9n1RsPxMvoG4MkTgfkTgB+/SaVvXBl+Xl0+Rh3H3WaUJcHzDL6fBrxwEfDylaXJn5CEQAU5bpSFBVnXJs/FwsZ6USj/RAD4fIRsVUW6Ra7W1o0jS91fvipLWYzzux8AtOqWvcH93vFjfM9xD+m0m2yjxE/2LYuNf2KJQsG5yn+U2f9liRnmLaKMh1mQ45Jx30vl42Jhifm/fPk/2apKx5KunY5D0LMcUcZfuDh8vykznQcC7fvKiE8Yy76SrevjvN2usrUdQQmS07hGiaJcPwh3tcdVC3O/BiFlQFkoyEqpg5VS7ymlHlRKHVzq8qRh+icG4jf86kMxJ/AUwz/Rr7yqMn3Sk62V2q9BMBX47z6yL0vfY4AOfYH5H4f7AbrW/mkjgU67Awc4MVXzVpAD/j8zQgZnuJcetzNbUWUogmEuFhY+yLG5UflQbB9kl4rK1FLVtTXBnWCbqBfmf+i6OwWWxahv36NFxhdMDLaSAykZn/kq0GEn4FDH19lWxgMV5IB005UsHxlnLHVC8qbkCrJS6jGl1FKl1DRP+lFKqZlKqTlKKe8yc140gLUAmgBYEFdZc6KQk/TiGn7dsNLnWgFB/E0K6WLhUlGZ/p8FDvHaLCxiWIBbdQkvi/nf9j8D2PlEYOV3wORhIScZnZm9LgIabSPft2SxLs2fAMx4JXi/X11WfAPc1Sv1++0h4XnEhXtvVUhHrqFRUZXqSAW6WKBAPsiFtCDnEcXCthx+9VEKqHBdyWpC8rBwozLdoNp0Dy+Leb3dBgM7nySuUROGBp9jMvBCoFEzJ98sCvLCSWIx3xrkpuVTl1UL013JXvujXbn8yGcVPso4IQASoCADGAbgKDNBKVUJ4AEARwPoB+BMpVQ/pdSuSqlXPJ+OAN7TWh8N4FoAnvVcS4z1JL2aAk7Si9iIbt2Q7je7Zgmw9Kvs5+XrYuFnnVUVQKOmALTEG7W1LvnV2XWBAIBm7cLLYl5vm3bA7mcDbXvJxJqg1fHMc/qfAVQ7CvLmtf7Huzx6OPDs2WGFyUz69JH0358Nzzzmg/uAIa2AlfPD8w+yim9YCQxp7b+UdwYNvPE0lbU0Gc82SS/fTnCOMg6kx+9dtxxYMi34WJe8XSz8FOTKlKK5dml+Mm7WoUWWsIzm9Vp2BnY5Gdh2V+Djf6fiIoexxzmGjGdRkB8+BHjuXLuyuHzxTPrv2aMzj5nwsMj4irnh+Qe1FZvXAzd3AL4cFX4+gAYv46TBE7L2aXHQWo9XSnX3JO8NYI7Wei4AKKWeATBIa307gLA1l38E0DiWguaKzSS9pTNkZadlM0sXAmrN9/LS3rgaeOjAgEkotjPcc5jA46Iqge33kO/PnOmzwqB7roWLxYIJsm29Q3bFw7X67uX4MSoFHDZElpz+Ww9gz3OlE1FZDVQ1BmYbcV1Pf1LSqp1GP8w/0VTag7C1zk0dCXT7KdB8W6CykUSpAIB7dwHOHQX0PEh+z31XrNZ116+Bb994yXQAGnjv70Cfw9L3zXtfLOqNW9iVrUFgRLHINklvxVzgh9kQ2SiRD/Kq74DKKokU8cQguZ/Zrh+HjFcYMj5icMqvN+NcizBv86PIuGPN7T849Z499C/A06cBd/cWBXjTWilf4xbAV68C6xzF+aShohzXKcghMv7D1+HlAPz/Pr9nZ8rTQM+DpYNf1ViiVADAfXsA57wA9Hbk9LuPgTlGxzZIQf5xntzTsbcC/U5I3zd/grRF7fv4nkpIQ6PkCnIAnQGYZrAFAPYJOlgpdTKAIwG0BnB/wDGXArgUALp161aocmZHWbhYfPGsbBdONBLzGX7Noee/ZYPEz1yz2OL6DkGNZ7aZ4S5+9amoAHocLMOf019CYENs42Ix/1OZiFPdLFzx0DoVf7XPkan0fidIA/r2/wGTn/A/98jbUg1NVVPZhoWO+jaLLzQQMPTtk/bCRbLd81zghH+l73viBODyidLYPeFpCGu3ikLtxW1UKyoz9w07VrZnOJZrDr+msJmk95XjUvPDHCNSTbFlfCPwyGHA8lkh1/f8Dholsh3C97UgV0is893OAj5/OtiSbeNisWCCTKht2Tm7360bR72vMWC54xEiw6Nv8B+VAYBD/gTsdoZ8r2oi2zAZX/RZeDmAgLL61O+lX8u234nA6Y+n7xt+CvCbj4GOPwEeOzJ9X9BzZEYS8fKos4DNBa87x1DGScMmqQqyn2QGmiy01v8F8N+wC2qthwIYCgADBw4soCNfFmx8kM3JVwUZfs2B4SdHX+QiqPHcZBnmzK+RVRWiJB94DTD9xeBzpzwF9DhArCsAMh4PrYEFnwI7HSNWkbD/Zvns1HfX6upywO+BfS8HPnpAYjT/OE8sLXv8QoZ02xo+g1XVsg2Lg+ynfGbgZ1kMeWRnj/Efcr1/IDDE514EKTd1jWdIwxhUjgf2EbeU/RpgaKi0ibhBEywN2aqTcb9QjjFO0nvuXGDd0mjnFDKKhYuqlP/goGtEQQ7ii2eBnY4zRjP8FOSJMoqyZkn4f2Nay/t4lMl9LwP2vlRkvFN/YPUi4NsPgf6ni2Xa9G2ucgYowxTkCptm1U/GQw6f+Zq/xf/fP40m4+5zqkLeQ0Ey/tBBMoH5YIuFlwgpA5Lgg+zHAgDmGqBdACwqUVnyw8YH2Y2vWd3c6NnnMfz65UsRCuiQphxbWg7ybTz9FGz3xd1hp2D3CkAs3U8MSim33pf6hh+BDSuAjjtnt+K71r0L3kg1gCZVjYEDfifK+IDzgRP/Deywb7pyDNhZl2waT1vrkktlI1FQbdm4Cri9KzDrzfR01zc5tIyecoy7QxSvZV+Ji0cuq3/VSzw+yAgLVwZg6XTjRwFcLNxnNgqmchwmWyb5zjPw6yy6ncQ23YEW2wefu2U98NQpKbck79+1ZQOweiHQsZ90qkNl/DXZnj0y5QplUtkI2P9qoNch4mpx4r9F3tv2SO8w1inIYZ1gGxn3u/chz09ltVj/bdm8DrizhzMKZ+bh/EehHXXPKMX79wIjzgQWT5FYzoygQxoISVWQPwXQRynVQylVDWAwAJtZBckjLQRUAJ12l21tDepeSjlZlzSwenF+M5iB7BPaXIIaz+4H2J3/7fuZae6Lu6IC6Paz7NdwffKCfCcbNXEWHglofJZ8Cbz9V2CH/cUSlQ+lbDyjdFaWTJf4r0+flj7ZSFtYl9wG11Uaxt2eim8LiM92Q8HVm9xnNkzutjeWUK6zIPscZ+NisXmdKIb5UG3pSx70XLnvrGx892FmmmsEUArYwULGX75atl4ZqJPxppkLj5ismCvLzXceAPQ61KrYgbid4LBl6G1GiSJ3gqtTcx5sWPmdGAiePy99Rby6TnBIGV13Mvc5fesmsWC7DD/ZvhyE1GNKriArpUYA+AhAX6XUAqXURVrrrQAuBzAawAwAz2mtp4ddJ7G4k/TChsgvcF4+NZvCXSwWTQGWzxGLyoYfM/d/9Ur2pVNtWL88YIelD/LZz/un9xuUPW/TN2773YOPO+Mp2c4dJw1AUONZWe1MogpoPEdfL9sjbs7f5y5OC3LY81MZcV6qGWXjtu2BVU5kxFoL69L0UE+m3Cyb9R33noZZfy9+2/gRYkFePMWR8Wn+0VOmv5i/VReQCXu+WMq466fqpc7lKQRbGT/xP7JdONFxUQkIQVdZnb76ppfRf5LtEbemwsvlSqWFG1VYB7OOiG5Ubr62mDJ+R9fUxEH3foaV0Z0TE8TccdHKQkg9peQ+yFrrMwPSXwPwmt++eoX7IgqzALqTuzrtjtDG83+/Cc/rnZvD/XYLTVDj2aipf/rPrhL/vgWfBl/TbDyDrgMAfY6QBu/NG4F576XCRtWVzWk8KxoFW5DX/QDM+wDYYT/xL84XV1ENs+bm4oNcsyVc+fKbcOey1acsmzxh6BZMlDjRNhbkOnLoTNTWAOPvAr4eC5z6GNCqs6SPvR3oczjQZaBYuPJVYoqBqcwoCwuyW6d2vcM7wa/+3jjH5/X84X3A1+9EK2s+BCnjfm4KAHDAH+T/+Ppt//0A0p7vJq2DD+t7DHD8fbLk8dyxQKuu6fvrZLwquBO8cZUodJ12F7eofFFKOsJhnWCbaEMZHfpsMh6iIPvFivd2rr55F2jXK2X5tnoP5SDjWgPv/wOY9QZw0oNA256SPv5uGS3Y4Wf1R8ZJg6fkCnLZUzf8GvLyq6gALn4HaNczvfGsrQE+ezJ1XJsewM8ul9ihc9+Vld682MQ2zRXbRQT86Hci0GUAcLETimje+2KF8Q7XmcOBXkXOpKJSJtaMu12G/b2NX511yVGQ/cr62ZMSg/XI2+zrEUZFhSjkYY2njf+e+Td/cJ/49rbtFXi4r9+0y1s3ZaZ98mD67+fPAzpPSyn2ZuPpDulH4YWLZSJU/9Pk96IpEjZw5Xy5XwDw30uA81+V/+PdO+Rz0HWy/fMPEo4s8Rgr6QHZ7+2l4yTigtkJrq2ViWruM9O0LXDIjaLgzHk7ATIewXWn+wEycbaH42L13Sdy358+Pf04c1KyudCHl4pK8Qd+a4i48ex4VPp+c5RIBfggf/6sLOpx1B329chGZWP/jmdduSzei+b/PPEx4JXfAtvuEnx8VYiCPP6uzLQP/pn++5Xfyv1xLd/ezlfYu9aPkRcBvQ8Fdj9Lfn8/VVxAtmwQlzUAGHEW8Bsnas87N8v2iFuAN/8EXL8QaNw8Wp6EFBl24+KmTkHO8tLsMsCZOGM0nuPvBl6+KnXM/r+VOL0/vwG4aDTw+5n5la3vscDpjr/ZnucBv3wPuGml/fnZ6mTiVeK67y8v2F1OSa1AB8jKVi57hCymoSqk0eh1CDD1OWkATLyNp591adZoicEaNswblaommWHunj4D+NxZBMDmP6vdCrz4K1kQwI1tvCIktmqYdWnBxMy0pV9mpr17Z8rVwn1m1y4Ti+XtnTOPD3NHmfo88N+LU7+HHiQTKkddnkr79gPgrt7piyF84gyprwmZj7tmSboCsnpx6Yd8bXyQAYn9u0279E7wR/cD/7ssdYwr4wddIzJ+zTf5la3nz4FzHR/xXU4BLn3XP+pBEFEUZK+Md9sH2PFIifhijvCsMWTcG4vXRDmravY5ApgxKnMELc3FotLfIj/rDbHaF8J67FLVOHOFvOfOBSYNk+82Mq5r5N0+pFXq3RXW8QmT8cWfZ6b9MDsz7Y3rU77r7kjduuWy+EhUGZ82MhWCDgAe3F/Czj17Tipt2Qzg5vbp8ZknPibbVSGLGa1dmt4BWbs0/RqEFIn6YKap39QtPxxiKTExG88v/wd02xf42ZXyYtvTszJTi+0k1u39A6OV6fJJQJNWMoGtcQuxXnfqHz5U76W2RiwGFY3sGoSgF/ypzgtz4SRZfarXIal9rbsBV0wWZWrO2+nROdz/qcte0nh6MS3I5kIOLvPelwlEB/w+89x8aNwifYlrQBrpWW/I8rY21qVJw4DPR9jnGXbf3MVSsmGOVLjKzN29g49f90O4zyQg1u+wodz1y4Fnzkr9btJKhsQnPylWVJMtG8QqNu52iSRyvGMhe+wImZB008oix2016l63/HCWJcZdlNEJ/vJ/MoHv4OtkMtk+v0o/tllb4HczgHt+Eq14v/4QaL6dWOKbtBLrdYefiMzbUlsLrPwWaNzKLnRjkC/8oPvls+RL4D/7Sug2lxbbAVd9IQrQ91+klEwg9ex0GZi5yhxgdIKd1Qm9Mr5wkrh6/DSLa1pU/GT8y//JZ8D5djI+dWS6zGUjTEG27SDOGSMfIOW+dlfIyNTqhdll/JOHwkeYarcCT52a+t2klWwnDQOOvjP92K2bJNTe23+VzpzbNgw/WSzUf1oWbkknpMBQQY4bN5yS36Q6X5zGs3YrsHwm8LMrJJZvEO16S0i0ZRZLQwPAflcB7T2KT5cBlmUzGOu4JdhakXfzdTVP0XmAv2WrXS/59BsEtN8RGP+39P2uj5uXWo+LhXf4depI2Q68KHvZo9C0Tfi9tokw4saGPeZu8cP8Rz/5fd7L8r9/51lspNA+qVqHDyEDEoEkWwPvWr9tceO8jv+bWPy26SiTAvsNAqa9kBo2njRMlL29Lk6ds3EV0LS1WKVbdwMuKYKfrqvoRpZxB10r1vw9zxNLaxAtOklH2Xvfgxh4IbDtzulp7sp12QuV+vrxA7K1jWs+8MLw/dv285fxNjsAe10kw/zNtwXeu0fk1/Xtzirj1f7x5qe+INu9L7Ervy1N2wQvPw/YKciu7Bx+M7DzicC9zmqC57wAjP97ZvSPxVOCr+W1ZtugdfhEQ0A6bF53LC+vXxMtX3cRlU8elFUAW+8gMe37DRJF33XPmPYC0GVveaaWOm3b+h+Alp2Af+4uVvzLPomWNyERoYIcN27j+f69mfv2ugQYeEF6Wt3Q1zJRplr6DH2lHa+AX38kyvQPc9KHuPw4dEj2Mt+0Evhr68x005pghv3JRtueQPf97I/3o0krsSruckq6X2afw8W3bt576ccv/kK2dcOvhotFbY1YpLvuk5ooViiatZXwSnV5+UzGseHMZ1Mrfl34JjDrdaDHgfKZ+boMy0dd2MWWz5/2t8p7GXVFPPkDwJMnpb6/9/fM/W9cmz5Mu/4HUZDXLUstD1wsXBkff3fmvgHn+yuOqkL87besB1qGxAIGRMYveF0WvFn5HTDijPDjj/bxSfViI+PZLJPm6FGTVpnLk0elcXNxH+t/hnT6XD/0HgeKO9jMV9OPd5eZ9nOjqq0Va+l2uwYr2LnSrG14yDVbo8Gp/w/YxZmDcclYUQp7HSqK49xxwHPniQ93HMweDdyxQ/bj3rgunvyBdMvyB/f65H2tjCpUVst/6irI7roBhMQMfZDjxm38pniWMb1oDHDs3ZmWHtcq5b6Am3fMnkdFhSw3+pPj7Y7NRtBQtTmEWZVlqNaNzAEUNrB8x51E6ajLpzFwyqOZx73+R9n6RbEYdaWEudpu18KVy2WbDunLdXsbS1ufzt6GstFtH+CwIanffY8GrpkrowFxYYaJcum0W3z55cJHxqry9+8l8Z1dvEPgcdKyk2y9nYoLXhdXEN//TUWTcaXEAtv3qOzH2kxwLISM25Q7F9r1Srf6VjaSiAhe3BjoFVVOJ9go++gbZEnt7foXvnzbdEz3o/biF1XCj77GyGDnPYEjb03dl54HA9d9C/z8Rt9TC4Kf5blrhAWHisGUp2SSJQA8uJ+EP3TZsLIkRSINByrIcbNtP5n8ZgbWv+YboOveASe4CrJjBdumQ+HKEjVerhfTPcAdEj4owMJwmBE9YXDIcrKFYJv2wfsqG0mnYONqseJPejzVWTni1sKXpUNf4MdvUz7nXoXYHNbsuLO4yPhho+Qc/n/pExyj8Eefpamzce4o4Nh7cssvbnQN8B9j0YlXfhdzfoaltW1P8fndYf9U2h9mhy+CoVTK0h32/MaKj5JsyrirLAUpaQcbsu9OBIyLxiELm7guFpvXid/75CdSEz6PsbCmR6V9H+ncuAqa1wBgKp5teog7kB82/uAHXSNuCLnwO0u3O5NzXhDXrqTyoDES+eIvS1cO0iCgglwMOvUHfvkucP5rwG8+kSG6ILwW5G0iWml2Oyt4n3dp5DCumJyZluYe4JSzVRf/839qzHDeLiR8USEImwhW1VgsyKu+k5BnL18p6Wc+E23Cki0d+gLQ4u4CpP9n65bL7G+X0x8XZdpLFEvtlT73yeQPc4C//Ci+n5dPlIkuQ1ZJNIWO/YzrfCZh10x6HChpR9wqE0SbthZf0YvG2JfvvJfTf7fpAQx6ID3etUnPnwdfq/fh9vlOfa4IS+IaCua2OwMXvApcONqZIJdNblXuMr5XiE9tlA71VVMy07wRWIBgFwVz0rC1j3OOKBW8yI4r42uXiN+76/pz0kNAdY4dyDA67CTb5bNka8r4hh8ltJzLaf/Pf+Elb0znMH7ls+KoydXTUjJ+xWTgxiXyvWUnoLMxgfvqqcAvXko/t/MAkdFj7hbXlsYtxHp/yVj78nk7R+13BI67VyZ3+mFO0qzDkSVzknY2Zr1RmEVzCAmACnIx6b6fuAiE4rwocrUunXBfcPi3PkfYX6ddL6B93/S0jcYEm9otAFRmBAWz8R48Ajj5Yfs88yFoeetm7fwXvvDGVC0U7n+2zLkHpkVu5AWpRhVI+dZ5yTbZyaT5tpkxkg/9i/hqA0DzDim3mvZ90meB/+YjGc24YrLjJ25YQM94Svygu+8vsbdP+FdqX+Dohw89DpSGsnU38ZW/aorEtr3JmdDWf7B0GgFxK3Fnrru03gFo6XTCzJGIIavELzWM/2srw91aAzNeDh6SHfMX4L4CLBQDyHLlXrcpP5TKfZToqDuCw7/tlOU/MWnTPXM5d9N/2302veHb3GcLAM5+QTo8xaBPwETGZm39ZXzX0zPTCkEHV8YdC60pw6OuAJYarj6q0t8nfu9L7fNr0lImrJnse3nK1ax1V2Mhml7pHf9L3gau/VY6x627Ab2MDugZw0W57XGgKMUnD03ti7JwUs+DZSJpi+2BX44HLv9U5tZc/5246fQ7UWQfkFEJ7/PSuGUqBvRpw1LpQ1aJ0h7Gze1TMj7zdWfFRR/G3Qn8PWIkGNLg4SS9pOFakDetFqtIk4BeeBCVjSR00mUTgAc8L1XTj9WGngfL5L/9fyurIzVpmdpXsyUVIcJl4IXAQdemfodF3yg0Z46QGLlLpwPv3JJSRJu2TZWx277AWc/JJLq4QoK16yWN4tIZ8tt0sfhmfPqxfqGbjr0n3cc6G0oBV0wSi/WP3wJPnSK+jfv9NrVUbxjN2qaPaFw2QVY77BViyTWpbi6xdeeOFZ/Qpm2Ag28AJjyUsqJfH7CssRnR4MopouxXNxPrvtYSR3XHo8SqtXCSKPcXvplyPzn1MYkPbbpW9DoE2PHolA/6ze0kzNfH/xZ3liNuER9uE++iClZkCX+VDVWRig7hTvKzpbJK7tnlk4D7PRFojvGZ0BhG9/0lYsJ+V8tEKXPCoOtLa/oi73WJvA9c8p2YF4VTHpa410umSTgwN4RhMyO2dKfdZdRj7ZL4Vmtr3U3+Eze6gmnFnOEZMfEb3TriVmDfyzLTw7h4DLB8tsQEHnaMTO7rtAdw1J3Zz23aWj4uV0wGVnxjf+8qqoBffQAsmiyxj5u2lfkP019MRdf4fYA7x5+MyYxXfSH3qnFzceXYvE7eWT0OkJCE896X9u6Sd1KjPyfcL23KvwyFves+0ta4LhY3t5MOw0f3i5J+9J2Z8bXHFWgxKNKgoIKcNJRKzQ6vapq7Itehrwy93Wu4N1gtL2pw5G1i7evUH5jvWR66dquUs+fPxUJ47kuFWa45Vxq3kE/73hK036WqOvUfbtdflHxT0S80VY1FEatTkEOGAP3iF/sOP2ZBKbEOt++TrnRW5OBz3qFvykIWxpG3y1Bqz4NFYWvfO31i1YDzwpdX92K6/7gKrNnBat1Ntt2MSUSNmoibyMALpRGfMFSWLt77kpSCDIhyDIjCPmKwDDN32UsULNN6q3U0ecunk1VZ7ayep8JXQgyjfW8ZLfq7cb+irkB48PVidd5+d5nkaEZGcUeJuuwlSvzgp8P9quOmehupc/vesvqjS+OWqU7wdruKAhbnKm0VlSIj7oI7YTLu5xay07G5PTu+Mp6Dm5gbOjMbx9wtLnS9D5N3VcedUivnAdLxtAlb6dLG8KXu7aOcuytvdjY6fVXVMrq1z6+kDB/+S+KO9z8j3QfZnbC7ZhHw3C/EbaTTbrKISrXxLLiGHUIsoIKcRNyh91wbTpfWXeVluvjzTHcJq3JUiXIMyEvFjGxQs0X2N+8QbCEsFe7CBu6wnru0bYcdi5N/5wHAV6+IhSSsAVEV4l4w+YlUzNkW2xanjPmyb5bFF/J9dm1RCjjuH8Dm9WKN2vsSSfMbQXF58kSJy+1djGXrpnj80v1wG+mqJvkp2i22Exn/fmr4cuRBVFSkVpKsrE5X9lxlomlr4Np5uZcxDlp1k3kFl7wj/5/7brLp3BWCzgOAKSPEbScsrJuqFPeGScNSSlyuk+6KTbb40VXVAIqwcIdSYhXeuhn44WtxT1FKRp3u293/nMePl5E0bzjSzWujj9iQBgsV5CRS2QjYguxhlmwpRHiuyup0d4HaLWJBTiKXvCPWnW2dSWhuLNFmRYoWsPuZEkt49psydBhEdXOgY1vgqNtEoQ/ynyPZqW4GnP1c6neHvqI4fjNeGksvfisVbl5XRAXZUSwK1ZEoRMjCykYeGd+aXBk/b5QM+bvWRte/vFgyvttZsmzyzNfSJ7t6ad5B3AaOvFX+2+Wz4nP9KHeqqsWVzqVtD5Hx+ROAR30m8PrF6t9EBZnYQwU5ibiNZ7Eaaxt0rViib9kOOGdksoeq3GFYl7rGMyR6SCHZYT9Z4OX58zP3XT5RhoS36ZDeUBZrolNDo8eBwNF/s1vxa9Nqie5hQ7YleLPhyo675G8SUErmHAxpJW4o7ihREmnbI90tx51AXCwZ7zJQIrK89OvMfb/5WJTi5tuly3gcIeeITBo+/r5UhKIwNq2OvzykbGBXNonUWZcSpCA3d4b+t24Anjlblko1F8RIMu4SwE2L1HhWVGZOkGvVDbj4HfEhbLEtrUjFZJ9f+i9x7MU7XPvOLcD0l0JOyMcH2bEcF8sVxQbTH/uZs2Si5UaL/y0JFFvGlcpcvKRZO+CCN2TRppbbU8aLyYDz7GT8Px4f+nfvAr54zv9Y0uBJqHmggVNV4OHXQnDYTRJd4atX/JcFTTKui0WUOND50vMg4M/LZUW3FXPF4kRKy/ULgDlv+Vv2XV66DDjuHpG98Y7Fb+cYlMQkdoIPuhbY5VSJSDLu9lKXJhornIVvCr2sdBjdfgr8+Qfxa10+K1r4QxIPNywGZr0OjAwJlfnceWLAqG4GjL1F0vrHFBKQ1GvYxU0iSWw8m3cEuu6Vvpx1y86lK08UBj0gQ+1xLBoQRmUjGfKlcpwMGrcAdj4J2MczLG4upjBlOHBLR+BlzzLey+cA330s37duQt5h3uom6SWoE7xNe4kSYkZSadSsdOWJwimPSKxgWxeZQlFZJZMYqRwng+pmEqd7v6vT082FbL58CbitU2pBGZcV30ioOUBkPF83KlLvoQU5iSSx8XTpMhDY/RygWZvgZaaTxh7nyIcQADj6Dpmh//1UcSvovh/wyOGpuLqARB1wWTAJeMRZ4evKz4D7nMY2l6gRLknsBLtstwuw18USgeGQP5W6NHbseqp8CAGAw/8qi5UsnCwdvx4HAsNPBeYYq4BOfiL1ff6nwKNO6Dk3dOJ+VwOH3kRXmQYMFeQkkuTGEwBO5IQyUs/xxoI9/xWxHPvhKscAMO2F1PcVX+eef6GjWBSaYyMuOEJI0mjTXT4ug58GbglYtdJVjgFxIwTElXDLek6ubMCwa5REkt54ElJuVDUG+g2S7626Bh/3zi0Fyi/hnWBCyo2qamD3s+V7l72Cj3v196nvE4YCtREWPCJlBS3ISaTOxSJBIaAIKXdOe1y2tTViUVr0WfjxJz2Ue15JHyUipBwZ9IB8dC0w7DhZZj2MQ/4E6BrQltgw4V1PIrQgE1J8lJJPZRVw6Tjguvnibw8Ae56befxug3PPy1xJjxBSHFwZr6gELnwduH4hMPAi2Tfg/MzjD/xjcuP9k9ihBTmJ1MVIZeNJSMlo0lL87U98QGa0N24pK7ctm5lanjlX2AkmpPQ0bi5hHY+7R343aw+06w2sWZTfJFxSFlBBTiJJjmJBSENEKVkuuFDQxYKQ5HHon0tdApIg6GKRRDj8Skh5QwsyIYQkGirISYaNJyHlCTvBhBCSaKggJxHthJVh40lIeaKcVy9lnBBCEgkV5CTiKsiN2HgSUpZQxgkhJNFQQU4i7hrwtC4RUp64CnIl3agIISSJUEFOInSxIKS8cTvBFZWlLQchhBBfqCAnkQon+l5tTWnLQQiJB1fGt24qbTkIIYT4QgU5iTRpJdtNq0tbDkJIPFDGCSEk0VBBTiLtesuWLhaElCdte8q2unlpy0EIIcQXrqSXRH76a2Cb9sCup5W6JISQONjtTPE/3uWUUpeEEEKID1SQk0hFJbDb4FKXghASFxUVlHFCCEkwdLEghBBCCCHEgAoyIYQQQgghBlSQCSGEEEIIMaCCTAghhBBCiAEVZEIIIYQQQgyoIBNCCCGEEGJABZkQQgghhBADKsiEEEIIIYQYUEEmhBBCCCHEgAoyIYQQQgghBlSQCSGEEEIIMaCCTAghhBBCiAEVZEIIIYQQQgyoIBNCCCGEEGJABZkQQgghhBADpbUudRmKjlJqGYBvY86mPYDlMeeRVBpq3VnvhkVDrTfQcOvOejcsilHvHbTWHWLOg+RAg1SQi4FSaqLWemCpy1EKGmrdWe+GRUOtN9Bw6856Nywaar2JQBcLQgghhBBCDKggE0IIIYQQYkAFOT6GlroAJaSh1p31blg01HoDDbfurHfDoqHWm4A+yIQQQgghhKRBCzIhhBBCCCEGVJAJIYQQQggxoIIcA0qpo5RSM5VSc5RS15W6PFFRSnVVSo1VSs1QSk1XSl3lpA9RSi1USk1xPscY51zv1HemUupII32AUmqqs+8+pZRy0hsrpZ510j9RSnUvekUDUErNc8o8RSk10Ulrq5Qao5Sa7WzbGMfX+7orpfoa93WKUmq1UurqcrznSqnHlFJLlVLTjLSi3F+l1HlOHrOVUucVqcp1BNT9LqXUV0qpL5RSLyqlWjvp3ZVSG4x7/6BxTr2qe0C9i/JsJ7Dezxp1nqeUmuKkl9P9DmrDGoSckwKhteangB8AlQC+BtATQDWAzwH0K3W5ItahE4A9ne8tAMwC0A/AEAB/8Dm+n1PPxgB6OPWvdPZNALAvAAXgdQBHO+m/AfCg830wgGdLXW+jPvMAtPek/Q3Adc736wDcWY51N57h7wHsUI73HMCBAPYEMK2Y9xdAWwBznW0b53ubBNT9CABVzvc7jbp3N4/zXKde1T2g3rE/20mst2f/3wH8pQzvd1Ab1iDknJ/CfGhBLjx7A5ijtZ6rtd4M4BkAg0pcpkhorRdrrSc739cAmAGgc8gpgwA8o7XepLX+BsAcAHsrpToBaKm1/kjLm+MJACca5zzufB8J4FC3Z55QzPI+jvR6lFvdDwXwtdY6bLXJeltvrfV4ACs8ycW4v0cCGKO1XqG1/hHAGABHFbp+YfjVXWv9ptZ6q/PzYwBdwq5RH+secM+DKJt7HlZvp3ynAxgRdo16Wu+gNqxByDkpDFSQC09nAPON3wsQrlwmGmfYaA8AnzhJlysZin3MGJ4KqnNn57s3Pe0cp3FeBaBdHHXIAQ3gTaXUJKXUpU7atlrrxYC8fAF0dNLLre6AWEPMRrMh3PNi3N/68G64EGIlc+mhlPpMKfWuUuoAJ62c6h73s53UegPAAQCWaK1nG2lld789bRjlnFhDBbnw+FnE6mUsPaVUcwAvALhaa70awH8A9AKwO4DFkOE5ILjOYf9Fkv+n/bTWewI4GsBlSqkDQ44tq7orpaoBnADgeSepodzzIApZz0TXXyl1I4CtAJ5ykhYD6Ka13gPA7wA8rZRqifKpezGe7STW2+VMpHeEy+5++7RhgYf6pJXjPScRoIJceBYA6Gr87gJgUYnKkjNKqUaQF8tTWuv/AoDWeonWukZrXQvgYYg7CRBc5wVIH641/4u6c5RSVQBawX4INFa01ouc7VIAL0LqucQZbnOHHJc6h5dV3SGdgsla6yVAw7nnKM79Tey7wZlIdByAs52hZDjDzT843ydB/DJ3RJnUvUjPduLqDdSV8WQAz7pp5Xa//dowNHA5J9Ggglx4PgXQRynVw7HGDQYwqsRlioTjR/UogBla63uM9E7GYScBcGdGjwIw2JnV2wNAHwATnCGsNUqpnzrXPBfA/4xzznO+nwrgHbdhLiVKqW2UUi3c75AJTNOQXt7zkF6Psqi7Q5pVqSHcc4di3N/RAI5QSrVxhvOPcNJKilLqKADXAjhBa73eSO+glKp0vveE1H1uudS9SM924urtcBiAr7TWde4D5XS/g9owNGA5JzmgEzBTsNw+AI6BzJr9GsCNpS5PDuXfHzIk9AWAKc7nGABPApjqpI8C0Mk450anvjPhzPJ10gdCGp6vAdyP1OqNTSDD+HMgs4R7lrreTrl6QmYzfw5gunv/IL5lbwOY7WzblmHdmwH4AUArI63s7jmkA7AYwBaIteeiYt1fiI/vHOdzQULqPgfiM+nKujsz/xRHBj4HMBnA8fW17gH1LsqznbR6O+nDAPzKc2w53e+gNqxByDk/hflwqWlCCCGEEEIM6GJBCCGEEEKIARVkQgghhBBCDKggE0IIIYQQYkAFmRBCCCGEEAMqyIQQQgghhBhQQSaEkCKhlOqulNJKqf1LXRZCCCHBUEEmhDQIlFLDHOXU+1lb6rIRQghJFlWlLgAhhBSR9wCc7kmrLUVBCCGEJBdakAkhDYnNWuvvPZ+lAKCUGqeUekwpdYdSarlSarVS6hGlVFP3ZKVUI2f/QqXUZqXUl0qps8wMlFLNlVL3KqXmK6U2KaXmKaVu8JRje6XUy0qp9UqpuUqpXxSh7oQQQiyhgkwIISlOhSxHewCAswGcAOBOY/9tAC4BcDWAXQAMBzBcKXUoACilFIBXnPOuAPATAOcCWObJ5w7IUsf9ATwH4P8ppfrEUiNCCCGR4VLThJAGgVJqGIBzAGz07BqrtT5eKTUOQHcAvbTWNc45lwL4F4C2ADSAHwH8Vmv9b+O6LwJopbU+xFGU3wKwl9Z6ok8ZugP4BsDvtdb3OGlVAFY6aQ8Vqr6EEEJyhz7IhJCGxCcAzvOkrTe+T3CVY4cPAFQD6OX8rgYw3nP+uwCud74PAPCjn3LsYYr7RWu9VSm1BMC2WUtPCCGkKFBBJoQ0JDZoredEOF75pHmH3ZQnzWZYbrPPNenyRgghCYEvZEIISbGXUqrS+L0vRJn9GsAcAJsAHOQ550AA053vkwC0VUoNjLughBBC4oMWZEJIQ6JaKbWdT/oSZ9sOwANKqX8C6AngZgAPa63XAYBS6j4ANyullkHcJE4DMAjA4c7570BCyT2rlPodgC8AbA/gJ1rrR+KpEiGEkEJDBZkQ0pA4AMBin/QOznYkgDUA3of4Gz8P4BrjuBshcZPvdc6ZA+AcrfXbAKC11kqpYyHRLh6EKNwLAXDyHSGE1CMYxYIQQiBxkAHM0VpfXOqyEEIIKS30QSaEEEIIIcSACjIhhBBCCCEGdLEghBBCCCHEgBZkQgghhBBCDKggE0IIIYQQYkAFmRBCCCGEEAMqyIQQQgghhBhQQSaEEEIIIcTg/wNOmNEPEToKTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制各loss成分随训练次数epoch变化图\n",
    "epoch_total = len(loss_list)\n",
    "epoch_array = np.array(range(0, epoch_total * n_epoch, n_epoch))\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # 设置图像大小为原始大小的1.3倍，10英寸6英寸\n",
    "plt.plot(epoch_array,lpde_list,label=r'$L_{r}(\\theta)$')\n",
    "#plt.plot(epoch_array,lmiu_list, label='Loss of μ ')\n",
    "plt.plot(epoch_array,lE_list, label=r'$L_{E}(\\theta)$')\n",
    "plt.plot(epoch_array,l0_list, label=r'$L_{ic}(\\theta)$')\n",
    "plt.plot(epoch_array,loss_list, label=r'$L(\\theta)$')\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "plt.ylabel(r'$Rel.\\;L^2\\;Error$', fontsize='x-large')\n",
    "# plt.title(r'$Convergence\\;of\\;rel.\\;L^2\\;error\\;during\\;training\\;process$')\n",
    "# 添加图例并设置字体大小，并将其放在图形外部\n",
    "plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "plt.tight_layout()# 自动调整布局，确保图像完整显示\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(epoch_array,lamda1_list,label=r'$λ_{r}(\\theta)$')\n",
    "# plt.plot(epoch_array,lamda2_list,label=r'$λ_{E}(\\theta)$')\n",
    "# plt.plot(epoch_array,lamda3_list,label=r'$λ_{ic}(\\theta)$')\n",
    "# #plt.plot(epoch_array,lamda4_list,label='λ for loss of μ')\n",
    "# plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "# plt.xlabel('Epoch', fontsize='x-large')\n",
    "# plt.ylabel('Adaptive weights', fontsize='x-large')\n",
    "# # plt.title('Adaptive weights during training process')\n",
    "# plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# plt.show()#绘图\n",
    "\n",
    "plt.plot(epoch_array,loss_test_list)\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "plt.ylabel('Squared Euclidean Error', fontsize='x-large')\n",
    "# plt.title('Geometric difference of position from classic data during training process')\n",
    "\n",
    "plt.show()#绘图\n",
    "\n",
    "plt.plot(epoch_array,lossmean_test_list)\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "plt.ylabel('Summed Error', fontsize='x-large')\n",
    "# plt.title('Arithmetic difference of position from classic data during training process')\n",
    "\n",
    "plt.show()#绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01238435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hxm\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#绘制损失函数在各时刻的分布\n",
    "lpde_tl_list=[]\n",
    "\n",
    "lE_tl_list=[]\n",
    "\n",
    "loss_test_tl_list=[]\n",
    "\n",
    "lossmean_test_tl_list=[]\n",
    "for i in range(jump,(n_all+1+jump),10):\n",
    "    t_tl = torch.tensor([i*interval]).view(-1, 1).requires_grad_(True)#tl:trainloss\n",
    "    x_tl = u(t_tl)[:,0]\n",
    "    y_tl = u(t_tl)[:,1]\n",
    "    z_tl = u(t_tl)[:,2]\n",
    "    vx_tl = gradients(x_tl, t_tl, 1)\n",
    "    vy_tl = gradients(y_tl, t_tl, 1)\n",
    "    vz_tl = gradients(z_tl, t_tl, 1)\n",
    "    lpde1_tl = loss(gradients(vx_tl, t_tl, 1), q_over_m*(Ex + vy_tl * Bz(x_tl,y_tl,z_tl) - vz_tl * By(x_tl,y_tl,z_tl)))\n",
    "    lpde2_tl = loss(gradients(vy_tl, t_tl, 1), q_over_m*(Ey + vz_tl * Bx(x_tl,y_tl,z_tl) - vx_tl * Bz(x_tl,y_tl,z_tl)))\n",
    "    lpde3_tl = loss(gradients(vz_tl, t_tl, 1), q_over_m*(Ez + vx_tl * By(x_tl,y_tl,z_tl) - vy_tl * Bx(x_tl,y_tl,z_tl)))\n",
    "    lE_tl = loss((vx_tl**2+vy_tl**2+vz_tl**2)**0.5,tensortarget)\n",
    "    lpde_tl = lpde1_tl + lpde2_tl + lpde3_tl\n",
    "    x_real_tl = x_real_plt[i-jump]\n",
    "    y_real_tl = y_real_plt[i-jump]\n",
    "    z_real_tl = z_real_plt[i-jump]\n",
    "    vx_real_tl = vx_real_plt[i-jump]\n",
    "    vy_real_tl = vy_real_plt[i-jump]\n",
    "    vz_real_tl = vz_real_plt[i-jump]\n",
    "    loss_test_tl = loss(x_tl,x_real_tl)+loss(y_tl,y_real_tl)+loss(z_tl,z_real_tl)\n",
    "    lossmean_test_tl = (x_tl-x_real_tl+y_tl-y_real_tl+z_tl-z_real_tl)\n",
    "    lpde_tl_list.append(lpde_tl.item())\n",
    "    lE_tl_list.append(lE_tl.item())\n",
    "    loss_test_tl_list.append(loss_test_tl.item())\n",
    "    lossmean_test_tl_list.append(lossmean_test_tl.item())\n",
    "tl_array = np.arange(jump*interval, (n_all+1+jump)*interval, 10*interval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c19e73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用作提醒\n",
    "# lpde_tl_list=[]\n",
    "# lcq_tl_list=[]\n",
    "# lE_tl_list=[]\n",
    "# lmiu_tl_list=[]\n",
    "# loss_test_tl_list=[]\n",
    "# lmiu_test_tl_list=[]\n",
    "# lossmean_test_tl_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "781e2de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAELCAYAAABj+Hm+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABCJUlEQVR4nO3dd3xUZdbA8d9JIwRCqKGkEHovgVAUEcQGSFERF+yIuLq64vr6uuK6+q6r66677lrWDooFQVCRImsvICIQivTeEnqHACHtvH/cwQ1hktxJZpJJON/P536Yufc+z3NmHDnce58iqooxxhgTjELKOwBjjDGmMJakjDHGBC1LUsYYY4KWJSljjDFBy5KUMcaYoGVJyhhjTNAKK+8AKpu6detqUlJSeYdhjDEVypIlSw6oar2C+y1J+VlSUhKpqanlHYYxxlQoIrLd23673eeCiDQVkQki8mF5x2KMMeeTMk9SIhIqIstEZHYhx98UkX0isqrA/poi8qGIrBORtSJyQSliKKyN/iKyXkQ2icjDZ/ar6hZVHV3S9owxxpRMeVxJjQXWFnF8ItDfy/7ngc9UtTXQyVsdIhIrItEF9jV304aIhAIvAQOAtsBIEWlbRJzGGGMCrEyTlIjEA1cB4ws7R1XnAocKlKsBXAxM8JyTpapHvBTvA8wQkUhPuTHAC27aALoDmzxXTVnAFGCou09mjDEmEMr6Suo54CEgz8dyTYH9wFueW4XjRaRawZNUdRrwGTBFRG4Ebgeud9lGHJCW7326Zx8iUkdEXgWSRWSct8IiMlhEXj969KjrD2WMMaZoZZakRGQQsE9Vl5SgeBjQBXhFVZOBE8DD3k5U1WeATOAVYIiqZrgN0Vt1njoPqupdqtpMVZ8upN1ZqnpnTEyMy+aMMcYUpyyvpHoBQ0RkG86ttH4i8p7LsulAuqou9Lz/ECdpnUNEegPtgenA4z7Elw4k5HsfD+zyobwxxhg/K7MkparjVDVeVZOAEcA3qnqTy7J7gDQRaeXZdSmwpuB5IpIMvIHzLGkUUFtEnnQZ4mKghYg0EZEIT4wzXZYNmCXbDzN7xS7y8mzdL2PM+ScoxkmJyBwRaeR5PRlYALQSkXQROdP1+7fAJBFZAXQG/uKlqihguKpuVtU84FbgnAFi3tpQ1RzgXuBznJ6DU1V1tV8/qI8WbD7IDW/8xL3vL2P4awtYvcuedxljzi9iK/P6V0pKivpjxomlOw5z0/iFxNWsyi0XJvHclxs4fDKLWy5I4neXtySmargfojXGmOAgIktUNaXgfpsWKQit2nmUW99cRL3oKky6owexNSIZ0rERz365nncWbGP2il2MG9CGa7vEIeKtv4cxxlQOQXG7z/zXxr3HueXNRURXCfslQQHERIXzxND2zLz3IuJrRfE/035mzDup2JWwMaYysyQVRLYfPMGN4xcSGiJMGtOT+FpR55zTPi6Gj+++kPv6NeertftYvO1wOURqjDFlw5JUkNh55BQ3vLGQ7Nw83hvdgyZ1zxmr/IuQEOHuvs2JqRrOW/O3lmGUxhhTtixJBYG8PGXM26kcO5XNO7f3oFWD6GLLVI0IZWT3RD5fvYe0QyfLIEpjjCl7lqSCQEiI8Keh7XhrVDc6xLufseKWCxojIrz7k9dlWIwxpsKzJBUkuiXVJiWptk9lGtWsSv/2DZi8aAcnTucEKDJjjCk/lqQquNt7NeF4Zg4fL00v71CMMcbvLElVcF0Sa9IpPoa35m+zqZOMMZWOJakKTkS4/aImbDlwgu837i/vcIwxxq8sSVUCA9o3JDa6Cm/+YN3RjTGVS7FJSkTCRWShiLQui4CM7yLCQrjlgsbM23iAjXuPl3c4xhjjN8UmKVXNBpoB1n0siI3snkiVsBDe+nFbeYdijDF+4/Z23wfADYEMxJROnepVuLpzHB8vTefIyazyDscYY/zC7Szoh4AHPKveLsJZvv0XquptbSdTxkZdlMQHqWlMXpTG3X2blXc4xhhTam6T1E3AYaC5Z8tP8b4AYaUhIk2BPwAxqnpdecdTmNYNanBhszq8s2Abd17clNAQW8bDGFOxubrdp6pNitia+tKgiISKyDIRmV3I8TdFZJ+IrCqwf5uIrBSR5SJSqlUFi2ijv4isF5FNIvLwmf2qukVVR59bU/C5sUdjdh/NZOGWg+UdijHGlJrPXdBFJFJEIkvR5lic5dkLMxHoX8ixS1S1s7fVGz2xxYpIdIF9Ba/8vLYhIqHAS8AAoC0wUkTaFhFnULq0TSzVq4QxY/mu8g7FGGNKzXWSEpFRIrIJyAAyRGSjiNzmS2MiEg9cBYwv7BxVnYvzDKwk+gAzziRRERkDvOCyje7AJs9VUxYwBRhawjjKTWR4KFe2a8CcVbs5nZNb3uEYY0ypuEpSIjIWeBmYCQwDrgNmAy+LyG99aO854CEgz7cwAefZ1xciskRE7vR6guo04DNgiojcCNwOXO+y/jggLd/7dM8+RKSOiLwKJIvIOG+FRWSwiLx+9OhRl80FztDOjTiemcN3620GCmNMxeb2Suq3wFhVfUBVZ6jqJ6r6O+B3OLfviiUig4B9qrqkhLH2UtUuOLfj7hGRi72dpKrPAJnAK8AQVc1wWb+3XgbqqfOgqt6lqs1U9elC2p2lqnfGxLhfaiNQLmxWh7rVI5hpt/yMMRWc2ySVAHztZf/XnmNu9AKGiMg2nFtp/UTkPZdlUdVdnj/3AdNxbs+dw9NNvr3nnMfd1o9z5ZT/s8QDFfJv+bDQEK7q0JCv1u7leGZ2eYdjjDEl5jZJpQN9vezv6zlWLFUdp6rxqpoEjAC+UdWb3JQVkWpnOkSISDXgCmCVl/OSgTdwniWNAmqLyJNu2gAWAy1EpImIRHhinOmybNAZ0jmO0zl5fLF6b3mHYowxJeY2Sb0CvCgiT4vIQBEZICJ/BZ7HeVZVKiIyR0QaeV5PBhYArUQkXURGA/WBH0TkZ5zBxJ+q6mdeqooChqvqZlXNA24Fzlm21lsbqpoD3At8jtP7cKqqri7tZysvXRJrEl+rKjN+rpAXg8YYA4CouluDSETuAX6PcxsMnCuop1X1lQDFViGlpKRoamqphnH5zd8/X8er32/hp3GXUi+6SnmHY4wxhRKRJd6GF7mdBf0ZYLaqJgIxODMvJFqCCm5DO8eRm6fMWbm7vEMxxpgScTsL+m/w9H5T1eOqautBVAAt60fTukE0M5bvLO9QjDGmRNzO3fc9cCGwLXChmEAY2jmOv322jh0HT5JYJypg7WTn5vHvbzZx6EQW0ZFhREeGU6Oq82fNquFc0KwO4aG2xqYxxjduk9Qk4K8ikoTTC67gLOg/+jku4yeDOzXkb5+tY9aKXdxzibcZovzj2S828Or3m6kZFU5GZg45eWc/67yuazz/GN4pYO0bYyont0nqzHgmb925FQj1TzjG3+JrRdEtqRYzlu8MWJL6fsN+Xv1+MyO7J/D0tR1RVU5l53I8M4fjmdm8NX8b7y/awZjeTWnVILr4Co0xxsPt/ZcmRWw+zYJuyt6QznFs2JvBuj3H/F73vmOZPPDBclrWr85jg9oBICJERYRRv0YkzWOj+d8rW1G9Shh//3y939s3xlRurnr34YxNqq6q271tgQ/TlMZVHRoSFiJ+nxk9N0+5/4PlnMjK4aUbulA1wvsFdc2oCO7q04yv1u4ldVtJ5w42xpyP3Pbuy/VspgKqXS2C3i3qMnP5LvLy3I2Lc+Plbzfx4+aDPDGkPS3qF30bb1SvJOpFV+Fvn63D7dg8Y4xxe7tvPHBfIAMxgTWsazw7j5xitp/GTC3aeoh/fbWBoZ0bMTwlvtjzoyLCuO/SFizedphv1+/zSwzGmMrPbZJqBNwoIutEZJKIvJ5/C2SAxj8Gtm9I6wbRPPvFerJySrJSyn8dPpHF2CnLSKwdxVPXdEDE3TL1I7ol0LhOFM98tt6vV3TGmMrLbZJqBiwFduMkrBYFNhPkQkKE3/dvzfaDJ5myeEeJ61FV/vfDnzmYkcW/b+hC9SpuO4hCeGgI/3NFK9btOc5Mm1PQGOOCq79hVPWSQAdiAq9vq3r0aFKbF77eyLAu8VTzIcGc8db8bXy1dh+PDWpL+zjf184a1KEhr32/mWe/XM/ADg2JCLMBvsaYwpX6bwgRqe2PQEzgiQi/H9CaAxlZjJ+31efyq3Ye5a//WcdlbWIZ1SupRDGEhAgP9W9N2qFTTF5U8is6Y8z5ocgkJSLHRKRuvvczRKRBvvf1AVujvALpkliL/u0a8PrczRzMOO263InTOdw3eRm1qoXzzHWdXD+H8ubiFnXp2bQ2L36zkROnc0pcjzGm8ivuSqp6gXP64azZlF/J/7Yy5eLBK1txKjuXF7/Z5LrM4zNXs/XgCZ77VTK1q0WUqn0R5/nYgYwsJv64rVR1GWMqN388EKj03bREpKmITBCRD8s7Fn9oHlud61MSmLRwO2mHThZ7/ozlO/lwSTr3XtKcC5rV8UsMyYm16NW8DlNT02zclDGmUGX+1FpEQkVkmYjMLuT4myKyT0S8LQ9fZFkfYvDahoj0F5H1IrJJRB4+s19Vt6jq6NK0GWzuv6wlISL888sNRZ63/eAJ/jB9FSmNazH2Uv925Ly6cxzbD55kedoRv9ZrjKk8iktSyrlXSqX9Z+9YnOXZCzMR6F+SsiISKyLRBfZ5m1X1nDZEJBR4CRgAtAVGikjbIuKs0BrERDKqVxM+Wb6TNbu8z+mXlZPHfZOXESLw3IjOhPl5qY0r2zcgIizE79M1GWMqj+L+1hFgmoh8ISJfAJHAO/nef+BLYyISD1yFM4OFV6o6Fzhngjc3ZYE+wAwRifSUGQO84LKN7sAmz1VTFjAFGFrkB6rg7u7TjBqR4Tz9n7Ws3X2MzfszSDt0kn3HMjlyMot/fLGen9OP8rdhHYmv5f+1qGpEhnNZm1hmr9hFTm7pBhgbYyqn4gbKvF3g/XtezvGlL/NzwENASdZrKLasqk4TkSbAFBGZBtwOXO6y/jggLd/7dKAHgIjUAZ4CkkVknKo+XbCwiAwGBjdvHrg1m/wtJiqcey9pzlNz1jLg+Xlez7mhRyIDOjQMWAxDOsUxZ+Ue5m8+SJ+W9QLWjjGmYioySanqKH81JCKDgH2qukRE+gaqrKo+IyJTgFeAZqqa4bYZb9V56jwI3FVMu7OAWSkpKWNcthcU7ujdhHZxNThyMpvs3DxO5+SR5dmqRoRyTXJcQNu/pHU9oiPDmLF8pyUpY8w5fJ9yoOR6AUNEZCDObcMaIvKeqt7kz7Ii0htoD0wHHgfudRlfOpCQ7308UOkflogIFzarW/yJAVIlLJSB7Rsye8UuTl2dW+hyH8aY81OZ9e5T1XGqGq+qScAI4BuXCcp1WRFJBt7AeZY0CqgtIt5WE/ZmMdBCRJqISISnnZkuy5pSGJrciBNZuXy1dm95h2KMCTJBMXGaiMwRkUae15OBBUArEUkXEV+6fkcBw1V1s6rmAbcC5yzK6K0NVc3Buer6HKcH4VRVXV26T2bc6NGkDvVrVLFefsaYc4gNpPSvlJQUTU1NLe8wKpynPl3DxB+3sfgPl1EzqnQzWhhjKh4RWaKqKQX3B8WVlDFDO8eRnavMWbmnvEMxxgQRn5KUiESISLyIJObfAhWcOX+0a1SDZvWq8cnyneUdijEmiLhKUp65674FTuI849nq2bbh2zgpY7wSEYZ2jmPR1kPsOnKqvMMxxgQJt1dS44EY4EacWR0u9my9PX8aU2pDOzcCsFV7jTG/cDtOqjtwgaquDGQw5vzWuE41OifU5JNlO7mrT7MybXvD3uO8MXcLS3ccZsKt3UiqW61M2zfGeOf2SioNsFGWJuCu7tyIdXuOs37P8YC3par8uOkAt721iCv+NZdZK3ax52gmYz9YTrbNJWhMUHCbpH4P/MWWijeBdlXHRoSGCDMC2IEiN0+ZsXwng178gRvGL2TVzqP8z+UtWfDwpfx9eCd+TjvCv4pZwsQYUzbc3u57FmgI7BGRXUBW/oOq2tLfgZnzU73oKvRpWY+pqWncd2kLIsP9fwH/9Jy1jP9hK83qVeOv13bg6uS4X9oZ2KEhI7ol8Mr3m7moeV0ubF5+U0YZY9wnKW+znxsTEKMvasKN4xcyc/kuru+WUHwBHyzbcZgJ87cysnsCT13dgZCQc+cVfmxwWxZtPcTvpi7ns7EXU6uaDS42przYjBN+ZjNOlJ6qMuD5eeSp8vn9FyPibYJ632Xl5DH4xR84lpnNF7+7mOjI8ELPXbXzKNe8PJ9LWsXy2s1d/RaDMcY7m3HCVBgiwh29m7JhbwbzNh7wW72vfLeZ9XuP89Q17YtMUADt42L4ff/WfLFmL5MW7vBbDMYY37gdzBshIo+LyHoRyRSR3PxboIM0558hnRoRG12FN+Zt8Ut9G/ce59/fbmRIp0b0a13fVZnbezWhd4u6/Hn2GjbuDXxvQ2PMudxeST0O3ImzkKACjwITcJZg/21gQjPns4iwEG69MIl5Gw+Uujt6bp7y+49WUL1KGI8Pbuu6XEiI8Oz1naheJYzfTl7G6Rz795gxZc1tkhoB/FpVnwNycJaxuBN4ErgwQLGZ89wN3ROJDA9hwg+lu5p6d8E2lu44wmOD21KnehWfysZGR/KXazuwbs9x5qzcXao4jDG+c5ukGgIrPK9PADU8r2cBg/wdlDEAtapFMLxrAp8s28W+45klqiP98Eme+Xw9fVvV4+rOcSWq4/I29YmvVZWPltjkt8aUNbdJahcQ63m9jf/O19ce58qqUvNMsDtBRD4s71jON6N6JZGdl8d7C85Zu7JYqsoj01chwJNXty9xD72QEGFYl3jmbz5gk98aU8bcJqlvgCGe1xOAZ0RkAfA+MM2XBkUkVESWicjsQo6/KSL7RGRVvn2RIrJIRH4WkdUi8idf2nTThmd/f0/nkE0i8vCZ/aq6RVV9WSHY+EnTetW5tHV93v1pO5nZvj0TmpqaxtwN+3mof2via0WVKo5hXeJRhenL7GrKmLLkKkl5nj897nn9BnATsBhnuiRfO06MxVmevTATgf4F9p0G+qlqJ6Az0F9EehYsKCKxIhJdYF9zN22ISCjwEjAAaAuMFBH3T9lNwIzp3YTDJ7P5eKn7BPHjpgM8+skqLmxWh5t7Ni51DIl1ouieVJuPlqRjYwuNKTuux0lpvv8zVXWaqt6nqi+pquvbfSISD1yFs/RHYe3Mxek1eFbbqprheRvu2bz9TdEHmCEikZ72xgAvuGkDZ6b3TZ6rpixgCjDUzecygdW9SW06xMUw/oct5OUVnyDW7j7Gr99dQtO61Xnlpq5eZ5Uoieu6xrPlwAmW7jjil/qMMcVznaREpJWI/FNEZolIA8++ISLSyYf2ngMeAnyeYtpzm3A5sA/4UlUXFjxHVacBnwFTRORG4HbgepdNxOHM9n5GumcfIlJHRF4FkkVkXCHxDRaR148ePer2IxmXnMG9Tdiy/wTfbdhX5Lm7jpxi1FuLqVYljLdGdSOmatGDdn0xoEMDIsND+Ghput/qNMYUze1g3t7AcqATcAVw5gZ/W+Axl3UMAvap6hLfwwRVzVXVzkA80F1E2hdy3jNAJs6YriH5rsCKDdFbdZ46D6rqXaraTFWfLqTdWap6Z0xMjMvmjC8GdmhIw5hIHpuxmtkrdnm9ojp6Kpvb3lrEidM5TLy9G41qVvVrDNGR4Qxo35BZP+/y+fmYMaZk3F5J/QV4QlUv5ewZ0L/BuU3mRi9giIhsw7mV1k9EfJ64VlWPAN9x7nMr4JeE2h6Yjuc5mkvpQP7ZTONxejWaIBAeGsLzI5KpGh7Kve8v46oXf+CrNXt/eT50OieXX7+bytYDJ3jt5q60blCjmBpLZliXeI5n5vDlmr0Bqd8Ycza3SaoT8IGX/XuBem4qUNVxqhqvqkk4g4O/UdWb3JQVkXoiUtPzuipwGbDOy3nJwBs4z5JGAbVF5Ek3beB0BGkhIk1EJMIT40yXZU0Z6N6kNp/dfzHPj+jMqawc7ngnlatf/tHpwffhCn7acoi/X9cpoMtrXNCsDg1jIu2WnzFlxG2SygS83cdqCewvbRAiMkdEGnleTwYWAK1EJF1ERuMMJv5WRFbgJJMvVdVbF/YoYLiqblbVPOBW4JwBNt7a8HQAuRf4HKf34VRVXV3az2b8KzREGNo5ji8f6MPfhnXgwPHT3PLmImYs38VD/VtxdXLJBuz60v61XeKYu2E/e4+VbICxMcY9V0t1iMhEnAQwAjgKdASOA58Cqap6TwBjrFBsqY6ydTonl6mp6ZzOzmX0RU3KZEmNzfszuPTZ7xk3oDW/7tMs4O0Zcz4o7VIdDwHtcGabiAQ+AbYCVXEmmzWmXFQJC+Xmno25o3fTMlvzqVm96iQn1uSjpTZmyphAczuYdx/QFacn32vAfJxBud1U9XDgwjMmOF3XNZ4NezNYudOGHBgTSL4M5s1U1Ymqeq+q/kZV31TV04EMzphgNahjIyLCQvhoiXWgMCaQwgo7ICI3uK1EVd/3TzjGVAwxVcO5vG19Zvy8i0euakOVsNDyDsmYSqnQJAUUHMOknDvg9cwNeUtS5rxzXdd4Pl2xm6/X7mNgh4blHY4xlVKht/tUNeTMBvQDVgGDgVpATc/rFcClZRCnMUHn4hb1aBgTyZTFacWf7EeZ2bk8MHU5D0xdzqksm/nCVG5FXUnl9xzwgKp+nW/fpyKSiTOBa0d/B2ZMsAsNEYanJPDiNxtJO3SShNqlWw7EjaOnshnzdiqLtzvzI2/al8H4W1KIrREZ8LaNKQ9uO060Arytk7ATaOG/cIypWH7VzZlJa2pq4K+m9h7L5FevLWBZ2mFeGJHM6zensHFvBle/NJ91e44FvH1jyoPbJLUBeFBEfjlfnEEpD3qOGXNeiqtZlT4t6zE1NY2cXJ8n93dt8/4Mrn35R9IOneSt27ozuFMjLm9bn2l3XUCuKte9soDv1hc9Q7wxFZHbJHU/zmwTm0XkAxGZAmzx7Ls/MKEZUzGM7J7I3mOn+XZ9qWcI82p52hGue+VHMrNzmXLnBVzU4r9zE7aPi+GTe3qRWDuK2ycu5t0F2wISgzHlxe1g3m9xbutNwnmOFYHT+6+l55gx561+rWOpF12FKYt2+L3uuRv2c8MbP1E9MowP776QDvHnTqHZMKYq0+66gH6tY/njjNX880u7uWEqD18G8+5W1UdVdZiqXquqf1RVW8rCnPfCQ0MY3jWeb9fvY/fRU36rd++xTH4zaSmJtaP46O4LaVK3WqHnVqsSxms3pzCkUyNe+W4T+47b5Lemcig0SZ2ZlfzM66K2sgnVmOA1olsieQpTF/tvBoonZq8hKzePV2/qSmx08b33QkOE+y9rQXauMrWMu8UbEyhFXUmliUis53U6ztLqBbcz+405ryXWieKi5nWZmppGrpdVg301d8N+Pl2xm3v6NiepiCuogprWq85Fzevy/sIdfonDmPJWVJLqBxzyvL7E877gdma/Mee9kd0T2XnkFHM3lq4DRWZ2Ln+csYqmdatxV9+mPpe/qWciu45m8s066+1nKr5CB/Oq6vfeXp+PRKQp8AcgRlWvK+94THC6vG196lSLYMqiHVzSKrb4AoV4+bvNbD94kkl39CjRnICXtalP/RpVePen7Vzetn6J4zAmGLjuOOEvIhIqIstExNvKuojImyKyT0RW5duXICLfishaEVktImNLGcM5bXj29xeR9SKySUQePrNfVbeo6ujStGkqv4iwEIZ1jefrtfvYV8JVe7fsz+DV7zYztHMjejWvW3wBL8JCQ7ihe2PmbtjP9oMnSlSHMcGiqI4T2SKS5Wbzsc2xOMuzF2Yi0L/Avhzgf1S1DdATuEdE2nqJOVZEogvsa+6mDREJBV4CBgBtgZHe2jCmKCO6JZCTp0wrwRIeqspjM1ZTJTyEP1zVpnRxdE8gNESYtND/3eKNKUtFzd03hv/Ocu4XIhIPXAU8BTzg7RxVnSsiSQX27QZ2e14fF5G1QBywpkDxPsDdIjJQVTNFZAxwDTCwuDaA7sAmVd3iiXUKMNRLG8YUqmm96vRoUpsPFqdxd59mhIS4Xy145s+7+GHTAZ4Y2s5Vb76i1K8RyZXt6jM1NY0HLm9JZLgtJWIqpqKeSU0MQHvP4SxFH13MeYXyJJdkYGHBY6o6TUSaAFNEZBpwO3C5y6rjOLunYjrQw9NmHZzEmiwi41T1aS9xDQYGN2/u7cLNnE9u6JHI2CnL+Xz1Hga4XMLjWGY2T366lo7xMdzYo7Ff4ripR2PmrNzDpyt2M6xrvF/qNKasuXomJSLdRKSHl/09RCTFZR2DgH2qusTHGPPXUR34CLhfVb3OqKmqzwCZwCvAEFXNcFu9t+o8dR5U1btUtZm3BOU5Z5aq3hkTc+6MAOb8cmW7BrRpWIP7P1jO/E0Hij1fVfnbf9ZxMOM0T13dgVAfrr6KckGzOjStV413f9rul/qMKQ9uO068CCR52Z/gOeZGL2CIiGwDpgD9RKTgwoqFEpFwnAQ1SVU/LuK83kB7YDrwuNv6ca6cEvK9jwdsRg3js8jwUN4b3Z2kOtUY/fZiftxceKLKzM7lfz9cwaSFO7jtwiZepz0qKRHhph6NWZ52hFU7j/qtXmPKktsk1Q5I9bJ/KU4ng2Kp6jhVjVfVJJyJab9R1ZvclPXMuD4BWKuq/yzivGTgDZxnSaOA2iLypJs2gMVACxFpIiIRnhhnuixrzFnqVK/CpDE9SKgVxeiJqfy05eA55+w8corrX1vAh0vSue/SFjxays4S3gzrGk9keAjv2dWUqaDcJqk8oIaX/bV8qKNQIjLnzPRKIjIZWAC0EpF0ERmNcxV2M87V13LPNtBLVVHAcFXdrKp5wK3AOf93emtDVXOAe4HPcXofTlXV1aX9bOb8Vbd6Fd4f05O4WlW5feJiFm099MuxHzcfYPCLP7Bl/wlev7krD1ze0qdOFm7FVA1naKc4ZizfxdFT2X6v35hAE9XiO/CJyH+AgwWvfETkfaCuql4RoPgqnJSUFE1N9XbRac5X+45nMuL1n9h7NJO3b+/O8rQjPP2fdSTVieL1W1JoVq96QNtftfMog178gccHt2VUryYBbcuYkhKRJap6Th8Ht0mqK/A9sBH4GqdDwWU4y3f0VVX7W9nDkpTxZu8xJ1HtOHSS3Dzlynb1+cfwTkRHhpdJ+0Nfmk9GZjZfPdAH5+65McGlsCTldj2pJTjdsVfhDHYdCKwEelqCMqZ49WtEMnlMT7ol1eKh/q145cauZZagAEZ2S2Dz/hMsTztSZm0a4w9FDeY9i+f5zM0BjMWYSq1BTCRT7rygXNoe2LEhj89czUdL00lOrFUuMRhTEm7HSSUWtQU6SGNM6dSIDOfKdg2Y9fNuTufklnc4xrjmtmfeNmBrEZsxJsgN6xrP0VPZfLPWlvAwFYfb2329C7wPB7oCvwHG+TUiY0xAXNS8LrHRVfhoabrr6Zr84fCJLGKqhgeki72p/FwlKVWd72X3dyKyA7gNmOrPoIwx/hcaIlyTHMeEH7ZyIOM0datXCXib363fx+i3U6ldLYJLW8dyWZv69Gpel6oRNuGtcae0A3GXAH39EIcxpgwM6xpPTp4yc3ngZ/xKO3SSsVOW07RuNbo3qc3sFbu5451UOj/xBXe8vZgpi3aQlZMX8DhMxea6d19BnqmKRuNZQsMYE/xa1o+mQ1wMHy1N5/aLAjewNzM7l7snLSFPlTduSSGpbjWycvJYtPUQX63dy5dr9vLV2n1sOXCCRwb6fzooU3m47d23UUQ25Ns2Akdwlt1wOzeeMSYIXNsljtW7jrFuj9eFBEpNVfnjJ6tYtfMY/7q+M0l1qwHOysUXtajL/w1pxw+/v4ShnRvx7oLtHDrh67qp5nzi9nbfe8CkfNs7OAmqXYDWnTLGBMiQTo0ICxE+XrozIPVPWZzGtCXp/LZfcy5rW9/rOSLCb/s1JzMnlwk/bAlIHKZycNtx4k+BDsQYUzbqVK/CJa1jmb5sJw9d2Yqw0FLPEf2Ln9OO8PiM1Vzcsh73X9ayyHObx0YzsH1D3v5xO3f2bkZMVNnNwGEqjiJ/nSLSRUQKPUdEIkTkWv+HZYwJpGFd4th//DTzXCzK6NahE1nc/d4S6kVX4flfdXa1eOM9lzQn43QOby/Y5rc4TOVS3D+hFgN1z7wRkUOe5dnPqAVMC0RgxpjAuaR1LDWjwv12yy83T7lv8jIOnMji1Zu6UqtahKtybRvV4LI2sbw5fysZp3P8EoupXIpLUgX/KRTuZZ+N0DOmgqkSFsqQTo34YvUejmWWfp2piT9u44dNB/jz0HY+ry58zyXNOXIym0m2MKPxwh83o4tf66OCE5GmIjJBRD4s71iM8ZdhXeI5nZPHpytKN4ok/fBJnv1iPf1ax3J9SoLP5ZMTa9G7RV3emLeFzGybV9CczX9PTF0SkVARWSYisws5/qaI7BORVW72lzCGwtroLyLrRWSTiDx8Zr+qblHV0aVt15hg0jE+hmb1qvHRkvQS16GqPDbDWcD6iaHtSrxW1b2XNOdARhaTF+0ocSymciouSSlnXykVfF8SY3GWZy/MRKC/D/t/ISKxIhJdYF9zN3WJSCjwEs56WW2BkSLStqj2jKnIRISR3RNJ3X6YL9fsLVEdn67czTfr9vE/V7QivlZUiWPp0bQO3ZvU5rXvt9gs7eYsbp5J7RSRLBHJAqoD6/O9T/OlMRGJB64Cxhd2jqrOBQ653V9AH2CGiER62hsDvOCyru7AJs9VUxYwBRhaTHvGVGi3XJBE24Y1GPfxSg77OKj26Mls/m/mGjrGx3DbhUmljuW3/Zqz51gmHy0JzPgtUzEVN05qlJ/bew5nEHB0MeeViKpO8/Q+nCIi04DbgctdFo/j7KSbjrMaMSJSB3gKSBaRcar6dMHCIjIYGNy8ubcLN2OCU0RYCP8Y3omhL/3AYzNX8+LIZNdl//rZWg6fzGLiqG6uupsX56LmdemUUJOXv9vE8JR4wv04fstUXEUmKVV9218NicggYJ+qLhGRvv6qtyBVfUZEpgCvAM1UNcNtiN6q89R5ELirmHZnAbNSUlLG+BKvMeWtbaMa3NevBc9+uYEB7Rsw0MUyHgu3HGTyojR+fXFT2sf51puvMCLCby9pzh3vpDJz+S6GdY33S72mYivLf6r0AoaIyDacW2n9ROQ9fzciIr2B9sB04HEfiqYD+bsmxQOBnyramCBwV99mdIiL4dFPVnEg43SR557OyWXc9JUk1K7K2Mta+DWOS9vE0rReNT5Y7NOTBFOJlVmSUtVxqhqvqknACOAbVb3Jn22ISDLwBs6zpFFAbRFxOwHuYqCFiDQRkQhPjDP9GZ8xwSo8NIRnr+9ERmYOf/xkFaqF9496+dvNbNl/giev7kBURIkXUvBKRLg2OY5F2w6RduikX+s2FVNQ3PQVkTki0sjzejKwAGglIukiMrqo/QVEAcNVdbOq5gG3AueMEPRWl6rmAPcCn+P0Ppyqqqv9/2mNCU4t60fzu8tb8p9Ve5jlZezUwYzTjJ+3hZe/28TVnRvRp2W9gMQxtHMcADOWWwcKA1LUv5iM71JSUjQ1NbW8wzCmRHLzlOte/ZGtB07wxe8upnZUBN+t38+0JWl8vXYfOXlK18a1eP3mrtQJ4Mq+17+2gAMZp/n6gT4lHntlKhYRWaKqKQX3+/da3RhToYWGCP8Y3omBz8/jlgmLOJCR5VlqPoJRvZIYnpJAy/oB6Zx7lmuS4xj38UpWpB+lU0LNgLdnglehSUpEbnBbiaq+759wjDHlrVm96jwysA1/nr2Gfq1jGZ6SQN9W9cq0S/jADg15fOZqpi/baUnqPFfo7T4RySuwSzm3m/aZLtqh/g+tYrLbfaayyM7NK9exSr+ZtISFWw7x0yOX2pip80Bht/sK/S+vqiFnNqAfsAoYjLM8R03P6xXApQGJ2BhTrso7MVzdOY6DJ7KYt3F/ucZhypfbX+FzwAOq+qmqHlXVY6r6KfAgXqYdMsaY0urbKpZaflzzqqT2HM1k497j5RrD+cxtx4lWgLdfyk7Av6P5jDEGZ8qmQR0bMTU1jeOZ2URHBn55+bw8ZdP+DBZvO0TqtsMs3naI9MOnCBGY/pte9nysHLi9ktoAPJh/KXlx+oU+6DlmjDF+d02XOE7n5PGfVXsC3taM5TtJ/vOXXPGvufxh+irmbTxAx/gYHr2qDXWrV+GR6SvJyS34qN4EmtsrqfuBWcClIrIIp8NED6AezrMpY4zxu+SEmiTViWL60p0lWlDRrZ1HTvHIxytpHludmy9IoltSLRJrR/0yRqthTFXueX8p7yzYzu0XNQlYHOZcrq6kVPVbnNt6k3ASWwTwHtDSc8wYY/xORLg6OY6fth5k15FTAWlDVXl0+koU+PcNXbiuazyN61Q7axDxwA4N6NuqHs9+sZ7dRwMTh/HOdfcdVd2tqo+q6jBVvVZV/6iqNgGrMSagrkmOQxVmLA/MXzczf97Ft+v38+AVrUio7X3hRhHhz0Pbk5On/GnmmoDEYbxznaREpJWI/FNEZopIA8++ISLSKXDhGWPOd43rVKNr41pMX5Ze5MS3JXHoRBZ/mrWGzgk1ubWYhRsTakdx36Ut+Gz1Hr5eW7KVjI3vXCUpz/IXy4FOwJU4E7mCs8z6YwGJzBhjPK5OjmPD3gxW7zrm13qfmLWa45nZPHNdR1cLN47p3ZQWsdV5bMZqTmbl+DUW453bK6m/AE+o6qVA/jWmv8FZdt0YYwJmUIeGhIcK01L9t87Ut+v38cnyXdzdt7nr+QgjwkJ46poO7Dxyiue/3ui3WEzh3CapTsAHXvbvxenhZ4wxAVOrWgRXd45j8uI0v3RcyDidwx88vfnuuaSZT2W7N6nN9SnxTJi3lXV7/HtlZ87lNkllAt7WiG4J2JwlxpiAG3tZC1SVF77eVOq6/v7ZOnYfy+RvwzpSJcz3qUfHDWhDjarhPPLxSvLybLmjQHKbpOYA4/IN5lURqQs8yXmyeq2INBWRCSLyYXnHYsz5KL5WFDf2aMzU1DS2HjhR4nqWbD/EOz9t59YLkujauFaJ6qhVLYLf92/F0h1H+HHzwRLHYornNkk9BLQDtgGRwCfAVqAq8Ki/ghGRUBFZJiKzCzn+pojsE5FVfmjLa10i0l9E1ovIJhF5+Mx+Vd2iqt5WAzbGlJHfXNKMiNAQ/vVlySa6OXE6h/+Z+jONYqry4JWtShXL0M5xREeG8dHS9FLVY4rmNkll4Mww8RjwGjAfGAt0U9XDfoxnLM7S7YWZCPQv7KCIxIpIdIF9zd3WJSKhwEvAAJyeiyNFpG2xURtjykRsdCSjeiUx8+ddrClBT78nZq1h+6GTPHt9J6pXKd2ar5HhoQzq2IjPVu0h47T19AuUYpOUiIQBx4DGqjpRVe9V1d+o6puqetpfgYhIPHAVML6wc1R1LnCoiGr6ADNEJNJT5xgKmaW9kLq6A5s8V01ZwBRgqOsPYYwJuF9f3IwakWH888v1PpX7bNUePkhN464+zejZtI5fYrmuaxynsnOZs3K3X+oz5yo2SalqDpAGBHphw+dwbiuWeAZHVZ0GfAZMEZEbgduB632oIg7ns56R7tmHiNQRkVeBZBEZV7CgiAwWkdePHj1a0vCNMS7ERIXz6z7N+GrtPpZsd3cjZ++xTB7+eAXt42rwu8ta+i2WLom1aFK3Gh8tsVt+geL2dt+zwOMiUjUQQYjIIGCfqi4pbV2q+gxOb8RXgCGqmuFLKN6q9NR7UFXvUtVmqvq0l3ZnqeqdMTHeOkEaY/xpVK8k6laP4O+fryt2Foq8POXBaT+TmZ3Lc79KJiLMf4s5igjXJsexcOsh0g6d9Fu95r/c/tcaClwG7BSR+SLyRf7ND3H0AoaIyDacW2z9ROS9klTkmR2jPTAdeNzH4ulA/qmW4wGbn9CYIBMVEca9lzTnpy2HmL+p6N51b/24jXkbD/DoVW1pHlvd77Fc0yUOoNwXZ6ys3CapdOBjYAbO+lE7C2yloqrjVDVeVZOAEcA3qnqTr/WISDLwBk5SHQXUFpEnfahiMdBCRJqISIQnlvOii70xFc3IHonE1axa5NXUuj3H+Ntn67isTSw39kgMSBzxtaK4oGkdPg7A3ILG/VIdo4raAhmgiMwRkUae15OBBUArEUkXkYJdwqOA4aq6WVXzgFuB7YXUe05dnudv9wKf4/QynKqqqwPzyYwxpVElLJT7L2vBz+lHGT9vKyvTj7LryClO5+QCkJmdy9jJy6kRGcZfh3U8a+kNfxvWNZ7tB0+S6vIZmXFPLPP7V0pKiqamppZ3GMacF3Jy8xj87/ms3X12d/QakWFUjQhl77HTvHVbNy5pHRvQOE6czqHbU18xpFMj/jqsY0DbqqxEZImqphTc73qggIjcCtwANMZZ9PAXqtq01BEaY4yPwkJD+OjuC1i35zgHjp/mQEYWBzNOcyDDed2zWZ2AJyiAalXC6N++AZ+u2M3/DWlHZHigO0OfP1wlKRF5APg/4E2csUjjcebt6w48H6jgjDGmOFERYXRJLNn0Rv50XZd4Pl66k89X72Fo57gybz8vT5m2JI2EWlFc2LxumbcfKG47TtwJ3KWq9wPZwD9V9QrgRaB2gGIzxpgKo2fTOsTVrMpH5dDL70DGaUZNXMzvP1rJbW8tZkElmk/QbZJKxJkKCZwxSGemHnoHpwecMcac10JChGuS4/hh4372Hssss3Z/2HiAAc/PY8GWgzx6VRsS60Rx5zupJZo2Khi5TVL7gZqe1+lAsud1HBDu55iMMaZCurZLHHkKnywL/NVUdm4ef/tsHTe/uZCYquHMvLcXd/Ruyju3d6d6ZBi3vrWoUgwwdpuk5gJXeF5/APzL04V7Ms40RMYYc95rWq86XRJr8tHSwI6ZSjt0kutfW8Ar321mRLcEZt17Ea0b1ACgUc2qvHN7d7Jz87h5wkIOZPhtitVy4TZJ/Rbn1h7A33CWk68GvIfzvMoYYwzOmKkNezNYnnYkIPUfy8xm2Cs/smlvBv++IZmnr+1I1YizexO2qB/NhFu7sedYJqPeWlyhZ2l3O5j3iKru9bxWVf27qg5R1f9V1cpx49MYY/xgSKdGVK8SxlvztwWk/he+2sj+jNNMGtODQR0bFXpe18a1ePnGLqzZfYy73l1CVk6J5+4uV66SlIgkFrUFOkhjjKkooiPDGdEtgU9X7mbXkVN+rXvTvuNM/HEbI7ol0DG+ZrHn92tdn78N68gPmw7wp1kVc/Ict7f7tuGsxFvYZowxxuO2XkmoKm//uM1vdaoqf5q1hqoRoTx4hftVha/rGs9NPROZlprOoRNZfounrLhNUr2Bi/Ntl+Ks/bQNGBmQyIwxpoKKrxXFgPYNeX/RDk746XnQl2v2Mm/jAR64vCV1qlfxqewtFySRlZvHxxVwqXu3z6TmF9i+U9VngYdxJnE1xhiTz+jeTTiemcO01LTiTy5GZnYuf/50DS3rV+emno19Lt+yfjQpjWvx/qIdFW6m9tKu/rUE6OuHOIwxplLpkliLLok1eXP+NnLzSpcYxs/bQtqhUzw+uB3hoSX7a3tk90S27D/Boq2HShVLWStxkhJn3vvRwG7/hWOMMZXH6IuasuPQSb5au7fEdew+eoqXvt3MgPYN6FWKOfmu6tiQGpFhTF60o8R1lAe3vfs2isiGfNtG4AjOcylfFhU0xpjzxpXt6hNXsyoT5pW8f9nTc9aRp8ojA9uUKpbI8FCu7RLPnFV7OFyBOlC4vZJ6D5iUb3sHJ0G1U9WJgQkteIhIUxGZICIflncsxpiKIyw0hFG9kli07RAr0o/4XH7R1kPM/HkXv+7TjITaUaWOZ0T3BLJy8vi4DKZt8he3HSf+VGD7s6q+pqobfG1QREJFZJmIzC7keH8RWS8im0Tk4Xz7x4rIKhFZLSL3+9pugTbeFJF9IrLKTduqukVVC64CbIwxxfpVtwSqVwljwg++XU1lZufy2IxVNIqJ5O4+zfwSS+sGNeiSWJP3F26vMB0oSttxoiTG4izNfg4RCQVeAgYAbYGRItJWRNoDY3DWr+oEDBKRFl7Kx4pIdIF9zb00NRHo76Zt3z6aMcacLToynF91S+DTFe4H9+blKQ9MXc66Pcd5Ymj7c6Y9Ko2R3RPZvP8Ei7dVjKXu3T6TyhaRLDdbMfXEA1fhLJroTXdgk+fKJQuYAgwF2gA/qepJVc0Bvgeu8VK+DzBDRCI97Y0BXih4kqrOBQp2cSmsbWOMKZXbLkwiT5W3F2xzdf5f5qxlzso9PHpVGy5rW9+vsQzq2IjoCtSBwu2V1EPACWAG8L+ebQaQ4Tk2Jt9WlOc85xc2iVQckH9QQbpn3yrgYhGpIyJRwEAgoWBhVZ2GMyv7FBG5EbgduL74j1dk23jafRVIFpFx3gqLyGARef3o0aMumzPGnC8SakfRv30DJi/cwfHM7CLPfWv+Vsb/sJXbLkxi9EVN/B5L1YhQrkmO49OVuzlyMvg7ULhNUt2Ap1R1uKo+79mGA08BF6rq22e2wioQkUHAPlVdUkQ74mWfqupanNnXv8RJQj8DXodxq+ozOAszvgIMUdUMNx+wsLY9dR5U1btUtZmqPl1Iu7NU9c6YmBiXzRljzidjejfl+Okc+j83j/+s3O31mdBnq/bwxOw1XNG2Pn8c1BZnpI//jeiW6HSgKIdVhH3lNkkNAj7xsn8GzjMcN3oBQ0RkG86ttH4i8l6Bc9I5+wopHtgFoKoTVLWLql6Mc6tuo7dGRKQ30B6YDjzuMrYi2zbGmNJKTqzF+3f0JDoyjLsnLeXG8QtZv+f4L8eX7jjM2CnL6JxQk+dHJBMaEpgEBdC2UQ06JdRkcgWYgcJtkjoF9PSyv6fnWLFUdZyqxqtqEs6S89+o6k0FTlsMtBCRJiIS4TlvJjidIjx/JgLX4iy4eBYRSQbewHmWNAqoLSJux3EV2rYxxvjDBc3qMPu3F/HE0Has3nWMgS/M4/9mrubntCPc8XYqDWMiGX9Lil87ShTmhu4JbNyXwZLtwd2Bwm2Seh14RUSeEJEBnq7afwZe9hwrFRGZIyKNPJ0i7gU+x+kBOFVVz8wv/5GIrAFmAfeoqrdvNgoYrqqbVTUPZ17B7V7amwwsAFqJSLqIjC6mbWOM8Yuw0BBuuSCJ7x7syw3dE3lnwTaGvjQfgImjuvs8eWxJDerorHv1/sLg7kAhbi/1RGQs8CCezgTATuBZ4HkN9uvFMpSSkqKpqanlHYYxpoJYu/sYb8zbwq0XJNEpoWaZtv2H6Sv5cEk6ix65jJio8DJtuyARWaKqKQX3ux4n5ekskQDEADVVNUFVn7MEZYwxJdemYQ3+eX3nMk9QADf0SOR0Th4fLwveJTx8HsyrqseBTiJyrYjUDkBMxhhjykC7RjF0io8J6g4URSYpEblXRB4tsG8GzmDaD4GNItI6gPEZY4wJoJHdE9mwN3g7UBR3JXUL8MtTNREZgjOQ9macsVMbgUcCFp0xxpiAGtzJ04EiSGegKC5JNQWW5Xt/FTBbVSd5BuX+AWc5eWOMMRVQtSphDO3ciE9X7OboyaJnwygPxSWpKOBYvvc9gbn53m8EYv0dlDHGmLIzsnvwdqAoLkmlAx0BRKQW0A5nfNEZ9Tg7iRljjKlg2scFbweK4pLUB8ALIvIb4G2cCVgX5TueAqwPUGzGGGPKSLB2oCguST2F05PvKaA5cKNnJoczRgKfBig2Y4wxZSRYO1AUmaRUNVNVb1PVWqraVlV/LHC8r2fWcWOMMRVYsHagKI+VeY0xxgShYOxAYUnKGGMM4HSg6BhkHSgsSRljjPnFDUHWgcKSlDHGmF/80oEiSJbwsCRljDHmF9WqhDGsSxyfLN/Jf1buLu9wLEkZY4w52+8HtKZzQk3GTlnOvI37iz1/y/4M/jB9JTm5ecWe6ytLUi6ISFMRmSAiH5Z3LMYYE2hREWG8dVt3mtarxq/fXcLSHYU/n/rPyt0M+fd85qzczbaDJ/0eS5knKREJFZFlIjK7kOP9RWS9iGwSkYfz7f+diKwWkVUiMllEIksRw5sisk9EVrlpW1W3qOrokrZnjDEVTUxUOO+M7k5sdBVue3MR6/acPQNeTm4eT326hrsnLaVZbHVm39eb5rHV/R5HeVxJjQXWejsgIqHAS8AAoC0wUkTaikgccB+QoqrtgVBghJfysSISXWBfcy9NTQT6u2nbt49mjDGVR2x0JO+O7kHViFBunrCI7QdPALDvWCY3jF/IG/O2cnPPxkz9dU/ialYNSAxlmqREJB5nuY/xhZzSHdjkuXLJAqYAQz3HwoCqIhKGMzv7Li/l+wAzzlxlicgY4IWCJ6nqXOCQD227+WyDReT1o0ePui1ijDFBL6F2FO+N7kFObh43TVjIpyt2c9WLP7Ai/Qj/+lUn/nx1e6qEhQas/bK+knoOeAgo7OlaHM4ktmekA3GquhP4B84CjLuBo6r6RcHCqjoN+AyYIiI3ArcD17uMzWvbACJSR0ReBZJFZJy3wqo6S1XvjImJcdmcMcZUDC3qRzNxVHcOZWRxz/tLqV4ljE/u6cU1yfEBbzss4C14iMggYJ+qLhGRvoWd5mWfepYJGQo0AY4A00TkJlV975yTVZ8RkSnAK0AzVc1wG6K3tj11HgTuclmPMcZUOp0SavLO6O58vnovv+3XnOjI8DJptyyvpHoBQ0RkG86ttH4iUjDJpAMJ+d7H49zWuwzYqqr7VTUb+Bi40FsjItIbaA9MBx73Ib7C2jbGGAN0bVybRwa2KbMEBWWYpFR1nKrGq2oSTqeHb1T1pgKnLQZaiEgTEYnwnDcT5zZfTxGJEhEBLsVL5wsRSQbewLnqGgXUFpEnXYZYWNvGGGPKSVCMkxKROSLSSFVzgHuBz3GS0FRVXa2qC4EPgaXASpy4X/dSVRQwXFU3e9a9uhXY7qW9yTgrDLcSkXQRGV1Y237/sMYYY1yTYJnptrJISUnR1NTU8g7DGGMqFBFZoqopBfcHxZWUMcYY440lKWOMMUHLkpQxxpigZUnKGGNM0LIkZYwxJmhZ7z4/E5H9eOn27lJd4IAfw6mM7Dtyx76n4tl35E5ZfU+NVbVewZ2WpIKIiKR664Jp/su+I3fseyqefUfulPf3ZLf7jDHGBC1LUsYYY4KWJang4m2qJ3M2+47cse+pePYduVOu35M9kzLGGBO07ErKGGNM0LIkVQZEpL+IrBeRTSLysJfjIiIveI6vEJEubstWJqX8nraJyEoRWS4ilXaGXxffUWsRWSAip0XkQV/KVial/J7st+Qcv9Hz/9kKEflRRDq5LetXqmpbADcgFNgMNAUigJ+BtgXOGQj8B2d14J7AQrdlK8tWmu/Jc2wbULe8P0cQfEexQDfgKeBBX8pWlq0035P9ls4650Kgluf1gPL6e8mupAKvO7BJVbeoahbOqsRDC5wzFHhHHT8BNUWkocuylUVpvqfzRbHfkaruU9XFQLavZSuR0nxP5ws339GPqnrY8/YnnNXKXZX1J0tSgRcHpOV7n+7Z5+YcN2Uri9J8TwAKfCEiS0TkzoBFWb5K83uw35J79ls612icuxglKVsqYYGq2PxCvOwr2KWysHPclK0sSvM9AfRS1V0iEgt8KSLrVHWuXyMsf6X5PdhvyT37LeU/UeQSnCR1ka9l/cGupAIvHUjI9z4e2OXyHDdlK4vSfE+o6pk/9wHTcW5JVDal+T3Yb8kl+y39l4h0BMYDQ1X1oC9l/cWSVOAtBlqISBMRiQBGADMLnDMTuMXTe60ncFRVd7ssW1mU+HsSkWoiEg0gItWAK4BVZRl8GSnN78F+Sy7Yb+m/RCQR+Bi4WVU3+FLWn+x2X4Cpao6I3At8jtMr5k1VXS0id3mOvwrMwem5tgk4CYwqqmw5fIyAK833BNQHposIOL/p91X1szL+CAHn5jsSkQZAKlADyBOR+3F6Xh2z31Lx3xPOjN/2W3L+f3sMqAO87Pk+clQ1paz/XrIZJ4wxxgQtu91njDEmaFmSMsYYE7QsSRljjAlalqSMMcYELUtSxhhjgpYlKWOMMUHLkpQxFZSIfCUiEws5tk1EhpRxSMb4nSUpYyoZzzpbdYEvyzsWY0rLkpQxFZDnCupS4FYRUc/W13P4WuAzVT0lIn09x+ILlM8Rkdvyvb9DRNaKSKaIHBSRuQXLGFMebFokYyqmsTiLzu32vAY45PnzGuAvbisSka7Aq8DtwPc4UwX18FukxpSCJSljKiBVPSoiWcApVd1zZr+ItARaAJ/6UF0icAL4RFWPefat9FuwxpSC3e4zpnK5FvhWVY/4UOZLYAuwVUSmiMidIlI3INEZ4yNLUsZULtfgrIFUKHGmtP5l4TpVzQBSPGU3AHcBmzy3AY0pV5akjKm4snCWSgDA09EhBZjh5dwG+V43pcD/+6qaq6pzVfUxoCvOs64b/B6xMT6yZ1LGVFxbgUtEpBlwFOdKaKFnwcyCnhaRB3CuoJ7x7GstIvWAC3ES11xgP06SSgDWBDh+Y4plScqYiutZoAPwM1ANyAMeLuTc+cDXQBXg3zhLgN8DfAMcBgYDjwDRQBrwJPBmAGM3xhVb9NCYSkBEagN7gTaquinf/r7At0CCqqaXT3TGlJw9kzKmcqgLjMufoIypDOx2nzGVgKpuAP5R3nEY4292u88YY0zQstt9xhhjgpYlKWOMMUHLkpQxxpigZUnKGGNM0LIkZYwxJmhZkjLGGBO0/h/JeSYa/xoqLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))  # 设置图像大小为原始大小的1.3倍，10英寸6英寸\n",
    "plt.plot(tl_array,lpde_tl_list,label=r'$L_{r}(\\theta)$')\n",
    "plt.plot(tl_array,lE_tl_list,label=r'$L_{E}(\\theta)$')\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('t/μs', fontsize='x-large')\n",
    "plt.ylabel(r'$Rel.\\;L^2\\;Error$', fontsize='x-large')\n",
    "# plt.title('Loss of ODEs and loss of E from real data during motion process')\n",
    "plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()# 自动调整布局，确保图像完整显示\n",
    "plt.show()\n",
    "plt.plot(tl_array,loss_test_tl_list)\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('t/μs', fontsize='x-large')\n",
    "plt.ylabel('Squared Euclidean Error', fontsize='x-large')\n",
    "# plt.title('Geometric differences of position from real data during motion process')\n",
    "\n",
    "plt.show()#绘图\n",
    "plt.plot(tl_array,lossmean_test_tl_list)\n",
    "plt.xlabel('t/μs', fontsize='x-large')\n",
    "plt.ylabel('Summed Error', fontsize='x-large')\n",
    "# plt.title('Arithmetic differences of position from real data during motion process')\n",
    "\n",
    "plt.show()#绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58213125",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = [lpde_tl_list,  lE_tl_list,  loss_test_tl_list, lossmean_test_tl_list]\n",
    "file_names = ['hh_lpde_tl_list.txt', 'hh_lE_tl_list.txt',  'hh_loss_test_tl_list.txt', 'hh_lossmean_test_tl_list.txt']\n",
    "\n",
    "for file_list, old_name in zip(file_lists, file_names):\n",
    "    new_name = new_prefix + old_name[2:]  # 保留原始文件名中的后缀部分\n",
    "    with open(new_name, 'w') as f:\n",
    "        for item in file_list:\n",
    "            f.write(\"%s\\n\" % item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
