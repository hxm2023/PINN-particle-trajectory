{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f5115f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空内核状态\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "777db9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setup_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17109ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#要设置的参数\n",
    "Ex=0#E也要放小e6倍，这里是0就不放了\n",
    "Ey=0\n",
    "Ez=0#托卡马克里面没电场\n",
    "B0=5#磁轴中心的磁感应强度为5T\n",
    "q=2.5#安全因子，注意，不是电荷\n",
    "R0=6.2#托卡马克大半径6.2m\n",
    "q_over_m = 4.822452834e1  # 电荷与质量之比\n",
    "\n",
    "#单位问题：跑太大的数，程序吃不消，得归一化。几个大数，q_over_m = 4.8e7，vx0vy0 1e6 5e6，interval 4.1473e-9，要动\n",
    "#程序中，要让轨迹相对形状不变，又因为B和位置有关，所以轨迹数值也不能变\n",
    "#a=q/m（E+vB），x=vt+0.5at^2\n",
    "#让位移x=vt+0.5at^2不变，让interval扩大e6倍，让v缩小e6倍(让v0和x0在同一量级，这样好训练)，让q_over_m缩小e6倍，E也要放小e6倍，这样a放小e12个\n",
    "def Bx(x,y,z):\n",
    "    return B0/q*(-q*R0*y+z*x)/(x**2+y**2)\n",
    "def By(x,y,z):\n",
    "    return B0/q*(q*R0*x+z*y)/(x**2+y**2)\n",
    "def Bz(x,y,z):\n",
    "    return B0/q*(-1+R0/(x**2+y**2)**0.5)\n",
    "    \n",
    "\n",
    "target_x0=torch.tensor([7.2])\n",
    "target_y0=torch.tensor([0.0])\n",
    "target_z0=torch.tensor([0.0])\n",
    "target_vx0=torch.tensor([1.0])\n",
    "target_vy0=torch.tensor([5.0])#这里是通行α粒子数据\n",
    "target_vz0=torch.tensor([0.0])\n",
    "\n",
    "\n",
    "interval=4.147267104135095e-4#根据学长给的数据取值,e-3是小圈的1/2π,e-4就是小圈的60分之一，更精确\n",
    "#总运动时间是n*interval\n",
    "learning_rate=8e-4\n",
    "\n",
    "stop_condition = 5e-4#停止训练的loss值要求\n",
    "\n",
    "\n",
    "#设置初始权重\n",
    "lamda1=2#lpde权重\n",
    "lamda2=400#lE权重\n",
    "lamda3=600#l0权重\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dc698242",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100#训练中的t共n个时间点,注意画三维图的点不建议超过200个，容易炸内核\n",
    "n_all=500#总覆盖时间点数，绘图用\n",
    "jump=0#单位是interval\n",
    "n_epoch=100#每几次epoch就计数\n",
    "\n",
    "n_test=50#在n_all范围内，等距取多少个test点\n",
    "new_prefix = \"8.3.duangu-activation\"  # 新的文件名前缀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ebd73786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "#t作为输入，x,y,z作为输出，中间三个隐藏层\n",
    "#MLP是最基础的全连接神经网络\n",
    "\n",
    "class SinActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(1 * x)\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 128),  # 0层\n",
    "            SinActivation(),  # 使用SinActivation2x作为激活函数\n",
    "            torch.nn.Linear(128, 128),  # 2层\n",
    "            SinActivation(),\n",
    "            torch.nn.Linear(128, 128),  # 4层\n",
    "            SinActivation(),\n",
    "            torch.nn.Linear(128, 128),  # 6层\n",
    "            SinActivation(),\n",
    "            torch.nn.Linear(128, 6),  # 8层\n",
    " \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    \n",
    "u = MLP()  # 网络名称\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ac3cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# #from ceshi_Copy1 import MLP  # 导入你的模型类定义\n",
    "\n",
    "# # 创建模型实例\n",
    "# # u = MyModel()\n",
    "\n",
    "# # 加载模型参数\n",
    "# u.load_state_dict(torch.load('3.1.1保存.pth'))\n",
    "\n",
    "# # 设置模型为评估模式（如果只是进行推理）\n",
    "# # u.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25c88f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#下面是求导\n",
    "def gradients(x,t,order=1):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(x,t,grad_outputs=torch.ones_like(x),#用于计算某个标量相对于一组输入张量的梯度\n",
    "                                  create_graph = True,\n",
    "                                  only_inputs=True,)[0]#create_graph： 这是一个布尔值，如果设置为 True，则创建一个用于计算更高阶梯度的计算图。\n",
    "                                                    #这对于执行高阶梯度的操作是有用的。在训练深度学习模型时，可能需要计算模型参数的二阶梯度。\n",
    "    else:\n",
    "        return gradients(gradients(x,t),t,order = order-1)#二阶及以上导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0737703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#损失函数\n",
    "#LOSS\n",
    "loss = torch.nn.MSELoss()\n",
    "tensortarget = (target_vx0**2+target_vy0**2+target_vz0**2)**0.5\n",
    "target_initial = tensortarget.repeat(n+1).view(-1, 1)#保能量项用的\n",
    "\n",
    "def funcmiu(x,y,z,vx,vy,vz):\n",
    "    miu=(vx**2+vy**2+vz**2)/(Bx(x,y,z)**2+By(x,y,z)**2+Bz(x,y,z)**2)**0.5-(vx*Bx(x,y,z)+vy*By(x,y,z)+vz*Bz(x,y,z))**2/(Bx(x,y,z)**2+By(x,y,z)**2+Bz(x,y,z)**2)**1.5\n",
    "    return miu\n",
    "\n",
    "\n",
    "def LOSS(u):\n",
    "    \n",
    "    samples = torch.arange(jump*interval, (n_all+1+jump)*interval, step=int(n_all/n)*interval)#+torch.rand(n+1) * interval*int(n_all/n)*1   #random jitter to samples 10%#实际上n+1个点\n",
    "    t = samples.view(-1, 1).requires_grad_(True)\n",
    "    x = u(t)[:, 0].view(-1, 1)\n",
    "    y = u(t)[:, 1].view(-1, 1)\n",
    "    z = u(t)[:, 2].view(-1, 1)\n",
    "    vx = gradients(x, t, 1)\n",
    "    vy = gradients(y, t, 1)\n",
    "    vz = gradients(z, t, 1)\n",
    "\n",
    "    lpde1 = loss(gradients(vx, t, 1), q_over_m*(Ex + vy * Bz(x,y,z) - vz * By(x,y,z)))\n",
    "    lpde2 = loss(gradients(vy, t, 1), q_over_m*(Ey + vz * Bx(x,y,z) - vx * Bz(x,y,z)))\n",
    "    lpde3 = loss(gradients(vz, t, 1), q_over_m*(Ez + vx * By(x,y,z) - vy * Bx(x,y,z)))\n",
    "\n",
    "    lE = loss((vx**2+vy**2+vz**2)**0.5,target_initial)\n",
    "    miu=funcmiu(x,y,z,vx,vy,vz)\n",
    "    lpde = lpde1 + lpde2 + lpde3 \n",
    "\n",
    "    t0=torch.tensor([0.0]).requires_grad_(True)\n",
    "    l00=(u(t0)[0] - target_x0)**2\n",
    "    l01=(u(t0)[1] - target_y0)**2\n",
    "    l02=(u(t0)[2] - target_z0)**2\n",
    "    l03=(gradients(u(t0)[0],t0,1) - target_vx0)**2\n",
    "    l04=(gradients(u(t0)[1],t0,1) - target_vy0)**2\n",
    "    l05=(gradients(u(t0)[2],t0,1) - target_vz0)**2\n",
    "    l0=l00+l01+l02+l03+l04+l05\n",
    "\n",
    "    return lpde,lE,l0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "82fddc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(u.parameters(), lr=learning_rate)\n",
    "def funcweight(lpde):\n",
    "    lpde.backward(retain_graph=True)#初态只对第0层的weight的梯度才全是0，其他情况都有梯度\n",
    "    # 获取网络的参数列表\n",
    "    gradientlw0 = u.net[0].weight.grad.clone()\n",
    "    gradientlb0 = u.net[0].bias.grad.clone()\n",
    "    gradientlw2 = u.net[2].weight.grad.clone()\n",
    "    gradientlb2 = u.net[2].bias.grad.clone()\n",
    "    gradientlw4 = u.net[4].weight.grad.clone()\n",
    "    gradientlb4 = u.net[4].bias.grad.clone()\n",
    "    gradientlw6 = u.net[6].weight.grad.clone()\n",
    "    gradientlb6 = u.net[6].bias.grad.clone()\n",
    "    gradientlw8 = u.net[8].weight.grad.clone()\n",
    "    gradientlb8 = u.net[8].bias.grad.clone()\n",
    "    opt.zero_grad()\n",
    "    tensors_l = [gradientlw0,gradientlb0,gradientlw2,gradientlb2,gradientlw4,gradientlb4,gradientlw6,gradientlb6,\n",
    "                gradientlw8,gradientlb8]\n",
    "    squared_sums = [torch.sum(tensor ** 2) for tensor in tensors_l]\n",
    "    # 将所有平方和相加\n",
    "    total_squared_sum = sum(squared_sums)\n",
    "    l2_norm_gradient_l=(total_squared_sum.item())**0.5\n",
    "    return l2_norm_gradient_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c08a42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文本文件\n",
    "xdata = np.loadtxt('通行x_real.txt')\n",
    "# 从第四个数据开始，每隔10个数据读取一个，共读取50个数据\n",
    "xselected_data = xdata[jump::int(n_all/n_test)][:(n_test+1)]\n",
    "# 将所选数据转换为PyTorch张量\n",
    "x_real = torch.tensor(xselected_data, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "ydata = np.loadtxt('通行y_real.txt')\n",
    "yselected_data = ydata[jump::int(n_all/n_test)][:(n_test+1)]\n",
    "y_real = torch.tensor(yselected_data, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "zdata = np.loadtxt('通行z_real.txt')\n",
    "zselected_data = zdata[jump::int(n_all/n_test)][:(n_test+1)]\n",
    "z_real = torch.tensor(zselected_data, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xdata=None\n",
    "ydata=None\n",
    "zdata=None\n",
    "xselected_data=None\n",
    "yselected_data=None\n",
    "zselected_data=None\n",
    "\n",
    "#x_real：用于训练过程神经网络输出值与真实值对比，3，13,23…493共50个时刻点，对应t_test\n",
    "#x_real_plt：用于绘制真实图，0~500全点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db7929b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练过程中记录的量\n",
    "loss_list=[]#总损失，带权重\n",
    "lpde_list=[]#方程项损失\n",
    "l0_list=[]#初态损失\n",
    "lE_list=[]#能量项损失loss，也是与真实能量做对比diff\n",
    "# lamda1_list=[]#方程项权重，把保能量保磁矩也放在这一项\n",
    "# #lamda2_list=[]#能量项权重\n",
    "# lamda3_list=[]#初态权重\n",
    "# l_withoutweight_list=[]#总损失，不带权重\n",
    "# time_list=[]#训练时间记录\n",
    "loss_test_list=[]#部分时刻点，输出位置与真实位置误差向量的模平方，即位置与真实值的误差\n",
    "lossmean_test_list=[]#部分时刻点，输出位置与真实位置误差的算术平均值，(sigma（xn+yn+zn）-sigma(xc+yc+zc))/n ,证明轨迹可以视为导心\n",
    "# miu_train_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92fdeef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_lists = [loss_list, lpde_list, l0_list, lE_list, loss_test_list, lossmean_test_list]\n",
    "file_names = ['hh_loss.txt', 'hh_lpde.txt', 'hh_l0.txt', 'hh_lE.txt', 'hh_loss_test.txt', 'hh_lossmean_test.txt']\n",
    "\n",
    "def Save():\n",
    "    for file_list, old_name in zip(file_lists, file_names):\n",
    "        # 构建新文件名，保留原始文件名中的后缀部分\n",
    "        new_name = new_prefix + old_name[2:]\n",
    "\n",
    "        # 检查是否已经存在该文件，如果存在，则在文件末尾追加写入\n",
    "        if os.path.exists(new_name):\n",
    "            mode = 'a'  # 追加模式\n",
    "        else:\n",
    "            mode = 'w'  # 新建文件模式\n",
    "\n",
    "        # 打开文件进行写入\n",
    "        with open(new_name, mode) as f:\n",
    "            for item in file_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n",
    "        # 清空列表\n",
    "        file_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "deb10e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100000], Loss: 1.619e+05,   LOSS_function: 6.055e+04,   LOSS_E:24.66,    LOSS_initial: 68.01,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 0.05859208106994629\n",
      "loss_compared with real:27.509,   miu_train:0.0002414,    lossmean:-2.876\n",
      "Epoch [100/100000], Loss: 6868,   LOSS_function: 16.58,   LOSS_E:10.88,    LOSS_initial: 11.39,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 5.66080379486084\n",
      "loss_compared with real:0.36793,   miu_train:9.619e-05,    lossmean:-0.296\n",
      "Epoch [200/100000], Loss: 946,   LOSS_function: 196.9,   LOSS_E:0.04258,    LOSS_initial: 0.9203,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 11.554617166519165\n",
      "loss_compared with real:0.21056,   miu_train:0.0005026,    lossmean:0.02333\n",
      "Epoch [300/100000], Loss: 424,   LOSS_function: 3.917,   LOSS_E:0.008523,    LOSS_initial: 0.6936,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 17.356664419174194\n",
      "loss_compared with real:0.22811,   miu_train:0.0001041,    lossmean:-0.1537\n",
      "Epoch [400/100000], Loss: 422.5,   LOSS_function: 3.617,   LOSS_E:0.005107,    LOSS_initial: 0.6921,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 23.239672422409058\n",
      "loss_compared with real:0.22636,   miu_train:0.0001051,    lossmean:-0.1535\n",
      "Epoch [500/100000], Loss: 426.8,   LOSS_function: 9.091,   LOSS_E:0.002457,    LOSS_initial: 0.681,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 29.17863917350769\n",
      "loss_compared with real:0.22845,   miu_train:0.0001242,    lossmean:-0.1637\n",
      "Epoch [600/100000], Loss: 421,   LOSS_function: 3.523,   LOSS_E:0.002426,    LOSS_initial: 0.69,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 34.977057218551636\n",
      "loss_compared with real:0.22457,   miu_train:0.0001059,    lossmean:-0.1526\n",
      "Epoch [700/100000], Loss: 419.9,   LOSS_function: 3.322,   LOSS_E:0.00104,    LOSS_initial: 0.6887,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 40.91185760498047\n",
      "loss_compared with real:0.22258,   miu_train:0.0001088,    lossmean:-0.1518\n",
      "Epoch [800/100000], Loss: 420.1,   LOSS_function: 3.034,   LOSS_E:0.001267,    LOSS_initial: 0.6901,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 46.866844177246094\n",
      "loss_compared with real:0.22357,   miu_train:0.0001123,    lossmean:-0.1513\n",
      "Epoch [900/100000], Loss: 419.1,   LOSS_function: 3.242,   LOSS_E:0.0005614,    LOSS_initial: 0.6877,\n",
      "lamda1:2,    lamda3:600,      learn rate:0.0008,    time: 52.753201484680176\n",
      "loss_compared with real:0.22183,   miu_train:0.0001068,    lossmean:-0.151\n",
      "Epoch [1000/100000], Loss: 902,   LOSS_function: 26.68,   LOSS_E:0.01696,    LOSS_initial: 0.7255,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 58.79324293136597\n",
      "loss_compared with real:0.19118,   miu_train:0.0007256,    lossmean:-0.1064\n",
      "Epoch [1100/100000], Loss: 801,   LOSS_function: 35.93,   LOSS_E:0.001031,    LOSS_initial: 0.632,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 64.68147802352905\n",
      "loss_compared with real:0.20189,   miu_train:0.0003219,    lossmean:-0.1404\n",
      "Epoch [1200/100000], Loss: 797.1,   LOSS_function: 37.18,   LOSS_E:0.004635,    LOSS_initial: 0.6274,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 70.54165029525757\n",
      "loss_compared with real:0.1984,   miu_train:0.0003294,    lossmean:-0.139\n",
      "Epoch [1300/100000], Loss: 793.5,   LOSS_function: 38.34,   LOSS_E:0.01109,    LOSS_initial: 0.6233,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 76.42293763160706\n",
      "loss_compared with real:0.19515,   miu_train:0.0003351,    lossmean:-0.1374\n",
      "Epoch [1400/100000], Loss: 790.3,   LOSS_function: 39.8,   LOSS_E:0.01984,    LOSS_initial: 0.6191,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 82.25138306617737\n",
      "loss_compared with real:0.19203,   miu_train:0.0003418,    lossmean:-0.1359\n",
      "Epoch [1500/100000], Loss: 901.3,   LOSS_function: 38.33,   LOSS_E:0.0113,    LOSS_initial: 0.7132,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 88.01271748542786\n",
      "loss_compared with real:0.16819,   miu_train:0.001254,    lossmean:-0.08766\n",
      "Epoch [1600/100000], Loss: 786.9,   LOSS_function: 41.7,   LOSS_E:0.02699,    LOSS_initial: 0.6144,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 93.92919588088989\n",
      "loss_compared with real:0.1893,   miu_train:0.0003507,    lossmean:-0.1345\n",
      "Epoch [1700/100000], Loss: 881.2,   LOSS_function: 160.9,   LOSS_E:0.03304,    LOSS_initial: 0.5737,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 99.81536841392517\n",
      "loss_compared with real:0.18241,   miu_train:0.001081,    lossmean:-0.1196\n",
      "Epoch [1800/100000], Loss: 783,   LOSS_function: 44,   LOSS_E:0.03807,    LOSS_initial: 0.6089,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 105.7741048336029\n",
      "loss_compared with real:0.18608,   miu_train:0.0003644,    lossmean:-0.1327\n",
      "Epoch [1900/100000], Loss: 884.3,   LOSS_function: 154.8,   LOSS_E:0.02211,    LOSS_initial: 0.5824,\n",
      "lamda1:1.201,    lamda3:1199,      learn rate:0.0007616,    time: 111.64945650100708\n",
      "loss_compared with real:0.24842,   miu_train:0.0001445,    lossmean:-0.1473\n",
      "Epoch [2000/100000], Loss: 673.3,   LOSS_function: 45.39,   LOSS_E:0.04281,    LOSS_initial: 0.6041,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 117.62272095680237\n",
      "loss_compared with real:0.18409,   miu_train:0.0003689,    lossmean:-0.1316\n",
      "Epoch [2100/100000], Loss: 670.8,   LOSS_function: 47.21,   LOSS_E:0.04763,    LOSS_initial: 0.5999,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 123.7719292640686\n",
      "loss_compared with real:0.18199,   miu_train:0.0003786,    lossmean:-0.1305\n",
      "Epoch [2200/100000], Loss: 668.1,   LOSS_function: 49.21,   LOSS_E:0.04946,    LOSS_initial: 0.5952,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 129.69585132598877\n",
      "loss_compared with real:0.18025,   miu_train:0.0003904,    lossmean:-0.1295\n",
      "Epoch [2300/100000], Loss: 671.4,   LOSS_function: 47.65,   LOSS_E:0.04953,    LOSS_initial: 0.6,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 135.58875918388367\n",
      "loss_compared with real:0.18387,   miu_train:0.0003934,    lossmean:-0.1304\n",
      "Epoch [2400/100000], Loss: 668.4,   LOSS_function: 49.09,   LOSS_E:0.05008,    LOSS_initial: 0.5957,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 141.62552738189697\n",
      "loss_compared with real:0.18021,   miu_train:0.0003898,    lossmean:-0.1294\n",
      "Epoch [2500/100000], Loss: 668.4,   LOSS_function: 44.54,   LOSS_E:0.03779,    LOSS_initial: 0.6002,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 147.34148359298706\n",
      "loss_compared with real:0.18234,   miu_train:0.0004091,    lossmean:-0.1301\n",
      "Epoch [2600/100000], Loss: 663,   LOSS_function: 51.41,   LOSS_E:0.03602,    LOSS_initial: 0.5881,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 153.073668718338\n",
      "loss_compared with real:0.17922,   miu_train:0.0004084,    lossmean:-0.1288\n",
      "Epoch [2700/100000], Loss: 664,   LOSS_function: 53.61,   LOSS_E:0.02998,    LOSS_initial: 0.5869,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 158.64277935028076\n",
      "loss_compared with real:0.17928,   miu_train:0.0003742,    lossmean:-0.1286\n",
      "Epoch [2800/100000], Loss: 659.8,   LOSS_function: 61.17,   LOSS_E:0.02465,    LOSS_initial: 0.5752,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 164.2050142288208\n",
      "loss_compared with real:0.17661,   miu_train:0.0004256,    lossmean:-0.1255\n",
      "Epoch [2900/100000], Loss: 665.6,   LOSS_function: 68.19,   LOSS_E:0.03027,    LOSS_initial: 0.5738,\n",
      "lamda1:1.041,    lamda3:1036,      learn rate:0.000725,    time: 169.73722195625305\n",
      "loss_compared with real:0.17551,   miu_train:0.0003014,    lossmean:-0.1246\n",
      "Epoch [3000/100000], Loss: 636.5,   LOSS_function: 56.4,   LOSS_E:0.02423,    LOSS_initial: 0.5779,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 175.29265069961548\n",
      "loss_compared with real:0.17696,   miu_train:0.0004412,    lossmean:-0.1274\n",
      "Epoch [3100/100000], Loss: 641.7,   LOSS_function: 50.91,   LOSS_E:0.01333,    LOSS_initial: 0.5887,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 180.8740518093109\n",
      "loss_compared with real:0.18133,   miu_train:0.000879,    lossmean:-0.1307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3200/100000], Loss: 635.1,   LOSS_function: 56.15,   LOSS_E:0.01295,    LOSS_initial: 0.5768,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 186.46520519256592\n",
      "loss_compared with real:0.17866,   miu_train:0.0004495,    lossmean:-0.1287\n",
      "Epoch [3300/100000], Loss: 631.6,   LOSS_function: 62.88,   LOSS_E:0.006637,    LOSS_initial: 0.5665,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 191.97710967063904\n",
      "loss_compared with real:0.17644,   miu_train:0.0004817,    lossmean:-0.1271\n",
      "Epoch [3400/100000], Loss: 691.4,   LOSS_function: 76.05,   LOSS_E:0.0009033,    LOSS_initial: 0.6129,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 197.4923346042633\n",
      "loss_compared with real:0.18612,   miu_train:0.0002708,    lossmean:-0.1302\n",
      "Epoch [3500/100000], Loss: 645,   LOSS_function: 44.43,   LOSS_E:0.004339,    LOSS_initial: 0.5984,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 202.994323015213\n",
      "loss_compared with real:0.18839,   miu_train:0.0003727,    lossmean:-0.1341\n",
      "Epoch [3600/100000], Loss: 641,   LOSS_function: 47.6,   LOSS_E:0.00664,    LOSS_initial: 0.5913,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 208.48636269569397\n",
      "loss_compared with real:0.18506,   miu_train:0.0003919,    lossmean:-0.1324\n",
      "Epoch [3700/100000], Loss: 637,   LOSS_function: 51.98,   LOSS_E:0.007387,    LOSS_initial: 0.5829,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 214.19142317771912\n",
      "loss_compared with real:0.1819,   miu_train:0.0004175,    lossmean:-0.1306\n",
      "Epoch [3800/100000], Loss: 633.2,   LOSS_function: 58.01,   LOSS_E:0.005821,    LOSS_initial: 0.5731,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 219.97359156608582\n",
      "loss_compared with real:0.17891,   miu_train:0.0004526,    lossmean:-0.1288\n",
      "Epoch [3900/100000], Loss: 630.5,   LOSS_function: 65.02,   LOSS_E:0.002825,    LOSS_initial: 0.5633,\n",
      "lamda1:1.009,    lamda3:1003,      learn rate:0.0006902,    time: 226.03574419021606\n",
      "loss_compared with real:0.1766,   miu_train:0.0004924,    lossmean:-0.1273\n",
      "Epoch [4000/100000], Loss: 870.1,   LOSS_function: 77.16,   LOSS_E:0.006551,    LOSS_initial: 0.5587,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 232.1111454963684\n",
      "loss_compared with real:0.19043,   miu_train:0.0007929,    lossmean:-0.1382\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-5.4469e-01, -5.5487e-01, -3.2542e-01, -9.7455e-01, -7.8129e-02,\n",
      "        -3.5357e-01,  4.6009e-01, -8.5909e-01,  9.2198e-01,  3.2677e-01,\n",
      "         7.9316e-01,  5.5371e-01,  6.5429e-01, -4.5320e-02,  7.0961e-01,\n",
      "        -3.3359e-01,  8.7974e-01,  3.3980e-02,  8.2743e-01, -8.3580e-01,\n",
      "        -2.9829e-01, -9.7708e-01, -5.1268e-01, -3.5538e-01, -3.3203e-01,\n",
      "        -3.9209e-01,  7.5016e-01, -6.9268e-01, -2.7022e-01,  4.4207e-01,\n",
      "        -3.4895e-01, -2.0795e-01,  1.1583e-01,  6.5410e-01, -7.4132e-01,\n",
      "        -8.2852e-01, -7.3188e-01, -5.8321e-01, -2.8403e-01, -4.9527e-02,\n",
      "        -8.4201e-01, -9.5666e-01, -7.7561e-02,  8.3382e-01, -6.4888e-01,\n",
      "         8.7702e-01, -6.9110e-01,  9.2504e-01,  6.2083e-01, -9.5631e-01,\n",
      "        -7.7603e-01, -3.7180e-01,  8.7682e-01, -6.2762e-01,  9.3945e-01,\n",
      "        -1.3326e-01, -9.1718e-01,  4.2875e-01, -2.8021e-01, -8.7868e-01,\n",
      "         8.2851e-01, -3.3078e-01,  2.8330e-01, -1.1822e-01, -5.5761e-01,\n",
      "        -8.2974e-02, -3.4623e-02,  4.2994e-01, -4.2362e-01, -3.7485e-01,\n",
      "         6.1029e-01, -4.6086e-01, -5.1752e-01,  8.8678e-01,  8.3490e-01,\n",
      "        -4.5385e-01, -4.7301e-01,  1.4127e-02, -3.5403e-01, -5.6841e-01,\n",
      "        -7.8454e-01, -7.5484e-01,  9.6613e-01,  1.2434e-02,  1.2101e-01,\n",
      "         8.2182e-01,  7.1649e-01,  2.4826e-01, -3.1332e-02, -7.8221e-02,\n",
      "         6.9955e-01,  7.3498e-01, -6.9713e-01,  9.1294e-01,  2.2632e-01,\n",
      "         5.7354e-01, -6.6835e-01, -1.4188e-01,  6.2453e-01,  2.4183e-02,\n",
      "        -8.6423e-01,  1.0100e-01, -5.7702e-04, -2.2533e-01,  4.4609e-01,\n",
      "         5.3452e-01,  6.8078e-01,  5.3097e-02,  2.5927e-01,  6.6839e-01,\n",
      "        -6.5593e-01, -2.7397e-01,  6.2684e-01,  8.0549e-01,  7.7624e-01,\n",
      "        -3.0021e-03, -9.7663e-01,  9.1563e-01, -3.2162e-01, -9.0063e-01,\n",
      "        -9.7478e-01,  9.2271e-01, -2.4313e-01,  3.8817e-01, -2.5020e-01,\n",
      "         4.5603e-01, -2.2433e-01,  1.9023e-01], requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1097, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 1.2212e-02, -2.1462e-02,  2.1291e-02,  7.4089e-02, -5.0189e-02,\n",
      "        -3.1853e-02, -4.1618e-02,  2.6464e-02, -3.7985e-02,  4.0857e-02,\n",
      "        -1.0869e-02, -9.3352e-02,  4.9350e-02, -4.6163e-02,  6.4264e-02,\n",
      "         1.9850e-02, -2.0975e-02, -1.9729e-02, -2.5085e-02,  4.0146e-02,\n",
      "        -6.8000e-02,  6.0758e-02,  2.7902e-02,  6.2481e-03,  9.8376e-03,\n",
      "        -1.3794e-02,  6.0840e-02, -4.1854e-02, -4.0655e-02, -7.0678e-02,\n",
      "         2.6313e-02, -7.1707e-02,  8.3410e-02, -3.5154e-02,  5.3478e-02,\n",
      "         6.8149e-03, -5.5128e-02,  5.8298e-02,  4.4949e-02, -6.2296e-02,\n",
      "        -9.4934e-02, -7.5706e-02,  1.8597e-02,  7.4433e-02,  7.9676e-02,\n",
      "         7.9435e-02, -3.0062e-02,  6.8893e-02, -3.1320e-02, -4.8871e-03,\n",
      "         3.8766e-02,  3.0770e-02, -2.7299e-02,  2.1407e-03,  2.2200e-02,\n",
      "        -6.7984e-03,  6.2222e-02,  4.0504e-02,  4.7357e-02,  4.0554e-02,\n",
      "         1.4066e-02, -2.1026e-02, -2.4775e-02,  4.9623e-02,  4.5418e-02,\n",
      "         1.7932e-02,  7.3221e-02,  2.7624e-02,  4.3752e-02,  1.9087e-02,\n",
      "         5.4811e-02,  1.3358e-02, -3.1860e-02, -1.4680e-02, -7.5509e-02,\n",
      "         2.6251e-06, -4.7289e-02,  6.2504e-02, -8.7457e-03,  1.8813e-02,\n",
      "         3.1867e-02, -1.7013e-02, -1.5136e-02,  4.2673e-02,  4.1378e-02,\n",
      "        -6.8348e-02, -2.2681e-02, -8.7798e-03,  8.9743e-02,  7.0399e-02,\n",
      "         3.4135e-02,  5.8106e-02, -6.6406e-02, -7.2568e-02,  7.2262e-02,\n",
      "        -6.6887e-02,  5.1751e-02,  4.0148e-02,  2.3138e-02,  7.6418e-02,\n",
      "         7.5376e-02,  5.6699e-02,  5.7781e-02,  7.2165e-02,  6.4099e-02,\n",
      "        -1.1891e-03, -7.7086e-02, -7.7617e-02,  9.3209e-03, -5.0153e-02,\n",
      "         3.6418e-02,  3.0552e-02, -2.8131e-02, -4.0088e-02, -4.6882e-03,\n",
      "         4.0366e-02,  5.5054e-02, -5.5944e-02, -9.6219e-02,  2.2921e-02,\n",
      "         7.1553e-02,  2.1530e-02,  1.9799e-02, -2.4217e-02,  1.0869e-02,\n",
      "         1.3733e-02, -6.2142e-02,  7.1728e-02], requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1245, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0622, -0.0323, -0.0492,  0.0433, -0.0366, -0.0415, -0.0767, -0.0323,\n",
      "        -0.0207,  0.0552, -0.0089, -0.0617, -0.0356,  0.0111, -0.0246, -0.0922,\n",
      "        -0.0538,  0.0624,  0.0031, -0.0913,  0.0101, -0.0289, -0.0467, -0.0267,\n",
      "         0.0335,  0.0211,  0.0629,  0.0456, -0.0664, -0.0594, -0.0282,  0.0482,\n",
      "         0.0353, -0.0206,  0.0521,  0.0699,  0.0782,  0.0032,  0.0318,  0.0926,\n",
      "        -0.0392,  0.0342,  0.0256, -0.0357,  0.0495,  0.0207, -0.0716, -0.0549,\n",
      "        -0.0060, -0.0302, -0.0759,  0.0602,  0.0653, -0.0824,  0.0530,  0.0271,\n",
      "         0.0305, -0.0700,  0.0056, -0.0778,  0.0269,  0.0580, -0.0198,  0.0830,\n",
      "         0.0654, -0.0498,  0.0248, -0.0072, -0.0023,  0.0256, -0.0821, -0.0100,\n",
      "         0.0095,  0.0344, -0.0120,  0.0462,  0.0780,  0.0223,  0.0113, -0.0054,\n",
      "         0.0937, -0.0278, -0.0802,  0.0838,  0.0029, -0.0072,  0.0213,  0.0705,\n",
      "         0.0020, -0.0759,  0.0040, -0.0760,  0.0189, -0.0221, -0.0758,  0.0548,\n",
      "        -0.0749, -0.0744, -0.0828,  0.0817, -0.0781,  0.0138,  0.0063,  0.0327,\n",
      "        -0.0291, -0.0600,  0.0325, -0.0750, -0.0884, -0.0352, -0.0763,  0.0060,\n",
      "         0.0641, -0.0687, -0.0381, -0.0256, -0.0274, -0.0428,  0.0859, -0.0056,\n",
      "        -0.0570,  0.0365,  0.0661,  0.0799, -0.0476, -0.0708, -0.0119, -0.0570],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1130, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0413, -0.0650, -0.0133,  0.0940, -0.0904,  0.0236, -0.0234, -0.0119,\n",
      "         0.0760,  0.0131,  0.0484,  0.0551,  0.0356, -0.0918, -0.0411,  0.0564,\n",
      "        -0.0068,  0.0190, -0.0161, -0.0174, -0.0338,  0.0037,  0.0504,  0.0764,\n",
      "         0.0086, -0.0395,  0.0062, -0.0254, -0.0041,  0.0415, -0.0068,  0.0351,\n",
      "         0.0378, -0.0161, -0.0747,  0.0487, -0.0689, -0.0947, -0.0701, -0.0057,\n",
      "         0.0784, -0.0882,  0.0349,  0.0256,  0.0531, -0.0546,  0.0891,  0.0219,\n",
      "        -0.0955, -0.0645, -0.0232, -0.0642, -0.0317,  0.0608,  0.0488,  0.0353,\n",
      "        -0.0131, -0.0577,  0.0737,  0.0415,  0.0184, -0.0656, -0.0151, -0.0470,\n",
      "         0.0133, -0.0718, -0.0678, -0.0576,  0.0309, -0.0658, -0.0723, -0.0313,\n",
      "        -0.0215,  0.0171, -0.0584,  0.0115, -0.0304, -0.0316,  0.0730, -0.0244,\n",
      "        -0.0440,  0.0608, -0.0094,  0.0359,  0.0121, -0.0885, -0.0145, -0.0569,\n",
      "         0.0152,  0.0203, -0.0473, -0.0812,  0.0509,  0.0745,  0.0137,  0.0786,\n",
      "        -0.0687, -0.0763,  0.0348, -0.0671, -0.0367,  0.0465, -0.0742, -0.0226,\n",
      "         0.0366,  0.0356,  0.0069, -0.0838,  0.0510, -0.0784,  0.0800,  0.0735,\n",
      "        -0.0620, -0.0779,  0.0605,  0.0059, -0.0766,  0.0253, -0.0257,  0.0326,\n",
      "         0.0659, -0.0573,  0.0687, -0.0726, -0.0426,  0.0452, -0.0131,  0.0524],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.1111, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0476,  0.0280,  0.0475], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4100/100000], Loss: 923.8,   LOSS_function: 52.52,   LOSS_E:0.002982,    LOSS_initial: 0.6139,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 238.16682171821594\n",
      "loss_compared with real:0.21847,   miu_train:0.001538,    lossmean:-0.1297\n",
      "Epoch [4200/100000], Loss: 856.8,   LOSS_function: 149.6,   LOSS_E:0.00143,    LOSS_initial: 0.4982,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 244.30084705352783\n",
      "loss_compared with real:0.14501,   miu_train:0.0005136,    lossmean:-0.1031\n",
      "Epoch [4300/100000], Loss: 875,   LOSS_function: 203.3,   LOSS_E:0.001633,    LOSS_initial: 0.4731,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 250.40331435203552\n",
      "loss_compared with real:0.13553,   miu_train:0.0005042,    lossmean:-0.1092\n",
      "Epoch [4400/100000], Loss: 856.2,   LOSS_function: 100.1,   LOSS_E:0.002303,    LOSS_initial: 0.5327,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 256.4768793582916\n",
      "loss_compared with real:0.17008,   miu_train:0.001122,    lossmean:-0.1264\n",
      "Epoch [4500/100000], Loss: 887.6,   LOSS_function: 85.89,   LOSS_E:0.003877,    LOSS_initial: 0.5648,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 262.49464654922485\n",
      "loss_compared with real:0.18279,   miu_train:0.00167,    lossmean:-0.1328\n",
      "Epoch [4600/100000], Loss: 848.6,   LOSS_function: 128.3,   LOSS_E:0.002322,    LOSS_initial: 0.5074,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 268.5890066623688\n",
      "loss_compared with real:0.15835,   miu_train:0.00079,    lossmean:-0.1166\n",
      "Epoch [4700/100000], Loss: 855.6,   LOSS_function: 98.24,   LOSS_E:0.00352,    LOSS_initial: 0.5336,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 274.6410450935364\n",
      "loss_compared with real:0.17474,   miu_train:0.001176,    lossmean:-0.1276\n",
      "Epoch [4800/100000], Loss: 845.5,   LOSS_function: 121.9,   LOSS_E:0.00395,    LOSS_initial: 0.5098,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 281.24650597572327\n",
      "loss_compared with real:0.16392,   miu_train:0.0009887,    lossmean:-0.1242\n",
      "Epoch [4900/100000], Loss: 864,   LOSS_function: 196,   LOSS_E:0.003117,    LOSS_initial: 0.4704,\n",
      "lamda1:1.002,    lamda3:1419,      learn rate:0.0006571,    time: 287.7465329170227\n",
      "loss_compared with real:0.14486,   miu_train:0.0005784,    lossmean:-0.1109\n",
      "Epoch [5000/100000], Loss: 875.1,   LOSS_function: 129.8,   LOSS_E:0.001891,    LOSS_initial: 0.5045,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 294.3347020149231\n",
      "loss_compared with real:0.16238,   miu_train:0.000907,    lossmean:-0.1206\n",
      "Epoch [5100/100000], Loss: 875,   LOSS_function: 167.1,   LOSS_E:0.004369,    LOSS_initial: 0.4792,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 300.8922703266144\n",
      "loss_compared with real:0.14902,   miu_train:0.0007874,    lossmean:-0.1102\n",
      "Epoch [5200/100000], Loss: 892.6,   LOSS_function: 205.3,   LOSS_E:0.005294,    LOSS_initial: 0.4653,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 307.53061294555664\n",
      "loss_compared with real:0.14885,   miu_train:0.0007592,    lossmean:-0.1045\n",
      "Epoch [5300/100000], Loss: 876.6,   LOSS_function: 175.8,   LOSS_E:0.004995,    LOSS_initial: 0.4744,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 314.07977843284607\n",
      "loss_compared with real:0.14876,   miu_train:0.0007219,    lossmean:-0.108\n",
      "Epoch [5400/100000], Loss: 937.3,   LOSS_function: 173.8,   LOSS_E:0.005432,    LOSS_initial: 0.5168,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 320.63061904907227\n",
      "loss_compared with real:0.15784,   miu_train:0.00114,    lossmean:-0.1167\n",
      "Epoch [5500/100000], Loss: 873,   LOSS_function: 131,   LOSS_E:0.003009,    LOSS_initial: 0.5023,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 327.0779547691345\n",
      "loss_compared with real:0.15752,   miu_train:0.0008788,    lossmean:-0.1206\n",
      "Epoch [5600/100000], Loss: 899.2,   LOSS_function: 106.1,   LOSS_E:0.009039,    LOSS_initial: 0.5369,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 333.6157202720642\n",
      "loss_compared with real:0.17396,   miu_train:0.001164,    lossmean:-0.1286\n",
      "Epoch [5700/100000], Loss: 877.1,   LOSS_function: 176.4,   LOSS_E:0.005723,    LOSS_initial: 0.4743,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 340.050963640213\n",
      "loss_compared with real:0.14741,   miu_train:0.0009195,    lossmean:-0.1012\n",
      "Epoch [5800/100000], Loss: 928.2,   LOSS_function: 253.1,   LOSS_E:0.007936,    LOSS_initial: 0.4569,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 346.7083013057709\n",
      "loss_compared with real:0.15437,   miu_train:0.00147,    lossmean:-0.09499\n",
      "Epoch [5900/100000], Loss: 866,   LOSS_function: 159.3,   LOSS_E:0.009166,    LOSS_initial: 0.4784,\n",
      "lamda1:1.001,    lamda3:1477,      learn rate:0.0006256,    time: 353.13101267814636\n",
      "loss_compared with real:0.15275,   miu_train:0.0008928,    lossmean:-0.1132\n",
      "Epoch [6000/100000], Loss: 1732,   LOSS_function: 284.8,   LOSS_E:0.01178,    LOSS_initial: 0.4375,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 359.60860085487366\n",
      "loss_compared with real:0.27917,   miu_train:0.005749,    lossmean:-0.1675\n",
      "Epoch [6100/100000], Loss: 2069,   LOSS_function: 361.2,   LOSS_E:0.3698,    LOSS_initial: 0.5163,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 366.40995240211487\n",
      "loss_compared with real:0.19783,   miu_train:0.00191,    lossmean:-0.1412\n",
      "Epoch [6200/100000], Loss: 2027,   LOSS_function: 340.6,   LOSS_E:0.2561,    LOSS_initial: 0.5099,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 372.9293966293335\n",
      "loss_compared with real:0.18715,   miu_train:0.001942,    lossmean:-0.1283\n",
      "Epoch [6300/100000], Loss: 1987,   LOSS_function: 335.3,   LOSS_E:0.1652,    LOSS_initial: 0.4993,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 379.48519945144653\n",
      "loss_compared with real:0.1786,   miu_train:0.001953,    lossmean:-0.1247\n",
      "Epoch [6400/100000], Loss: 1942,   LOSS_function: 330.8,   LOSS_E:0.08847,    LOSS_initial: 0.4871,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 385.9757647514343\n",
      "loss_compared with real:0.16909,   miu_train:0.001965,    lossmean:-0.1207\n",
      "Epoch [6500/100000], Loss: 1886,   LOSS_function: 326.4,   LOSS_E:0.02678,    LOSS_initial: 0.4715,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 392.4523117542267\n",
      "loss_compared with real:0.15743,   miu_train:0.001977,    lossmean:-0.1156\n",
      "Epoch [6600/100000], Loss: 1998,   LOSS_function: 128.5,   LOSS_E:0.005455,    LOSS_initial: 0.5651,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 399.3058910369873\n",
      "loss_compared with real:0.18303,   miu_train:0.001072,    lossmean:-0.1119\n",
      "Epoch [6700/100000], Loss: 1754,   LOSS_function: 337.2,   LOSS_E:0.03029,    LOSS_initial: 0.4284,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 405.7886781692505\n",
      "loss_compared with real:0.12909,   miu_train:0.002095,    lossmean:-0.1006\n",
      "Epoch [6800/100000], Loss: 1995,   LOSS_function: 943.1,   LOSS_E:0.04512,    LOSS_initial: 0.318,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 412.3342616558075\n",
      "loss_compared with real:0.1301,   miu_train:0.001968,    lossmean:-0.1166\n",
      "Epoch [6900/100000], Loss: 1649,   LOSS_function: 426,   LOSS_E:0.1326,    LOSS_initial: 0.3697,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.0005955,    time: 418.7601978778839\n",
      "loss_compared with real:0.10382,   miu_train:0.00258,    lossmean:-0.08369\n",
      "Epoch [7000/100000], Loss: 1616,   LOSS_function: 485,   LOSS_E:0.0783,    LOSS_initial: 0.3417,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 425.3366959095001\n",
      "loss_compared with real:0.097523,   miu_train:0.002959,    lossmean:-0.0786\n",
      "Epoch [7100/100000], Loss: 1596,   LOSS_function: 500.4,   LOSS_E:0.009652,    LOSS_initial: 0.3313,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 431.8973355293274\n",
      "loss_compared with real:0.10064,   miu_train:0.00306,    lossmean:-0.08134\n",
      "Epoch [7200/100000], Loss: 1589,   LOSS_function: 431.8,   LOSS_E:0.007824,    LOSS_initial: 0.3498,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 438.39980244636536\n",
      "loss_compared with real:0.10619,   miu_train:0.002701,    lossmean:-0.09009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7300/100000], Loss: 1581,   LOSS_function: 531.4,   LOSS_E:0.02303,    LOSS_initial: 0.3172,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 444.9695634841919\n",
      "loss_compared with real:0.10896,   miu_train:0.003072,    lossmean:-0.08649\n",
      "Epoch [7400/100000], Loss: 1551,   LOSS_function: 537.3,   LOSS_E:0.03106,    LOSS_initial: 0.3063,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 451.1498086452484\n",
      "loss_compared with real:0.10452,   miu_train:0.003124,    lossmean:-0.08284\n",
      "Epoch [7500/100000], Loss: 1532,   LOSS_function: 514.5,   LOSS_E:0.05501,    LOSS_initial: 0.3076,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 457.1853268146515\n",
      "loss_compared with real:0.10344,   miu_train:0.003127,    lossmean:-0.08536\n",
      "Epoch [7600/100000], Loss: 1503,   LOSS_function: 532.8,   LOSS_E:0.06591,    LOSS_initial: 0.2932,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 463.4710023403168\n",
      "loss_compared with real:0.10063,   miu_train:0.002963,    lossmean:-0.08364\n",
      "Epoch [7700/100000], Loss: 1541,   LOSS_function: 572.8,   LOSS_E:0.1273,    LOSS_initial: 0.2928,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 469.45731949806213\n",
      "loss_compared with real:0.09977,   miu_train:0.003413,    lossmean:-0.08082\n",
      "Epoch [7800/100000], Loss: 1389,   LOSS_function: 507,   LOSS_E:0.05811,    LOSS_initial: 0.2664,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 475.513635635376\n",
      "loss_compared with real:0.088552,   miu_train:0.003184,    lossmean:-0.07673\n",
      "Epoch [7900/100000], Loss: 1519,   LOSS_function: 519.2,   LOSS_E:0.02476,    LOSS_initial: 0.3022,\n",
      "lamda1:1,    lamda3:3308,      learn rate:0.000567,    time: 481.56762742996216\n",
      "loss_compared with real:0.10054,   miu_train:0.003088,    lossmean:-0.08526\n",
      "Epoch [8000/100000], Loss: 1413,   LOSS_function: 504,   LOSS_E:0.04515,    LOSS_initial: 0.2748,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 487.67599153518677\n",
      "loss_compared with real:0.092954,   miu_train:0.003162,    lossmean:-0.0799\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5364, -0.5465, -0.3155, -0.9739, -0.0742, -0.3446,  0.4555, -0.8513,\n",
      "         0.9108,  0.3234,  0.7846,  0.5452,  0.6502, -0.0389,  0.7059, -0.3302,\n",
      "         0.8714,  0.0329,  0.8050, -0.8128, -0.2846, -0.9759, -0.5006, -0.3438,\n",
      "        -0.3207, -0.3813,  0.7410, -0.6497, -0.2579,  0.4374, -0.3297, -0.2054,\n",
      "         0.1103,  0.6450, -0.7042, -0.8187, -0.7163, -0.5808, -0.2787, -0.0500,\n",
      "        -0.8299, -0.9472, -0.0721,  0.8181, -0.6286,  0.8648, -0.6952,  0.9115,\n",
      "         0.6040, -0.9503, -0.7621, -0.3638,  0.8602, -0.6075,  0.9170, -0.1264,\n",
      "        -0.8967,  0.4240, -0.2698, -0.8728,  0.8316, -0.3207,  0.2757, -0.1180,\n",
      "        -0.5531, -0.0814, -0.0310,  0.4230, -0.4125, -0.3680,  0.6019, -0.4493,\n",
      "        -0.5125,  0.8716,  0.8331, -0.4442, -0.4563,  0.0166, -0.3453, -0.5542,\n",
      "        -0.7602, -0.7448,  0.9507,  0.0129,  0.1162,  0.8144,  0.7045,  0.2407,\n",
      "        -0.0317, -0.0823,  0.6759,  0.7147, -0.6890,  0.8989,  0.2262,  0.5708,\n",
      "        -0.6728, -0.1400,  0.6212,  0.0254, -0.8626,  0.0885, -0.0053, -0.2115,\n",
      "         0.4256,  0.5121,  0.6687,  0.0551,  0.2544,  0.6572, -0.6475, -0.2695,\n",
      "         0.6138,  0.7901,  0.7711,  0.0041, -0.9677,  0.9025, -0.3153, -0.8795,\n",
      "        -0.9702,  0.9175, -0.2374,  0.3757, -0.2426,  0.4463, -0.2159,  0.1863],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1162, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0230, -0.0363,  0.0321,  0.0706, -0.0459, -0.0297, -0.0344,  0.0227,\n",
      "        -0.0308,  0.0397, -0.0118, -0.0947,  0.0496, -0.0429,  0.0637,  0.0243,\n",
      "        -0.0336, -0.0188, -0.0163,  0.0326, -0.0635,  0.0601,  0.0373,  0.0324,\n",
      "         0.0108, -0.0056,  0.0695, -0.0488, -0.0375, -0.0780,  0.0210, -0.0776,\n",
      "         0.0832, -0.0413,  0.0466,  0.0047, -0.0636,  0.0623,  0.0389, -0.0736,\n",
      "        -0.0903, -0.0703,  0.0131,  0.0686,  0.0598,  0.0817, -0.0283,  0.0848,\n",
      "        -0.0256,  0.0004,  0.0329,  0.0051, -0.0240,  0.0063,  0.0131, -0.0079,\n",
      "         0.0614,  0.0225,  0.0392,  0.0368,  0.0067, -0.0213, -0.0267,  0.0476,\n",
      "         0.0511,  0.0285,  0.0718,  0.0204,  0.0343,  0.0224,  0.0500,  0.0110,\n",
      "        -0.0321,  0.0048, -0.0825,  0.0012, -0.0392,  0.0611, -0.0061,  0.0164,\n",
      "         0.0507, -0.0218, -0.0168,  0.0411,  0.0221, -0.0906, -0.0190, -0.0078,\n",
      "         0.0921,  0.0759,  0.0312,  0.0565, -0.0550, -0.0742,  0.0700, -0.0668,\n",
      "         0.0436,  0.0452,  0.0291,  0.0848,  0.0767,  0.0534,  0.0471,  0.0821,\n",
      "         0.0666, -0.0104, -0.0686, -0.0733,  0.0075, -0.0469,  0.0377,  0.0311,\n",
      "        -0.0327, -0.0422, -0.0074,  0.0335,  0.0509, -0.0643, -0.1014,  0.0303,\n",
      "         0.0717,  0.0219,  0.0038, -0.0160,  0.0105,  0.0175, -0.0598,  0.0597],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1316, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0669, -0.0475, -0.0418,  0.0406, -0.0551, -0.0334, -0.0596, -0.0227,\n",
      "        -0.0150,  0.0683,  0.0109, -0.0469, -0.0359,  0.0066, -0.0293, -0.0911,\n",
      "        -0.0466,  0.0475,  0.0140, -0.1022,  0.0140, -0.0340, -0.0421, -0.0186,\n",
      "         0.0244,  0.0191,  0.0731,  0.0268, -0.0746, -0.0714, -0.0327,  0.0359,\n",
      "         0.0237, -0.0278,  0.0487,  0.0822,  0.0916,  0.0098,  0.0324,  0.1005,\n",
      "        -0.0611,  0.0379,  0.0245, -0.0448,  0.0579,  0.0291, -0.0684, -0.0681,\n",
      "         0.0031, -0.0311, -0.0622,  0.0601,  0.0547, -0.0679,  0.0469,  0.0354,\n",
      "         0.0267, -0.0887,  0.0123, -0.0718,  0.0288,  0.0611, -0.0248,  0.0540,\n",
      "         0.0808, -0.0255,  0.0186, -0.0135,  0.0156,  0.0176, -0.0885, -0.0331,\n",
      "         0.0006,  0.0510, -0.0058,  0.0584,  0.0863,  0.0226,  0.0057, -0.0216,\n",
      "         0.1108, -0.0039, -0.0582,  0.0873, -0.0064, -0.0156,  0.0248,  0.0689,\n",
      "         0.0064, -0.0809,  0.0318, -0.0896,  0.0115, -0.0389, -0.0676,  0.0586,\n",
      "        -0.0647, -0.0702, -0.0768,  0.0754, -0.0845,  0.0081,  0.0231,  0.0356,\n",
      "        -0.0315, -0.0591,  0.0508, -0.0746, -0.0860, -0.0500, -0.0712,  0.0035,\n",
      "         0.0621, -0.0655, -0.0441, -0.0193, -0.0183, -0.0328,  0.1014,  0.0039,\n",
      "        -0.0538,  0.0289,  0.0657,  0.0853, -0.0429, -0.0697, -0.0174, -0.0633],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1055, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0545, -0.0537, -0.0085,  0.1103, -0.0912,  0.0293, -0.0251, -0.0205,\n",
      "         0.0771,  0.0059,  0.0375,  0.0501,  0.0558, -0.1081, -0.0493,  0.0344,\n",
      "        -0.0208,  0.0092, -0.0119, -0.0324, -0.0364,  0.0229,  0.0775,  0.0726,\n",
      "         0.0260, -0.0407, -0.0054, -0.0360, -0.0186,  0.0374, -0.0086,  0.0505,\n",
      "         0.0439, -0.0089, -0.0750,  0.0515, -0.0502, -0.1156, -0.0687,  0.0137,\n",
      "         0.0635, -0.0866,  0.0526,  0.0353,  0.0529, -0.0608,  0.0789,  0.0038,\n",
      "        -0.0994, -0.0713, -0.0318, -0.0685, -0.0333,  0.0610,  0.0230,  0.0382,\n",
      "        -0.0171, -0.0631,  0.0630,  0.0295,  0.0125, -0.0621, -0.0330, -0.0345,\n",
      "         0.0119, -0.0807, -0.0733, -0.0744,  0.0397, -0.0658, -0.0672, -0.0406,\n",
      "        -0.0169, -0.0039, -0.0606,  0.0115, -0.0187, -0.0535,  0.0707, -0.0242,\n",
      "        -0.0641,  0.0699, -0.0036,  0.0547,  0.0278, -0.1090, -0.0027, -0.0406,\n",
      "        -0.0048,  0.0023, -0.0440, -0.0720,  0.0723,  0.0670, -0.0008,  0.0730,\n",
      "        -0.0753, -0.0764,  0.0572, -0.0604, -0.0369,  0.0187, -0.0557, -0.0054,\n",
      "         0.0370,  0.0653,  0.0248, -0.0935,  0.0499, -0.0927,  0.0654,  0.0650,\n",
      "        -0.0502, -0.0440,  0.0641, -0.0098, -0.0803,  0.0271, -0.0302,  0.0453,\n",
      "         0.0781, -0.0394,  0.0670, -0.0832, -0.0546,  0.0501, -0.0116,  0.0517],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0871, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0369,  0.0190,  0.0548], requires_grad=True)\n",
      "Epoch [8100/100000], Loss: 1769,   LOSS_function: 320.9,   LOSS_E:0.2173,    LOSS_initial: 0.4378,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 493.67717838287354\n",
      "loss_compared with real:0.1623,   miu_train:0.002269,    lossmean:-0.1051\n",
      "Epoch [8200/100000], Loss: 1475,   LOSS_function: 500.4,   LOSS_E:0.0369,    LOSS_initial: 0.2945,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 499.72463369369507\n",
      "loss_compared with real:0.096545,   miu_train:0.003114,    lossmean:-0.08214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8300/100000], Loss: 1322,   LOSS_function: 510.6,   LOSS_E:0.03099,    LOSS_initial: 0.2453,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 505.7174401283264\n",
      "loss_compared with real:0.079975,   miu_train:0.003295,    lossmean:-0.07138\n",
      "Epoch [8400/100000], Loss: 2560,   LOSS_function: 1319,   LOSS_E:0.3849,    LOSS_initial: 0.375,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 511.88507533073425\n",
      "loss_compared with real:0.27153,   miu_train:0.002566,    lossmean:-0.1976\n",
      "Epoch [8500/100000], Loss: 1238,   LOSS_function: 560,   LOSS_E:0.02018,    LOSS_initial: 0.2049,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 518.033376455307\n",
      "loss_compared with real:0.068287,   miu_train:0.003748,    lossmean:-0.0644\n",
      "Epoch [8600/100000], Loss: 1265,   LOSS_function: 749.9,   LOSS_E:0.01224,    LOSS_initial: 0.1558,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 524.3382909297943\n",
      "loss_compared with real:0.063582,   miu_train:0.00246,    lossmean:-0.06303\n",
      "Epoch [8700/100000], Loss: 1247,   LOSS_function: 790.6,   LOSS_E:0.01133,    LOSS_initial: 0.1381,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 530.3705866336823\n",
      "loss_compared with real:0.060605,   miu_train:0.002381,    lossmean:-0.05883\n",
      "Epoch [8800/100000], Loss: 1151,   LOSS_function: 469.3,   LOSS_E:0.02316,    LOSS_initial: 0.206,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 536.4438226222992\n",
      "loss_compared with real:0.058188,   miu_train:0.004301,    lossmean:-0.05665\n",
      "Epoch [8900/100000], Loss: 1530,   LOSS_function: 746.4,   LOSS_E:0.3034,    LOSS_initial: 0.237,\n",
      "lamda1:1,    lamda3:3307,      learn rate:0.0005397,    time: 542.4836146831512\n",
      "loss_compared with real:0.11789,   miu_train:0.003368,    lossmean:-0.1194\n",
      "Epoch [9000/100000], Loss: 1176,   LOSS_function: 472.7,   LOSS_E:0.03249,    LOSS_initial: 0.2479,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 548.5348789691925\n",
      "loss_compared with real:0.067505,   miu_train:0.002642,    lossmean:-0.05701\n",
      "Epoch [9100/100000], Loss: 1046,   LOSS_function: 481.9,   LOSS_E:0.007414,    LOSS_initial: 0.1989,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 554.4845972061157\n",
      "loss_compared with real:0.067167,   miu_train:0.003317,    lossmean:-0.06435\n",
      "Epoch [9200/100000], Loss: 951.9,   LOSS_function: 471.8,   LOSS_E:0.01848,    LOSS_initial: 0.1691,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 560.5370399951935\n",
      "loss_compared with real:0.060023,   miu_train:0.003271,    lossmean:-0.05944\n",
      "Epoch [9300/100000], Loss: 976,   LOSS_function: 473.3,   LOSS_E:0.01655,    LOSS_initial: 0.1771,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 566.5050570964813\n",
      "loss_compared with real:0.062393,   miu_train:0.003333,    lossmean:-0.06273\n",
      "Epoch [9400/100000], Loss: 1311,   LOSS_function: 524.2,   LOSS_E:0.6889,    LOSS_initial: 0.2774,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 572.5424048900604\n",
      "loss_compared with real:0.12526,   miu_train:0.00574,    lossmean:-0.1727\n",
      "Epoch [9500/100000], Loss: 1020,   LOSS_function: 467.5,   LOSS_E:0.003736,    LOSS_initial: 0.1946,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 578.8148720264435\n",
      "loss_compared with real:0.062452,   miu_train:0.00325,    lossmean:-0.0607\n",
      "Epoch [9600/100000], Loss: 923.9,   LOSS_function: 476.9,   LOSS_E:0.01611,    LOSS_initial: 0.1575,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 585.5770218372345\n",
      "loss_compared with real:0.05496,   miu_train:0.003401,    lossmean:-0.05472\n",
      "Epoch [9700/100000], Loss: 1109,   LOSS_function: 812.7,   LOSS_E:0.01714,    LOSS_initial: 0.1042,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 592.0925850868225\n",
      "loss_compared with real:0.06046,   miu_train:0.002684,    lossmean:-0.05706\n",
      "Epoch [9800/100000], Loss: 1128,   LOSS_function: 191.8,   LOSS_E:0.01612,    LOSS_initial: 0.3299,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 598.5802383422852\n",
      "loss_compared with real:0.092788,   miu_train:0.0027,    lossmean:-0.08513\n",
      "Epoch [9900/100000], Loss: 863.1,   LOSS_function: 465.6,   LOSS_E:0.01511,    LOSS_initial: 0.14,\n",
      "lamda1:1,    lamda3:2838,      learn rate:0.0005138,    time: 605.2384996414185\n",
      "loss_compared with real:0.048716,   miu_train:0.003533,    lossmean:-0.05075\n",
      "Epoch [10000/100000], Loss: 1307,   LOSS_function: 410.2,   LOSS_E:0.4163,    LOSS_initial: 0.3412,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 612.2497315406799\n",
      "loss_compared with real:0.13681,   miu_train:0.002272,    lossmean:-0.1081\n",
      "Epoch [10100/100000], Loss: 1191,   LOSS_function: 376.6,   LOSS_E:0.0561,    LOSS_initial: 0.3098,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 619.2854356765747\n",
      "loss_compared with real:0.10714,   miu_train:0.002425,    lossmean:-0.08978\n",
      "Epoch [10200/100000], Loss: 2803,   LOSS_function: 811.1,   LOSS_E:0.02388,    LOSS_initial: 0.7582,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 626.0104200839996\n",
      "loss_compared with real:0.082632,   miu_train:0.001288,    lossmean:-0.007586\n",
      "Epoch [10300/100000], Loss: 1026,   LOSS_function: 431.7,   LOSS_E:0.01418,    LOSS_initial: 0.2261,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 632.5506620407104\n",
      "loss_compared with real:0.074855,   miu_train:0.003051,    lossmean:-0.07149\n",
      "Epoch [10400/100000], Loss: 936.9,   LOSS_function: 429.6,   LOSS_E:0.01331,    LOSS_initial: 0.1931,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 639.2386314868927\n",
      "loss_compared with real:0.064647,   miu_train:0.003056,    lossmean:-0.06401\n",
      "Epoch [10500/100000], Loss: 923.4,   LOSS_function: 416,   LOSS_E:0.03534,    LOSS_initial: 0.1931,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 646.1009957790375\n",
      "loss_compared with real:0.062899,   miu_train:0.003238,    lossmean:-0.06438\n",
      "Epoch [10600/100000], Loss: 844.8,   LOSS_function: 441.4,   LOSS_E:0.01413,    LOSS_initial: 0.1535,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 652.6398599147797\n",
      "loss_compared with real:0.054304,   miu_train:0.003255,    lossmean:-0.05405\n",
      "Epoch [10700/100000], Loss: 1028,   LOSS_function: 434.3,   LOSS_E:0.007413,    LOSS_initial: 0.226,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 659.1547119617462\n",
      "loss_compared with real:0.075441,   miu_train:0.00304,    lossmean:-0.07295\n",
      "Epoch [10800/100000], Loss: 864.2,   LOSS_function: 425.1,   LOSS_E:0.01754,    LOSS_initial: 0.1671,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 665.7445337772369\n",
      "loss_compared with real:0.056943,   miu_train:0.003182,    lossmean:-0.05837\n",
      "Epoch [10900/100000], Loss: 865.6,   LOSS_function: 288.9,   LOSS_E:0.007141,    LOSS_initial: 0.2195,\n",
      "lamda1:1,    lamda3:2627,      learn rate:0.0004892,    time: 672.6094689369202\n",
      "loss_compared with real:0.053245,   miu_train:0.004505,    lossmean:-0.05377\n",
      "Epoch [11000/100000], Loss: 1043,   LOSS_function: 452,   LOSS_E:0.7884,    LOSS_initial: 0.2321,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 679.188086271286\n",
      "loss_compared with real:0.11036,   miu_train:0.002872,    lossmean:-0.0873\n",
      "Epoch [11100/100000], Loss: 873.1,   LOSS_function: 418.6,   LOSS_E:0.007917,    LOSS_initial: 0.1784,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 685.7493193149567\n",
      "loss_compared with real:0.058499,   miu_train:0.00309,    lossmean:-0.05822\n",
      "Epoch [11200/100000], Loss: 815.8,   LOSS_function: 428.6,   LOSS_E:0.01062,    LOSS_initial: 0.152,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 692.2891399860382\n",
      "loss_compared with real:0.053013,   miu_train:0.003194,    lossmean:-0.05236\n",
      "Epoch [11300/100000], Loss: 779.4,   LOSS_function: 426.1,   LOSS_E:0.01174,    LOSS_initial: 0.1387,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 700.7987155914307\n",
      "loss_compared with real:0.049074,   miu_train:0.003231,    lossmean:-0.04967\n",
      "Epoch [11400/100000], Loss: 896.7,   LOSS_function: 415.5,   LOSS_E:0.0164,    LOSS_initial: 0.1889,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 708.4022014141083\n",
      "loss_compared with real:0.063694,   miu_train:0.003098,    lossmean:-0.06135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11500/100000], Loss: 772.6,   LOSS_function: 373.2,   LOSS_E:0.008624,    LOSS_initial: 0.1568,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 715.9126629829407\n",
      "loss_compared with real:0.04931,   miu_train:0.003703,    lossmean:-0.05069\n",
      "Epoch [11600/100000], Loss: 758.2,   LOSS_function: 428.3,   LOSS_E:0.006432,    LOSS_initial: 0.1295,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 723.3116602897644\n",
      "loss_compared with real:0.046103,   miu_train:0.003249,    lossmean:-0.04665\n",
      "Epoch [11700/100000], Loss: 1488,   LOSS_function: 531.2,   LOSS_E:0.005105,    LOSS_initial: 0.3758,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 730.7636163234711\n",
      "loss_compared with real:0.10106,   miu_train:0.003129,    lossmean:-0.1218\n",
      "Epoch [11800/100000], Loss: 944.3,   LOSS_function: 445.8,   LOSS_E:0.1542,    LOSS_initial: 0.1957,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 737.738849401474\n",
      "loss_compared with real:0.063848,   miu_train:0.004157,    lossmean:-0.04597\n",
      "Epoch [11900/100000], Loss: 964.2,   LOSS_function: 218.5,   LOSS_E:0.005431,    LOSS_initial: 0.2928,\n",
      "lamda1:1,    lamda3:2546,      learn rate:0.0004657,    time: 744.6408953666687\n",
      "loss_compared with real:0.052306,   miu_train:0.004891,    lossmean:-0.0537\n",
      "Epoch [12000/100000], Loss: 603.4,   LOSS_function: 305.7,   LOSS_E:0.01142,    LOSS_initial: 0.1765,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 751.5736167430878\n",
      "loss_compared with real:0.040961,   miu_train:0.002101,    lossmean:-0.04188\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5311, -0.5385, -0.3080, -0.9690, -0.0722, -0.3388,  0.4499, -0.8423,\n",
      "         0.8934,  0.3196,  0.7729,  0.5345,  0.6432, -0.0364,  0.7032, -0.3274,\n",
      "         0.8588,  0.0299,  0.7962, -0.7981, -0.2710, -0.9606, -0.4939, -0.3396,\n",
      "        -0.3127, -0.3744,  0.7217, -0.6244, -0.2525,  0.4313, -0.3209, -0.2001,\n",
      "         0.1068,  0.6392, -0.6892, -0.8061, -0.7046, -0.5757, -0.2706, -0.0457,\n",
      "        -0.8176, -0.9364, -0.0678,  0.8116, -0.6242,  0.8586, -0.6908,  0.9055,\n",
      "         0.5921, -0.9425, -0.7533, -0.3569,  0.8499, -0.6001,  0.9090, -0.1229,\n",
      "        -0.8832,  0.4199, -0.2663, -0.8614,  0.8255, -0.3164,  0.2703, -0.1162,\n",
      "        -0.5472, -0.0794, -0.0292,  0.4182, -0.4083, -0.3625,  0.5943, -0.4428,\n",
      "        -0.5067,  0.8602,  0.8122, -0.4387, -0.4499,  0.0173, -0.3394, -0.5445,\n",
      "        -0.7517, -0.7318,  0.9327,  0.0135,  0.1152,  0.8009,  0.6950,  0.2360,\n",
      "        -0.0320, -0.0813,  0.6660,  0.7099, -0.6785,  0.8904,  0.2230,  0.5654,\n",
      "        -0.6582, -0.1358,  0.6118,  0.0253, -0.8613,  0.0856, -0.0060, -0.2043,\n",
      "         0.4185,  0.5001,  0.6563,  0.0556,  0.2482,  0.6474, -0.6297, -0.2630,\n",
      "         0.5992,  0.7812,  0.7506,  0.0050, -0.9644,  0.8927, -0.3096, -0.8707,\n",
      "        -0.9629,  0.9082, -0.2343,  0.3723, -0.2373,  0.4344, -0.2119,  0.1840],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.1636, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0310, -0.0352,  0.0274,  0.0717, -0.0450, -0.0290, -0.0377,  0.0258,\n",
      "        -0.0343,  0.0436, -0.0120, -0.0945,  0.0483, -0.0435,  0.0678,  0.0252,\n",
      "        -0.0347, -0.0221, -0.0170,  0.0363, -0.0710,  0.0634,  0.0381,  0.0300,\n",
      "         0.0110, -0.0069,  0.0641, -0.0472, -0.0374, -0.0733,  0.0207, -0.0761,\n",
      "         0.0853, -0.0406,  0.0528,  0.0052, -0.0635,  0.0566,  0.0405, -0.0670,\n",
      "        -0.0920, -0.0783,  0.0122,  0.0759,  0.0592,  0.0816, -0.0339,  0.0861,\n",
      "        -0.0322,  0.0014,  0.0348,  0.0075, -0.0232,  0.0041,  0.0115, -0.0100,\n",
      "         0.0607,  0.0287,  0.0361,  0.0331,  0.0059, -0.0196, -0.0268,  0.0469,\n",
      "         0.0563,  0.0162,  0.0711,  0.0216,  0.0379,  0.0253,  0.0476,  0.0082,\n",
      "        -0.0353,  0.0023, -0.0775,  0.0019, -0.0368,  0.0603, -0.0091,  0.0186,\n",
      "         0.0445, -0.0241, -0.0196,  0.0432,  0.0201, -0.0944, -0.0195, -0.0022,\n",
      "         0.0948,  0.0754,  0.0380,  0.0587, -0.0524, -0.0713,  0.0695, -0.0677,\n",
      "         0.0417,  0.0464,  0.0324,  0.0811,  0.0755,  0.0527,  0.0431,  0.0849,\n",
      "         0.0673, -0.0064, -0.0671, -0.0731,  0.0103, -0.0425,  0.0387,  0.0312,\n",
      "        -0.0284, -0.0429, -0.0074,  0.0301,  0.0488, -0.0646, -0.1027,  0.0338,\n",
      "         0.0701,  0.0199,  0.0117, -0.0158,  0.0094,  0.0190, -0.0595,  0.0615],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1608, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0642, -0.0460, -0.0391,  0.0362, -0.0558, -0.0251, -0.0611, -0.0184,\n",
      "        -0.0219,  0.0613,  0.0117, -0.0415, -0.0325,  0.0030, -0.0292, -0.0916,\n",
      "        -0.0465,  0.0455,  0.0192, -0.1119,  0.0082, -0.0256, -0.0437, -0.0136,\n",
      "         0.0365,  0.0203,  0.0627,  0.0240, -0.0848, -0.0690, -0.0296,  0.0347,\n",
      "         0.0280, -0.0230,  0.0558,  0.0806,  0.0898,  0.0048,  0.0301,  0.1031,\n",
      "        -0.0591,  0.0368,  0.0205, -0.0433,  0.0514,  0.0323, -0.0746, -0.0709,\n",
      "         0.0071, -0.0263, -0.0584,  0.0655,  0.0455, -0.0619,  0.0459,  0.0363,\n",
      "         0.0237, -0.0861,  0.0119, -0.0728,  0.0295,  0.0543, -0.0208,  0.0493,\n",
      "         0.0805, -0.0169,  0.0218, -0.0145,  0.0155,  0.0251, -0.0856, -0.0362,\n",
      "         0.0014,  0.0487, -0.0049,  0.0650,  0.0869,  0.0179,  0.0069, -0.0228,\n",
      "         0.1133,  0.0083, -0.0609,  0.0850, -0.0119, -0.0078,  0.0271,  0.0655,\n",
      "         0.0067, -0.0843,  0.0358, -0.0863,  0.0106, -0.0453, -0.0647,  0.0548,\n",
      "        -0.0626, -0.0745, -0.0779,  0.0748, -0.0794,  0.0121,  0.0226,  0.0415,\n",
      "        -0.0307, -0.0581,  0.0474, -0.0751, -0.0876, -0.0519, -0.0689,  0.0024,\n",
      "         0.0631, -0.0673, -0.0473, -0.0236, -0.0225, -0.0294,  0.1030,  0.0011,\n",
      "        -0.0508,  0.0275,  0.0696,  0.0859, -0.0427, -0.0707, -0.0086, -0.0591],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1017, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0524, -0.0523, -0.0058,  0.1073, -0.0927,  0.0376, -0.0267, -0.0273,\n",
      "         0.0700,  0.0075,  0.0406,  0.0515,  0.0554, -0.1193, -0.0524,  0.0372,\n",
      "        -0.0190,  0.0051, -0.0167, -0.0300, -0.0278,  0.0260,  0.0855,  0.0699,\n",
      "         0.0295, -0.0432, -0.0094, -0.0333, -0.0189,  0.0317, -0.0023,  0.0490,\n",
      "         0.0452, -0.0031, -0.0614,  0.0605, -0.0428, -0.1136, -0.0702,  0.0207,\n",
      "         0.0651, -0.0893,  0.0536,  0.0447,  0.0560, -0.0704,  0.0806, -0.0010,\n",
      "        -0.1046, -0.0732, -0.0327, -0.0691, -0.0450,  0.0606,  0.0199,  0.0344,\n",
      "        -0.0194, -0.0683,  0.0611,  0.0209,  0.0182, -0.0519, -0.0348, -0.0337,\n",
      "         0.0186, -0.0831, -0.0827, -0.0775,  0.0393, -0.0621, -0.0632, -0.0419,\n",
      "        -0.0181, -0.0132, -0.0622,  0.0055, -0.0205, -0.0535,  0.0731, -0.0250,\n",
      "        -0.0794,  0.0627, -0.0066,  0.0574,  0.0311, -0.1062, -0.0063, -0.0406,\n",
      "        -0.0119,  0.0084, -0.0551, -0.0657,  0.0779,  0.0703, -0.0058,  0.0677,\n",
      "        -0.0744, -0.0775,  0.0614, -0.0543, -0.0426,  0.0189, -0.0546, -0.0209,\n",
      "         0.0374,  0.0671,  0.0252, -0.0988,  0.0472, -0.0991,  0.0659,  0.0585,\n",
      "        -0.0487, -0.0383,  0.0694, -0.0139, -0.0795,  0.0192, -0.0225,  0.0574,\n",
      "         0.0814, -0.0417,  0.0704, -0.0891, -0.0571,  0.0410, -0.0074,  0.0595],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0773, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0356,  0.0200,  0.0559], requires_grad=True)\n",
      "Epoch [12100/100000], Loss: 577.9,   LOSS_function: 285.1,   LOSS_E:0.007964,    LOSS_initial: 0.1736,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 758.3945553302765\n",
      "loss_compared with real:0.060725,   miu_train:0.002403,    lossmean:-0.05691\n",
      "Epoch [12200/100000], Loss: 570.1,   LOSS_function: 287.1,   LOSS_E:0.008224,    LOSS_initial: 0.1678,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 764.981128692627\n",
      "loss_compared with real:0.059087,   miu_train:0.002457,    lossmean:-0.05531\n",
      "Epoch [12300/100000], Loss: 563.8,   LOSS_function: 287.4,   LOSS_E:0.008404,    LOSS_initial: 0.1638,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 771.3091270923615\n",
      "loss_compared with real:0.057797,   miu_train:0.002494,    lossmean:-0.05437\n",
      "Epoch [12400/100000], Loss: 598.5,   LOSS_function: 405.6,   LOSS_E:0.01053,    LOSS_initial: 0.1143,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 777.7533314228058\n",
      "loss_compared with real:0.056715,   miu_train:0.001934,    lossmean:-0.05209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12500/100000], Loss: 554.2,   LOSS_function: 279.9,   LOSS_E:0.008141,    LOSS_initial: 0.1627,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 783.8912761211395\n",
      "loss_compared with real:0.056306,   miu_train:0.002541,    lossmean:-0.05397\n",
      "Epoch [12600/100000], Loss: 569.1,   LOSS_function: 342.3,   LOSS_E:0.01135,    LOSS_initial: 0.1344,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 790.0577805042267\n",
      "loss_compared with real:0.060148,   miu_train:0.00187,    lossmean:-0.05564\n",
      "Epoch [12700/100000], Loss: 546.7,   LOSS_function: 311.1,   LOSS_E:0.008485,    LOSS_initial: 0.1396,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 796.1956360340118\n",
      "loss_compared with real:0.052917,   miu_train:0.002437,    lossmean:-0.05075\n",
      "Epoch [12800/100000], Loss: 694.5,   LOSS_function: 462.9,   LOSS_E:0.01119,    LOSS_initial: 0.1372,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 802.3805372714996\n",
      "loss_compared with real:0.068639,   miu_train:0.002732,    lossmean:-0.07313\n",
      "Epoch [12900/100000], Loss: 563.8,   LOSS_function: 367.1,   LOSS_E:0.008662,    LOSS_initial: 0.1165,\n",
      "lamda1:1.001,    lamda3:1686,      learn rate:0.0004433,    time: 808.4713106155396\n",
      "loss_compared with real:0.04936,   miu_train:0.002229,    lossmean:-0.04609\n",
      "Epoch [13000/100000], Loss: 665.5,   LOSS_function: 365.9,   LOSS_E:0.01082,    LOSS_initial: 0.1138,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 814.5888273715973\n",
      "loss_compared with real:0.055049,   miu_train:0.004396,    lossmean:-0.05332\n",
      "Epoch [13100/100000], Loss: 1171,   LOSS_function: 357.5,   LOSS_E:0.001477,    LOSS_initial: 0.3092,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 820.9363749027252\n",
      "loss_compared with real:0.096751,   miu_train:0.002426,    lossmean:-0.08018\n",
      "Epoch [13200/100000], Loss: 1078,   LOSS_function: 420.9,   LOSS_E:0.000413,    LOSS_initial: 0.2497,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 826.9761686325073\n",
      "loss_compared with real:0.078095,   miu_train:0.002941,    lossmean:-0.07186\n",
      "Epoch [13300/100000], Loss: 1434,   LOSS_function: 1002,   LOSS_E:0.3616,    LOSS_initial: 0.1638,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 832.9673538208008\n",
      "loss_compared with real:0.1702,   miu_train:0.01357,    lossmean:0.03681\n",
      "Epoch [13400/100000], Loss: 1033,   LOSS_function: 427.7,   LOSS_E:0.0007167,    LOSS_initial: 0.23,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 839.5830373764038\n",
      "loss_compared with real:0.072627,   miu_train:0.00301,    lossmean:-0.06772\n",
      "Epoch [13500/100000], Loss: 958.9,   LOSS_function: 423.1,   LOSS_E:0.002153,    LOSS_initial: 0.2035,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 845.6887826919556\n",
      "loss_compared with real:0.065373,   miu_train:0.003101,    lossmean:-0.06382\n",
      "Epoch [13600/100000], Loss: 949.2,   LOSS_function: 418.9,   LOSS_E:0.003407,    LOSS_initial: 0.2015,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 851.754478931427\n",
      "loss_compared with real:0.063642,   miu_train:0.003155,    lossmean:-0.06311\n",
      "Epoch [13700/100000], Loss: 884.3,   LOSS_function: 450.9,   LOSS_E:0.01364,    LOSS_initial: 0.1646,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 857.8404610157013\n",
      "loss_compared with real:0.056181,   miu_train:0.003483,    lossmean:-0.05762\n",
      "Epoch [13800/100000], Loss: 923.6,   LOSS_function: 425.3,   LOSS_E:0.003704,    LOSS_initial: 0.1893,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 863.9202303886414\n",
      "loss_compared with real:0.057629,   miu_train:0.00347,    lossmean:-0.05699\n",
      "Epoch [13900/100000], Loss: 844.9,   LOSS_function: 444.8,   LOSS_E:0.01788,    LOSS_initial: 0.152,\n",
      "lamda1:1,    lamda3:2631,      learn rate:0.0004221,    time: 869.9997367858887\n",
      "loss_compared with real:0.053408,   miu_train:0.003529,    lossmean:-0.05586\n",
      "Epoch [14000/100000], Loss: 1416,   LOSS_function: 614.8,   LOSS_E:0.1773,    LOSS_initial: 0.1523,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 876.1769909858704\n",
      "loss_compared with real:0.085166,   miu_train:0.005107,    lossmean:-0.07855\n",
      "Epoch [14100/100000], Loss: 1161,   LOSS_function: 454.1,   LOSS_E:0.02087,    LOSS_initial: 0.1343,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 882.6053063869476\n",
      "loss_compared with real:0.028441,   miu_train:0.007082,    lossmean:-0.03704\n",
      "Epoch [14200/100000], Loss: 1248,   LOSS_function: 1096,   LOSS_E:0.02103,    LOSS_initial: 0.02882,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 889.2055671215057\n",
      "loss_compared with real:0.013932,   miu_train:0.003763,    lossmean:-0.01777\n",
      "Epoch [14300/100000], Loss: 949,   LOSS_function: 750.9,   LOSS_E:0.02644,    LOSS_initial: 0.03763,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 895.6946883201599\n",
      "loss_compared with real:0.014217,   miu_train:0.005214,    lossmean:-0.0191\n",
      "Epoch [14400/100000], Loss: 905.7,   LOSS_function: 578.9,   LOSS_E:0.006064,    LOSS_initial: 0.06208,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 902.1992769241333\n",
      "loss_compared with real:0.01774,   miu_train:0.006186,    lossmean:-0.02744\n",
      "Epoch [14500/100000], Loss: 875.3,   LOSS_function: 724.9,   LOSS_E:0.02515,    LOSS_initial: 0.02857,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 908.9118430614471\n",
      "loss_compared with real:0.013135,   miu_train:0.005416,    lossmean:-0.01683\n",
      "Epoch [14600/100000], Loss: 904.1,   LOSS_function: 644.9,   LOSS_E:0.01217,    LOSS_initial: 0.04924,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 915.3648426532745\n",
      "loss_compared with real:0.015422,   miu_train:0.006416,    lossmean:-0.02087\n",
      "Epoch [14700/100000], Loss: 797,   LOSS_function: 554.5,   LOSS_E:0.0166,    LOSS_initial: 0.04606,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 921.8378477096558\n",
      "loss_compared with real:0.011858,   miu_train:0.006177,    lossmean:-0.0195\n",
      "Epoch [14800/100000], Loss: 773.6,   LOSS_function: 622.8,   LOSS_E:0.02627,    LOSS_initial: 0.02864,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 928.5336184501648\n",
      "loss_compared with real:0.016022,   miu_train:0.006071,    lossmean:-0.02614\n",
      "Epoch [14900/100000], Loss: 1395,   LOSS_function: 378.1,   LOSS_E:0.01704,    LOSS_initial: 0.1933,\n",
      "lamda1:1,    lamda3:5261,      learn rate:0.0004018,    time: 935.1980354785919\n",
      "loss_compared with real:0.014086,   miu_train:0.007459,    lossmean:-0.0229\n",
      "Epoch [15000/100000], Loss: 807.8,   LOSS_function: 610.5,   LOSS_E:0.03523,    LOSS_initial: 0.03517,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 942.0560522079468\n",
      "loss_compared with real:0.0098425,   miu_train:0.005954,    lossmean:-0.01411\n",
      "Epoch [15100/100000], Loss: 731.3,   LOSS_function: 575.3,   LOSS_E:0.005248,    LOSS_initial: 0.02782,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 948.6265788078308\n",
      "loss_compared with real:0.0093436,   miu_train:0.006701,    lossmean:-0.01818\n",
      "Epoch [15200/100000], Loss: 797.5,   LOSS_function: 469.1,   LOSS_E:0.01191,    LOSS_initial: 0.05856,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 955.2473921775818\n",
      "loss_compared with real:0.010597,   miu_train:0.007403,    lossmean:-0.02084\n",
      "Epoch [15300/100000], Loss: 730.2,   LOSS_function: 518.9,   LOSS_E:0.02968,    LOSS_initial: 0.03768,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 961.8310036659241\n",
      "loss_compared with real:0.0087189,   miu_train:0.007048,    lossmean:-0.01646\n",
      "Epoch [15400/100000], Loss: 1081,   LOSS_function: 897.9,   LOSS_E:0.004793,    LOSS_initial: 0.0327,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 968.4697911739349\n",
      "loss_compared with real:0.011857,   miu_train:0.007309,    lossmean:-0.018\n",
      "Epoch [15500/100000], Loss: 758.4,   LOSS_function: 685.2,   LOSS_E:0.01002,    LOSS_initial: 0.01304,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 975.4147355556488\n",
      "loss_compared with real:0.0071232,   miu_train:0.005974,    lossmean:-0.01254\n",
      "Epoch [15600/100000], Loss: 803.2,   LOSS_function: 708.6,   LOSS_E:0.0114,    LOSS_initial: 0.01686,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 981.9917845726013\n",
      "loss_compared with real:0.0067463,   miu_train:0.006312,    lossmean:-0.01186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15700/100000], Loss: 673.9,   LOSS_function: 520.9,   LOSS_E:0.01062,    LOSS_initial: 0.02727,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 988.4463028907776\n",
      "loss_compared with real:0.0061815,   miu_train:0.007539,    lossmean:-0.009332\n",
      "Epoch [15800/100000], Loss: 642.4,   LOSS_function: 565.6,   LOSS_E:0.01587,    LOSS_initial: 0.01368,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 995.0156121253967\n",
      "loss_compared with real:0.007489,   miu_train:0.006942,    lossmean:-0.01445\n",
      "Epoch [15900/100000], Loss: 712.4,   LOSS_function: 402.8,   LOSS_E:0.008373,    LOSS_initial: 0.05521,\n",
      "lamda1:1,    lamda3:5606,      learn rate:0.0003825,    time: 1001.836460351944\n",
      "loss_compared with real:0.0065753,   miu_train:0.007861,    lossmean:-0.01441\n",
      "Epoch [16000/100000], Loss: 567.2,   LOSS_function: 459.2,   LOSS_E:0.01458,    LOSS_initial: 0.02638,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1008.3881742954254\n",
      "loss_compared with real:0.0059888,   miu_train:0.006766,    lossmean:-0.01338\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5260, -0.5299, -0.3020, -0.9657, -0.0699, -0.3304,  0.4437, -0.8279,\n",
      "         0.8673,  0.3162,  0.7628,  0.5308,  0.6328, -0.0343,  0.7029, -0.3241,\n",
      "         0.8323,  0.0285,  0.7882, -0.7939, -0.2663, -0.9675, -0.4907, -0.3346,\n",
      "        -0.3075, -0.3683,  0.7060, -0.6234, -0.2444,  0.4250, -0.3110, -0.1971,\n",
      "         0.1044,  0.6337, -0.6801, -0.7967, -0.7024, -0.5697, -0.2622, -0.0437,\n",
      "        -0.8129, -0.9515, -0.0639,  0.8016, -0.6122,  0.8583, -0.6837,  0.9080,\n",
      "         0.5889, -0.9303, -0.7484, -0.3505,  0.8361, -0.5975,  0.9127, -0.1204,\n",
      "        -0.8825,  0.4182, -0.2619, -0.8601,  0.8318, -0.3157,  0.2648, -0.1155,\n",
      "        -0.5390, -0.0792, -0.0274,  0.4134, -0.4068, -0.3560,  0.5810, -0.4354,\n",
      "        -0.5008,  0.8667,  0.7968, -0.4342, -0.4454,  0.0184, -0.3318, -0.5365,\n",
      "        -0.7430, -0.7010,  0.9007,  0.0141,  0.1152,  0.7682,  0.6856,  0.2315,\n",
      "        -0.0326, -0.0817,  0.6565,  0.7106, -0.6641,  0.9142,  0.2213,  0.5623,\n",
      "        -0.6564, -0.1344,  0.6089,  0.0258, -0.8620,  0.0822, -0.0069, -0.1969,\n",
      "         0.4068,  0.4964,  0.6476,  0.0557,  0.2434,  0.6363, -0.6225, -0.2617,\n",
      "         0.5982,  0.7694,  0.7331,  0.0059, -0.9622,  0.8827, -0.3027, -0.8735,\n",
      "        -0.9669,  0.8973, -0.2314,  0.3677, -0.2335,  0.4256, -0.2076,  0.1831],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2198, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0293, -0.0333,  0.0258,  0.0728, -0.0417, -0.0318, -0.0373,  0.0275,\n",
      "        -0.0329,  0.0431, -0.0134, -0.0959,  0.0468, -0.0439,  0.0690,  0.0269,\n",
      "        -0.0348, -0.0219, -0.0206,  0.0358, -0.0698,  0.0616,  0.0363,  0.0251,\n",
      "         0.0124, -0.0104,  0.0632, -0.0493, -0.0365, -0.0720,  0.0235, -0.0707,\n",
      "         0.0855, -0.0449,  0.0573,  0.0054, -0.0697,  0.0593,  0.0364, -0.0612,\n",
      "        -0.0941, -0.0749,  0.0127,  0.0766,  0.0584,  0.0792, -0.0355,  0.0838,\n",
      "        -0.0334,  0.0033,  0.0390,  0.0088, -0.0226,  0.0092,  0.0124, -0.0085,\n",
      "         0.0622,  0.0284,  0.0266,  0.0343,  0.0053, -0.0192, -0.0242,  0.0462,\n",
      "         0.0574,  0.0090,  0.0705,  0.0235,  0.0385,  0.0214,  0.0488,  0.0049,\n",
      "        -0.0313,  0.0015, -0.0762,  0.0019, -0.0377,  0.0624, -0.0077,  0.0155,\n",
      "         0.0383, -0.0253, -0.0161,  0.0469,  0.0218, -0.0927, -0.0210,  0.0013,\n",
      "         0.0895,  0.0745,  0.0415,  0.0560, -0.0493, -0.0691,  0.0657, -0.0663,\n",
      "         0.0397,  0.0469,  0.0350,  0.0815,  0.0745,  0.0502,  0.0480,  0.0816,\n",
      "         0.0704, -0.0074, -0.0690, -0.0733,  0.0193, -0.0418,  0.0393,  0.0323,\n",
      "        -0.0234, -0.0450, -0.0049,  0.0262,  0.0498, -0.0643, -0.1047,  0.0336,\n",
      "         0.0700,  0.0215,  0.0147, -0.0183,  0.0104,  0.0184, -0.0595,  0.0649],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.1971, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0655, -0.0490, -0.0395,  0.0359, -0.0610, -0.0171, -0.0575, -0.0163,\n",
      "        -0.0246,  0.0564,  0.0121, -0.0337, -0.0321, -0.0041, -0.0279, -0.0862,\n",
      "        -0.0471,  0.0463,  0.0249, -0.1130,  0.0074, -0.0230, -0.0428, -0.0088,\n",
      "         0.0380,  0.0167,  0.0639,  0.0192, -0.0883, -0.0685, -0.0273,  0.0269,\n",
      "         0.0280, -0.0196,  0.0530,  0.0753,  0.0904,  0.0039,  0.0285,  0.1126,\n",
      "        -0.0564,  0.0310,  0.0130, -0.0414,  0.0526,  0.0353, -0.0760, -0.0722,\n",
      "         0.0036, -0.0263, -0.0621,  0.0660,  0.0445, -0.0657,  0.0463,  0.0340,\n",
      "         0.0229, -0.0949,  0.0136, -0.0740,  0.0269,  0.0511, -0.0250,  0.0515,\n",
      "         0.0854, -0.0136,  0.0221, -0.0075,  0.0287,  0.0362, -0.0835, -0.0399,\n",
      "        -0.0043,  0.0426, -0.0021,  0.0611,  0.0873,  0.0063,  0.0069, -0.0210,\n",
      "         0.1151,  0.0094, -0.0580,  0.0854, -0.0098, -0.0099,  0.0279,  0.0691,\n",
      "         0.0059, -0.0865,  0.0425, -0.0869,  0.0118, -0.0470, -0.0579,  0.0526,\n",
      "        -0.0591, -0.0862, -0.0775,  0.0778, -0.0751,  0.0126,  0.0169,  0.0388,\n",
      "        -0.0283, -0.0586,  0.0482, -0.0739, -0.0928, -0.0523, -0.0646,  0.0041,\n",
      "         0.0625, -0.0539, -0.0491, -0.0238, -0.0246, -0.0240,  0.0995,  0.0114,\n",
      "        -0.0412,  0.0262,  0.0715,  0.0899, -0.0426, -0.0722, -0.0074, -0.0654],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1039, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0597, -0.0499, -0.0068,  0.1098, -0.0940,  0.0405, -0.0278, -0.0264,\n",
      "         0.0681,  0.0078,  0.0444,  0.0539,  0.0576, -0.1210, -0.0548,  0.0347,\n",
      "        -0.0220,  0.0016, -0.0218, -0.0288, -0.0253,  0.0312,  0.0892,  0.0613,\n",
      "         0.0339, -0.0460, -0.0086, -0.0312, -0.0234,  0.0342,  0.0013,  0.0494,\n",
      "         0.0325,  0.0030, -0.0569,  0.0681, -0.0412, -0.1159, -0.0736,  0.0222,\n",
      "         0.0618, -0.0844,  0.0526,  0.0473,  0.0517, -0.0733,  0.0772,  0.0012,\n",
      "        -0.1141, -0.0733, -0.0328, -0.0702, -0.0437,  0.0622,  0.0179,  0.0325,\n",
      "        -0.0202, -0.0636,  0.0588,  0.0195,  0.0236, -0.0530, -0.0369, -0.0358,\n",
      "         0.0252, -0.0879, -0.0874, -0.0841,  0.0418, -0.0591, -0.0660, -0.0476,\n",
      "        -0.0170, -0.0145, -0.0648,  0.0016, -0.0255, -0.0625,  0.0680, -0.0185,\n",
      "        -0.0770,  0.0521, -0.0103,  0.0684,  0.0298, -0.1049, -0.0090, -0.0407,\n",
      "        -0.0133,  0.0156, -0.0620, -0.0730,  0.0815,  0.0660, -0.0031,  0.0679,\n",
      "        -0.0781, -0.0698,  0.0640, -0.0537, -0.0408,  0.0111, -0.0512, -0.0176,\n",
      "         0.0394,  0.0696,  0.0365, -0.0975,  0.0444, -0.1024,  0.0634,  0.0665,\n",
      "        -0.0431, -0.0339,  0.0716, -0.0141, -0.0768,  0.0162, -0.0269,  0.0594,\n",
      "         0.0853, -0.0398,  0.0753, -0.0876, -0.0530,  0.0370, -0.0037,  0.0593],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0778, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0297,  0.0195,  0.0597], requires_grad=True)\n",
      "Epoch [16100/100000], Loss: 523.8,   LOSS_function: 422.3,   LOSS_E:0.007409,    LOSS_initial: 0.02479,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1014.8871378898621\n",
      "loss_compared with real:0.0085877,   miu_train:0.00727,    lossmean:-0.01633\n",
      "Epoch [16200/100000], Loss: 503.1,   LOSS_function: 406,   LOSS_E:0.006849,    LOSS_initial: 0.02373,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1021.4088044166565\n",
      "loss_compared with real:0.00798,   miu_train:0.007439,    lossmean:-0.01556\n",
      "Epoch [16300/100000], Loss: 482.8,   LOSS_function: 388.9,   LOSS_E:0.007221,    LOSS_initial: 0.02295,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1027.9284193515778\n",
      "loss_compared with real:0.0073487,   miu_train:0.007789,    lossmean:-0.01497\n",
      "Epoch [16400/100000], Loss: 480.5,   LOSS_function: 394.9,   LOSS_E:0.01028,    LOSS_initial: 0.02091,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1034.448857307434\n",
      "loss_compared with real:0.0082007,   miu_train:0.007806,    lossmean:-0.019\n",
      "Epoch [16500/100000], Loss: 476.5,   LOSS_function: 421.1,   LOSS_E:0.01098,    LOSS_initial: 0.01352,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1041.0511438846588\n",
      "loss_compared with real:0.0066469,   miu_train:0.008029,    lossmean:-0.01681\n",
      "Epoch [16600/100000], Loss: 467.3,   LOSS_function: 406.5,   LOSS_E:0.005884,    LOSS_initial: 0.01485,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1047.5844485759735\n",
      "loss_compared with real:0.0057114,   miu_train:0.007973,    lossmean:-0.01141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16700/100000], Loss: 433.1,   LOSS_function: 345.3,   LOSS_E:0.005846,    LOSS_initial: 0.02146,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1054.0205471515656\n",
      "loss_compared with real:0.0052697,   miu_train:0.009086,    lossmean:-0.00874\n",
      "Epoch [16800/100000], Loss: 410.9,   LOSS_function: 308.5,   LOSS_E:0.01096,    LOSS_initial: 0.02504,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1060.0988800525665\n",
      "loss_compared with real:0.0057229,   miu_train:0.009259,    lossmean:-0.01185\n",
      "Epoch [16900/100000], Loss: 436.3,   LOSS_function: 367.1,   LOSS_E:0.01501,    LOSS_initial: 0.01692,\n",
      "lamda1:1,    lamda3:4088,      learn rate:0.0003642,    time: 1066.409837961197\n",
      "loss_compared with real:0.0053108,   miu_train:0.009123,    lossmean:-0.01257\n",
      "Epoch [17000/100000], Loss: 388,   LOSS_function: 311.7,   LOSS_E:0.00873,    LOSS_initial: 0.01645,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1072.4528057575226\n",
      "loss_compared with real:0.0038012,   miu_train:0.01063,    lossmean:-0.008374\n",
      "Epoch [17100/100000], Loss: 388.5,   LOSS_function: 357.5,   LOSS_E:0.00402,    LOSS_initial: 0.006666,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1078.4875557422638\n",
      "loss_compared with real:0.0034907,   miu_train:0.009987,    lossmean:-0.005173\n",
      "Epoch [17200/100000], Loss: 331.5,   LOSS_function: 313,   LOSS_E:0.00735,    LOSS_initial: 0.003958,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1084.5522463321686\n",
      "loss_compared with real:0.002177,   miu_train:0.01033,    lossmean:-0.007182\n",
      "Epoch [17300/100000], Loss: 299,   LOSS_function: 251.5,   LOSS_E:0.006764,    LOSS_initial: 0.01024,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1090.575799703598\n",
      "loss_compared with real:0.0031253,   miu_train:0.01096,    lossmean:-0.006573\n",
      "Epoch [17400/100000], Loss: 387.2,   LOSS_function: 363.3,   LOSS_E:0.01464,    LOSS_initial: 0.005138,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1096.6147575378418\n",
      "loss_compared with real:0.0033936,   miu_train:0.01002,    lossmean:-0.008264\n",
      "Epoch [17500/100000], Loss: 274.6,   LOSS_function: 246.5,   LOSS_E:0.007916,    LOSS_initial: 0.006059,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1102.7293901443481\n",
      "loss_compared with real:0.0017462,   miu_train:0.01171,    lossmean:-0.005118\n",
      "Epoch [17600/100000], Loss: 333.7,   LOSS_function: 275.4,   LOSS_E:0.01136,    LOSS_initial: 0.01256,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1108.7832980155945\n",
      "loss_compared with real:0.002044,   miu_train:0.01052,    lossmean:-0.004582\n",
      "Epoch [17700/100000], Loss: 347.1,   LOSS_function: 270.3,   LOSS_E:0.01591,    LOSS_initial: 0.01657,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1114.8399593830109\n",
      "loss_compared with real:0.0034565,   miu_train:0.0127,    lossmean:-0.008798\n",
      "Epoch [17800/100000], Loss: 242,   LOSS_function: 225.8,   LOSS_E:0.00807,    LOSS_initial: 0.003482,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1121.0036120414734\n",
      "loss_compared with real:0.0014692,   miu_train:0.01214,    lossmean:-0.004812\n",
      "Epoch [17900/100000], Loss: 307.8,   LOSS_function: 273.4,   LOSS_E:0.01027,    LOSS_initial: 0.00742,\n",
      "lamda1:1,    lamda3:4635,      learn rate:0.0003467,    time: 1127.22714304924\n",
      "loss_compared with real:0.0021487,   miu_train:0.009979,    lossmean:-0.004287\n",
      "Epoch [18000/100000], Loss: 216.7,   LOSS_function: 199.6,   LOSS_E:0.007537,    LOSS_initial: 0.004637,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1133.3187098503113\n",
      "loss_compared with real:0.0012797,   miu_train:0.01245,    lossmean:-0.004611\n",
      "Epoch [18100/100000], Loss: 199.9,   LOSS_function: 182.5,   LOSS_E:0.006669,    LOSS_initial: 0.004749,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1139.3844299316406\n",
      "loss_compared with real:0.0016023,   miu_train:0.01252,    lossmean:-0.004967\n",
      "Epoch [18200/100000], Loss: 199.5,   LOSS_function: 180,   LOSS_E:0.008057,    LOSS_initial: 0.005296,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1145.4197998046875\n",
      "loss_compared with real:0.001674,   miu_train:0.01254,    lossmean:-0.004463\n",
      "Epoch [18300/100000], Loss: 191.6,   LOSS_function: 177.1,   LOSS_E:0.007341,    LOSS_initial: 0.003943,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1151.4679279327393\n",
      "loss_compared with real:0.0014534,   miu_train:0.01256,    lossmean:-0.004456\n",
      "Epoch [18400/100000], Loss: 197.7,   LOSS_function: 179.3,   LOSS_E:0.01099,    LOSS_initial: 0.00498,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1157.573689699173\n",
      "loss_compared with real:0.0015702,   miu_train:0.01229,    lossmean:-0.005418\n",
      "Epoch [18500/100000], Loss: 185.4,   LOSS_function: 171.1,   LOSS_E:0.007741,    LOSS_initial: 0.003886,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1163.5884234905243\n",
      "loss_compared with real:0.001383,   miu_train:0.01269,    lossmean:-0.004752\n",
      "Epoch [18600/100000], Loss: 185,   LOSS_function: 171.1,   LOSS_E:0.007704,    LOSS_initial: 0.003769,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1169.7908565998077\n",
      "loss_compared with real:0.0013668,   miu_train:0.01264,    lossmean:-0.005033\n",
      "Epoch [18700/100000], Loss: 203.1,   LOSS_function: 183.3,   LOSS_E:0.008229,    LOSS_initial: 0.005378,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1175.8814668655396\n",
      "loss_compared with real:0.0013439,   miu_train:0.01233,    lossmean:-0.004777\n",
      "Epoch [18800/100000], Loss: 217,   LOSS_function: 184.9,   LOSS_E:0.009063,    LOSS_initial: 0.008728,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1182.1430323123932\n",
      "loss_compared with real:0.0016455,   miu_train:0.01233,    lossmean:-0.004548\n",
      "Epoch [18900/100000], Loss: 221,   LOSS_function: 171.3,   LOSS_E:0.008558,    LOSS_initial: 0.01351,\n",
      "lamda1:1,    lamda3:3673,      learn rate:0.00033,    time: 1188.6396639347076\n",
      "loss_compared with real:0.0015671,   miu_train:0.01267,    lossmean:-0.004653\n",
      "Epoch [19000/100000], Loss: 193.1,   LOSS_function: 169.6,   LOSS_E:0.007321,    LOSS_initial: 0.00842,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1195.2723717689514\n",
      "loss_compared with real:0.0015135,   miu_train:0.01182,    lossmean:-0.005332\n",
      "Epoch [19100/100000], Loss: 397.8,   LOSS_function: 374,   LOSS_E:0.01017,    LOSS_initial: 0.008486,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1201.7618067264557\n",
      "loss_compared with real:0.0018461,   miu_train:0.01514,    lossmean:-0.008203\n",
      "Epoch [19200/100000], Loss: 170.7,   LOSS_function: 156.3,   LOSS_E:0.009157,    LOSS_initial: 0.005162,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1208.3693430423737\n",
      "loss_compared with real:0.0020077,   miu_train:0.01256,    lossmean:-0.006217\n",
      "Epoch [19300/100000], Loss: 169.2,   LOSS_function: 152,   LOSS_E:0.008633,    LOSS_initial: 0.00614,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1214.82865691185\n",
      "loss_compared with real:0.0019131,   miu_train:0.01254,    lossmean:-0.006238\n",
      "Epoch [19400/100000], Loss: 197.5,   LOSS_function: 166.2,   LOSS_E:0.008623,    LOSS_initial: 0.01125,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1221.4140610694885\n",
      "loss_compared with real:0.0022617,   miu_train:0.01247,    lossmean:-0.008591\n",
      "Epoch [19500/100000], Loss: 180.3,   LOSS_function: 171.2,   LOSS_E:0.008344,    LOSS_initial: 0.003247,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1227.988713979721\n",
      "loss_compared with real:0.0017556,   miu_train:0.01229,    lossmean:-0.005202\n",
      "Epoch [19600/100000], Loss: 166.4,   LOSS_function: 154,   LOSS_E:0.007699,    LOSS_initial: 0.004458,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1234.710524559021\n",
      "loss_compared with real:0.0018246,   miu_train:0.01252,    lossmean:-0.006402\n",
      "Epoch [19700/100000], Loss: 177.8,   LOSS_function: 154.1,   LOSS_E:0.008198,    LOSS_initial: 0.008501,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1241.2573137283325\n",
      "loss_compared with real:0.0017372,   miu_train:0.01278,    lossmean:-0.006256\n",
      "Epoch [19800/100000], Loss: 397.5,   LOSS_function: 284.1,   LOSS_E:0.01176,    LOSS_initial: 0.0407,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1248.2946600914001\n",
      "loss_compared with real:0.0025168,   miu_train:0.0137,    lossmean:-0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19900/100000], Loss: 190.6,   LOSS_function: 180.5,   LOSS_E:0.009615,    LOSS_initial: 0.00362,\n",
      "lamda1:1,    lamda3:2781,      learn rate:0.0003142,    time: 1254.7825825214386\n",
      "loss_compared with real:0.0023112,   miu_train:0.01159,    lossmean:-0.007036\n",
      "Epoch [20000/100000], Loss: 168.8,   LOSS_function: 153.5,   LOSS_E:0.008248,    LOSS_initial: 0.00537,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1261.3135030269623\n",
      "loss_compared with real:0.0017342,   miu_train:0.01277,    lossmean:-0.005681\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5253, -0.5268, -0.3007, -0.9639, -0.0705, -0.3274,  0.4421, -0.8276,\n",
      "         0.8663,  0.3138,  0.7586,  0.5264,  0.6214, -0.0352,  0.7042, -0.3215,\n",
      "         0.8310,  0.0292,  0.7892, -0.7929, -0.2662, -0.9672, -0.4888, -0.3340,\n",
      "        -0.3035, -0.3660,  0.7065, -0.6209, -0.2446,  0.4216, -0.3109, -0.1951,\n",
      "         0.1047,  0.6296, -0.6801, -0.7955, -0.7024, -0.5635, -0.2601, -0.0432,\n",
      "        -0.8123, -0.9517, -0.0639,  0.7991, -0.6059,  0.8586, -0.6856,  0.9067,\n",
      "         0.5901, -0.9299, -0.7443, -0.3499,  0.8317, -0.5961,  0.9162, -0.1203,\n",
      "        -0.8851,  0.4163, -0.2606, -0.8660,  0.8393, -0.3140,  0.2636, -0.1140,\n",
      "        -0.5318, -0.0784, -0.0282,  0.4111, -0.4071, -0.3543,  0.5695, -0.4323,\n",
      "        -0.4964,  0.8775,  0.7973, -0.4335, -0.4450,  0.0171, -0.3297, -0.5317,\n",
      "        -0.7437, -0.6694,  0.8980,  0.0131,  0.1139,  0.7603,  0.6749,  0.2308,\n",
      "        -0.0314, -0.0806,  0.6466,  0.7173, -0.6510,  0.9287,  0.2187,  0.5599,\n",
      "        -0.6524, -0.1321,  0.6067,  0.0245, -0.8599,  0.0827, -0.0059, -0.1930,\n",
      "         0.4065,  0.4962,  0.6505,  0.0543,  0.2395,  0.6307, -0.6190, -0.2555,\n",
      "         0.5978,  0.7712,  0.7162,  0.0045, -0.9613,  0.8788, -0.3013, -0.8772,\n",
      "        -0.9661,  0.9001, -0.2284,  0.3635, -0.2329,  0.4219, -0.2063,  0.1828],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2497, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0278, -0.0316,  0.0251,  0.0724, -0.0413, -0.0302, -0.0377,  0.0288,\n",
      "        -0.0340,  0.0415, -0.0145, -0.0940,  0.0476, -0.0439,  0.0693,  0.0264,\n",
      "        -0.0381, -0.0224, -0.0185,  0.0352, -0.0719,  0.0604,  0.0344,  0.0227,\n",
      "         0.0127, -0.0116,  0.0630, -0.0456, -0.0382, -0.0736,  0.0275, -0.0679,\n",
      "         0.0831, -0.0468,  0.0590,  0.0053, -0.0687,  0.0538,  0.0376, -0.0585,\n",
      "        -0.0958, -0.0739,  0.0148,  0.0741,  0.0613,  0.0788, -0.0353,  0.0825,\n",
      "        -0.0327,  0.0035,  0.0392,  0.0109, -0.0209,  0.0090,  0.0118, -0.0075,\n",
      "         0.0621,  0.0267,  0.0275,  0.0320,  0.0051, -0.0172, -0.0248,  0.0464,\n",
      "         0.0572,  0.0045,  0.0704,  0.0229,  0.0386,  0.0190,  0.0497,  0.0066,\n",
      "        -0.0308,  0.0014, -0.0764,  0.0007, -0.0379,  0.0651, -0.0061,  0.0136,\n",
      "         0.0380, -0.0254, -0.0152,  0.0461,  0.0220, -0.0922, -0.0216,  0.0022,\n",
      "         0.0889,  0.0720,  0.0435,  0.0515, -0.0500, -0.0668,  0.0664, -0.0671,\n",
      "         0.0408,  0.0474,  0.0352,  0.0828,  0.0784,  0.0486,  0.0483,  0.0802,\n",
      "         0.0693, -0.0049, -0.0692, -0.0720,  0.0215, -0.0418,  0.0398,  0.0323,\n",
      "        -0.0209, -0.0462, -0.0049,  0.0247,  0.0485, -0.0646, -0.1046,  0.0321,\n",
      "         0.0712,  0.0210,  0.0190, -0.0190,  0.0123,  0.0168, -0.0597,  0.0649],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2237, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 6.8120e-02, -4.7581e-02, -3.8522e-02,  3.4497e-02, -5.9258e-02,\n",
      "        -1.8183e-02, -5.7197e-02, -1.4930e-02, -2.5630e-02,  5.4304e-02,\n",
      "         1.3161e-02, -3.4455e-02, -3.1610e-02, -7.2266e-03, -2.8951e-02,\n",
      "        -8.1774e-02, -4.7139e-02,  4.6060e-02,  2.5532e-02, -1.1649e-01,\n",
      "         1.0724e-02, -2.1224e-02, -4.2113e-02, -9.2862e-03,  3.7116e-02,\n",
      "         1.3115e-02,  5.8776e-02,  1.6273e-02, -9.0741e-02, -6.7282e-02,\n",
      "        -2.6554e-02,  2.3499e-02,  2.7336e-02, -1.9469e-02,  4.8897e-02,\n",
      "         7.5386e-02,  9.1302e-02,  6.9067e-03,  2.6673e-02,  1.1099e-01,\n",
      "        -5.6643e-02,  2.9304e-02,  9.2308e-03, -4.2869e-02,  5.0131e-02,\n",
      "         3.9237e-02, -7.6666e-02, -7.3898e-02,  5.9190e-03, -2.4497e-02,\n",
      "        -6.1172e-02,  6.6924e-02,  4.3564e-02, -7.0148e-02,  4.5048e-02,\n",
      "         3.7995e-02,  2.2024e-02, -9.8482e-02,  1.1260e-02, -7.4219e-02,\n",
      "         2.8880e-02,  5.0689e-02, -2.3325e-02,  4.9817e-02,  8.5156e-02,\n",
      "        -1.7006e-02,  2.3331e-02, -3.4585e-03,  2.9973e-02,  3.3788e-02,\n",
      "        -8.5748e-02, -4.1092e-02, -4.2748e-03,  4.1995e-02, -2.3762e-03,\n",
      "         6.3395e-02,  8.3548e-02,  2.7949e-03,  7.2427e-03, -2.1664e-02,\n",
      "         1.1809e-01,  9.6867e-03, -5.7642e-02,  8.6695e-02, -8.3847e-03,\n",
      "        -7.9826e-03,  2.6151e-02,  6.7682e-02,  4.0782e-03, -8.3416e-02,\n",
      "         4.1294e-02, -8.4590e-02,  8.7663e-03, -4.5650e-02, -5.6240e-02,\n",
      "         5.3494e-02, -5.9159e-02, -7.9372e-02, -7.7956e-02,  7.4191e-02,\n",
      "        -7.3831e-02,  1.5639e-02,  1.6870e-02,  3.7703e-02, -2.8269e-02,\n",
      "        -5.9918e-02,  4.6437e-02, -7.2914e-02, -9.6584e-02, -5.1070e-02,\n",
      "        -6.1479e-02, -5.1019e-05,  5.9292e-02, -5.7274e-02, -4.9648e-02,\n",
      "        -2.7249e-02, -2.3819e-02, -1.7843e-02,  1.0058e-01,  1.2212e-02,\n",
      "        -4.0394e-02,  2.0136e-02,  7.5101e-02,  8.8599e-02, -4.1220e-02,\n",
      "        -7.4139e-02, -5.4275e-03, -6.8327e-02], requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1079, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0625, -0.0516, -0.0031,  0.1090, -0.0946,  0.0434, -0.0287, -0.0261,\n",
      "         0.0583,  0.0089,  0.0467,  0.0581,  0.0593, -0.1240, -0.0565,  0.0343,\n",
      "        -0.0215,  0.0007, -0.0229, -0.0276, -0.0267,  0.0334,  0.0904,  0.0581,\n",
      "         0.0367, -0.0497, -0.0125, -0.0291, -0.0259,  0.0340,  0.0059,  0.0464,\n",
      "         0.0200,  0.0026, -0.0558,  0.0737, -0.0354, -0.1162, -0.0731,  0.0225,\n",
      "         0.0586, -0.0858,  0.0528,  0.0491,  0.0522, -0.0789,  0.0780,  0.0002,\n",
      "        -0.1128, -0.0750, -0.0341, -0.0717, -0.0421,  0.0633,  0.0207,  0.0324,\n",
      "        -0.0192, -0.0613,  0.0621,  0.0219,  0.0225, -0.0482, -0.0374, -0.0287,\n",
      "         0.0235, -0.0888, -0.0863, -0.0815,  0.0411, -0.0562, -0.0744, -0.0496,\n",
      "        -0.0168, -0.0106, -0.0647,  0.0010, -0.0293, -0.0629,  0.0667, -0.0173,\n",
      "        -0.0786,  0.0515, -0.0141,  0.0676,  0.0321, -0.1093, -0.0159, -0.0477,\n",
      "        -0.0136,  0.0160, -0.0649, -0.0756,  0.0827,  0.0677, -0.0030,  0.0634,\n",
      "        -0.0824, -0.0686,  0.0664, -0.0521, -0.0452,  0.0116, -0.0491, -0.0220,\n",
      "         0.0419,  0.0696,  0.0373, -0.0986,  0.0448, -0.1018,  0.0634,  0.0666,\n",
      "        -0.0383, -0.0331,  0.0635, -0.0146, -0.0780,  0.0141, -0.0255,  0.0607,\n",
      "         0.0858, -0.0364,  0.0758, -0.0882, -0.0527,  0.0379, -0.0031,  0.0602],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0744, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([-0.0112,  0.0229,  0.0618], requires_grad=True)\n",
      "Epoch [20100/100000], Loss: 172,   LOSS_function: 159,   LOSS_E:0.008535,    LOSS_initial: 0.004542,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1267.856913805008\n",
      "loss_compared with real:0.0018115,   miu_train:0.01249,    lossmean:-0.005576\n",
      "Epoch [20200/100000], Loss: 169.9,   LOSS_function: 152.2,   LOSS_E:0.007224,    LOSS_initial: 0.006165,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1274.775357723236\n",
      "loss_compared with real:0.001538,   miu_train:0.01295,    lossmean:-0.006304\n",
      "Epoch [20300/100000], Loss: 176.6,   LOSS_function: 152.8,   LOSS_E:0.008666,    LOSS_initial: 0.008356,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1281.3332924842834\n",
      "loss_compared with real:0.001846,   miu_train:0.01289,    lossmean:-0.006314\n",
      "Epoch [20400/100000], Loss: 184.4,   LOSS_function: 173.7,   LOSS_E:0.009624,    LOSS_initial: 0.003728,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1287.8316028118134\n",
      "loss_compared with real:0.0025215,   miu_train:0.01208,    lossmean:-0.007283\n",
      "Epoch [20500/100000], Loss: 313.1,   LOSS_function: 234.6,   LOSS_E:0.01284,    LOSS_initial: 0.02749,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1294.3803634643555\n",
      "loss_compared with real:0.0013242,   miu_train:0.01438,    lossmean:-0.002796\n",
      "Epoch [20600/100000], Loss: 258.4,   LOSS_function: 163.2,   LOSS_E:0.01109,    LOSS_initial: 0.03336,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1301.0931360721588\n",
      "loss_compared with real:0.0020517,   miu_train:0.01304,    lossmean:-0.008131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20700/100000], Loss: 176.3,   LOSS_function: 152,   LOSS_E:0.008181,    LOSS_initial: 0.008505,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1307.9169292449951\n",
      "loss_compared with real:0.0015403,   miu_train:0.01362,    lossmean:-0.006199\n",
      "Epoch [20800/100000], Loss: 201.6,   LOSS_function: 158.4,   LOSS_E:0.01098,    LOSS_initial: 0.01512,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1314.509661436081\n",
      "loss_compared with real:0.001933,   miu_train:0.01307,    lossmean:-0.006396\n",
      "Epoch [20900/100000], Loss: 156.5,   LOSS_function: 145.4,   LOSS_E:0.01022,    LOSS_initial: 0.003897,\n",
      "lamda1:1,    lamda3:2852,      learn rate:0.0002991,    time: 1321.015772819519\n",
      "loss_compared with real:0.0015175,   miu_train:0.01323,    lossmean:-0.005703\n",
      "Epoch [21000/100000], Loss: 190.3,   LOSS_function: 162.7,   LOSS_E:0.01058,    LOSS_initial: 0.008263,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1327.5650689601898\n",
      "loss_compared with real:0.0015419,   miu_train:0.01284,    lossmean:-0.006508\n",
      "Epoch [21100/100000], Loss: 170.7,   LOSS_function: 152.6,   LOSS_E:0.007871,    LOSS_initial: 0.00541,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1334.0661494731903\n",
      "loss_compared with real:0.0014158,   miu_train:0.01344,    lossmean:-0.005258\n",
      "Epoch [21200/100000], Loss: 173.3,   LOSS_function: 155.1,   LOSS_E:0.008495,    LOSS_initial: 0.005449,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1340.5856158733368\n",
      "loss_compared with real:0.0010858,   miu_train:0.01322,    lossmean:-0.004283\n",
      "Epoch [21300/100000], Loss: 196.9,   LOSS_function: 167.7,   LOSS_E:0.008792,    LOSS_initial: 0.008706,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1347.0751945972443\n",
      "loss_compared with real:0.0013446,   miu_train:0.01278,    lossmean:-0.004473\n",
      "Epoch [21400/100000], Loss: 169.6,   LOSS_function: 151.6,   LOSS_E:0.009034,    LOSS_initial: 0.005391,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1353.7421169281006\n",
      "loss_compared with real:0.0010188,   miu_train:0.01346,    lossmean:-0.004185\n",
      "Epoch [21500/100000], Loss: 203.6,   LOSS_function: 149.4,   LOSS_E:0.009533,    LOSS_initial: 0.01623,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1359.873654127121\n",
      "loss_compared with real:0.0015062,   miu_train:0.0136,    lossmean:-0.006385\n",
      "Epoch [21600/100000], Loss: 162.6,   LOSS_function: 143.9,   LOSS_E:0.01132,    LOSS_initial: 0.005582,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1366.3243913650513\n",
      "loss_compared with real:0.0012986,   miu_train:0.01366,    lossmean:-0.00563\n",
      "Epoch [21700/100000], Loss: 173.3,   LOSS_function: 148.9,   LOSS_E:0.008536,    LOSS_initial: 0.007296,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1372.3636417388916\n",
      "loss_compared with real:0.0012257,   miu_train:0.01403,    lossmean:-0.005393\n",
      "Epoch [21800/100000], Loss: 178.7,   LOSS_function: 157.6,   LOSS_E:0.01191,    LOSS_initial: 0.006319,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1378.434057712555\n",
      "loss_compared with real:0.0012606,   miu_train:0.01324,    lossmean:-0.00603\n",
      "Epoch [21900/100000], Loss: 204.9,   LOSS_function: 158,   LOSS_E:0.009746,    LOSS_initial: 0.01404,\n",
      "lamda1:1,    lamda3:3340,      learn rate:0.0002848,    time: 1384.4033098220825\n",
      "loss_compared with real:0.0017415,   miu_train:0.01412,    lossmean:-0.006779\n",
      "Epoch [22000/100000], Loss: 168.4,   LOSS_function: 152.6,   LOSS_E:0.01058,    LOSS_initial: 0.004782,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1390.5329008102417\n",
      "loss_compared with real:0.0010152,   miu_train:0.01369,    lossmean:-0.003582\n",
      "Epoch [22100/100000], Loss: 197.6,   LOSS_function: 169.9,   LOSS_E:0.06413,    LOSS_initial: 0.008387,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1396.849693775177\n",
      "loss_compared with real:0.0033502,   miu_train:0.0122,    lossmean:-0.01201\n",
      "Epoch [22200/100000], Loss: 148.7,   LOSS_function: 137.7,   LOSS_E:0.009554,    LOSS_initial: 0.003312,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1402.878339767456\n",
      "loss_compared with real:0.0010859,   miu_train:0.01429,    lossmean:-0.005193\n",
      "Epoch [22300/100000], Loss: 168.4,   LOSS_function: 146.8,   LOSS_E:0.008583,    LOSS_initial: 0.006557,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1408.9606673717499\n",
      "loss_compared with real:0.00093917,   miu_train:0.01411,    lossmean:-0.003342\n",
      "Epoch [22400/100000], Loss: 160.3,   LOSS_function: 144,   LOSS_E:0.008687,    LOSS_initial: 0.004924,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1415.0812726020813\n",
      "loss_compared with real:0.00097845,   miu_train:0.01422,    lossmean:-0.003785\n",
      "Epoch [22500/100000], Loss: 165,   LOSS_function: 158.9,   LOSS_E:0.007953,    LOSS_initial: 0.001845,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1421.1075172424316\n",
      "loss_compared with real:0.0010694,   miu_train:0.01395,    lossmean:-0.004258\n",
      "Epoch [22600/100000], Loss: 176.8,   LOSS_function: 166.7,   LOSS_E:0.01195,    LOSS_initial: 0.003036,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1427.5041198730469\n",
      "loss_compared with real:0.0012225,   miu_train:0.01458,    lossmean:-0.006112\n",
      "Epoch [22700/100000], Loss: 150.3,   LOSS_function: 131.2,   LOSS_E:0.009054,    LOSS_initial: 0.005782,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1433.7124135494232\n",
      "loss_compared with real:0.0009251,   miu_train:0.01512,    lossmean:-0.005141\n",
      "Epoch [22800/100000], Loss: 148.6,   LOSS_function: 135.2,   LOSS_E:0.01031,    LOSS_initial: 0.004044,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1439.8342745304108\n",
      "loss_compared with real:0.0012103,   miu_train:0.01438,    lossmean:-0.00442\n",
      "Epoch [22900/100000], Loss: 159.2,   LOSS_function: 153.9,   LOSS_E:0.008965,    LOSS_initial: 0.001576,\n",
      "lamda1:1,    lamda3:3298,      learn rate:0.0002711,    time: 1445.8963503837585\n",
      "loss_compared with real:0.00097324,   miu_train:0.01445,    lossmean:-0.00568\n",
      "Epoch [23000/100000], Loss: 150.3,   LOSS_function: 135,   LOSS_E:0.01111,    LOSS_initial: 0.003563,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1452.0293536186218\n",
      "loss_compared with real:0.00081914,   miu_train:0.01557,    lossmean:-0.003382\n",
      "Epoch [23100/100000], Loss: 953,   LOSS_function: 626.6,   LOSS_E:0.5156,    LOSS_initial: 0.07597,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1458.0821640491486\n",
      "loss_compared with real:0.041872,   miu_train:0.004893,    lossmean:-0.05271\n",
      "Epoch [23200/100000], Loss: 826.2,   LOSS_function: 565.1,   LOSS_E:0.02698,    LOSS_initial: 0.06077,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1464.1751942634583\n",
      "loss_compared with real:0.022546,   miu_train:0.005422,    lossmean:-0.03091\n",
      "Epoch [23300/100000], Loss: 778.2,   LOSS_function: 548.2,   LOSS_E:0.01185,    LOSS_initial: 0.05354,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1470.2619047164917\n",
      "loss_compared with real:0.018889,   miu_train:0.005691,    lossmean:-0.02674\n",
      "Epoch [23400/100000], Loss: 748.8,   LOSS_function: 538.3,   LOSS_E:0.00909,    LOSS_initial: 0.04902,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1476.3757145404816\n",
      "loss_compared with real:0.017047,   miu_train:0.005894,    lossmean:-0.02474\n",
      "Epoch [23500/100000], Loss: 724.6,   LOSS_function: 527.6,   LOSS_E:0.008921,    LOSS_initial: 0.04587,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1482.3715286254883\n",
      "loss_compared with real:0.015948,   miu_train:0.006019,    lossmean:-0.02371\n",
      "Epoch [23600/100000], Loss: 742.3,   LOSS_function: 587.6,   LOSS_E:0.01286,    LOSS_initial: 0.03602,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1489.0965917110443\n",
      "loss_compared with real:0.016763,   miu_train:0.006,    lossmean:-0.02442\n",
      "Epoch [23700/100000], Loss: 690.8,   LOSS_function: 510.9,   LOSS_E:0.009296,    LOSS_initial: 0.04186,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1495.6612000465393\n",
      "loss_compared with real:0.01465,   miu_train:0.006198,    lossmean:-0.02257\n",
      "Epoch [23800/100000], Loss: 703.4,   LOSS_function: 574.3,   LOSS_E:0.009988,    LOSS_initial: 0.03003,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1502.383723974228\n",
      "loss_compared with real:0.014017,   miu_train:0.006487,    lossmean:-0.02201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23900/100000], Loss: 666.5,   LOSS_function: 494.2,   LOSS_E:0.008997,    LOSS_initial: 0.04011,\n",
      "lamda1:1,    lamda3:4294,      learn rate:0.0002581,    time: 1509.0035424232483\n",
      "loss_compared with real:0.013751,   miu_train:0.006355,    lossmean:-0.02161\n",
      "Epoch [24000/100000], Loss: 646.9,   LOSS_function: 487.5,   LOSS_E:0.009083,    LOSS_initial: 0.0371,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1515.556378364563\n",
      "loss_compared with real:0.012974,   miu_train:0.006426,    lossmean:-0.02082\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5257, -0.5203, -0.2962, -0.9674, -0.0643, -0.3230,  0.4363, -0.8249,\n",
      "         0.8658,  0.3204,  0.7705,  0.5208,  0.6357, -0.0289,  0.6972, -0.3244,\n",
      "         0.8286,  0.0225,  0.7878, -0.8024, -0.2734, -0.9675, -0.4911, -0.3264,\n",
      "        -0.3131, -0.3580,  0.6983, -0.6095, -0.2346,  0.4230, -0.3079, -0.1931,\n",
      "         0.1025,  0.6390, -0.6932, -0.7968, -0.7081, -0.5671, -0.2585, -0.0368,\n",
      "        -0.8150, -0.9700, -0.0537,  0.8024, -0.5947,  0.8615, -0.6859,  0.9076,\n",
      "         0.5917, -0.9117, -0.7511, -0.3454,  0.8514, -0.5980,  0.9229, -0.1151,\n",
      "        -0.8902,  0.4192, -0.2563, -0.8672,  0.8309, -0.3183,  0.2569, -0.1187,\n",
      "        -0.5452, -0.0833, -0.0213,  0.4066, -0.4086, -0.3491,  0.5580, -0.4280,\n",
      "        -0.5041,  0.8768,  0.7926, -0.4267, -0.4410,  0.0248, -0.3169, -0.5357,\n",
      "        -0.7475, -0.6664,  0.9180,  0.0207,  0.1210,  0.7557,  0.6756,  0.2257,\n",
      "        -0.0381, -0.0868,  0.6382,  0.7124, -0.6445,  0.9251,  0.2253,  0.5649,\n",
      "        -0.6409, -0.1390,  0.6007,  0.0318, -0.8566,  0.0782, -0.0136, -0.1981,\n",
      "         0.4017,  0.4967,  0.6485,  0.0621,  0.2422,  0.6393, -0.6173, -0.2716,\n",
      "         0.5817,  0.7752,  0.7233,  0.0128, -0.9664,  0.8798, -0.2935, -0.8794,\n",
      "        -0.9665,  0.8992, -0.2330,  0.3715, -0.2277,  0.4233, -0.2037,  0.1861],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2491, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0214, -0.0372,  0.0196,  0.0768, -0.0414, -0.0393, -0.0361,  0.0297,\n",
      "        -0.0310,  0.0390, -0.0121, -0.1088,  0.0465, -0.0387,  0.0699,  0.0310,\n",
      "        -0.0390, -0.0215, -0.0127,  0.0355, -0.0704,  0.0595,  0.0353,  0.0173,\n",
      "         0.0095, -0.0112,  0.0617, -0.0431, -0.0363, -0.0815,  0.0267, -0.0639,\n",
      "         0.0841, -0.0476,  0.0562,  0.0010, -0.0668,  0.0577,  0.0362, -0.0590,\n",
      "        -0.0964, -0.0813,  0.0111,  0.0758,  0.0662,  0.0790, -0.0322,  0.0860,\n",
      "        -0.0312,  0.0061,  0.0358,  0.0131, -0.0226,  0.0125,  0.0013, -0.0011,\n",
      "         0.0598,  0.0281,  0.0338,  0.0343,  0.0088, -0.0192, -0.0254,  0.0533,\n",
      "         0.0602,  0.0042,  0.0734,  0.0164,  0.0340,  0.0236,  0.0516,  0.0082,\n",
      "        -0.0333,  0.0066, -0.0761, -0.0006, -0.0409,  0.0828, -0.0014,  0.0106,\n",
      "         0.0396, -0.0334, -0.0159,  0.0474,  0.0218, -0.0931, -0.0197,  0.0037,\n",
      "         0.0878,  0.0773,  0.0447,  0.0522, -0.0497, -0.0657,  0.0644, -0.0670,\n",
      "         0.0353,  0.0361,  0.0289,  0.0816,  0.0827,  0.0477,  0.0456,  0.0874,\n",
      "         0.0690, -0.0035, -0.0699, -0.0700,  0.0168, -0.0471,  0.0404,  0.0305,\n",
      "        -0.0159, -0.0421, -0.0063,  0.0247,  0.0398, -0.0686, -0.1038,  0.0322,\n",
      "         0.0743,  0.0189,  0.0269, -0.0211,  0.0155,  0.0181, -0.0627,  0.0598],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2081, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 7.2884e-02, -4.7778e-02, -3.8744e-02,  2.8240e-02, -6.0979e-02,\n",
      "        -2.4402e-02, -4.8440e-02, -1.2049e-02, -3.0751e-02,  4.9016e-02,\n",
      "         7.6792e-03, -3.0273e-02, -2.8205e-02, -9.9196e-03, -3.2939e-02,\n",
      "        -7.9728e-02, -4.2553e-02,  4.7494e-02,  2.8066e-02, -1.2424e-01,\n",
      "         1.7896e-02, -2.2072e-02, -4.0344e-02, -9.6320e-03,  4.0337e-02,\n",
      "         1.4400e-02,  5.8100e-02,  1.3223e-02, -9.5211e-02, -7.2003e-02,\n",
      "        -2.7437e-02,  2.6823e-02,  2.0513e-02, -2.3371e-02,  5.6683e-02,\n",
      "         7.3549e-02,  1.0801e-01,  1.5811e-02,  3.3764e-02,  1.0888e-01,\n",
      "        -4.3508e-02,  3.1630e-02,  2.7965e-03, -5.0565e-02,  5.5286e-02,\n",
      "         3.8495e-02, -8.1255e-02, -7.7754e-02,  9.9722e-03, -2.1569e-02,\n",
      "        -6.1342e-02,  5.9986e-02,  4.0474e-02, -7.8212e-02,  4.0445e-02,\n",
      "         4.1452e-02,  2.5910e-02, -8.4902e-02,  1.2686e-02, -6.6059e-02,\n",
      "         2.0029e-02,  5.2654e-02, -2.6329e-02,  4.4969e-02,  8.3323e-02,\n",
      "        -7.3395e-03,  2.7634e-02, -8.7960e-03,  3.5710e-02,  3.0204e-02,\n",
      "        -8.5523e-02, -3.9248e-02, -1.1560e-02,  4.9964e-02, -2.6443e-04,\n",
      "         6.7798e-02,  8.5013e-02,  4.4679e-03, -4.5947e-03, -2.3397e-02,\n",
      "         1.2476e-01,  1.1968e-02, -5.7113e-02,  9.6411e-02, -1.3827e-02,\n",
      "        -1.1126e-02,  1.9933e-02,  6.7733e-02, -8.2057e-04, -9.1692e-02,\n",
      "         5.0145e-02, -7.9579e-02,  1.2292e-04, -5.7764e-02, -6.0199e-02,\n",
      "         5.0486e-02, -5.7844e-02, -8.8332e-02, -8.3099e-02,  6.7417e-02,\n",
      "        -7.5299e-02,  1.9530e-02,  1.7571e-02,  3.4648e-02, -3.2007e-02,\n",
      "        -6.1421e-02,  5.4859e-02, -7.6787e-02, -1.0392e-01, -5.4916e-02,\n",
      "        -5.6709e-02,  1.0284e-03,  5.4627e-02, -4.8862e-02, -5.1597e-02,\n",
      "        -2.5804e-02, -2.0289e-02, -2.5204e-02,  9.3786e-02,  9.0324e-03,\n",
      "        -3.9733e-02,  2.3804e-02,  8.3009e-02,  9.4140e-02, -3.8157e-02,\n",
      "        -8.7047e-02, -6.6454e-03, -6.8590e-02], requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.0945, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0653, -0.0483,  0.0029,  0.1134, -0.0940,  0.0478, -0.0285, -0.0295,\n",
      "         0.0561,  0.0066,  0.0405,  0.0550,  0.0596, -0.1263, -0.0649,  0.0274,\n",
      "        -0.0215,  0.0001, -0.0268, -0.0259, -0.0220,  0.0362,  0.0958,  0.0620,\n",
      "         0.0447, -0.0497, -0.0121, -0.0274, -0.0305,  0.0378,  0.0028,  0.0460,\n",
      "         0.0167,  0.0071, -0.0640,  0.0766, -0.0345, -0.1184, -0.0755,  0.0262,\n",
      "         0.0602, -0.0887,  0.0554,  0.0507,  0.0523, -0.0842,  0.0811, -0.0004,\n",
      "        -0.1136, -0.0838, -0.0345, -0.0687, -0.0492,  0.0610,  0.0258,  0.0341,\n",
      "        -0.0230, -0.0653,  0.0619,  0.0153,  0.0194, -0.0522, -0.0346, -0.0301,\n",
      "         0.0289, -0.0960, -0.0876, -0.0813,  0.0427, -0.0563, -0.0698, -0.0496,\n",
      "        -0.0164, -0.0116, -0.0670, -0.0050, -0.0296, -0.0706,  0.0669, -0.0178,\n",
      "        -0.0856,  0.0469, -0.0091,  0.0720,  0.0346, -0.1109, -0.0104, -0.0546,\n",
      "        -0.0201,  0.0208, -0.0651, -0.0789,  0.0853,  0.0636, -0.0004,  0.0656,\n",
      "        -0.0819, -0.0611,  0.0623, -0.0567, -0.0489,  0.0061, -0.0433, -0.0267,\n",
      "         0.0384,  0.0693,  0.0371, -0.0903,  0.0390, -0.0998,  0.0613,  0.0664,\n",
      "        -0.0355, -0.0317,  0.0756, -0.0117, -0.0834,  0.0153, -0.0269,  0.0625,\n",
      "         0.0816, -0.0389,  0.0793, -0.0833, -0.0522,  0.0343,  0.0033,  0.0660],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0725, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0007, 0.0241, 0.0575], requires_grad=True)\n",
      "Epoch [24100/100000], Loss: 629.1,   LOSS_function: 478.4,   LOSS_E:0.008849,    LOSS_initial: 0.03506,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1522.10173869133\n",
      "loss_compared with real:0.012277,   miu_train:0.006503,    lossmean:-0.02\n",
      "Epoch [24200/100000], Loss: 627.7,   LOSS_function: 465.6,   LOSS_E:0.01108,    LOSS_initial: 0.03772,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1528.7874925136566\n",
      "loss_compared with real:0.012852,   miu_train:0.006613,    lossmean:-0.02002\n",
      "Epoch [24300/100000], Loss: 606.7,   LOSS_function: 465.3,   LOSS_E:0.007779,    LOSS_initial: 0.0329,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1535.3331925868988\n",
      "loss_compared with real:0.01139,   miu_train:0.006729,    lossmean:-0.01892\n",
      "Epoch [24400/100000], Loss: 1020,   LOSS_function: 830.9,   LOSS_E:0.01905,    LOSS_initial: 0.04407,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1541.8880569934845\n",
      "loss_compared with real:0.01081,   miu_train:0.007579,    lossmean:-0.009549\n",
      "Epoch [24500/100000], Loss: 574.4,   LOSS_function: 448.2,   LOSS_E:0.007837,    LOSS_initial: 0.02938,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1548.7091133594513\n",
      "loss_compared with real:0.01019,   miu_train:0.006992,    lossmean:-0.01749\n",
      "Epoch [24600/100000], Loss: 571.7,   LOSS_function: 439.4,   LOSS_E:0.00516,    LOSS_initial: 0.03078,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1555.2824466228485\n",
      "loss_compared with real:0.0097995,   miu_train:0.007252,    lossmean:-0.01734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24700/100000], Loss: 548.2,   LOSS_function: 432.3,   LOSS_E:0.007022,    LOSS_initial: 0.02696,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1561.805758714676\n",
      "loss_compared with real:0.0092452,   miu_train:0.007379,    lossmean:-0.01619\n",
      "Epoch [24800/100000], Loss: 545.4,   LOSS_function: 430.6,   LOSS_E:0.01131,    LOSS_initial: 0.0267,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1568.5831980705261\n",
      "loss_compared with real:0.0084574,   miu_train:0.007377,    lossmean:-0.01714\n",
      "Epoch [24900/100000], Loss: 512.9,   LOSS_function: 411.8,   LOSS_E:0.007373,    LOSS_initial: 0.02354,\n",
      "lamda1:1,    lamda3:4295,      learn rate:0.0002457,    time: 1575.174607515335\n",
      "loss_compared with real:0.0081046,   miu_train:0.007817,    lossmean:-0.01469\n",
      "Epoch [25000/100000], Loss: 503.4,   LOSS_function: 404.5,   LOSS_E:0.009805,    LOSS_initial: 0.02296,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1581.7312569618225\n",
      "loss_compared with real:0.008079,   miu_train:0.008007,    lossmean:-0.01335\n",
      "Epoch [25100/100000], Loss: 496.9,   LOSS_function: 399.9,   LOSS_E:0.01914,    LOSS_initial: 0.02251,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1588.263979434967\n",
      "loss_compared with real:0.0081743,   miu_train:0.008075,    lossmean:-0.01476\n",
      "Epoch [25200/100000], Loss: 465.9,   LOSS_function: 382.7,   LOSS_E:0.00668,    LOSS_initial: 0.01931,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1594.8466906547546\n",
      "loss_compared with real:0.00661,   miu_train:0.008638,    lossmean:-0.01235\n",
      "Epoch [25300/100000], Loss: 1814,   LOSS_function: 1209,   LOSS_E:0.02282,    LOSS_initial: 0.1405,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1601.3880372047424\n",
      "loss_compared with real:0.0048781,   miu_train:0.01308,    lossmean:-0.004351\n",
      "Epoch [25400/100000], Loss: 430.9,   LOSS_function: 358.3,   LOSS_E:0.006646,    LOSS_initial: 0.01684,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1608.2517592906952\n",
      "loss_compared with real:0.005673,   miu_train:0.009245,    lossmean:-0.01101\n",
      "Epoch [25500/100000], Loss: 431.4,   LOSS_function: 336.7,   LOSS_E:0.009327,    LOSS_initial: 0.02197,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1614.7641549110413\n",
      "loss_compared with real:0.0063823,   miu_train:0.008912,    lossmean:-0.01047\n",
      "Epoch [25600/100000], Loss: 398,   LOSS_function: 332.8,   LOSS_E:0.006542,    LOSS_initial: 0.01514,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1621.406867980957\n",
      "loss_compared with real:0.0049287,   miu_train:0.009634,    lossmean:-0.009606\n",
      "Epoch [25700/100000], Loss: 381.5,   LOSS_function: 320.6,   LOSS_E:0.006441,    LOSS_initial: 0.01413,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1627.9428429603577\n",
      "loss_compared with real:0.0046422,   miu_train:0.01003,    lossmean:-0.009115\n",
      "Epoch [25800/100000], Loss: 410.2,   LOSS_function: 341.4,   LOSS_E:0.01411,    LOSS_initial: 0.01595,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1634.6238231658936\n",
      "loss_compared with real:0.0044984,   miu_train:0.01038,    lossmean:-0.009346\n",
      "Epoch [25900/100000], Loss: 342.1,   LOSS_function: 293.7,   LOSS_E:0.007788,    LOSS_initial: 0.01123,\n",
      "lamda1:1,    lamda3:4305,      learn rate:0.0002339,    time: 1641.112669467926\n",
      "loss_compared with real:0.0039109,   miu_train:0.01049,    lossmean:-0.008159\n",
      "Epoch [26000/100000], Loss: 340.6,   LOSS_function: 291.1,   LOSS_E:0.02623,    LOSS_initial: 0.01184,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1647.7205476760864\n",
      "loss_compared with real:0.003842,   miu_train:0.011,    lossmean:-0.01041\n",
      "Epoch [26100/100000], Loss: 307.4,   LOSS_function: 266.4,   LOSS_E:0.008949,    LOSS_initial: 0.009814,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1654.3066856861115\n",
      "loss_compared with real:0.0034664,   miu_train:0.01112,    lossmean:-0.007436\n",
      "Epoch [26200/100000], Loss: 294.7,   LOSS_function: 265,   LOSS_E:0.009809,    LOSS_initial: 0.007103,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1660.517654657364\n",
      "loss_compared with real:0.0030732,   miu_train:0.01178,    lossmean:-0.007103\n",
      "Epoch [26300/100000], Loss: 281.8,   LOSS_function: 246.9,   LOSS_E:0.008702,    LOSS_initial: 0.008369,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1666.8828508853912\n",
      "loss_compared with real:0.0029593,   miu_train:0.01177,    lossmean:-0.006423\n",
      "Epoch [26400/100000], Loss: 298.3,   LOSS_function: 237.5,   LOSS_E:0.01005,    LOSS_initial: 0.01457,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1673.0082190036774\n",
      "loss_compared with real:0.002709,   miu_train:0.01326,    lossmean:-0.00623\n",
      "Epoch [26500/100000], Loss: 261.8,   LOSS_function: 231.8,   LOSS_E:0.009568,    LOSS_initial: 0.007186,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1679.0658674240112\n",
      "loss_compared with real:0.0025964,   miu_train:0.01227,    lossmean:-0.006169\n",
      "Epoch [26600/100000], Loss: 244.2,   LOSS_function: 218.5,   LOSS_E:0.01154,    LOSS_initial: 0.00615,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1685.197105884552\n",
      "loss_compared with real:0.002279,   miu_train:0.01279,    lossmean:-0.005699\n",
      "Epoch [26700/100000], Loss: 239.4,   LOSS_function: 214.2,   LOSS_E:0.01165,    LOSS_initial: 0.006031,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1691.2421808242798\n",
      "loss_compared with real:0.0021881,   miu_train:0.01287,    lossmean:-0.005264\n",
      "Epoch [26800/100000], Loss: 315.7,   LOSS_function: 217.3,   LOSS_E:0.03032,    LOSS_initial: 0.02358,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1697.7785601615906\n",
      "loss_compared with real:0.0030037,   miu_train:0.01293,    lossmean:-0.009588\n",
      "Epoch [26900/100000], Loss: 222.7,   LOSS_function: 201.5,   LOSS_E:0.01144,    LOSS_initial: 0.005084,\n",
      "lamda1:1,    lamda3:4169,      learn rate:0.0002227,    time: 1703.8745789527893\n",
      "loss_compared with real:0.001879,   miu_train:0.01344,    lossmean:-0.005002\n",
      "Epoch [27000/100000], Loss: 263.7,   LOSS_function: 212.4,   LOSS_E:0.01977,    LOSS_initial: 0.01476,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1709.9806752204895\n",
      "loss_compared with real:0.0013744,   miu_train:0.01343,    lossmean:-0.005744\n",
      "Epoch [27100/100000], Loss: 203.5,   LOSS_function: 182.2,   LOSS_E:0.01083,    LOSS_initial: 0.006104,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1716.074150800705\n",
      "loss_compared with real:0.0022122,   miu_train:0.01353,    lossmean:-0.005525\n",
      "Epoch [27200/100000], Loss: 195.2,   LOSS_function: 175,   LOSS_E:0.01043,    LOSS_initial: 0.005817,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1722.1591908931732\n",
      "loss_compared with real:0.0019533,   miu_train:0.01391,    lossmean:-0.004911\n",
      "Epoch [27300/100000], Loss: 194.2,   LOSS_function: 175,   LOSS_E:0.01004,    LOSS_initial: 0.005535,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1728.5740842819214\n",
      "loss_compared with real:0.00202,   miu_train:0.01373,    lossmean:-0.005097\n",
      "Epoch [27400/100000], Loss: 183.8,   LOSS_function: 166.8,   LOSS_E:0.009497,    LOSS_initial: 0.004893,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1734.6445934772491\n",
      "loss_compared with real:0.0017622,   miu_train:0.01413,    lossmean:-0.004735\n",
      "Epoch [27500/100000], Loss: 179.8,   LOSS_function: 164.1,   LOSS_E:0.008528,    LOSS_initial: 0.004516,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1740.6511871814728\n",
      "loss_compared with real:0.0016705,   miu_train:0.01441,    lossmean:-0.004676\n",
      "Epoch [27600/100000], Loss: 1110,   LOSS_function: 689.7,   LOSS_E:0.005339,    LOSS_initial: 0.1212,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1746.7153351306915\n",
      "loss_compared with real:0.0020912,   miu_train:0.01413,    lossmean:0.0004375\n",
      "Epoch [27700/100000], Loss: 167.9,   LOSS_function: 153.5,   LOSS_E:0.009055,    LOSS_initial: 0.004154,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1752.7424607276917\n",
      "loss_compared with real:0.0014628,   miu_train:0.01477,    lossmean:-0.004245\n",
      "Epoch [27800/100000], Loss: 164.1,   LOSS_function: 149.1,   LOSS_E:0.009272,    LOSS_initial: 0.004322,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1758.8453030586243\n",
      "loss_compared with real:0.0013929,   miu_train:0.01501,    lossmean:-0.004304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27900/100000], Loss: 165,   LOSS_function: 148.7,   LOSS_E:0.009149,    LOSS_initial: 0.004682,\n",
      "lamda1:1,    lamda3:3466,      learn rate:0.000212,    time: 1765.0463280677795\n",
      "loss_compared with real:0.0013916,   miu_train:0.01499,    lossmean:-0.005115\n",
      "Epoch [28000/100000], Loss: 154.9,   LOSS_function: 143.5,   LOSS_E:0.008946,    LOSS_initial: 0.003362,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1771.2092430591583\n",
      "loss_compared with real:0.001191,   miu_train:0.01546,    lossmean:-0.00394\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5232, -0.5155, -0.2929, -0.9685, -0.0631, -0.3206,  0.4332, -0.8230,\n",
      "         0.8630,  0.3187,  0.7681,  0.5203,  0.6089, -0.0280,  0.6982, -0.3231,\n",
      "         0.8268,  0.0219,  0.7866, -0.8015, -0.2706, -0.9690, -0.4921, -0.3231,\n",
      "        -0.3068, -0.3526,  0.6972, -0.6105, -0.2329,  0.4195, -0.3061, -0.1927,\n",
      "         0.1009,  0.6331, -0.6915, -0.7960, -0.7093, -0.5568, -0.2571, -0.0365,\n",
      "        -0.8183, -0.9703, -0.0513,  0.8028, -0.5870,  0.8658, -0.6856,  0.9068,\n",
      "         0.5973, -0.9115, -0.7536, -0.3441,  0.8466, -0.5984,  0.9241, -0.1126,\n",
      "        -0.8906,  0.4200, -0.2540, -0.8662,  0.8319, -0.3175,  0.2551, -0.1185,\n",
      "        -0.5222, -0.0833, -0.0209,  0.4048, -0.4065, -0.3455,  0.5448, -0.4237,\n",
      "        -0.4996,  0.8748,  0.7928, -0.4227, -0.4392,  0.0253, -0.3127, -0.5293,\n",
      "        -0.7528, -0.6543,  0.9170,  0.0211,  0.1209,  0.7530,  0.6709,  0.2241,\n",
      "        -0.0382, -0.0878,  0.6290,  0.7115, -0.6154,  0.9311,  0.2247,  0.5642,\n",
      "        -0.6424, -0.1371,  0.5939,  0.0319, -0.8547,  0.0771, -0.0144, -0.1988,\n",
      "         0.4008,  0.4954,  0.6505,  0.0616,  0.2429,  0.6258, -0.6254, -0.2639,\n",
      "         0.5823,  0.7711,  0.7184,  0.0131, -0.9614,  0.8808, -0.2922, -0.8800,\n",
      "        -0.9658,  0.8999, -0.2329,  0.3674, -0.2250,  0.4266, -0.2022,  0.1872],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2670, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0198, -0.0360,  0.0209,  0.0723, -0.0420, -0.0399, -0.0333,  0.0289,\n",
      "        -0.0290,  0.0406, -0.0096, -0.1039,  0.0491, -0.0402,  0.0690,  0.0294,\n",
      "        -0.0390, -0.0223, -0.0146,  0.0350, -0.0688,  0.0613,  0.0346,  0.0183,\n",
      "         0.0100, -0.0125,  0.0629, -0.0422, -0.0370, -0.0805,  0.0277, -0.0642,\n",
      "         0.0847, -0.0454,  0.0582, -0.0001, -0.0702,  0.0581,  0.0371, -0.0598,\n",
      "        -0.0923, -0.0794,  0.0093,  0.0752,  0.0655,  0.0770, -0.0345,  0.0886,\n",
      "        -0.0320,  0.0065,  0.0397,  0.0136, -0.0255,  0.0155,  0.0033, -0.0022,\n",
      "         0.0602,  0.0288,  0.0335,  0.0343,  0.0074, -0.0177, -0.0246,  0.0564,\n",
      "         0.0587,  0.0057,  0.0745,  0.0132,  0.0349,  0.0251,  0.0493,  0.0061,\n",
      "        -0.0312,  0.0084, -0.0768,  0.0052, -0.0403,  0.0842,  0.0002,  0.0107,\n",
      "         0.0381, -0.0336, -0.0155,  0.0464,  0.0223, -0.0919, -0.0214,  0.0028,\n",
      "         0.0877,  0.0759,  0.0450,  0.0512, -0.0503, -0.0679,  0.0667, -0.0684,\n",
      "         0.0337,  0.0369,  0.0307,  0.0825,  0.0765,  0.0444,  0.0483,  0.0862,\n",
      "         0.0700, -0.0047, -0.0688, -0.0710,  0.0160, -0.0418,  0.0398,  0.0350,\n",
      "        -0.0150, -0.0437, -0.0053,  0.0241,  0.0383, -0.0694, -0.1039,  0.0348,\n",
      "         0.0737,  0.0178,  0.0253, -0.0195,  0.0168,  0.0203, -0.0626,  0.0602],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2457, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0754, -0.0478, -0.0393,  0.0293, -0.0624, -0.0264, -0.0466, -0.0098,\n",
      "        -0.0290,  0.0480,  0.0064, -0.0289, -0.0285, -0.0102, -0.0321, -0.0811,\n",
      "        -0.0418,  0.0463,  0.0285, -0.1240,  0.0188, -0.0233, -0.0430, -0.0107,\n",
      "         0.0400,  0.0150,  0.0588,  0.0094, -0.0939, -0.0714, -0.0249,  0.0249,\n",
      "         0.0181, -0.0256,  0.0610,  0.0811,  0.1047,  0.0189,  0.0345,  0.1083,\n",
      "        -0.0431,  0.0289,  0.0005, -0.0525,  0.0589,  0.0407, -0.0800, -0.0803,\n",
      "         0.0132, -0.0212, -0.0628,  0.0601,  0.0399, -0.0789,  0.0415,  0.0435,\n",
      "         0.0235, -0.0856,  0.0116, -0.0711,  0.0206,  0.0514, -0.0256,  0.0455,\n",
      "         0.0768, -0.0067,  0.0257, -0.0108,  0.0364,  0.0290, -0.0899, -0.0374,\n",
      "        -0.0140,  0.0497, -0.0005,  0.0678,  0.0851,  0.0044, -0.0017, -0.0200,\n",
      "         0.1244,  0.0121, -0.0600,  0.0972, -0.0160, -0.0110,  0.0189,  0.0679,\n",
      "        -0.0036, -0.0896,  0.0516, -0.0774,  0.0006, -0.0568, -0.0621,  0.0521,\n",
      "        -0.0586, -0.0940, -0.0850,  0.0675, -0.0741,  0.0199,  0.0210,  0.0363,\n",
      "        -0.0334, -0.0659,  0.0546, -0.0768, -0.1019, -0.0542, -0.0565,  0.0073,\n",
      "         0.0560, -0.0504, -0.0536, -0.0270, -0.0205, -0.0219,  0.0962,  0.0103,\n",
      "        -0.0365,  0.0238,  0.0812,  0.0937, -0.0378, -0.0848, -0.0028, -0.0693],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1076, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0633, -0.0480,  0.0019,  0.1132, -0.0939,  0.0499, -0.0312, -0.0302,\n",
      "         0.0602,  0.0051,  0.0434,  0.0525,  0.0605, -0.1279, -0.0669,  0.0285,\n",
      "        -0.0198, -0.0003, -0.0270, -0.0245, -0.0182,  0.0348,  0.0961,  0.0634,\n",
      "         0.0463, -0.0513, -0.0119, -0.0246, -0.0341,  0.0418,  0.0012,  0.0478,\n",
      "         0.0153,  0.0077, -0.0631,  0.0738, -0.0364, -0.1180, -0.0780,  0.0281,\n",
      "         0.0599, -0.0881,  0.0565,  0.0510,  0.0514, -0.0798,  0.0788, -0.0016,\n",
      "        -0.1146, -0.0868, -0.0336, -0.0718, -0.0495,  0.0648,  0.0246,  0.0341,\n",
      "        -0.0242, -0.0649,  0.0620,  0.0157,  0.0200, -0.0530, -0.0380, -0.0284,\n",
      "         0.0284, -0.0974, -0.0906, -0.0786,  0.0424, -0.0529, -0.0725, -0.0508,\n",
      "        -0.0168, -0.0151, -0.0660, -0.0028, -0.0231, -0.0714,  0.0630, -0.0230,\n",
      "        -0.0856,  0.0497, -0.0176,  0.0707,  0.0337, -0.1117, -0.0099, -0.0534,\n",
      "        -0.0195,  0.0217, -0.0683, -0.0842,  0.0861,  0.0696, -0.0017,  0.0599,\n",
      "        -0.0829, -0.0653,  0.0641, -0.0546, -0.0479,  0.0078, -0.0458, -0.0259,\n",
      "         0.0406,  0.0717,  0.0385, -0.0929,  0.0371, -0.1014,  0.0602,  0.0661,\n",
      "        -0.0355, -0.0301,  0.0711, -0.0121, -0.0849,  0.0141, -0.0260,  0.0622,\n",
      "         0.0834, -0.0384,  0.0830, -0.0860, -0.0537,  0.0331,  0.0048,  0.0662],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0739, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0006, 0.0230, 0.0624], requires_grad=True)\n",
      "Epoch [28100/100000], Loss: 154.3,   LOSS_function: 141.1,   LOSS_E:0.00851,    LOSS_initial: 0.003897,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1777.3529319763184\n",
      "loss_compared with real:0.0012324,   miu_train:0.01561,    lossmean:-0.003014\n",
      "Epoch [28200/100000], Loss: 169.4,   LOSS_function: 161.5,   LOSS_E:0.008452,    LOSS_initial: 0.002349,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1783.4293758869171\n",
      "loss_compared with real:0.0011476,   miu_train:0.01594,    lossmean:-0.003786\n",
      "Epoch [28300/100000], Loss: 148.3,   LOSS_function: 138,   LOSS_E:0.008413,    LOSS_initial: 0.003053,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1790.0059747695923\n",
      "loss_compared with real:0.0011502,   miu_train:0.01603,    lossmean:-0.004189\n",
      "Epoch [28400/100000], Loss: 145.2,   LOSS_function: 135.8,   LOSS_E:0.00838,    LOSS_initial: 0.002775,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1796.616800069809\n",
      "loss_compared with real:0.0010845,   miu_train:0.01605,    lossmean:-0.003482\n",
      "Epoch [28500/100000], Loss: 142.2,   LOSS_function: 132.7,   LOSS_E:0.008913,    LOSS_initial: 0.002815,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1803.602212190628\n",
      "loss_compared with real:0.0010388,   miu_train:0.01629,    lossmean:-0.003222\n",
      "Epoch [28600/100000], Loss: 172.4,   LOSS_function: 145.6,   LOSS_E:0.02296,    LOSS_initial: 0.007944,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1810.7078688144684\n",
      "loss_compared with real:0.0011403,   miu_train:0.01661,    lossmean:-0.00227\n",
      "Epoch [28700/100000], Loss: 136.1,   LOSS_function: 127,   LOSS_E:0.0084,    LOSS_initial: 0.002679,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1817.27139377594\n",
      "loss_compared with real:0.0009543,   miu_train:0.01674,    lossmean:-0.003317\n",
      "Epoch [28800/100000], Loss: 135.8,   LOSS_function: 127,   LOSS_E:0.008386,    LOSS_initial: 0.002612,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1823.8279769420624\n",
      "loss_compared with real:0.0010041,   miu_train:0.0167,    lossmean:-0.00363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28900/100000], Loss: 163,   LOSS_function: 139.6,   LOSS_E:0.01367,    LOSS_initial: 0.006944,\n",
      "lamda1:1,    lamda3:3367,      learn rate:0.0002018,    time: 1830.4808065891266\n",
      "loss_compared with real:0.00089117,   miu_train:0.01647,    lossmean:-0.004862\n",
      "Epoch [29000/100000], Loss: 128,   LOSS_function: 119.8,   LOSS_E:0.008216,    LOSS_initial: 0.002405,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1837.1207518577576\n",
      "loss_compared with real:0.00084913,   miu_train:0.01752,    lossmean:-0.002969\n",
      "Epoch [29100/100000], Loss: 369.8,   LOSS_function: 306.1,   LOSS_E:0.02698,    LOSS_initial: 0.01893,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1843.6944870948792\n",
      "loss_compared with real:0.0021612,   miu_train:0.01741,    lossmean:-0.002227\n",
      "Epoch [29200/100000], Loss: 122,   LOSS_function: 114.5,   LOSS_E:0.008135,    LOSS_initial: 0.002225,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1850.6024980545044\n",
      "loss_compared with real:0.00078104,   miu_train:0.01807,    lossmean:-0.002682\n",
      "Epoch [29300/100000], Loss: 179.7,   LOSS_function: 161.1,   LOSS_E:0.01482,    LOSS_initial: 0.005535,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1857.103393793106\n",
      "loss_compared with real:0.0013922,   miu_train:0.01724,    lossmean:-0.008659\n",
      "Epoch [29400/100000], Loss: 117,   LOSS_function: 109.9,   LOSS_E:0.008287,    LOSS_initial: 0.002078,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1863.6764476299286\n",
      "loss_compared with real:0.0007284,   miu_train:0.01858,    lossmean:-0.002581\n",
      "Epoch [29500/100000], Loss: 116.3,   LOSS_function: 108.3,   LOSS_E:0.008153,    LOSS_initial: 0.002382,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1870.2454235553741\n",
      "loss_compared with real:0.00075498,   miu_train:0.01872,    lossmean:-0.003202\n",
      "Epoch [29600/100000], Loss: 144.3,   LOSS_function: 138.2,   LOSS_E:0.01324,    LOSS_initial: 0.001796,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1876.811613559723\n",
      "loss_compared with real:0.0018476,   miu_train:0.01867,    lossmean:-0.003808\n",
      "Epoch [29700/100000], Loss: 108.3,   LOSS_function: 102.3,   LOSS_E:0.008292,    LOSS_initial: 0.001795,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1883.2991380691528\n",
      "loss_compared with real:0.00064005,   miu_train:0.01977,    lossmean:-0.002206\n",
      "Epoch [29800/100000], Loss: 111.2,   LOSS_function: 103.2,   LOSS_E:0.007452,    LOSS_initial: 0.002362,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1889.8782577514648\n",
      "loss_compared with real:0.00066676,   miu_train:0.01939,    lossmean:-0.0004912\n",
      "Epoch [29900/100000], Loss: 103.6,   LOSS_function: 98.14,   LOSS_E:0.008394,    LOSS_initial: 0.001625,\n",
      "lamda1:1,    lamda3:3360,      learn rate:0.0001921,    time: 1896.5650446414948\n",
      "loss_compared with real:0.00058107,   miu_train:0.02061,    lossmean:-0.002038\n",
      "Epoch [30000/100000], Loss: 105.1,   LOSS_function: 98.4,   LOSS_E:0.007836,    LOSS_initial: 0.002153,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1903.1579682826996\n",
      "loss_compared with real:0.00060454,   miu_train:0.01996,    lossmean:-0.002112\n",
      "Epoch [30100/100000], Loss: 98.21,   LOSS_function: 92.72,   LOSS_E:0.008663,    LOSS_initial: 0.001756,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1909.9617166519165\n",
      "loss_compared with real:0.0006301,   miu_train:0.02122,    lossmean:-0.002201\n",
      "Epoch [30200/100000], Loss: 185.6,   LOSS_function: 179.2,   LOSS_E:0.02185,    LOSS_initial: 0.002044,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1916.552475452423\n",
      "loss_compared with real:0.00077083,   miu_train:0.02073,    lossmean:-0.001539\n",
      "Epoch [30300/100000], Loss: 96.04,   LOSS_function: 90.58,   LOSS_E:0.008602,    LOSS_initial: 0.001747,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1923.063909292221\n",
      "loss_compared with real:0.00061966,   miu_train:0.02142,    lossmean:-0.002245\n",
      "Epoch [30400/100000], Loss: 1107,   LOSS_function: 796.6,   LOSS_E:0.0207,    LOSS_initial: 0.09975,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1929.6821882724762\n",
      "loss_compared with real:0.00050819,   miu_train:0.02668,    lossmean:0.001021\n",
      "Epoch [30500/100000], Loss: 91.15,   LOSS_function: 86.13,   LOSS_E:0.008733,    LOSS_initial: 0.001607,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1936.2446217536926\n",
      "loss_compared with real:0.0005702,   miu_train:0.02245,    lossmean:-0.001948\n",
      "Epoch [30600/100000], Loss: 265.3,   LOSS_function: 254.6,   LOSS_E:0.008769,    LOSS_initial: 0.003414,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1942.8427691459656\n",
      "loss_compared with real:0.0012589,   miu_train:0.02193,    lossmean:-0.001178\n",
      "Epoch [30700/100000], Loss: 129.4,   LOSS_function: 102.3,   LOSS_E:0.01062,    LOSS_initial: 0.008736,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1949.3692898750305\n",
      "loss_compared with real:0.00053571,   miu_train:0.02333,    lossmean:-0.00206\n",
      "Epoch [30800/100000], Loss: 82.55,   LOSS_function: 78.32,   LOSS_E:0.008629,    LOSS_initial: 0.001351,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1955.9665350914001\n",
      "loss_compared with real:0.00048553,   miu_train:0.02401,    lossmean:-0.001838\n",
      "Epoch [30900/100000], Loss: 355.6,   LOSS_function: 274.3,   LOSS_E:0.01381,    LOSS_initial: 0.02613,\n",
      "lamda1:1,    lamda3:3107,      learn rate:0.0001829,    time: 1962.3590269088745\n",
      "loss_compared with real:0.0013063,   miu_train:0.02456,    lossmean:0.01159\n",
      "Epoch [31000/100000], Loss: 80.92,   LOSS_function: 76.89,   LOSS_E:0.008927,    LOSS_initial: 0.001301,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 1968.788717508316\n",
      "loss_compared with real:0.00047001,   miu_train:0.02423,    lossmean:-0.002052\n",
      "Epoch [31100/100000], Loss: 75.64,   LOSS_function: 72.05,   LOSS_E:0.00882,    LOSS_initial: 0.001158,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 1974.8283174037933\n",
      "loss_compared with real:0.00042569,   miu_train:0.02588,    lossmean:-0.001856\n",
      "Epoch [31200/100000], Loss: 78.22,   LOSS_function: 73.99,   LOSS_E:0.008804,    LOSS_initial: 0.001364,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 1980.951896429062\n",
      "loss_compared with real:0.00047678,   miu_train:0.02515,    lossmean:-0.001834\n",
      "Epoch [31300/100000], Loss: 76.8,   LOSS_function: 71.19,   LOSS_E:0.00876,    LOSS_initial: 0.001814,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 1987.0439622402191\n",
      "loss_compared with real:0.00043579,   miu_train:0.02601,    lossmean:-0.002205\n",
      "Epoch [31400/100000], Loss: 69.79,   LOSS_function: 66.69,   LOSS_E:0.008674,    LOSS_initial: 0.001001,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 1993.179650068283\n",
      "loss_compared with real:0.00036636,   miu_train:0.02777,    lossmean:-0.001804\n",
      "Epoch [31500/100000], Loss: 73.61,   LOSS_function: 68.26,   LOSS_E:0.007873,    LOSS_initial: 0.00173,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 1999.5840783119202\n",
      "loss_compared with real:0.00036971,   miu_train:0.0271,    lossmean:-0.0004685\n",
      "Epoch [31600/100000], Loss: 74.6,   LOSS_function: 67.41,   LOSS_E:0.008825,    LOSS_initial: 0.002327,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 2005.7063736915588\n",
      "loss_compared with real:0.00032624,   miu_train:0.02881,    lossmean:-0.001744\n",
      "Epoch [31700/100000], Loss: 66.87,   LOSS_function: 63.93,   LOSS_E:0.00865,    LOSS_initial: 0.0009485,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 2011.744390487671\n",
      "loss_compared with real:0.00033968,   miu_train:0.02853,    lossmean:-0.001916\n",
      "Epoch [31800/100000], Loss: 85.31,   LOSS_function: 79.15,   LOSS_E:0.0159,    LOSS_initial: 0.001988,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 2017.857649564743\n",
      "loss_compared with real:0.0006617,   miu_train:0.02834,    lossmean:-0.004301\n",
      "Epoch [31900/100000], Loss: 66.04,   LOSS_function: 63.3,   LOSS_E:0.008765,    LOSS_initial: 0.0008804,\n",
      "lamda1:1,    lamda3:3083,      learn rate:0.0001741,    time: 2023.970594406128\n",
      "loss_compared with real:0.00031868,   miu_train:0.03005,    lossmean:-0.001923\n",
      "Epoch [32000/100000], Loss: 63.86,   LOSS_function: 61.16,   LOSS_E:0.008519,    LOSS_initial: 0.0008861,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2030.4412388801575\n",
      "loss_compared with real:0.00032038,   miu_train:0.02993,    lossmean:-0.001734\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5225, -0.5129, -0.2909, -0.9666, -0.0634, -0.3200,  0.4322, -0.8237,\n",
      "         0.8629,  0.3165,  0.7665,  0.5206,  0.6017, -0.0288,  0.6983, -0.3227,\n",
      "         0.8280,  0.0224,  0.7892, -0.8027, -0.2699, -0.9693, -0.4903, -0.3207,\n",
      "        -0.3023, -0.3514,  0.6972, -0.6162, -0.2334,  0.4177, -0.3060, -0.1923,\n",
      "         0.1014,  0.6313, -0.6925, -0.7975, -0.7098, -0.5484, -0.2560, -0.0375,\n",
      "        -0.8196, -0.9704, -0.0510,  0.8013, -0.5827,  0.8660, -0.6854,  0.9045,\n",
      "         0.6074, -0.9113, -0.7529, -0.3438,  0.8456, -0.5992,  0.9233, -0.1125,\n",
      "        -0.8934,  0.4178, -0.2545, -0.8662,  0.8320, -0.3165,  0.2543, -0.1168,\n",
      "        -0.5154, -0.0822, -0.0219,  0.4058, -0.4053, -0.3449,  0.5381, -0.4220,\n",
      "        -0.4939,  0.8782,  0.7946, -0.4218, -0.4397,  0.0240, -0.3119, -0.5271,\n",
      "        -0.7538, -0.6532,  0.9156,  0.0197,  0.1187,  0.7533,  0.6705,  0.2237,\n",
      "        -0.0364, -0.0869,  0.6291,  0.7121, -0.6068,  0.9358,  0.2229,  0.5681,\n",
      "        -0.6418, -0.1350,  0.5872,  0.0306, -0.8548,  0.0766, -0.0132, -0.1971,\n",
      "         0.4012,  0.4953,  0.6554,  0.0601,  0.2413,  0.6242, -0.6264, -0.2607,\n",
      "         0.5793,  0.7715,  0.7175,  0.0120, -0.9600,  0.8792, -0.2923, -0.8823,\n",
      "        -0.9647,  0.8994, -0.2314,  0.3637, -0.2258,  0.4255, -0.2014,  0.1858],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2819, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0210, -0.0347,  0.0214,  0.0711, -0.0407, -0.0386, -0.0340,  0.0294,\n",
      "        -0.0284,  0.0431, -0.0097, -0.1015,  0.0487, -0.0409,  0.0711,  0.0279,\n",
      "        -0.0411, -0.0231, -0.0135,  0.0353, -0.0694,  0.0619,  0.0345,  0.0181,\n",
      "         0.0112, -0.0127,  0.0635, -0.0440, -0.0375, -0.0804,  0.0293, -0.0649,\n",
      "         0.0847, -0.0444,  0.0602, -0.0013, -0.0714,  0.0569,  0.0361, -0.0588,\n",
      "        -0.0926, -0.0785,  0.0096,  0.0752,  0.0653,  0.0773, -0.0341,  0.0880,\n",
      "        -0.0311,  0.0053,  0.0399,  0.0141, -0.0252,  0.0153,  0.0037, -0.0031,\n",
      "         0.0601,  0.0290,  0.0324,  0.0331,  0.0060, -0.0176, -0.0246,  0.0545,\n",
      "         0.0599,  0.0038,  0.0750,  0.0129,  0.0365,  0.0262,  0.0490,  0.0062,\n",
      "        -0.0297,  0.0080, -0.0772,  0.0057, -0.0382,  0.0844,  0.0003,  0.0117,\n",
      "         0.0374, -0.0339, -0.0151,  0.0469,  0.0220, -0.0921, -0.0225,  0.0013,\n",
      "         0.0870,  0.0769,  0.0447,  0.0509, -0.0502, -0.0676,  0.0667, -0.0684,\n",
      "         0.0307,  0.0360,  0.0310,  0.0848,  0.0749,  0.0442,  0.0495,  0.0853,\n",
      "         0.0713, -0.0051, -0.0689, -0.0725,  0.0185, -0.0401,  0.0398,  0.0334,\n",
      "        -0.0149, -0.0442, -0.0046,  0.0245,  0.0361, -0.0694, -0.1046,  0.0337,\n",
      "         0.0713,  0.0177,  0.0246, -0.0196,  0.0171,  0.0203, -0.0618,  0.0614],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2590, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0740, -0.0477, -0.0385,  0.0290, -0.0629, -0.0242, -0.0491, -0.0098,\n",
      "        -0.0276,  0.0482,  0.0096, -0.0291, -0.0294, -0.0121, -0.0307, -0.0820,\n",
      "        -0.0431,  0.0446,  0.0291, -0.1212,  0.0197, -0.0258, -0.0446, -0.0086,\n",
      "         0.0399,  0.0151,  0.0590,  0.0109, -0.0925, -0.0723, -0.0250,  0.0237,\n",
      "         0.0178, -0.0254,  0.0599,  0.0829,  0.1025,  0.0191,  0.0343,  0.1056,\n",
      "        -0.0420,  0.0284, -0.0008, -0.0527,  0.0601,  0.0392, -0.0797, -0.0793,\n",
      "         0.0130, -0.0238, -0.0626,  0.0590,  0.0403, -0.0782,  0.0403,  0.0433,\n",
      "         0.0216, -0.0869,  0.0099, -0.0720,  0.0210,  0.0512, -0.0248,  0.0447,\n",
      "         0.0783, -0.0055,  0.0245, -0.0095,  0.0351,  0.0283, -0.0902, -0.0362,\n",
      "        -0.0145,  0.0479, -0.0014,  0.0664,  0.0849,  0.0050, -0.0008, -0.0186,\n",
      "         0.1245,  0.0135, -0.0612,  0.0963, -0.0160, -0.0114,  0.0159,  0.0674,\n",
      "        -0.0030, -0.0903,  0.0501, -0.0780,  0.0019, -0.0565, -0.0604,  0.0541,\n",
      "        -0.0586, -0.0927, -0.0841,  0.0688, -0.0735,  0.0203,  0.0219,  0.0375,\n",
      "        -0.0342, -0.0661,  0.0551, -0.0764, -0.1044, -0.0542, -0.0527,  0.0073,\n",
      "         0.0556, -0.0509, -0.0525, -0.0282, -0.0208, -0.0222,  0.0954,  0.0121,\n",
      "        -0.0368,  0.0217,  0.0823,  0.0934, -0.0385, -0.0856, -0.0017, -0.0695],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1087, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0643, -0.0450,  0.0040,  0.1134, -0.0951,  0.0499, -0.0313, -0.0308,\n",
      "         0.0604,  0.0056,  0.0448,  0.0539,  0.0604, -0.1264, -0.0651,  0.0312,\n",
      "        -0.0193, -0.0053, -0.0263, -0.0246, -0.0189,  0.0356,  0.0955,  0.0630,\n",
      "         0.0450, -0.0527, -0.0127, -0.0269, -0.0348,  0.0444,  0.0029,  0.0483,\n",
      "         0.0138,  0.0084, -0.0625,  0.0744, -0.0364, -0.1188, -0.0799,  0.0272,\n",
      "         0.0597, -0.0895,  0.0557,  0.0520,  0.0521, -0.0797,  0.0795, -0.0007,\n",
      "        -0.1156, -0.0874, -0.0364, -0.0757, -0.0480,  0.0633,  0.0242,  0.0335,\n",
      "        -0.0238, -0.0656,  0.0596,  0.0189,  0.0216, -0.0522, -0.0381, -0.0284,\n",
      "         0.0301, -0.0975, -0.0869, -0.0793,  0.0426, -0.0544, -0.0727, -0.0521,\n",
      "        -0.0171, -0.0150, -0.0699, -0.0025, -0.0224, -0.0712,  0.0594, -0.0224,\n",
      "        -0.0845,  0.0511, -0.0182,  0.0702,  0.0350, -0.1150, -0.0103, -0.0569,\n",
      "        -0.0197,  0.0224, -0.0747, -0.0847,  0.0845,  0.0720, -0.0013,  0.0601,\n",
      "        -0.0836, -0.0634,  0.0659, -0.0533, -0.0476,  0.0081, -0.0461, -0.0268,\n",
      "         0.0408,  0.0719,  0.0397, -0.0931,  0.0388, -0.0997,  0.0570,  0.0664,\n",
      "        -0.0351, -0.0287,  0.0818, -0.0129, -0.0834,  0.0139, -0.0260,  0.0621,\n",
      "         0.0842, -0.0379,  0.0815, -0.0877, -0.0558,  0.0306,  0.0046,  0.0633],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0702, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0035, 0.0247, 0.0618], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32100/100000], Loss: 61,   LOSS_function: 58.61,   LOSS_E:0.008532,    LOSS_initial: 0.000784,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2036.490215063095\n",
      "loss_compared with real:0.00028752,   miu_train:0.03173,    lossmean:-0.001748\n",
      "Epoch [32200/100000], Loss: 63.82,   LOSS_function: 60.53,   LOSS_E:0.008296,    LOSS_initial: 0.001081,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2042.5518252849579\n",
      "loss_compared with real:0.00028856,   miu_train:0.03058,    lossmean:-0.001735\n",
      "Epoch [32300/100000], Loss: 59.16,   LOSS_function: 56.91,   LOSS_E:0.008527,    LOSS_initial: 0.0007363,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2048.586761236191\n",
      "loss_compared with real:0.0002663,   miu_train:0.0326,    lossmean:-0.001849\n",
      "Epoch [32400/100000], Loss: 60.89,   LOSS_function: 58.61,   LOSS_E:0.007965,    LOSS_initial: 0.0007456,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2054.685140609741\n",
      "loss_compared with real:0.00027059,   miu_train:0.03099,    lossmean:-0.002241\n",
      "Epoch [32500/100000], Loss: 60.23,   LOSS_function: 58.38,   LOSS_E:0.008659,    LOSS_initial: 0.0006063,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2060.7618691921234\n",
      "loss_compared with real:0.00027314,   miu_train:0.03338,    lossmean:-0.002058\n",
      "Epoch [32600/100000], Loss: 56.97,   LOSS_function: 54.88,   LOSS_E:0.008431,    LOSS_initial: 0.0006838,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2066.8603072166443\n",
      "loss_compared with real:0.00025574,   miu_train:0.0337,    lossmean:-0.0016\n",
      "Epoch [32700/100000], Loss: 58.29,   LOSS_function: 55.86,   LOSS_E:0.007075,    LOSS_initial: 0.0007974,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2072.9430027008057\n",
      "loss_compared with real:0.00024749,   miu_train:0.03305,    lossmean:-0.001647\n",
      "Epoch [32800/100000], Loss: 54.98,   LOSS_function: 53.06,   LOSS_E:0.00852,    LOSS_initial: 0.0006293,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2079.0233137607574\n",
      "loss_compared with real:0.00023276,   miu_train:0.03513,    lossmean:-0.001702\n",
      "Epoch [32900/100000], Loss: 56.85,   LOSS_function: 54.73,   LOSS_E:0.006878,    LOSS_initial: 0.0006953,\n",
      "lamda1:1,    lamda3:3026,      learn rate:0.0001658,    time: 2085.0611600875854\n",
      "loss_compared with real:0.00021892,   miu_train:0.03414,    lossmean:-0.001465\n",
      "Epoch [33000/100000], Loss: 63.19,   LOSS_function: 57.6,   LOSS_E:0.008344,    LOSS_initial: 0.00115,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2091.7119500637054\n",
      "loss_compared with real:0.00020245,   miu_train:0.03705,    lossmean:-0.001277\n",
      "Epoch [33100/100000], Loss: 108.3,   LOSS_function: 101.9,   LOSS_E:0.004237,    LOSS_initial: 0.001316,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2098.286636352539\n",
      "loss_compared with real:0.00038841,   miu_train:0.02059,    lossmean:0.0004932\n",
      "Epoch [33200/100000], Loss: 87.74,   LOSS_function: 84.08,   LOSS_E:0.008262,    LOSS_initial: 0.0007506,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2104.901245355606\n",
      "loss_compared with real:0.00026748,   miu_train:0.02336,    lossmean:-0.00116\n",
      "Epoch [33300/100000], Loss: 78.57,   LOSS_function: 75.81,   LOSS_E:0.008105,    LOSS_initial: 0.0005664,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2111.4502799510956\n",
      "loss_compared with real:0.00020565,   miu_train:0.02549,    lossmean:-0.0009251\n",
      "Epoch [33400/100000], Loss: 72.17,   LOSS_function: 69.89,   LOSS_E:0.008131,    LOSS_initial: 0.0004652,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2118.0021228790283\n",
      "loss_compared with real:0.00017355,   miu_train:0.02751,    lossmean:-0.0007516\n",
      "Epoch [33500/100000], Loss: 67.28,   LOSS_function: 65.32,   LOSS_E:0.008201,    LOSS_initial: 0.0004009,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2124.512283563614\n",
      "loss_compared with real:0.00015335,   miu_train:0.02939,    lossmean:-0.0006641\n",
      "Epoch [33600/100000], Loss: 63.33,   LOSS_function: 61.6,   LOSS_E:0.008262,    LOSS_initial: 0.0003538,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2131.129853248596\n",
      "loss_compared with real:0.00013786,   miu_train:0.03114,    lossmean:-0.00064\n",
      "Epoch [33700/100000], Loss: 62.13,   LOSS_function: 59.35,   LOSS_E:0.008205,    LOSS_initial: 0.0005694,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2137.603828907013\n",
      "loss_compared with real:0.00013994,   miu_train:0.03188,    lossmean:-0.0007271\n",
      "Epoch [33800/100000], Loss: 57.66,   LOSS_function: 56.2,   LOSS_E:0.008412,    LOSS_initial: 0.0002971,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2144.198572397232\n",
      "loss_compared with real:0.00011818,   miu_train:0.03383,    lossmean:-0.0007468\n",
      "Epoch [33900/100000], Loss: 55.21,   LOSS_function: 53.93,   LOSS_E:0.008431,    LOSS_initial: 0.0002622,\n",
      "lamda1:1,    lamda3:4854,      learn rate:0.0001578,    time: 2151.1247651576996\n",
      "loss_compared with real:0.00010671,   miu_train:0.03558,    lossmean:-0.0007354\n",
      "Epoch [34000/100000], Loss: 58.08,   LOSS_function: 56.03,   LOSS_E:0.008263,    LOSS_initial: 0.000143,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2157.845141887665\n",
      "loss_compared with real:7.6975e-05,   miu_train:0.03533,    lossmean:-0.0002869\n",
      "Epoch [34100/100000], Loss: 556,   LOSS_function: 521.9,   LOSS_E:0.1384,    LOSS_initial: 0.002391,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2164.582144021988\n",
      "loss_compared with real:0.0025738,   miu_train:0.01118,    lossmean:-0.01141\n",
      "Epoch [34200/100000], Loss: 313.8,   LOSS_function: 300.2,   LOSS_E:0.005633,    LOSS_initial: 0.0009478,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2171.200530052185\n",
      "loss_compared with real:0.00030177,   miu_train:0.01269,    lossmean:3.174e-05\n",
      "Epoch [34300/100000], Loss: 237.8,   LOSS_function: 229.8,   LOSS_E:0.007833,    LOSS_initial: 0.0005617,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2177.747851371765\n",
      "loss_compared with real:0.00020915,   miu_train:0.01454,    lossmean:-0.0001573\n",
      "Epoch [34400/100000], Loss: 196.4,   LOSS_function: 190.6,   LOSS_E:0.007497,    LOSS_initial: 0.0004086,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2184.2875084877014\n",
      "loss_compared with real:0.00015513,   miu_train:0.01618,    lossmean:8.567e-05\n",
      "Epoch [34500/100000], Loss: 166.5,   LOSS_function: 162,   LOSS_E:0.00702,    LOSS_initial: 0.0003134,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2190.8974459171295\n",
      "loss_compared with real:0.00011962,   miu_train:0.01774,    lossmean:0.0003323\n",
      "Epoch [34600/100000], Loss: 144.9,   LOSS_function: 141.3,   LOSS_E:0.007294,    LOSS_initial: 0.0002511,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2197.530744791031\n",
      "loss_compared with real:0.00010015,   miu_train:0.01901,    lossmean:0.0003864\n",
      "Epoch [34700/100000], Loss: 128.3,   LOSS_function: 125.3,   LOSS_E:0.008045,    LOSS_initial: 0.0002064,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2204.0382952690125\n",
      "loss_compared with real:8.8727e-05,   miu_train:0.01997,    lossmean:0.0002889\n",
      "Epoch [34800/100000], Loss: 115.4,   LOSS_function: 113,   LOSS_E:0.008975,    LOSS_initial: 0.0001709,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2210.958676338196\n",
      "loss_compared with real:8.0565e-05,   miu_train:0.02082,    lossmean:0.000129\n",
      "Epoch [34900/100000], Loss: 105.9,   LOSS_function: 103.9,   LOSS_E:0.009808,    LOSS_initial: 0.0001416,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.0001502,    time: 2217.508232355118\n",
      "loss_compared with real:7.3606e-05,   miu_train:0.02166,    lossmean:-1.395e-05\n",
      "Epoch [35000/100000], Loss: 99.04,   LOSS_function: 97.34,   LOSS_E:0.01035,    LOSS_initial: 0.0001189,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2224.2221615314484\n",
      "loss_compared with real:6.7325e-05,   miu_train:0.02251,    lossmean:-0.0001032\n",
      "Epoch [35100/100000], Loss: 94.06,   LOSS_function: 92.58,   LOSS_E:0.01057,    LOSS_initial: 0.0001031,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2230.841620206833\n",
      "loss_compared with real:6.2081e-05,   miu_train:0.02328,    lossmean:-0.0001396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35200/100000], Loss: 89.86,   LOSS_function: 88.55,   LOSS_E:0.01057,    LOSS_initial: 9.106e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2237.3989012241364\n",
      "loss_compared with real:5.7448e-05,   miu_train:0.02403,    lossmean:-0.0001412\n",
      "Epoch [35300/100000], Loss: 86.05,   LOSS_function: 84.88,   LOSS_E:0.01044,    LOSS_initial: 8.187e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2243.884878873825\n",
      "loss_compared with real:5.3387e-05,   miu_train:0.02477,    lossmean:-0.0001228\n",
      "Epoch [35400/100000], Loss: 82.48,   LOSS_function: 81.41,   LOSS_E:0.01025,    LOSS_initial: 7.443e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2250.489659309387\n",
      "loss_compared with real:4.9789e-05,   miu_train:0.02554,    lossmean:-9.337e-05\n",
      "Epoch [35500/100000], Loss: 79.08,   LOSS_function: 78.1,   LOSS_E:0.01003,    LOSS_initial: 6.822e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2257.1599061489105\n",
      "loss_compared with real:4.6584e-05,   miu_train:0.02634,    lossmean:-6.089e-05\n",
      "Epoch [35600/100000], Loss: 75.85,   LOSS_function: 74.95,   LOSS_E:0.009824,    LOSS_initial: 6.263e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2263.5328240394592\n",
      "loss_compared with real:4.372e-05,   miu_train:0.02719,    lossmean:-2.742e-05\n",
      "Epoch [35700/100000], Loss: 72.77,   LOSS_function: 71.95,   LOSS_E:0.009624,    LOSS_initial: 5.748e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2269.870612859726\n",
      "loss_compared with real:4.1146e-05,   miu_train:0.02809,    lossmean:3.689e-06\n",
      "Epoch [35800/100000], Loss: 69.96,   LOSS_function: 69.2,   LOSS_E:0.009378,    LOSS_initial: 5.349e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2275.9758048057556\n",
      "loss_compared with real:3.8842e-05,   miu_train:0.02901,    lossmean:3.921e-05\n",
      "Epoch [35900/100000], Loss: 68.28,   LOSS_function: 66.95,   LOSS_E:0.009072,    LOSS_initial: 9.249e-05,\n",
      "lamda1:1,    lamda3:1.425e+04,      learn rate:0.000143,    time: 2281.974857568741\n",
      "loss_compared with real:3.6134e-05,   miu_train:0.02983,    lossmean:0.000135\n",
      "Epoch [36000/100000], Loss: 93.1,   LOSS_function: 74.43,   LOSS_E:0.01039,    LOSS_initial: 0.003541,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2288.125060558319\n",
      "loss_compared with real:6.365e-05,   miu_train:0.03146,    lossmean:-0.0002491\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5215, -0.5099, -0.2898, -0.9674, -0.0635, -0.3200,  0.4319, -0.8235,\n",
      "         0.8648,  0.3147,  0.7669,  0.5175,  0.5986, -0.0292,  0.6986, -0.3214,\n",
      "         0.8284,  0.0223,  0.7909, -0.8036, -0.2662, -0.9689, -0.4907, -0.3220,\n",
      "        -0.3012, -0.3498,  0.6973, -0.6217, -0.2323,  0.4165, -0.3048, -0.1901,\n",
      "         0.1006,  0.6321, -0.6927, -0.7973, -0.7082, -0.5452, -0.2540, -0.0366,\n",
      "        -0.8218, -0.9693, -0.0500,  0.8020, -0.5809,  0.8663, -0.6884,  0.9052,\n",
      "         0.6123, -0.9111, -0.7532, -0.3428,  0.8447, -0.6007,  0.9237, -0.1120,\n",
      "        -0.8935,  0.4174, -0.2528, -0.8659,  0.8324, -0.3163,  0.2535, -0.1163,\n",
      "        -0.5108, -0.0823, -0.0223,  0.4046, -0.4046, -0.3431,  0.5320, -0.4208,\n",
      "        -0.4911,  0.8792,  0.7963, -0.4223, -0.4372,  0.0238, -0.3099, -0.5251,\n",
      "        -0.7540, -0.6525,  0.9157,  0.0193,  0.1176,  0.7530,  0.6697,  0.2233,\n",
      "        -0.0359, -0.0868,  0.6296,  0.7119, -0.6037,  0.9370,  0.2221,  0.5720,\n",
      "        -0.6439, -0.1350,  0.5866,  0.0303, -0.8522,  0.0772, -0.0128, -0.1981,\n",
      "         0.4031,  0.4945,  0.6566,  0.0597,  0.2399,  0.6242, -0.6268, -0.2603,\n",
      "         0.5793,  0.7722,  0.7183,  0.0115, -0.9603,  0.8787, -0.2915, -0.8831,\n",
      "        -0.9648,  0.8994, -0.2314,  0.3618, -0.2259,  0.4250, -0.2014,  0.1852],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2881, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0215, -0.0346,  0.0222,  0.0660, -0.0389, -0.0386, -0.0315,  0.0313,\n",
      "        -0.0291,  0.0438, -0.0105, -0.1008,  0.0496, -0.0399,  0.0716,  0.0273,\n",
      "        -0.0413, -0.0238, -0.0140,  0.0356, -0.0699,  0.0623,  0.0320,  0.0165,\n",
      "         0.0116, -0.0129,  0.0627, -0.0436, -0.0370, -0.0796,  0.0288, -0.0647,\n",
      "         0.0878, -0.0445,  0.0623,  0.0007, -0.0707,  0.0560,  0.0365, -0.0588,\n",
      "        -0.0935, -0.0768,  0.0101,  0.0751,  0.0629,  0.0771, -0.0336,  0.0859,\n",
      "        -0.0315,  0.0066,  0.0401,  0.0143, -0.0254,  0.0179,  0.0059, -0.0045,\n",
      "         0.0599,  0.0291,  0.0339,  0.0341,  0.0057, -0.0172, -0.0245,  0.0525,\n",
      "         0.0601,  0.0044,  0.0737,  0.0144,  0.0368,  0.0243,  0.0497,  0.0075,\n",
      "        -0.0283,  0.0077, -0.0767,  0.0039, -0.0339,  0.0846, -0.0008,  0.0111,\n",
      "         0.0370, -0.0337, -0.0156,  0.0463,  0.0215, -0.0933, -0.0226,  0.0015,\n",
      "         0.0863,  0.0765,  0.0449,  0.0506, -0.0498, -0.0679,  0.0664, -0.0685,\n",
      "         0.0312,  0.0373,  0.0315,  0.0857,  0.0780,  0.0453,  0.0506,  0.0860,\n",
      "         0.0699, -0.0071, -0.0697, -0.0735,  0.0183, -0.0395,  0.0400,  0.0360,\n",
      "        -0.0131, -0.0452, -0.0039,  0.0240,  0.0346, -0.0671, -0.1061,  0.0331,\n",
      "         0.0710,  0.0178,  0.0247, -0.0192,  0.0160,  0.0196, -0.0622,  0.0626],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2582, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0761, -0.0467, -0.0384,  0.0267, -0.0633, -0.0247, -0.0523, -0.0081,\n",
      "        -0.0278,  0.0493,  0.0114, -0.0285, -0.0320, -0.0132, -0.0289, -0.0797,\n",
      "        -0.0444,  0.0436,  0.0320, -0.1201,  0.0205, -0.0264, -0.0434, -0.0079,\n",
      "         0.0408,  0.0139,  0.0591,  0.0109, -0.0916, -0.0727, -0.0242,  0.0245,\n",
      "         0.0175, -0.0252,  0.0590,  0.0819,  0.1033,  0.0207,  0.0332,  0.1046,\n",
      "        -0.0419,  0.0277, -0.0010, -0.0539,  0.0610,  0.0382, -0.0813, -0.0809,\n",
      "         0.0117, -0.0229, -0.0629,  0.0597,  0.0404, -0.0758,  0.0406,  0.0421,\n",
      "         0.0193, -0.0867,  0.0084, -0.0720,  0.0222,  0.0510, -0.0252,  0.0429,\n",
      "         0.0789, -0.0064,  0.0242, -0.0080,  0.0362,  0.0291, -0.0900, -0.0369,\n",
      "        -0.0151,  0.0448, -0.0019,  0.0658,  0.0831,  0.0051, -0.0008, -0.0168,\n",
      "         0.1254,  0.0149, -0.0601,  0.0955, -0.0165, -0.0123,  0.0149,  0.0670,\n",
      "        -0.0027, -0.0905,  0.0489, -0.0774,  0.0053, -0.0568, -0.0587,  0.0562,\n",
      "        -0.0583, -0.0904, -0.0852,  0.0704, -0.0722,  0.0207,  0.0215,  0.0386,\n",
      "        -0.0359, -0.0660,  0.0560, -0.0755, -0.1040, -0.0548, -0.0525,  0.0074,\n",
      "         0.0549, -0.0504, -0.0525, -0.0286, -0.0213, -0.0190,  0.0933,  0.0138,\n",
      "        -0.0352,  0.0194,  0.0830,  0.0935, -0.0394, -0.0838,  0.0004, -0.0690],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1017, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0659, -0.0457,  0.0077,  0.1135, -0.0957,  0.0492, -0.0321, -0.0303,\n",
      "         0.0601,  0.0044,  0.0450,  0.0546,  0.0600, -0.1276, -0.0659,  0.0288,\n",
      "        -0.0203, -0.0067, -0.0273, -0.0251, -0.0194,  0.0360,  0.0957,  0.0619,\n",
      "         0.0447, -0.0536, -0.0114, -0.0262, -0.0355,  0.0474,  0.0020,  0.0505,\n",
      "         0.0152,  0.0093, -0.0611,  0.0748, -0.0365, -0.1193, -0.0828,  0.0281,\n",
      "         0.0603, -0.0892,  0.0561,  0.0531,  0.0511, -0.0795,  0.0793, -0.0024,\n",
      "        -0.1187, -0.0872, -0.0369, -0.0780, -0.0460,  0.0629,  0.0235,  0.0330,\n",
      "        -0.0253, -0.0672,  0.0580,  0.0191,  0.0228, -0.0524, -0.0379, -0.0269,\n",
      "         0.0313, -0.0986, -0.0869, -0.0831,  0.0430, -0.0532, -0.0763, -0.0541,\n",
      "        -0.0167, -0.0161, -0.0700, -0.0031, -0.0202, -0.0726,  0.0560, -0.0224,\n",
      "        -0.0835,  0.0507, -0.0177,  0.0719,  0.0359, -0.1154, -0.0123, -0.0623,\n",
      "        -0.0189,  0.0186, -0.0788, -0.0856,  0.0842,  0.0721, -0.0021,  0.0601,\n",
      "        -0.0929, -0.0636,  0.0684, -0.0528, -0.0476,  0.0090, -0.0453, -0.0264,\n",
      "         0.0428,  0.0728,  0.0400, -0.0938,  0.0401, -0.1000,  0.0556,  0.0666,\n",
      "        -0.0351, -0.0280,  0.0831, -0.0128, -0.0831,  0.0115, -0.0258,  0.0626,\n",
      "         0.0846, -0.0369,  0.0882, -0.0878, -0.0570,  0.0308,  0.0054,  0.0628],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0677, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0041, 0.0252, 0.0663], requires_grad=True)\n",
      "Epoch [36100/100000], Loss: 62.2,   LOSS_function: 60.58,   LOSS_E:0.008873,    LOSS_initial: 0.000304,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2294.2705681324005\n",
      "loss_compared with real:0.00012461,   miu_train:0.03111,    lossmean:-0.0007292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36200/100000], Loss: 60.26,   LOSS_function: 58.77,   LOSS_E:0.008716,    LOSS_initial: 0.0002814,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2300.7117018699646\n",
      "loss_compared with real:0.00011566,   miu_train:0.03208,    lossmean:-0.0007056\n",
      "Epoch [36300/100000], Loss: 58.49,   LOSS_function: 57.1,   LOSS_E:0.008618,    LOSS_initial: 0.0002614,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2306.763683080673\n",
      "loss_compared with real:0.0001079,   miu_train:0.03309,    lossmean:-0.0006824\n",
      "Epoch [36400/100000], Loss: 56.85,   LOSS_function: 55.55,   LOSS_E:0.008536,    LOSS_initial: 0.0002433,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2312.842022418976\n",
      "loss_compared with real:0.00010101,   miu_train:0.03412,    lossmean:-0.0006627\n",
      "Epoch [36500/100000], Loss: 55.34,   LOSS_function: 54.13,   LOSS_E:0.008469,    LOSS_initial: 0.000227,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2318.88703083992\n",
      "loss_compared with real:9.4857e-05,   miu_train:0.03515,    lossmean:-0.0006484\n",
      "Epoch [36600/100000], Loss: 53.96,   LOSS_function: 52.82,   LOSS_E:0.00842,    LOSS_initial: 0.0002121,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2324.979696750641\n",
      "loss_compared with real:8.9343e-05,   miu_train:0.03619,    lossmean:-0.0006377\n",
      "Epoch [36700/100000], Loss: 53.27,   LOSS_function: 52.3,   LOSS_E:0.009006,    LOSS_initial: 0.0001824,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2331.2975187301636\n",
      "loss_compared with real:8.8514e-05,   miu_train:0.0368,    lossmean:-0.0007718\n",
      "Epoch [36800/100000], Loss: 51.74,   LOSS_function: 50.72,   LOSS_E:0.008381,    LOSS_initial: 0.0001914,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2337.3770451545715\n",
      "loss_compared with real:8.1789e-05,   miu_train:0.03792,    lossmean:-0.0006466\n",
      "Epoch [36900/100000], Loss: 67.42,   LOSS_function: 64.36,   LOSS_E:0.008834,    LOSS_initial: 0.0005774,\n",
      "lamda1:1,    lamda3:5266,      learn rate:0.0001362,    time: 2343.449141740799\n",
      "loss_compared with real:8.8697e-05,   miu_train:0.03828,    lossmean:-0.0009385\n",
      "Epoch [37000/100000], Loss: 50.09,   LOSS_function: 49.14,   LOSS_E:0.008399,    LOSS_initial: 0.0001778,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2349.5980525016785\n",
      "loss_compared with real:7.6678e-05,   miu_train:0.0393,    lossmean:-0.0006884\n",
      "Epoch [37100/100000], Loss: 49.2,   LOSS_function: 48.34,   LOSS_E:0.008376,    LOSS_initial: 0.0001603,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2355.754373073578\n",
      "loss_compared with real:7.2938e-05,   miu_train:0.04035,    lossmean:-0.0006839\n",
      "Epoch [37200/100000], Loss: 48.5,   LOSS_function: 47.66,   LOSS_E:0.008423,    LOSS_initial: 0.000156,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2361.8961317539215\n",
      "loss_compared with real:7.1287e-05,   miu_train:0.041,    lossmean:-0.0006937\n",
      "Epoch [37300/100000], Loss: 49.12,   LOSS_function: 47.9,   LOSS_E:0.008377,    LOSS_initial: 0.0002275,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2367.9378237724304\n",
      "loss_compared with real:8.0776e-05,   miu_train:0.04088,    lossmean:-0.0005166\n",
      "Epoch [37400/100000], Loss: 47.41,   LOSS_function: 46.59,   LOSS_E:0.008445,    LOSS_initial: 0.0001518,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2374.0596380233765\n",
      "loss_compared with real:6.7613e-05,   miu_train:0.04214,    lossmean:-0.0007118\n",
      "Epoch [37500/100000], Loss: 46.99,   LOSS_function: 46.17,   LOSS_E:0.008184,    LOSS_initial: 0.0001525,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2380.09476685524\n",
      "loss_compared with real:6.7497e-05,   miu_train:0.04253,    lossmean:-0.0005321\n",
      "Epoch [37600/100000], Loss: 71.31,   LOSS_function: 68.19,   LOSS_E:0.007997,    LOSS_initial: 0.0005878,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2386.19557261467\n",
      "loss_compared with real:6.9028e-05,   miu_train:0.04213,    lossmean:-0.00114\n",
      "Epoch [37700/100000], Loss: 46.18,   LOSS_function: 45.43,   LOSS_E:0.008482,    LOSS_initial: 0.0001417,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2392.644528388977\n",
      "loss_compared with real:6.4617e-05,   miu_train:0.0435,    lossmean:-0.0007322\n",
      "Epoch [37800/100000], Loss: 247.3,   LOSS_function: 202.5,   LOSS_E:0.008284,    LOSS_initial: 0.008472,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2399.2433013916016\n",
      "loss_compared with real:7.7916e-05,   miu_train:0.04377,    lossmean:6.464e-05\n",
      "Epoch [37900/100000], Loss: 45.25,   LOSS_function: 44.55,   LOSS_E:0.008442,    LOSS_initial: 0.0001318,\n",
      "lamda1:1,    lamda3:5286,      learn rate:0.0001296,    time: 2405.919374704361\n",
      "loss_compared with real:6.1971e-05,   miu_train:0.04475,    lossmean:-0.0007145\n",
      "Epoch [38000/100000], Loss: 45.68,   LOSS_function: 44.84,   LOSS_E:0.008567,    LOSS_initial: 0.0001321,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2412.5583050251007\n",
      "loss_compared with real:6.2448e-05,   miu_train:0.04421,    lossmean:-0.0005953\n",
      "Epoch [38100/100000], Loss: 79.86,   LOSS_function: 57.61,   LOSS_E:0.009825,    LOSS_initial: 0.003535,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2419.0642001628876\n",
      "loss_compared with real:9.2771e-05,   miu_train:0.04604,    lossmean:0.0002734\n",
      "Epoch [38200/100000], Loss: 44.78,   LOSS_function: 44.17,   LOSS_E:0.008411,    LOSS_initial: 9.54e-05,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2425.7474596500397\n",
      "loss_compared with real:4.8248e-05,   miu_train:0.0455,    lossmean:-0.0005302\n",
      "Epoch [38300/100000], Loss: 44.19,   LOSS_function: 43.64,   LOSS_E:0.008447,    LOSS_initial: 8.657e-05,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2432.301851272583\n",
      "loss_compared with real:4.5748e-05,   miu_train:0.04675,    lossmean:-0.0005323\n",
      "Epoch [38400/100000], Loss: 45.05,   LOSS_function: 44.54,   LOSS_E:0.007825,    LOSS_initial: 8.034e-05,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2438.859641313553\n",
      "loss_compared with real:4.8472e-05,   miu_train:0.0462,    lossmean:-0.0004044\n",
      "Epoch [38500/100000], Loss: 64.84,   LOSS_function: 57.21,   LOSS_E:0.008655,    LOSS_initial: 0.00121,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2445.4930503368378\n",
      "loss_compared with real:4.7043e-05,   miu_train:0.04804,    lossmean:-0.0004444\n",
      "Epoch [38600/100000], Loss: 43.7,   LOSS_function: 43.12,   LOSS_E:0.008412,    LOSS_initial: 8.993e-05,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2452.309768676758\n",
      "loss_compared with real:4.6297e-05,   miu_train:0.04702,    lossmean:-0.0005822\n",
      "Epoch [38700/100000], Loss: 43.93,   LOSS_function: 43.34,   LOSS_E:0.00825,    LOSS_initial: 9.258e-05,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2458.8212094306946\n",
      "loss_compared with real:4.4575e-05,   miu_train:0.04715,    lossmean:-0.0003633\n",
      "Epoch [38800/100000], Loss: 43.08,   LOSS_function: 42.57,   LOSS_E:0.008441,    LOSS_initial: 8.04e-05,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2465.505399465561\n",
      "loss_compared with real:4.3623e-05,   miu_train:0.04841,    lossmean:-0.0005432\n",
      "Epoch [38900/100000], Loss: 43.52,   LOSS_function: 42.75,   LOSS_E:0.008528,    LOSS_initial: 0.0001219,\n",
      "lamda1:1,    lamda3:6294,      learn rate:0.0001234,    time: 2472.0679128170013\n",
      "loss_compared with real:4.7976e-05,   miu_train:0.04739,    lossmean:-0.0004236\n",
      "Epoch [39000/100000], Loss: 64.44,   LOSS_function: 57.36,   LOSS_E:0.009601,    LOSS_initial: 0.0005336,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2478.6652851104736\n",
      "loss_compared with real:6.2768e-05,   miu_train:0.04767,    lossmean:-0.0006528\n",
      "Epoch [39100/100000], Loss: 98.65,   LOSS_function: 95.9,   LOSS_E:0.001708,    LOSS_initial: 0.0002066,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2485.238792657852\n",
      "loss_compared with real:7.1073e-05,   miu_train:0.0287,    lossmean:0.002117\n",
      "Epoch [39200/100000], Loss: 70.25,   LOSS_function: 68.97,   LOSS_E:0.00892,    LOSS_initial: 9.562e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2491.9643547534943\n",
      "loss_compared with real:5.2659e-05,   miu_train:0.03175,    lossmean:0.0002255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39300/100000], Loss: 60.38,   LOSS_function: 59.54,   LOSS_E:0.009023,    LOSS_initial: 6.281e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2498.4899163246155\n",
      "loss_compared with real:4.0541e-05,   miu_train:0.03391,    lossmean:0.0001155\n",
      "Epoch [39400/100000], Loss: 55.2,   LOSS_function: 54.56,   LOSS_E:0.009002,    LOSS_initial: 4.721e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2505.1139681339264\n",
      "loss_compared with real:3.4499e-05,   miu_train:0.03596,    lossmean:6.177e-05\n",
      "Epoch [39500/100000], Loss: 51.87,   LOSS_function: 51.35,   LOSS_E:0.008963,    LOSS_initial: 3.853e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2512.014842748642\n",
      "loss_compared with real:3.1088e-05,   miu_train:0.0379,    lossmean:3.106e-05\n",
      "Epoch [39600/100000], Loss: 49.5,   LOSS_function: 49.06,   LOSS_E:0.008883,    LOSS_initial: 3.312e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2518.625659227371\n",
      "loss_compared with real:2.8812e-05,   miu_train:0.03973,    lossmean:1.742e-05\n",
      "Epoch [39700/100000], Loss: 47.75,   LOSS_function: 47.36,   LOSS_E:0.008784,    LOSS_initial: 2.909e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2525.1878612041473\n",
      "loss_compared with real:2.713e-05,   miu_train:0.04144,    lossmean:1.09e-05\n",
      "Epoch [39800/100000], Loss: 46.43,   LOSS_function: 46.08,   LOSS_E:0.008688,    LOSS_initial: 2.607e-05,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2531.7697625160217\n",
      "loss_compared with real:2.582e-05,   miu_train:0.04302,    lossmean:6.137e-06\n",
      "Epoch [39900/100000], Loss: 47.27,   LOSS_function: 45.28,   LOSS_E:0.008378,    LOSS_initial: 0.0001503,\n",
      "lamda1:1,    lamda3:1.326e+04,      learn rate:0.0001175,    time: 2538.2881247997284\n",
      "loss_compared with real:2.5502e-05,   miu_train:0.04433,    lossmean:1.095e-06\n",
      "Epoch [40000/100000], Loss: 44.81,   LOSS_function: 44.48,   LOSS_E:0.008603,    LOSS_initial: 2.174e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2544.895045042038\n",
      "loss_compared with real:2.4492e-05,   miu_train:0.04537,    lossmean:7.535e-06\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5205, -0.5076, -0.2893, -0.9667, -0.0640, -0.3195,  0.4310, -0.8246,\n",
      "         0.8657,  0.3140,  0.7664,  0.5173,  0.5963, -0.0298,  0.6970, -0.3211,\n",
      "         0.8290,  0.0227,  0.7910, -0.8035, -0.2646, -0.9692, -0.4867, -0.3211,\n",
      "        -0.3000, -0.3498,  0.6949, -0.6233, -0.2328,  0.4155, -0.3057, -0.1906,\n",
      "         0.1020,  0.6318, -0.6927, -0.7982, -0.7075, -0.5432, -0.2535, -0.0375,\n",
      "        -0.8216, -0.9691, -0.0506,  0.8004, -0.5796,  0.8652, -0.6886,  0.9049,\n",
      "         0.6162, -0.9113, -0.7526, -0.3424,  0.8446, -0.6019,  0.9233, -0.1117,\n",
      "        -0.8945,  0.4149, -0.2531, -0.8651,  0.8314, -0.3157,  0.2531, -0.1151,\n",
      "        -0.5078, -0.0816, -0.0228,  0.4048, -0.4043, -0.3435,  0.5312, -0.4203,\n",
      "        -0.4871,  0.8805,  0.7966, -0.4218, -0.4382,  0.0229, -0.3101, -0.5240,\n",
      "        -0.7540, -0.6535,  0.9150,  0.0186,  0.1170,  0.7533,  0.6700,  0.2237,\n",
      "        -0.0352, -0.0863,  0.6286,  0.7113, -0.6033,  0.9391,  0.2212,  0.5735,\n",
      "        -0.6451, -0.1345,  0.5846,  0.0297, -0.8523,  0.0768, -0.0123, -0.1977,\n",
      "         0.4039,  0.4947,  0.6584,  0.0589,  0.2394,  0.6242, -0.6266, -0.2599,\n",
      "         0.5788,  0.7719,  0.7179,  0.0107, -0.9603,  0.8771, -0.2918, -0.8839,\n",
      "        -0.9643,  0.8993, -0.2305,  0.3604, -0.2263,  0.4249, -0.2013,  0.1844],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2926, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0222, -0.0334,  0.0220,  0.0665, -0.0398, -0.0381, -0.0324,  0.0307,\n",
      "        -0.0296,  0.0438, -0.0102, -0.0998,  0.0482, -0.0390,  0.0726,  0.0270,\n",
      "        -0.0422, -0.0232, -0.0120,  0.0359, -0.0700,  0.0623,  0.0324,  0.0170,\n",
      "         0.0118, -0.0127,  0.0640, -0.0436, -0.0369, -0.0790,  0.0294, -0.0655,\n",
      "         0.0866, -0.0459,  0.0614,  0.0003, -0.0712,  0.0563,  0.0360, -0.0582,\n",
      "        -0.0943, -0.0760,  0.0105,  0.0752,  0.0621,  0.0773, -0.0336,  0.0848,\n",
      "        -0.0311,  0.0061,  0.0403,  0.0145, -0.0257,  0.0168,  0.0059, -0.0045,\n",
      "         0.0598,  0.0293,  0.0329,  0.0339,  0.0056, -0.0164, -0.0251,  0.0523,\n",
      "         0.0593,  0.0039,  0.0731,  0.0139,  0.0364,  0.0245,  0.0484,  0.0078,\n",
      "        -0.0291,  0.0082, -0.0790,  0.0046, -0.0350,  0.0839, -0.0023,  0.0111,\n",
      "         0.0369, -0.0342, -0.0149,  0.0468,  0.0213, -0.0927, -0.0237,  0.0007,\n",
      "         0.0855,  0.0772,  0.0445,  0.0503, -0.0508, -0.0678,  0.0662, -0.0682,\n",
      "         0.0295,  0.0377,  0.0326,  0.0869,  0.0788,  0.0443,  0.0495,  0.0854,\n",
      "         0.0704, -0.0063, -0.0693, -0.0737,  0.0187, -0.0397,  0.0401,  0.0351,\n",
      "        -0.0138, -0.0455, -0.0038,  0.0239,  0.0331, -0.0699, -0.1059,  0.0319,\n",
      "         0.0705,  0.0173,  0.0249, -0.0193,  0.0168,  0.0191, -0.0630,  0.0636],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2629, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0756, -0.0467, -0.0381,  0.0270, -0.0635, -0.0247, -0.0516, -0.0083,\n",
      "        -0.0282,  0.0502,  0.0093, -0.0294, -0.0295, -0.0136, -0.0271, -0.0802,\n",
      "        -0.0444,  0.0434,  0.0322, -0.1185,  0.0201, -0.0268, -0.0438, -0.0075,\n",
      "         0.0407,  0.0132,  0.0586,  0.0118, -0.0916, -0.0730, -0.0251,  0.0240,\n",
      "         0.0177, -0.0253,  0.0598,  0.0834,  0.1024,  0.0193,  0.0338,  0.1042,\n",
      "        -0.0418,  0.0271, -0.0002, -0.0540,  0.0600,  0.0379, -0.0810, -0.0809,\n",
      "         0.0140, -0.0230, -0.0635,  0.0612,  0.0399, -0.0759,  0.0408,  0.0416,\n",
      "         0.0183, -0.0868,  0.0082, -0.0726,  0.0224,  0.0501, -0.0258,  0.0422,\n",
      "         0.0792, -0.0062,  0.0241, -0.0066,  0.0365,  0.0284, -0.0887, -0.0369,\n",
      "        -0.0157,  0.0464, -0.0031,  0.0671,  0.0836,  0.0055, -0.0004, -0.0164,\n",
      "         0.1258,  0.0139, -0.0596,  0.0964, -0.0166, -0.0131,  0.0139,  0.0667,\n",
      "        -0.0036, -0.0904,  0.0491, -0.0778,  0.0054, -0.0564, -0.0578,  0.0565,\n",
      "        -0.0582, -0.0907, -0.0850,  0.0715, -0.0722,  0.0208,  0.0222,  0.0371,\n",
      "        -0.0360, -0.0663,  0.0545, -0.0752, -0.1050, -0.0560, -0.0525,  0.0071,\n",
      "         0.0553, -0.0503, -0.0533, -0.0276, -0.0202, -0.0200,  0.0945,  0.0138,\n",
      "        -0.0344,  0.0207,  0.0828,  0.0939, -0.0396, -0.0833,  0.0008, -0.0703],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1010, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0664, -0.0442,  0.0080,  0.1143, -0.0964,  0.0493, -0.0320, -0.0306,\n",
      "         0.0597,  0.0047,  0.0443,  0.0558,  0.0599, -0.1279, -0.0661,  0.0292,\n",
      "        -0.0204, -0.0102, -0.0277, -0.0249, -0.0196,  0.0371,  0.0955,  0.0609,\n",
      "         0.0441, -0.0535, -0.0110, -0.0265, -0.0351,  0.0476,  0.0026,  0.0513,\n",
      "         0.0153,  0.0086, -0.0603,  0.0747, -0.0362, -0.1189, -0.0841,  0.0278,\n",
      "         0.0605, -0.0898,  0.0560,  0.0532,  0.0510, -0.0790,  0.0792, -0.0025,\n",
      "        -0.1183, -0.0874, -0.0374, -0.0789, -0.0456,  0.0625,  0.0228,  0.0332,\n",
      "        -0.0266, -0.0664,  0.0573,  0.0193,  0.0243, -0.0518, -0.0385, -0.0267,\n",
      "         0.0318, -0.0992, -0.0864, -0.0839,  0.0428, -0.0548, -0.0768, -0.0547,\n",
      "        -0.0169, -0.0164, -0.0700, -0.0030, -0.0189, -0.0729,  0.0562, -0.0218,\n",
      "        -0.0837,  0.0506, -0.0202,  0.0716,  0.0356, -0.1154, -0.0130, -0.0623,\n",
      "        -0.0191,  0.0196, -0.0807, -0.0856,  0.0842,  0.0733, -0.0017,  0.0597,\n",
      "        -0.0932, -0.0625,  0.0684, -0.0528, -0.0481,  0.0092, -0.0447, -0.0266,\n",
      "         0.0424,  0.0726,  0.0409, -0.0942,  0.0409, -0.0997,  0.0558,  0.0661,\n",
      "        -0.0351, -0.0277,  0.0859, -0.0127, -0.0835,  0.0110, -0.0254,  0.0631,\n",
      "         0.0852, -0.0371,  0.0957, -0.0885, -0.0573,  0.0307,  0.0056,  0.0623],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0672, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0027, 0.0260, 0.0664], requires_grad=True)\n",
      "Epoch [40100/100000], Loss: 44.12,   LOSS_function: 43.86,   LOSS_E:0.008573,    LOSS_initial: 1.683e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2551.481853723526\n",
      "loss_compared with real:2.2091e-05,   miu_train:0.04659,    lossmean:1.248e-05\n",
      "Epoch [40200/100000], Loss: 44.04,   LOSS_function: 43.48,   LOSS_E:0.008547,    LOSS_initial: 3.675e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2558.291029691696\n",
      "loss_compared with real:2.2849e-05,   miu_train:0.04717,    lossmean:1.976e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40300/100000], Loss: 134.9,   LOSS_function: 71.41,   LOSS_E:0.008807,    LOSS_initial: 0.004238,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2564.637831926346\n",
      "loss_compared with real:2.0273e-05,   miu_train:0.04848,    lossmean:0.0007853\n",
      "Epoch [40400/100000], Loss: 42.95,   LOSS_function: 42.69,   LOSS_E:0.008598,    LOSS_initial: 1.695e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2571.0369453430176\n",
      "loss_compared with real:2.1396e-05,   miu_train:0.04881,    lossmean:-3.294e-05\n",
      "Epoch [40500/100000], Loss: 60.29,   LOSS_function: 48.2,   LOSS_E:0.01053,    LOSS_initial: 0.0008068,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2577.097608566284\n",
      "loss_compared with real:5.7014e-05,   miu_train:0.04883,    lossmean:-0.001663\n",
      "Epoch [40600/100000], Loss: 42.41,   LOSS_function: 42.18,   LOSS_E:0.008576,    LOSS_initial: 1.546e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2583.2308478355408\n",
      "loss_compared with real:2.1036e-05,   miu_train:0.05,    lossmean:-6.681e-05\n",
      "Epoch [40700/100000], Loss: 42.66,   LOSS_function: 42.01,   LOSS_E:0.008626,    LOSS_initial: 4.314e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2589.286341190338\n",
      "loss_compared with real:2.1809e-05,   miu_train:0.05004,    lossmean:-7.26e-05\n",
      "Epoch [40800/100000], Loss: 41.96,   LOSS_function: 41.75,   LOSS_E:0.008651,    LOSS_initial: 1.405e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2595.415071249008\n",
      "loss_compared with real:2.0629e-05,   miu_train:0.051,    lossmean:-9.365e-05\n",
      "Epoch [40900/100000], Loss: 41.94,   LOSS_function: 41.74,   LOSS_E:0.008521,    LOSS_initial: 1.325e-05,\n",
      "lamda1:1,    lamda3:1.499e+04,      learn rate:0.0001118,    time: 2601.7669932842255\n",
      "loss_compared with real:2.1051e-05,   miu_train:0.05101,    lossmean:-9.267e-05\n",
      "Epoch [41000/100000], Loss: 41.65,   LOSS_function: 41.45,   LOSS_E:0.008673,    LOSS_initial: 1.038e-05,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2607.8611273765564\n",
      "loss_compared with real:2.0108e-05,   miu_train:0.05188,    lossmean:-9.205e-05\n",
      "Epoch [41100/100000], Loss: 46.49,   LOSS_function: 46.07,   LOSS_E:0.008502,    LOSS_initial: 2.171e-05,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2613.9433073997498\n",
      "loss_compared with real:2.3876e-05,   miu_train:0.0461,    lossmean:-0.0001049\n",
      "Epoch [41200/100000], Loss: 43.11,   LOSS_function: 42.88,   LOSS_E:0.008775,    LOSS_initial: 1.165e-05,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2620.161877155304\n",
      "loss_compared with real:2.0041e-05,   miu_train:0.04793,    lossmean:1.085e-05\n",
      "Epoch [41300/100000], Loss: 42.3,   LOSS_function: 42.11,   LOSS_E:0.008807,    LOSS_initial: 9.663e-06,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2626.2588126659393\n",
      "loss_compared with real:1.919e-05,   miu_train:0.04936,    lossmean:-1.952e-05\n",
      "Epoch [41400/100000], Loss: 41.85,   LOSS_function: 41.68,   LOSS_E:0.008747,    LOSS_initial: 8.756e-06,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2632.644222974777\n",
      "loss_compared with real:1.8728e-05,   miu_train:0.05051,    lossmean:-1.654e-05\n",
      "Epoch [41500/100000], Loss: 42.51,   LOSS_function: 41.52,   LOSS_E:0.008611,    LOSS_initial: 5.128e-05,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2638.704241037369\n",
      "loss_compared with real:1.8483e-05,   miu_train:0.051,    lossmean:3.131e-05\n",
      "Epoch [41600/100000], Loss: 41.38,   LOSS_function: 41.22,   LOSS_E:0.008632,    LOSS_initial: 8.234e-06,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2644.809241294861\n",
      "loss_compared with real:1.8319e-05,   miu_train:0.05187,    lossmean:-4.586e-06\n",
      "Epoch [41700/100000], Loss: 41.18,   LOSS_function: 41.08,   LOSS_E:0.008633,    LOSS_initial: 5.088e-06,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2650.868543624878\n",
      "loss_compared with real:1.8121e-05,   miu_train:0.05262,    lossmean:-2.772e-05\n",
      "Epoch [41800/100000], Loss: 41.08,   LOSS_function: 40.92,   LOSS_E:0.008491,    LOSS_initial: 8.279e-06,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2656.94579577446\n",
      "loss_compared with real:1.8111e-05,   miu_train:0.05276,    lossmean:2.601e-05\n",
      "Epoch [41900/100000], Loss: 40.96,   LOSS_function: 40.78,   LOSS_E:0.008588,    LOSS_initial: 9.26e-06,\n",
      "lamda1:1,    lamda3:1.921e+04,      learn rate:0.0001065,    time: 2662.9887557029724\n",
      "loss_compared with real:1.8155e-05,   miu_train:0.05296,    lossmean:-4.533e-06\n",
      "Epoch [42000/100000], Loss: 53.44,   LOSS_function: 46.86,   LOSS_E:0.008714,    LOSS_initial: 0.0006311,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2669.121122121811\n",
      "loss_compared with real:1.8915e-05,   miu_train:0.05364,    lossmean:-0.0001086\n",
      "Epoch [42100/100000], Loss: 40.38,   LOSS_function: 40.13,   LOSS_E:0.008526,    LOSS_initial: 2.346e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2675.243554830551\n",
      "loss_compared with real:2.3829e-05,   miu_train:0.05391,    lossmean:-0.0002775\n",
      "Epoch [42200/100000], Loss: 54.52,   LOSS_function: 54.42,   LOSS_E:0.008887,    LOSS_initial: 9.194e-06,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2681.406383752823\n",
      "loss_compared with real:2.266e-05,   miu_train:0.05443,    lossmean:-0.0003975\n",
      "Epoch [42300/100000], Loss: 40.12,   LOSS_function: 39.87,   LOSS_E:0.008554,    LOSS_initial: 2.372e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2687.621787548065\n",
      "loss_compared with real:2.3822e-05,   miu_train:0.05409,    lossmean:-0.0002859\n",
      "Epoch [42400/100000], Loss: 39.92,   LOSS_function: 39.68,   LOSS_E:0.008489,    LOSS_initial: 2.336e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2694.0495851039886\n",
      "loss_compared with real:2.3438e-05,   miu_train:0.05463,    lossmean:-0.0002722\n",
      "Epoch [42500/100000], Loss: 40.04,   LOSS_function: 39.71,   LOSS_E:0.008347,    LOSS_initial: 3.129e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2700.6155087947845\n",
      "loss_compared with real:2.3981e-05,   miu_train:0.05399,    lossmean:-0.0003086\n",
      "Epoch [42600/100000], Loss: 40.7,   LOSS_function: 40.49,   LOSS_E:0.008113,    LOSS_initial: 1.945e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2707.224081993103\n",
      "loss_compared with real:2.9715e-05,   miu_train:0.05445,    lossmean:0.0004222\n",
      "Epoch [42700/100000], Loss: 39.61,   LOSS_function: 39.36,   LOSS_E:0.008483,    LOSS_initial: 2.344e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2713.7716331481934\n",
      "loss_compared with real:2.346e-05,   miu_train:0.05462,    lossmean:-0.0002789\n",
      "Epoch [42800/100000], Loss: 201.4,   LOSS_function: 187.5,   LOSS_E:0.008142,    LOSS_initial: 0.001334,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2720.3633325099945\n",
      "loss_compared with real:2.9924e-05,   miu_train:0.05578,    lossmean:0.0007565\n",
      "Epoch [42900/100000], Loss: 39.41,   LOSS_function: 39.18,   LOSS_E:0.008448,    LOSS_initial: 2.133e-05,\n",
      "lamda1:1,    lamda3:1.042e+04,      learn rate:0.0001014,    time: 2726.890486240387\n",
      "loss_compared with real:2.3322e-05,   miu_train:0.05479,    lossmean:-0.0002818\n",
      "Epoch [43000/100000], Loss: 39.35,   LOSS_function: 39.08,   LOSS_E:0.008416,    LOSS_initial: 2.479e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2733.508038043976\n",
      "loss_compared with real:2.3102e-05,   miu_train:0.05471,    lossmean:-0.0002578\n",
      "Epoch [43100/100000], Loss: 39.12,   LOSS_function: 38.89,   LOSS_E:0.008398,    LOSS_initial: 2.074e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2740.085635662079\n",
      "loss_compared with real:2.2134e-05,   miu_train:0.05548,    lossmean:-0.0002438\n",
      "Epoch [43200/100000], Loss: 46.71,   LOSS_function: 43.48,   LOSS_E:0.008395,    LOSS_initial: 0.0002955,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2746.665931224823\n",
      "loss_compared with real:2.032e-05,   miu_train:0.05489,    lossmean:-0.000195\n",
      "Epoch [43300/100000], Loss: 39.06,   LOSS_function: 38.82,   LOSS_E:0.008379,    LOSS_initial: 2.247e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2753.60795545578\n",
      "loss_compared with real:2.1954e-05,   miu_train:0.05565,    lossmean:-0.0002387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43400/100000], Loss: 38.9,   LOSS_function: 38.65,   LOSS_E:0.008369,    LOSS_initial: 2.279e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2760.272162437439\n",
      "loss_compared with real:2.2226e-05,   miu_train:0.05542,    lossmean:-0.0002434\n",
      "Epoch [43500/100000], Loss: 39.06,   LOSS_function: 38.82,   LOSS_E:0.008121,    LOSS_initial: 2.155e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2766.80331659317\n",
      "loss_compared with real:2.3987e-05,   miu_train:0.05569,    lossmean:-0.0002425\n",
      "Epoch [43600/100000], Loss: 40.49,   LOSS_function: 39.26,   LOSS_E:0.008473,    LOSS_initial: 0.0001125,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2773.3786318302155\n",
      "loss_compared with real:2.2978e-05,   miu_train:0.0554,    lossmean:-0.0004143\n",
      "Epoch [43700/100000], Loss: 39.4,   LOSS_function: 38.69,   LOSS_E:0.008299,    LOSS_initial: 6.456e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2779.8900566101074\n",
      "loss_compared with real:2.1126e-05,   miu_train:0.05527,    lossmean:-5.739e-05\n",
      "Epoch [43800/100000], Loss: 38.43,   LOSS_function: 38.18,   LOSS_E:0.008325,    LOSS_initial: 2.232e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2786.5141859054565\n",
      "loss_compared with real:2.174e-05,   miu_train:0.05622,    lossmean:-0.0002487\n",
      "Epoch [43900/100000], Loss: 38.42,   LOSS_function: 38.13,   LOSS_E:0.008292,    LOSS_initial: 2.664e-05,\n",
      "lamda1:1,    lamda3:1.091e+04,      learn rate:9.649e-05,    time: 2793.0827667713165\n",
      "loss_compared with real:2.2102e-05,   miu_train:0.05608,    lossmean:-0.0002721\n",
      "Epoch [44000/100000], Loss: 38.28,   LOSS_function: 38.04,   LOSS_E:0.008124,    LOSS_initial: 2.873e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2799.6938910484314\n",
      "loss_compared with real:2.1581e-05,   miu_train:0.056,    lossmean:-0.0002572\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5204, -0.5074, -0.2890, -0.9666, -0.0642, -0.3192,  0.4308, -0.8249,\n",
      "         0.8656,  0.3139,  0.7663,  0.5167,  0.5955, -0.0299,  0.6970, -0.3212,\n",
      "         0.8291,  0.0229,  0.7912, -0.8032, -0.2648, -0.9690, -0.4847, -0.3210,\n",
      "        -0.2993, -0.3497,  0.6956, -0.6239, -0.2327,  0.4149, -0.3062, -0.1911,\n",
      "         0.1026,  0.6319, -0.6928, -0.7983, -0.7074, -0.5430, -0.2540, -0.0375,\n",
      "        -0.8218, -0.9687, -0.0507,  0.8006, -0.5791,  0.8648, -0.6889,  0.9042,\n",
      "         0.6166, -0.9113, -0.7525, -0.3421,  0.8448, -0.6022,  0.9224, -0.1113,\n",
      "        -0.8949,  0.4137, -0.2533, -0.8651,  0.8315, -0.3154,  0.2532, -0.1149,\n",
      "        -0.5068, -0.0815, -0.0231,  0.4051, -0.4044, -0.3432,  0.5316, -0.4203,\n",
      "        -0.4855,  0.8804,  0.7972, -0.4221, -0.4393,  0.0226, -0.3102, -0.5237,\n",
      "        -0.7542, -0.6534,  0.9150,  0.0183,  0.1166,  0.7535,  0.6702,  0.2239,\n",
      "        -0.0349, -0.0860,  0.6283,  0.7116, -0.6031,  0.9403,  0.2208,  0.5743,\n",
      "        -0.6449, -0.1343,  0.5841,  0.0295, -0.8524,  0.0767, -0.0120, -0.1972,\n",
      "         0.4043,  0.4945,  0.6588,  0.0586,  0.2393,  0.6243, -0.6257, -0.2595,\n",
      "         0.5789,  0.7719,  0.7180,  0.0104, -0.9603,  0.8770, -0.2916, -0.8839,\n",
      "        -0.9644,  0.8994, -0.2302,  0.3604, -0.2264,  0.4245, -0.2014,  0.1840],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2940, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0221, -0.0337,  0.0226,  0.0666, -0.0392, -0.0379, -0.0325,  0.0310,\n",
      "        -0.0301,  0.0436, -0.0104, -0.0997,  0.0480, -0.0397,  0.0724,  0.0271,\n",
      "        -0.0425, -0.0229, -0.0125,  0.0355, -0.0696,  0.0624,  0.0328,  0.0177,\n",
      "         0.0120, -0.0127,  0.0641, -0.0435, -0.0364, -0.0788,  0.0300, -0.0648,\n",
      "         0.0863, -0.0447,  0.0608,  0.0005, -0.0715,  0.0561,  0.0362, -0.0581,\n",
      "        -0.0942, -0.0752,  0.0103,  0.0751,  0.0626,  0.0774, -0.0334,  0.0850,\n",
      "        -0.0307,  0.0059,  0.0402,  0.0149, -0.0259,  0.0162,  0.0052, -0.0049,\n",
      "         0.0592,  0.0293,  0.0336,  0.0337,  0.0057, -0.0161, -0.0248,  0.0523,\n",
      "         0.0594,  0.0040,  0.0727,  0.0139,  0.0358,  0.0236,  0.0480,  0.0075,\n",
      "        -0.0291,  0.0079, -0.0785,  0.0048, -0.0347,  0.0837, -0.0024,  0.0116,\n",
      "         0.0368, -0.0336, -0.0152,  0.0466,  0.0214, -0.0924, -0.0237,  0.0004,\n",
      "         0.0846,  0.0776,  0.0446,  0.0507, -0.0499, -0.0675,  0.0662, -0.0683,\n",
      "         0.0286,  0.0384,  0.0318,  0.0862,  0.0788,  0.0447,  0.0500,  0.0853,\n",
      "         0.0707, -0.0067, -0.0696, -0.0740,  0.0192, -0.0391,  0.0402,  0.0342,\n",
      "        -0.0143, -0.0454, -0.0035,  0.0242,  0.0329, -0.0707, -0.1057,  0.0314,\n",
      "         0.0701,  0.0173,  0.0255, -0.0194,  0.0161,  0.0185, -0.0624,  0.0635],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2640, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0756, -0.0474, -0.0377,  0.0270, -0.0632, -0.0251, -0.0518, -0.0084,\n",
      "        -0.0277,  0.0495,  0.0107, -0.0285, -0.0292, -0.0133, -0.0282, -0.0815,\n",
      "        -0.0447,  0.0435,  0.0325, -0.1187,  0.0197, -0.0271, -0.0438, -0.0076,\n",
      "         0.0406,  0.0127,  0.0583,  0.0112, -0.0916, -0.0734, -0.0255,  0.0236,\n",
      "         0.0180, -0.0252,  0.0607,  0.0828,  0.1027,  0.0192,  0.0337,  0.1043,\n",
      "        -0.0408,  0.0269, -0.0002, -0.0541,  0.0603,  0.0379, -0.0805, -0.0838,\n",
      "         0.0147, -0.0227, -0.0637,  0.0616,  0.0397, -0.0762,  0.0410,  0.0418,\n",
      "         0.0175, -0.0864,  0.0081, -0.0735,  0.0233,  0.0498, -0.0263,  0.0413,\n",
      "         0.0787, -0.0064,  0.0246, -0.0060,  0.0371,  0.0274, -0.0881, -0.0370,\n",
      "        -0.0157,  0.0467, -0.0034,  0.0671,  0.0845,  0.0050, -0.0003, -0.0164,\n",
      "         0.1260,  0.0135, -0.0597,  0.0965, -0.0169, -0.0135,  0.0140,  0.0673,\n",
      "        -0.0043, -0.0903,  0.0492, -0.0777,  0.0056, -0.0568, -0.0580,  0.0570,\n",
      "        -0.0581, -0.0908, -0.0853,  0.0714, -0.0718,  0.0206,  0.0223,  0.0373,\n",
      "        -0.0357, -0.0660,  0.0542, -0.0760, -0.1048, -0.0562, -0.0524,  0.0071,\n",
      "         0.0553, -0.0500, -0.0533, -0.0267, -0.0203, -0.0207,  0.0944,  0.0143,\n",
      "        -0.0350,  0.0217,  0.0824,  0.0939, -0.0395, -0.0837,  0.0018, -0.0707],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1015, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0664, -0.0440,  0.0074,  0.1146, -0.0965,  0.0494, -0.0320, -0.0306,\n",
      "         0.0591,  0.0046,  0.0436,  0.0560,  0.0596, -0.1271, -0.0662,  0.0300,\n",
      "        -0.0205, -0.0101, -0.0275, -0.0248, -0.0196,  0.0368,  0.0953,  0.0609,\n",
      "         0.0440, -0.0536, -0.0110, -0.0266, -0.0354,  0.0480,  0.0023,  0.0508,\n",
      "         0.0159,  0.0088, -0.0600,  0.0747, -0.0356, -0.1188, -0.0846,  0.0278,\n",
      "         0.0604, -0.0902,  0.0558,  0.0529,  0.0512, -0.0790,  0.0792, -0.0019,\n",
      "        -0.1183, -0.0874, -0.0375, -0.0796, -0.0451,  0.0627,  0.0226,  0.0336,\n",
      "        -0.0262, -0.0666,  0.0558,  0.0192,  0.0244, -0.0516, -0.0385, -0.0261,\n",
      "         0.0319, -0.0993, -0.0864, -0.0842,  0.0427, -0.0548, -0.0769, -0.0550,\n",
      "        -0.0169, -0.0165, -0.0700, -0.0035, -0.0184, -0.0733,  0.0558, -0.0214,\n",
      "        -0.0845,  0.0507, -0.0216,  0.0717,  0.0354, -0.1162, -0.0130, -0.0629,\n",
      "        -0.0186,  0.0194, -0.0807, -0.0856,  0.0845,  0.0735, -0.0016,  0.0595,\n",
      "        -0.0939, -0.0625,  0.0679, -0.0530, -0.0483,  0.0091, -0.0446, -0.0267,\n",
      "         0.0430,  0.0726,  0.0412, -0.0943,  0.0410, -0.0997,  0.0559,  0.0658,\n",
      "        -0.0351, -0.0279,  0.0863, -0.0127, -0.0837,  0.0106, -0.0251,  0.0631,\n",
      "         0.0852, -0.0372,  0.0995, -0.0883, -0.0575,  0.0306,  0.0053,  0.0623],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0672, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0051, 0.0265, 0.0689], requires_grad=True)\n",
      "Epoch [44100/100000], Loss: 38.03,   LOSS_function: 37.74,   LOSS_E:0.008227,    LOSS_initial: 3.496e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2806.2315752506256\n",
      "loss_compared with real:2.6618e-05,   miu_train:0.05663,    lossmean:-0.0004072\n",
      "Epoch [44200/100000], Loss: 45.79,   LOSS_function: 45,   LOSS_E:0.00833,    LOSS_initial: 9.601e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2813.169666528702\n",
      "loss_compared with real:2.6705e-05,   miu_train:0.05583,    lossmean:-0.0003459\n",
      "Epoch [44300/100000], Loss: 37.79,   LOSS_function: 37.51,   LOSS_E:0.008224,    LOSS_initial: 3.41e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2819.8202688694\n",
      "loss_compared with real:2.6643e-05,   miu_train:0.05683,    lossmean:-0.0004046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44400/100000], Loss: 37.9,   LOSS_function: 37.54,   LOSS_E:0.008132,    LOSS_initial: 4.272e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2826.4381606578827\n",
      "loss_compared with real:2.7388e-05,   miu_train:0.05629,    lossmean:-0.0003793\n",
      "Epoch [44500/100000], Loss: 37.6,   LOSS_function: 37.32,   LOSS_E:0.008163,    LOSS_initial: 3.427e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2832.9778435230255\n",
      "loss_compared with real:2.6135e-05,   miu_train:0.05723,    lossmean:-0.0004001\n",
      "Epoch [44600/100000], Loss: 40.36,   LOSS_function: 39.74,   LOSS_E:0.007927,    LOSS_initial: 7.446e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2839.547380208969\n",
      "loss_compared with real:2.6736e-05,   miu_train:0.0565,    lossmean:-0.000321\n",
      "Epoch [44700/100000], Loss: 46.77,   LOSS_function: 45.19,   LOSS_E:0.008409,    LOSS_initial: 0.000192,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2846.162654876709\n",
      "loss_compared with real:2.4988e-05,   miu_train:0.05654,    lossmean:-0.0004959\n",
      "Epoch [44800/100000], Loss: 37.65,   LOSS_function: 37.44,   LOSS_E:0.00815,    LOSS_initial: 2.507e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2852.7406628131866\n",
      "loss_compared with real:2.8277e-05,   miu_train:0.0572,    lossmean:-0.0004656\n",
      "Epoch [44900/100000], Loss: 37.24,   LOSS_function: 36.96,   LOSS_E:0.008174,    LOSS_initial: 3.479e-05,\n",
      "lamda1:1,    lamda3:8179,      learn rate:9.186e-05,    time: 2859.3049597740173\n",
      "loss_compared with real:2.6355e-05,   miu_train:0.05743,    lossmean:-0.0003978\n",
      "Epoch [45000/100000], Loss: 38.58,   LOSS_function: 38.03,   LOSS_E:0.008,    LOSS_initial: 2.933e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2865.744019985199\n",
      "loss_compared with real:2.5193e-05,   miu_train:0.0569,    lossmean:9.227e-05\n",
      "Epoch [45100/100000], Loss: 65.4,   LOSS_function: 64.4,   LOSS_E:0.004476,    LOSS_initial: 5.295e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2872.050311088562\n",
      "loss_compared with real:2.8358e-05,   miu_train:0.04036,    lossmean:0.0009828\n",
      "Epoch [45200/100000], Loss: 48.52,   LOSS_function: 48.03,   LOSS_E:0.008186,    LOSS_initial: 2.578e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2878.1997628211975\n",
      "loss_compared with real:2.4512e-05,   miu_train:0.04368,    lossmean:0.000312\n",
      "Epoch [45300/100000], Loss: 43.48,   LOSS_function: 43.16,   LOSS_E:0.008486,    LOSS_initial: 1.689e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2884.343075990677\n",
      "loss_compared with real:2.1265e-05,   miu_train:0.04596,    lossmean:0.0001753\n",
      "Epoch [45400/100000], Loss: 41.28,   LOSS_function: 41.04,   LOSS_E:0.008558,    LOSS_initial: 1.307e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2890.5381445884705\n",
      "loss_compared with real:1.9712e-05,   miu_train:0.04782,    lossmean:0.0001058\n",
      "Epoch [45500/100000], Loss: 40.04,   LOSS_function: 39.83,   LOSS_E:0.008516,    LOSS_initial: 1.109e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2896.6309611797333\n",
      "loss_compared with real:1.8755e-05,   miu_train:0.04943,    lossmean:7.772e-05\n",
      "Epoch [45600/100000], Loss: 39.25,   LOSS_function: 39.06,   LOSS_E:0.008429,    LOSS_initial: 9.842e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2902.9725625514984\n",
      "loss_compared with real:1.8074e-05,   miu_train:0.05087,    lossmean:6.99e-05\n",
      "Epoch [45700/100000], Loss: 38.7,   LOSS_function: 38.53,   LOSS_E:0.008338,    LOSS_initial: 8.943e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2909.2308900356293\n",
      "loss_compared with real:1.7564e-05,   miu_train:0.05214,    lossmean:6.834e-05\n",
      "Epoch [45800/100000], Loss: 38.31,   LOSS_function: 38.15,   LOSS_E:0.008256,    LOSS_initial: 8.264e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2915.3469870090485\n",
      "loss_compared with real:1.7168e-05,   miu_train:0.05326,    lossmean:6.903e-05\n",
      "Epoch [45900/100000], Loss: 37.99,   LOSS_function: 37.84,   LOSS_E:0.008192,    LOSS_initial: 7.827e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.745e-05,    time: 2921.4555978775024\n",
      "loss_compared with real:1.6854e-05,   miu_train:0.05424,    lossmean:6.845e-05\n",
      "Epoch [46000/100000], Loss: 37.75,   LOSS_function: 37.57,   LOSS_E:0.008144,    LOSS_initial: 9.103e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2927.610071182251\n",
      "loss_compared with real:1.658e-05,   miu_train:0.0551,    lossmean:7.176e-05\n",
      "Epoch [46100/100000], Loss: 106,   LOSS_function: 49.24,   LOSS_E:0.008504,    LOSS_initial: 0.003007,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2933.95490527153\n",
      "loss_compared with real:1.5901e-05,   miu_train:0.05551,    lossmean:0.0004534\n",
      "Epoch [46200/100000], Loss: 37.38,   LOSS_function: 37.24,   LOSS_E:0.008056,    LOSS_initial: 7.421e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2940.1052882671356\n",
      "loss_compared with real:1.6309e-05,   miu_train:0.05631,    lossmean:6.455e-05\n",
      "Epoch [46300/100000], Loss: 168.7,   LOSS_function: 71.94,   LOSS_E:0.00833,    LOSS_initial: 0.005126,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2946.1712186336517\n",
      "loss_compared with real:2.1806e-05,   miu_train:0.05733,    lossmean:-0.0005967\n",
      "Epoch [46400/100000], Loss: 37.12,   LOSS_function: 37,   LOSS_E:0.008002,    LOSS_initial: 6.169e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2952.425127506256\n",
      "loss_compared with real:1.6096e-05,   miu_train:0.05719,    lossmean:5.702e-05\n",
      "Epoch [46500/100000], Loss: 36.96,   LOSS_function: 36.84,   LOSS_E:0.008028,    LOSS_initial: 6.37e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2958.5043807029724\n",
      "loss_compared with real:1.5906e-05,   miu_train:0.05778,    lossmean:3.992e-05\n",
      "Epoch [46600/100000], Loss: 37.27,   LOSS_function: 36.68,   LOSS_E:0.008111,    LOSS_initial: 3.107e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2964.578293323517\n",
      "loss_compared with real:1.6069e-05,   miu_train:0.05792,    lossmean:4.691e-05\n",
      "Epoch [46700/100000], Loss: 37.9,   LOSS_function: 36.66,   LOSS_E:0.007985,    LOSS_initial: 6.555e-05,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2970.709620952606\n",
      "loss_compared with real:1.6399e-05,   miu_train:0.05813,    lossmean:0.000197\n",
      "Epoch [46800/100000], Loss: 36.66,   LOSS_function: 36.52,   LOSS_E:0.007977,    LOSS_initial: 7.318e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2976.855162858963\n",
      "loss_compared with real:1.564e-05,   miu_train:0.05871,    lossmean:3.363e-05\n",
      "Epoch [46900/100000], Loss: 36.7,   LOSS_function: 36.61,   LOSS_E:0.007867,    LOSS_initial: 4.654e-06,\n",
      "lamda1:1,    lamda3:1.887e+04,      learn rate:8.325e-05,    time: 2982.9098455905914\n",
      "loss_compared with real:1.5639e-05,   miu_train:0.05879,    lossmean:4.049e-05\n",
      "Epoch [47000/100000], Loss: 108.9,   LOSS_function: 77.25,   LOSS_E:0.009081,    LOSS_initial: 0.002241,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 2989.0166850090027\n",
      "loss_compared with real:1.7116e-05,   miu_train:0.05907,    lossmean:7.054e-05\n",
      "Epoch [47100/100000], Loss: 36.38,   LOSS_function: 36.22,   LOSS_E:0.007945,    LOSS_initial: 1.071e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 2995.4794063568115\n",
      "loss_compared with real:1.7148e-05,   miu_train:0.0593,    lossmean:-8.093e-05\n",
      "Epoch [47200/100000], Loss: 36.25,   LOSS_function: 36.09,   LOSS_E:0.00794,    LOSS_initial: 1.074e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3002.057064294815\n",
      "loss_compared with real:1.6984e-05,   miu_train:0.05977,    lossmean:-8.18e-05\n",
      "Epoch [47300/100000], Loss: 36.13,   LOSS_function: 35.98,   LOSS_E:0.007921,    LOSS_initial: 1.054e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3008.5846803188324\n",
      "loss_compared with real:1.6861e-05,   miu_train:0.06016,    lossmean:-7.733e-05\n",
      "Epoch [47400/100000], Loss: 41.59,   LOSS_function: 40.9,   LOSS_E:0.008892,    LOSS_initial: 4.865e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3015.299902677536\n",
      "loss_compared with real:1.8519e-05,   miu_train:0.05986,    lossmean:-0.0002546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47500/100000], Loss: 35.99,   LOSS_function: 35.83,   LOSS_E:0.007906,    LOSS_initial: 1.058e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3021.9630076885223\n",
      "loss_compared with real:1.6865e-05,   miu_train:0.06018,    lossmean:-8.116e-05\n",
      "Epoch [47600/100000], Loss: 39.52,   LOSS_function: 38.17,   LOSS_E:0.007847,    LOSS_initial: 9.56e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3028.50093626976\n",
      "loss_compared with real:1.7781e-05,   miu_train:0.06006,    lossmean:-5.478e-05\n",
      "Epoch [47700/100000], Loss: 35.8,   LOSS_function: 35.65,   LOSS_E:0.007896,    LOSS_initial: 1.025e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3035.077553510666\n",
      "loss_compared with real:1.6747e-05,   miu_train:0.06057,    lossmean:-8.015e-05\n",
      "Epoch [47800/100000], Loss: 35.94,   LOSS_function: 35.67,   LOSS_E:0.007678,    LOSS_initial: 1.909e-05,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3041.6642923355103\n",
      "loss_compared with real:1.6783e-05,   miu_train:0.06033,    lossmean:-4.318e-05\n",
      "Epoch [47900/100000], Loss: 44.56,   LOSS_function: 39.4,   LOSS_E:0.007499,    LOSS_initial: 0.0003651,\n",
      "lamda1:1,    lamda3:1.414e+04,      learn rate:7.925e-05,    time: 3048.2003111839294\n",
      "loss_compared with real:1.9562e-05,   miu_train:0.06034,    lossmean:-0.0002956\n",
      "Epoch [48000/100000], Loss: 35.57,   LOSS_function: 35.42,   LOSS_E:0.007859,    LOSS_initial: 1.068e-05,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3055.2844853401184\n",
      "loss_compared with real:1.6681e-05,   miu_train:0.06084,    lossmean:-8.496e-05\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5206, -0.5069, -0.2889, -0.9671, -0.0643, -0.3191,  0.4305, -0.8252,\n",
      "         0.8657,  0.3138,  0.7665,  0.5164,  0.5950, -0.0300,  0.6967, -0.3213,\n",
      "         0.8293,  0.0230,  0.7913, -0.8032, -0.2647, -0.9688, -0.4842, -0.3207,\n",
      "        -0.2987, -0.3498,  0.6956, -0.6245, -0.2325,  0.4147, -0.3060, -0.1908,\n",
      "         0.1028,  0.6319, -0.6928, -0.7983, -0.7075, -0.5425, -0.2540, -0.0375,\n",
      "        -0.8223, -0.9683, -0.0507,  0.8008, -0.5788,  0.8646, -0.6889,  0.9037,\n",
      "         0.6175, -0.9113, -0.7524, -0.3417,  0.8449, -0.6029,  0.9220, -0.1110,\n",
      "        -0.8952,  0.4132, -0.2532, -0.8651,  0.8315, -0.3151,  0.2531, -0.1146,\n",
      "        -0.5062, -0.0813, -0.0232,  0.4050, -0.4043, -0.3429,  0.5312, -0.4203,\n",
      "        -0.4848,  0.8805,  0.7975, -0.4219, -0.4403,  0.0224, -0.3101, -0.5235,\n",
      "        -0.7540, -0.6534,  0.9150,  0.0181,  0.1164,  0.7535,  0.6704,  0.2239,\n",
      "        -0.0347, -0.0859,  0.6279,  0.7116, -0.6027,  0.9412,  0.2204,  0.5752,\n",
      "        -0.6451, -0.1342,  0.5837,  0.0294, -0.8524,  0.0767, -0.0119, -0.1970,\n",
      "         0.4042,  0.4944,  0.6590,  0.0584,  0.2392,  0.6243, -0.6252, -0.2593,\n",
      "         0.5791,  0.7723,  0.7179,  0.0102, -0.9602,  0.8769, -0.2915, -0.8845,\n",
      "        -0.9644,  0.8995, -0.2300,  0.3604, -0.2264,  0.4243, -0.2015,  0.1838],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2948, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0223, -0.0335,  0.0232,  0.0666, -0.0391, -0.0378, -0.0326,  0.0314,\n",
      "        -0.0306,  0.0435, -0.0106, -0.0997,  0.0481, -0.0392,  0.0728,  0.0268,\n",
      "        -0.0427, -0.0224, -0.0120,  0.0356, -0.0696,  0.0628,  0.0337,  0.0178,\n",
      "         0.0121, -0.0138,  0.0642, -0.0436, -0.0362, -0.0788,  0.0300, -0.0647,\n",
      "         0.0861, -0.0440,  0.0608,  0.0010, -0.0714,  0.0560,  0.0363, -0.0581,\n",
      "        -0.0944, -0.0747,  0.0102,  0.0750,  0.0625,  0.0776, -0.0336,  0.0846,\n",
      "        -0.0301,  0.0056,  0.0403,  0.0153, -0.0262,  0.0155,  0.0052, -0.0052,\n",
      "         0.0592,  0.0294,  0.0337,  0.0337,  0.0057, -0.0162, -0.0246,  0.0524,\n",
      "         0.0594,  0.0035,  0.0724,  0.0137,  0.0356,  0.0238,  0.0479,  0.0069,\n",
      "        -0.0292,  0.0079, -0.0795,  0.0042, -0.0350,  0.0836, -0.0025,  0.0117,\n",
      "         0.0366, -0.0334, -0.0153,  0.0459,  0.0227, -0.0926, -0.0237,  0.0002,\n",
      "         0.0839,  0.0776,  0.0446,  0.0508, -0.0499, -0.0674,  0.0661, -0.0684,\n",
      "         0.0286,  0.0391,  0.0319,  0.0863,  0.0788,  0.0447,  0.0500,  0.0854,\n",
      "         0.0710, -0.0070, -0.0698, -0.0745,  0.0197, -0.0392,  0.0402,  0.0337,\n",
      "        -0.0143, -0.0454, -0.0033,  0.0234,  0.0322, -0.0713, -0.1058,  0.0315,\n",
      "         0.0699,  0.0173,  0.0254, -0.0193,  0.0163,  0.0183, -0.0624,  0.0637],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2643, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 7.5608e-02, -4.7697e-02, -3.7129e-02,  2.6921e-02, -6.2993e-02,\n",
      "        -2.5237e-02, -5.1494e-02, -8.6163e-03, -2.7297e-02,  4.9497e-02,\n",
      "         1.0621e-02, -2.7747e-02, -2.9473e-02, -1.3081e-02, -2.8382e-02,\n",
      "        -8.1782e-02, -4.4881e-02,  4.3446e-02,  3.2884e-02, -1.1879e-01,\n",
      "         1.9713e-02, -2.7181e-02, -4.3844e-02, -7.2980e-03,  4.0661e-02,\n",
      "         1.1958e-02,  5.8204e-02,  1.1288e-02, -9.1620e-02, -7.3548e-02,\n",
      "        -2.5088e-02,  2.4139e-02,  1.8554e-02, -2.4953e-02,  6.0949e-02,\n",
      "         8.2344e-02,  1.0236e-01,  1.8692e-02,  3.3801e-02,  1.0412e-01,\n",
      "        -4.0782e-02,  2.6703e-02, -1.4679e-04, -5.4071e-02,  6.0261e-02,\n",
      "         3.8161e-02, -8.0161e-02, -8.4931e-02,  1.5155e-02, -2.2737e-02,\n",
      "        -6.3875e-02,  6.2248e-02,  3.9564e-02, -7.5369e-02,  4.1272e-02,\n",
      "         4.1930e-02,  1.6643e-02, -8.7212e-02,  7.9228e-03, -7.3714e-02,\n",
      "         2.4006e-02,  4.9623e-02, -2.6064e-02,  4.0377e-02,  7.8346e-02,\n",
      "        -6.4374e-03,  2.5006e-02, -5.4659e-03,  3.7916e-02,  2.6931e-02,\n",
      "        -8.7597e-02, -3.6833e-02, -1.5751e-02,  4.6829e-02, -3.4836e-03,\n",
      "         6.7286e-02,  8.4702e-02,  4.7072e-03, -1.1633e-04, -1.6442e-02,\n",
      "         1.2592e-01,  1.2915e-02, -5.9719e-02,  9.7055e-02, -1.6848e-02,\n",
      "        -1.3766e-02,  1.4148e-02,  6.7523e-02, -4.5701e-03, -9.0584e-02,\n",
      "         4.9452e-02, -7.7583e-02,  6.5402e-03, -5.6914e-02, -5.8194e-02,\n",
      "         5.7605e-02, -5.7713e-02, -9.0766e-02, -8.5767e-02,  7.1698e-02,\n",
      "        -7.1298e-02,  2.0776e-02,  2.2605e-02,  3.7055e-02, -3.5488e-02,\n",
      "        -6.6074e-02,  5.3474e-02, -7.6138e-02, -1.0455e-01, -5.6386e-02,\n",
      "        -5.2619e-02,  7.0978e-03,  5.5034e-02, -4.9511e-02, -5.3485e-02,\n",
      "        -2.6381e-02, -2.0154e-02, -2.0611e-02,  9.4663e-02,  1.4989e-02,\n",
      "        -3.5408e-02,  2.2726e-02,  8.2301e-02,  9.4337e-02, -3.9355e-02,\n",
      "        -8.3989e-02,  2.6217e-03, -7.0630e-02], requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1009, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0663, -0.0440,  0.0078,  0.1148, -0.0970,  0.0492, -0.0320, -0.0306,\n",
      "         0.0590,  0.0046,  0.0434,  0.0564,  0.0596, -0.1270, -0.0667,  0.0302,\n",
      "        -0.0208, -0.0103, -0.0274, -0.0248, -0.0198,  0.0366,  0.0951,  0.0609,\n",
      "         0.0439, -0.0537, -0.0101, -0.0267, -0.0356,  0.0483,  0.0026,  0.0510,\n",
      "         0.0168,  0.0085, -0.0597,  0.0746, -0.0355, -0.1188, -0.0855,  0.0279,\n",
      "         0.0604, -0.0899,  0.0556,  0.0527,  0.0512, -0.0790,  0.0788, -0.0020,\n",
      "        -0.1183, -0.0871, -0.0377, -0.0799, -0.0449,  0.0628,  0.0224,  0.0337,\n",
      "        -0.0265, -0.0668,  0.0553,  0.0189,  0.0248, -0.0514, -0.0385, -0.0257,\n",
      "         0.0319, -0.0994, -0.0864, -0.0845,  0.0427, -0.0549, -0.0771, -0.0548,\n",
      "        -0.0171, -0.0168, -0.0699, -0.0040, -0.0179, -0.0735,  0.0558, -0.0209,\n",
      "        -0.0851,  0.0506, -0.0225,  0.0717,  0.0352, -0.1168, -0.0131, -0.0632,\n",
      "        -0.0185,  0.0198, -0.0807, -0.0855,  0.0845,  0.0737, -0.0015,  0.0594,\n",
      "        -0.0946, -0.0628,  0.0681, -0.0526, -0.0486,  0.0093, -0.0445, -0.0266,\n",
      "         0.0432,  0.0726,  0.0414, -0.0948,  0.0413, -0.1001,  0.0560,  0.0657,\n",
      "        -0.0351, -0.0278,  0.0867, -0.0128, -0.0837,  0.0109, -0.0250,  0.0631,\n",
      "         0.0854, -0.0370,  0.1016, -0.0882, -0.0577,  0.0308,  0.0051,  0.0622],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0671, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0057, 0.0263, 0.0714], requires_grad=True)\n",
      "Epoch [48100/100000], Loss: 35.44,   LOSS_function: 35.29,   LOSS_E:0.007843,    LOSS_initial: 1.065e-05,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3061.8427743911743\n",
      "loss_compared with real:1.6657e-05,   miu_train:0.06132,    lossmean:-8.686e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48200/100000], Loss: 35.46,   LOSS_function: 35.32,   LOSS_E:0.007681,    LOSS_initial: 9.779e-06,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3068.4501678943634\n",
      "loss_compared with real:1.6689e-05,   miu_train:0.06093,    lossmean:-5.431e-05\n",
      "Epoch [48300/100000], Loss: 47.32,   LOSS_function: 39.28,   LOSS_E:0.007586,    LOSS_initial: 0.0005847,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3074.9966101646423\n",
      "loss_compared with real:2.1215e-05,   miu_train:0.06133,    lossmean:-0.0003374\n",
      "Epoch [48400/100000], Loss: 36.25,   LOSS_function: 35.66,   LOSS_E:0.007741,    LOSS_initial: 4.303e-05,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3081.690262556076\n",
      "loss_compared with real:1.7082e-05,   miu_train:0.06121,    lossmean:-0.0001141\n",
      "Epoch [48500/100000], Loss: 35.55,   LOSS_function: 35.17,   LOSS_E:0.007919,    LOSS_initial: 2.73e-05,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3088.21861076355\n",
      "loss_compared with real:1.8667e-05,   miu_train:0.06124,    lossmean:-9.432e-05\n",
      "Epoch [48600/100000], Loss: 39.25,   LOSS_function: 37.58,   LOSS_E:0.007501,    LOSS_initial: 0.0001215,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3094.8650257587433\n",
      "loss_compared with real:1.8445e-05,   miu_train:0.06107,    lossmean:-9.866e-05\n",
      "Epoch [48700/100000], Loss: 35.65,   LOSS_function: 34.84,   LOSS_E:0.007922,    LOSS_initial: 5.851e-05,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3101.454929113388\n",
      "loss_compared with real:1.5594e-05,   miu_train:0.06181,    lossmean:-2.106e-05\n",
      "Epoch [48800/100000], Loss: 35.01,   LOSS_function: 34.76,   LOSS_E:0.007812,    LOSS_initial: 1.815e-05,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3108.057633161545\n",
      "loss_compared with real:1.7083e-05,   miu_train:0.06178,    lossmean:-7.223e-05\n",
      "Epoch [48900/100000], Loss: 52.95,   LOSS_function: 47.64,   LOSS_E:0.008262,    LOSS_initial: 0.0003858,\n",
      "lamda1:1,    lamda3:1.374e+04,      learn rate:7.545e-05,    time: 3114.8909595012665\n",
      "loss_compared with real:1.9338e-05,   miu_train:0.06174,    lossmean:-0.0001459\n",
      "Epoch [49000/100000], Loss: 53.13,   LOSS_function: 45.29,   LOSS_E:0.007859,    LOSS_initial: 0.0004525,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3121.5301337242126\n",
      "loss_compared with real:1.7105e-05,   miu_train:0.06166,    lossmean:9.124e-05\n",
      "Epoch [49100/100000], Loss: 35.32,   LOSS_function: 35.16,   LOSS_E:0.007794,    LOSS_initial: 9.014e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3128.0279800891876\n",
      "loss_compared with real:1.5841e-05,   miu_train:0.06023,    lossmean:3.526e-05\n",
      "Epoch [49200/100000], Loss: 34.93,   LOSS_function: 34.8,   LOSS_E:0.007788,    LOSS_initial: 7.29e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3134.5929396152496\n",
      "loss_compared with real:1.5167e-05,   miu_train:0.06129,    lossmean:6.723e-06\n",
      "Epoch [49300/100000], Loss: 34.77,   LOSS_function: 34.65,   LOSS_E:0.007747,    LOSS_initial: 6.793e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3141.0933122634888\n",
      "loss_compared with real:1.4924e-05,   miu_train:0.06201,    lossmean:1.087e-05\n",
      "Epoch [49400/100000], Loss: 48.03,   LOSS_function: 37.5,   LOSS_E:0.007936,    LOSS_initial: 0.0006075,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3147.735554933548\n",
      "loss_compared with real:1.3634e-05,   miu_train:0.06297,    lossmean:0.0002143\n",
      "Epoch [49500/100000], Loss: 34.6,   LOSS_function: 34.48,   LOSS_E:0.007696,    LOSS_initial: 6.875e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3154.3718626499176\n",
      "loss_compared with real:1.4831e-05,   miu_train:0.06259,    lossmean:1.688e-05\n",
      "Epoch [49600/100000], Loss: 34.48,   LOSS_function: 34.36,   LOSS_E:0.007662,    LOSS_initial: 6.352e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3161.042238712311\n",
      "loss_compared with real:1.464e-05,   miu_train:0.06303,    lossmean:2.027e-05\n",
      "Epoch [49700/100000], Loss: 34.9,   LOSS_function: 34.46,   LOSS_E:0.007561,    LOSS_initial: 2.56e-05,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3167.5455298423767\n",
      "loss_compared with real:1.5025e-05,   miu_train:0.06286,    lossmean:2.112e-05\n",
      "Epoch [49800/100000], Loss: 64.98,   LOSS_function: 54.71,   LOSS_E:0.008533,    LOSS_initial: 0.0005927,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3173.9201962947845\n",
      "loss_compared with real:1.4784e-05,   miu_train:0.06305,    lossmean:6.068e-06\n",
      "Epoch [49900/100000], Loss: 34.25,   LOSS_function: 34.14,   LOSS_E:0.007644,    LOSS_initial: 6.51e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:7.183e-05,    time: 3179.98881649971\n",
      "loss_compared with real:1.4566e-05,   miu_train:0.06337,    lossmean:1.893e-05\n",
      "Epoch [50000/100000], Loss: 34.26,   LOSS_function: 34.12,   LOSS_E:0.007459,    LOSS_initial: 8.062e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3186.187545776367\n",
      "loss_compared with real:1.4636e-05,   miu_train:0.06327,    lossmean:3.137e-05\n",
      "Epoch [50100/100000], Loss: 34.09,   LOSS_function: 33.98,   LOSS_E:0.007625,    LOSS_initial: 6.229e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3192.278421640396\n",
      "loss_compared with real:1.4451e-05,   miu_train:0.06375,    lossmean:1.71e-05\n",
      "Epoch [50200/100000], Loss: 37.34,   LOSS_function: 35.75,   LOSS_E:0.007576,    LOSS_initial: 9.161e-05,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3198.4225697517395\n",
      "loss_compared with real:1.4703e-05,   miu_train:0.06385,    lossmean:9.526e-05\n",
      "Epoch [50300/100000], Loss: 33.95,   LOSS_function: 33.81,   LOSS_E:0.00753,    LOSS_initial: 8.132e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3204.573333263397\n",
      "loss_compared with real:1.4423e-05,   miu_train:0.06385,    lossmean:3.72e-05\n",
      "Epoch [50400/100000], Loss: 34.03,   LOSS_function: 33.86,   LOSS_E:0.007495,    LOSS_initial: 9.545e-06,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3210.9478707313538\n",
      "loss_compared with real:1.4472e-05,   miu_train:0.0639,    lossmean:2.039e-05\n",
      "Epoch [50500/100000], Loss: 39.86,   LOSS_function: 36.47,   LOSS_E:0.008527,    LOSS_initial: 0.0001955,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3217.1345405578613\n",
      "loss_compared with real:1.5161e-05,   miu_train:0.06381,    lossmean:-2.355e-06\n",
      "Epoch [50600/100000], Loss: 34.71,   LOSS_function: 33.8,   LOSS_E:0.007743,    LOSS_initial: 5.262e-05,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3223.279940843582\n",
      "loss_compared with real:1.4742e-05,   miu_train:0.06401,    lossmean:3.462e-05\n",
      "Epoch [50700/100000], Loss: 34.09,   LOSS_function: 33.62,   LOSS_E:0.007551,    LOSS_initial: 2.699e-05,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3229.3532593250275\n",
      "loss_compared with real:1.4318e-05,   miu_train:0.06435,    lossmean:2.04e-05\n",
      "Epoch [50800/100000], Loss: 35.11,   LOSS_function: 33.95,   LOSS_E:0.008046,    LOSS_initial: 6.729e-05,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3235.675175666809\n",
      "loss_compared with real:1.3691e-05,   miu_train:0.06432,    lossmean:0.0001851\n",
      "Epoch [50900/100000], Loss: 35.96,   LOSS_function: 33.8,   LOSS_E:0.007365,    LOSS_initial: 0.000124,\n",
      "lamda1:1,    lamda3:1.733e+04,      learn rate:6.838e-05,    time: 3241.7794959545135\n",
      "loss_compared with real:1.4685e-05,   miu_train:0.06439,    lossmean:2.626e-05\n",
      "Epoch [51000/100000], Loss: 33.91,   LOSS_function: 33.68,   LOSS_E:0.007762,    LOSS_initial: 1.259e-05,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3247.9694197177887\n",
      "loss_compared with real:1.473e-05,   miu_train:0.06449,    lossmean:-5.042e-05\n",
      "Epoch [51100/100000], Loss: 34,   LOSS_function: 33.43,   LOSS_E:0.007481,    LOSS_initial: 3.166e-05,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3254.0119409561157\n",
      "loss_compared with real:1.473e-05,   miu_train:0.06495,    lossmean:-5.742e-05\n",
      "Epoch [51200/100000], Loss: 40.07,   LOSS_function: 37.13,   LOSS_E:0.007514,    LOSS_initial: 0.0001643,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3260.1071631908417\n",
      "loss_compared with real:1.4306e-05,   miu_train:0.06501,    lossmean:-4.841e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51300/100000], Loss: 33.18,   LOSS_function: 33.11,   LOSS_E:0.007498,    LOSS_initial: 4.094e-06,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3266.195361852646\n",
      "loss_compared with real:1.3824e-05,   miu_train:0.06531,    lossmean:4.231e-05\n",
      "Epoch [51400/100000], Loss: 33.21,   LOSS_function: 33.08,   LOSS_E:0.00749,    LOSS_initial: 7.129e-06,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3272.352251291275\n",
      "loss_compared with real:1.3946e-05,   miu_train:0.06496,    lossmean:3.989e-05\n",
      "Epoch [51500/100000], Loss: 34.45,   LOSS_function: 33.03,   LOSS_E:0.007457,    LOSS_initial: 7.872e-05,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3278.5202407836914\n",
      "loss_compared with real:1.4285e-05,   miu_train:0.06535,    lossmean:3.424e-05\n",
      "Epoch [51600/100000], Loss: 33.45,   LOSS_function: 33.08,   LOSS_E:0.007519,    LOSS_initial: 2.042e-05,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3284.747724056244\n",
      "loss_compared with real:1.3395e-05,   miu_train:0.06554,    lossmean:0.0001076\n",
      "Epoch [51700/100000], Loss: 33.13,   LOSS_function: 32.77,   LOSS_E:0.007373,    LOSS_initial: 2.03e-05,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3290.8288521766663\n",
      "loss_compared with real:1.3667e-05,   miu_train:0.06569,    lossmean:7.076e-05\n",
      "Epoch [51800/100000], Loss: 53.87,   LOSS_function: 41.61,   LOSS_E:0.007216,    LOSS_initial: 0.0006842,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3297.2333629131317\n",
      "loss_compared with real:1.4067e-05,   miu_train:0.06538,    lossmean:5.39e-05\n",
      "Epoch [51900/100000], Loss: 43.46,   LOSS_function: 33.05,   LOSS_E:0.007166,    LOSS_initial: 0.0005801,\n",
      "lamda1:1,    lamda3:1.793e+04,      learn rate:6.51e-05,    time: 3303.7547357082367\n",
      "loss_compared with real:1.6278e-05,   miu_train:0.06596,    lossmean:-0.0001404\n",
      "Epoch [52000/100000], Loss: 39.42,   LOSS_function: 36.1,   LOSS_E:0.007464,    LOSS_initial: 0.0002454,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3310.3602862358093\n",
      "loss_compared with real:1.3431e-05,   miu_train:0.06601,    lossmean:0.0001121\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5206, -0.5070, -0.2888, -0.9673, -0.0643, -0.3191,  0.4303, -0.8254,\n",
      "         0.8657,  0.3139,  0.7665,  0.5157,  0.5944, -0.0301,  0.6968, -0.3217,\n",
      "         0.8294,  0.0230,  0.7913, -0.8031, -0.2650, -0.9688, -0.4838, -0.3206,\n",
      "        -0.2987, -0.3498,  0.6959, -0.6248, -0.2323,  0.4144, -0.3062, -0.1905,\n",
      "         0.1029,  0.6318, -0.6927, -0.7984, -0.7075, -0.5425, -0.2544, -0.0374,\n",
      "        -0.8228, -0.9686, -0.0507,  0.8011, -0.5787,  0.8646, -0.6889,  0.9034,\n",
      "         0.6179, -0.9112, -0.7523, -0.3415,  0.8453, -0.6027,  0.9217, -0.1109,\n",
      "        -0.8957,  0.4127, -0.2535, -0.8651,  0.8315, -0.3150,  0.2532, -0.1146,\n",
      "        -0.5065, -0.0814, -0.0234,  0.4049, -0.4046, -0.3428,  0.5317, -0.4201,\n",
      "        -0.4844,  0.8810,  0.7981, -0.4217, -0.4407,  0.0222, -0.3101, -0.5238,\n",
      "        -0.7539, -0.6534,  0.9150,  0.0179,  0.1163,  0.7534,  0.6706,  0.2239,\n",
      "        -0.0346, -0.0858,  0.6278,  0.7115, -0.6026,  0.9418,  0.2202,  0.5756,\n",
      "        -0.6446, -0.1342,  0.5837,  0.0293, -0.8526,  0.0765, -0.0117, -0.1970,\n",
      "         0.4044,  0.4943,  0.6589,  0.0581,  0.2392,  0.6245, -0.6248, -0.2592,\n",
      "         0.5791,  0.7721,  0.7177,  0.0100, -0.9603,  0.8768, -0.2915, -0.8848,\n",
      "        -0.9645,  0.8994, -0.2299,  0.3605, -0.2263,  0.4241, -0.2015,  0.1837],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2948, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 2.2375e-02, -3.3342e-02,  2.3575e-02,  6.6778e-02, -3.9013e-02,\n",
      "        -3.7713e-02, -3.2289e-02,  3.1841e-02, -3.0635e-02,  4.3548e-02,\n",
      "        -1.0925e-02, -9.9758e-02,  4.8136e-02, -3.9157e-02,  7.2607e-02,\n",
      "         2.6808e-02, -4.3192e-02, -2.2101e-02, -1.2063e-02,  3.5529e-02,\n",
      "        -6.9151e-02,  6.2472e-02,  3.4478e-02,  1.7671e-02,  1.1944e-02,\n",
      "        -1.3384e-02,  6.4179e-02, -4.3648e-02, -3.6234e-02, -7.8635e-02,\n",
      "         2.9886e-02, -6.4780e-02,  8.5707e-02, -4.3690e-02,  6.0815e-02,\n",
      "         1.1787e-03, -7.1139e-02,  5.6073e-02,  3.6185e-02, -5.8254e-02,\n",
      "        -9.4182e-02, -7.4464e-02,  1.0245e-02,  7.5014e-02,  6.2254e-02,\n",
      "         7.7744e-02, -3.3172e-02,  8.4416e-02, -3.0130e-02,  5.4127e-03,\n",
      "         4.0328e-02,  1.5365e-02, -2.6284e-02,  1.5543e-02,  5.0898e-03,\n",
      "        -5.4383e-03,  5.9474e-02,  2.9586e-02,  3.4204e-02,  3.3581e-02,\n",
      "         5.9077e-03, -1.6242e-02, -2.4382e-02,  5.2788e-02,  5.9338e-02,\n",
      "         3.8995e-03,  7.2416e-02,  1.3494e-02,  3.5283e-02,  2.3731e-02,\n",
      "         4.7990e-02,  6.4799e-03, -2.9696e-02,  7.6672e-03, -7.8778e-02,\n",
      "         3.7851e-03, -3.4800e-02,  8.3341e-02, -2.4268e-03,  1.1867e-02,\n",
      "         3.6466e-02, -3.3068e-02, -1.5343e-02,  4.5709e-02,  2.2209e-02,\n",
      "        -9.2385e-02, -2.3724e-02, -6.2881e-05,  8.4053e-02,  7.7799e-02,\n",
      "         4.4550e-02,  5.0952e-02, -4.9911e-02, -6.7370e-02,  6.6238e-02,\n",
      "        -6.8468e-02,  2.8329e-02,  3.9243e-02,  3.1810e-02,  8.6177e-02,\n",
      "         7.8646e-02,  4.4628e-02,  4.9953e-02,  8.5330e-02,  7.1219e-02,\n",
      "        -7.0953e-03, -7.0081e-02, -7.5270e-02,  1.9959e-02, -3.9027e-02,\n",
      "         4.0310e-02,  3.3549e-02, -1.4729e-02, -4.5260e-02, -3.3526e-03,\n",
      "         2.3232e-02,  3.1971e-02, -7.1949e-02, -1.0597e-01,  3.1464e-02,\n",
      "         6.9863e-02,  1.7102e-02,  2.5295e-02, -1.9329e-02,  1.5680e-02,\n",
      "         1.7989e-02, -6.2364e-02,  6.3783e-02], requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2646, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 7.5497e-02, -4.7772e-02, -3.7057e-02,  2.6735e-02, -6.2957e-02,\n",
      "        -2.5277e-02, -5.1277e-02, -8.7428e-03, -2.6980e-02,  4.9402e-02,\n",
      "         1.1153e-02, -2.7268e-02, -2.9835e-02, -1.2975e-02, -2.8484e-02,\n",
      "        -8.2523e-02, -4.4877e-02,  4.3576e-02,  3.2934e-02, -1.1871e-01,\n",
      "         1.9641e-02, -2.7487e-02, -4.3853e-02, -7.4947e-03,  4.0497e-02,\n",
      "         1.1682e-02,  5.8062e-02,  1.1261e-02, -9.1512e-02, -7.3652e-02,\n",
      "        -2.5016e-02,  2.3955e-02,  1.8919e-02, -2.5070e-02,  6.1347e-02,\n",
      "         8.2545e-02,  1.0207e-01,  1.8479e-02,  3.4067e-02,  1.0409e-01,\n",
      "        -3.9945e-02,  2.6404e-02,  3.4636e-05, -5.4415e-02,  6.0023e-02,\n",
      "         3.7899e-02, -8.0136e-02, -8.5630e-02,  1.5201e-02, -2.2658e-02,\n",
      "        -6.3964e-02,  6.2360e-02,  3.9582e-02, -7.5273e-02,  4.1560e-02,\n",
      "         4.2314e-02,  1.5852e-02, -8.7135e-02,  7.9421e-03, -7.4190e-02,\n",
      "         2.4242e-02,  4.9423e-02, -2.6023e-02,  3.9780e-02,  7.7801e-02,\n",
      "        -6.5518e-03,  2.4907e-02, -5.3902e-03,  3.7862e-02,  2.6461e-02,\n",
      "        -8.7149e-02, -3.6661e-02, -1.5732e-02,  4.6093e-02, -3.5442e-03,\n",
      "         6.7343e-02,  8.4813e-02,  4.6560e-03,  1.7328e-05, -1.6648e-02,\n",
      "         1.2597e-01,  1.2887e-02, -5.9835e-02,  9.7241e-02, -1.7045e-02,\n",
      "        -1.3956e-02,  1.4173e-02,  6.7832e-02, -4.9435e-03, -9.0688e-02,\n",
      "         4.9624e-02, -7.7671e-02,  6.7081e-03, -5.6952e-02, -5.8154e-02,\n",
      "         5.7735e-02, -5.7640e-02, -9.0607e-02, -8.5816e-02,  7.1629e-02,\n",
      "        -7.0825e-02,  2.0991e-02,  2.3015e-02,  3.6991e-02, -3.5487e-02,\n",
      "        -6.6088e-02,  5.2552e-02, -7.7052e-02, -1.0438e-01, -5.6788e-02,\n",
      "        -5.2767e-02,  7.1374e-03,  5.4979e-02, -4.9059e-02, -5.3480e-02,\n",
      "        -2.6009e-02, -2.0055e-02, -2.1289e-02,  9.4515e-02,  1.5312e-02,\n",
      "        -3.5425e-02,  2.3216e-02,  8.2163e-02,  9.4304e-02, -3.9010e-02,\n",
      "        -8.4427e-02,  3.2086e-03, -7.0758e-02], requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1010, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0664, -0.0434,  0.0084,  0.1149, -0.0970,  0.0491, -0.0320, -0.0306,\n",
      "         0.0587,  0.0046,  0.0432,  0.0570,  0.0594, -0.1269, -0.0669,  0.0309,\n",
      "        -0.0210, -0.0105, -0.0275, -0.0247, -0.0197,  0.0367,  0.0950,  0.0609,\n",
      "         0.0438, -0.0538, -0.0099, -0.0268, -0.0356,  0.0485,  0.0030,  0.0507,\n",
      "         0.0173,  0.0082, -0.0595,  0.0746, -0.0352, -0.1187, -0.0858,  0.0280,\n",
      "         0.0606, -0.0900,  0.0556,  0.0527,  0.0513, -0.0790,  0.0786, -0.0019,\n",
      "        -0.1182, -0.0868, -0.0378, -0.0800, -0.0449,  0.0628,  0.0225,  0.0339,\n",
      "        -0.0265, -0.0668,  0.0548,  0.0191,  0.0249, -0.0512, -0.0385, -0.0253,\n",
      "         0.0320, -0.0993, -0.0865, -0.0844,  0.0427, -0.0550, -0.0772, -0.0547,\n",
      "        -0.0172, -0.0170, -0.0698, -0.0042, -0.0176, -0.0740,  0.0553, -0.0203,\n",
      "        -0.0854,  0.0507, -0.0231,  0.0712,  0.0350, -0.1175, -0.0131, -0.0633,\n",
      "        -0.0184,  0.0193, -0.0809, -0.0855,  0.0846,  0.0739, -0.0014,  0.0594,\n",
      "        -0.0952, -0.0628,  0.0680, -0.0527, -0.0488,  0.0093, -0.0444, -0.0267,\n",
      "         0.0434,  0.0725,  0.0415, -0.0949,  0.0415, -0.1003,  0.0558,  0.0654,\n",
      "        -0.0352, -0.0277,  0.0873, -0.0127, -0.0837,  0.0105, -0.0248,  0.0631,\n",
      "         0.0853, -0.0369,  0.1033, -0.0883, -0.0579,  0.0303,  0.0052,  0.0620],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0674, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0085, 0.0267, 0.0746], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52100/100000], Loss: 32.55,   LOSS_function: 32.43,   LOSS_E:0.007401,    LOSS_initial: 9.278e-06,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3316.900024175644\n",
      "loss_compared with real:1.49e-05,   miu_train:0.06632,    lossmean:-4.064e-05\n",
      "Epoch [52200/100000], Loss: 33.88,   LOSS_function: 33.8,   LOSS_E:0.007418,    LOSS_initial: 5.384e-06,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3323.4508378505707\n",
      "loss_compared with real:1.4477e-05,   miu_train:0.06622,    lossmean:-3.981e-05\n",
      "Epoch [52300/100000], Loss: 32.76,   LOSS_function: 32.6,   LOSS_E:0.00737,    LOSS_initial: 1.219e-05,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3329.9916026592255\n",
      "loss_compared with real:1.5044e-05,   miu_train:0.06621,    lossmean:-3.326e-05\n",
      "Epoch [52400/100000], Loss: 32.29,   LOSS_function: 32.16,   LOSS_E:0.007376,    LOSS_initial: 9.281e-06,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3336.7099623680115\n",
      "loss_compared with real:1.4757e-05,   miu_train:0.06667,    lossmean:-3.076e-05\n",
      "Epoch [52500/100000], Loss: 32.3,   LOSS_function: 32.12,   LOSS_E:0.007292,    LOSS_initial: 1.306e-05,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3343.3195955753326\n",
      "loss_compared with real:1.4707e-05,   miu_train:0.06633,    lossmean:-2.444e-05\n",
      "Epoch [52600/100000], Loss: 57.64,   LOSS_function: 50.4,   LOSS_E:0.006998,    LOSS_initial: 0.0005361,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3350.094556093216\n",
      "loss_compared with real:1.686e-05,   miu_train:0.0662,    lossmean:-0.0001409\n",
      "Epoch [52700/100000], Loss: 32.09,   LOSS_function: 31.96,   LOSS_E:0.00737,    LOSS_initial: 9.074e-06,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3356.8941509723663\n",
      "loss_compared with real:1.4745e-05,   miu_train:0.06677,    lossmean:-3.439e-05\n",
      "Epoch [52800/100000], Loss: 33.17,   LOSS_function: 32.97,   LOSS_E:0.007655,    LOSS_initial: 1.513e-05,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3363.4776661396027\n",
      "loss_compared with real:1.5943e-05,   miu_train:0.06681,    lossmean:-0.000152\n",
      "Epoch [52900/100000], Loss: 44.05,   LOSS_function: 40.65,   LOSS_E:0.007218,    LOSS_initial: 0.0002513,\n",
      "lamda1:1,    lamda3:1.35e+04,      learn rate:6.197e-05,    time: 3370.0289022922516\n",
      "loss_compared with real:1.682e-05,   miu_train:0.0671,    lossmean:-0.0001578\n",
      "Epoch [53000/100000], Loss: 37.26,   LOSS_function: 34.24,   LOSS_E:0.007218,    LOSS_initial: 0.0001715,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3376.647978067398\n",
      "loss_compared with real:1.3976e-05,   miu_train:0.06682,    lossmean:0.0001514\n",
      "Epoch [53100/100000], Loss: 32.09,   LOSS_function: 31.97,   LOSS_E:0.007363,    LOSS_initial: 6.915e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3383.247593641281\n",
      "loss_compared with real:1.3863e-05,   miu_train:0.06634,    lossmean:4.605e-05\n",
      "Epoch [53200/100000], Loss: 31.89,   LOSS_function: 31.79,   LOSS_E:0.007392,    LOSS_initial: 5.659e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3389.840021133423\n",
      "loss_compared with real:1.3366e-05,   miu_train:0.06708,    lossmean:3.067e-05\n",
      "Epoch [53300/100000], Loss: 32.58,   LOSS_function: 31.73,   LOSS_E:0.007302,    LOSS_initial: 4.818e-05,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3396.47140955925\n",
      "loss_compared with real:1.3067e-05,   miu_train:0.06742,    lossmean:8.866e-05\n",
      "Epoch [53400/100000], Loss: 31.71,   LOSS_function: 31.61,   LOSS_E:0.007314,    LOSS_initial: 5.348e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3403.0541541576385\n",
      "loss_compared with real:1.3142e-05,   miu_train:0.06774,    lossmean:4.151e-05\n",
      "Epoch [53500/100000], Loss: 31.81,   LOSS_function: 31.58,   LOSS_E:0.007246,    LOSS_initial: 1.298e-05,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3409.5739958286285\n",
      "loss_compared with real:1.3423e-05,   miu_train:0.06788,    lossmean:1.999e-05\n",
      "Epoch [53600/100000], Loss: 31.57,   LOSS_function: 31.47,   LOSS_E:0.007256,    LOSS_initial: 5.338e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3416.606388092041\n",
      "loss_compared with real:1.2996e-05,   miu_train:0.06811,    lossmean:6.017e-05\n",
      "Epoch [53700/100000], Loss: 31.52,   LOSS_function: 31.41,   LOSS_E:0.007194,    LOSS_initial: 6.162e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3423.1893088817596\n",
      "loss_compared with real:1.2898e-05,   miu_train:0.0682,    lossmean:5.904e-05\n",
      "Epoch [53800/100000], Loss: 32.03,   LOSS_function: 31.46,   LOSS_E:0.007424,    LOSS_initial: 3.249e-05,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3429.7357807159424\n",
      "loss_compared with real:1.3653e-05,   miu_train:0.06826,    lossmean:-1.634e-05\n",
      "Epoch [53900/100000], Loss: 31.98,   LOSS_function: 31.84,   LOSS_E:0.007394,    LOSS_initial: 7.701e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.9e-05,    time: 3436.3270406723022\n",
      "loss_compared with real:1.2793e-05,   miu_train:0.06835,    lossmean:0.0001212\n",
      "Epoch [54000/100000], Loss: 31.38,   LOSS_function: 31.21,   LOSS_E:0.007333,    LOSS_initial: 9.346e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3442.953520298004\n",
      "loss_compared with real:1.2871e-05,   miu_train:0.06837,    lossmean:6.799e-05\n",
      "Epoch [54100/100000], Loss: 31.17,   LOSS_function: 31.08,   LOSS_E:0.007235,    LOSS_initial: 5.249e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3449.498016834259\n",
      "loss_compared with real:1.2835e-05,   miu_train:0.0688,    lossmean:5.322e-05\n",
      "Epoch [54200/100000], Loss: 31.87,   LOSS_function: 31.12,   LOSS_E:0.00709,    LOSS_initial: 4.251e-05,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3456.125110387802\n",
      "loss_compared with real:1.3096e-05,   miu_train:0.06871,    lossmean:0.0001692\n",
      "Epoch [54300/100000], Loss: 31.09,   LOSS_function: 31.01,   LOSS_E:0.007391,    LOSS_initial: 4.91e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3462.694993495941\n",
      "loss_compared with real:1.2724e-05,   miu_train:0.06892,    lossmean:9.171e-05\n",
      "Epoch [54400/100000], Loss: 31.24,   LOSS_function: 31.08,   LOSS_E:0.007132,    LOSS_initial: 8.566e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3469.2708563804626\n",
      "loss_compared with real:1.2817e-05,   miu_train:0.06918,    lossmean:4.929e-05\n",
      "Epoch [54500/100000], Loss: 76.3,   LOSS_function: 63.85,   LOSS_E:0.007771,    LOSS_initial: 0.000708,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3475.6607160568237\n",
      "loss_compared with real:1.3433e-05,   miu_train:0.06953,    lossmean:-0.0002346\n",
      "Epoch [54600/100000], Loss: 30.93,   LOSS_function: 30.76,   LOSS_E:0.007208,    LOSS_initial: 9.909e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3481.914896965027\n",
      "loss_compared with real:1.2874e-05,   miu_train:0.0694,    lossmean:3.146e-05\n",
      "Epoch [54700/100000], Loss: 33.14,   LOSS_function: 32.16,   LOSS_E:0.007375,    LOSS_initial: 5.553e-05,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3488.0319311618805\n",
      "loss_compared with real:1.2668e-05,   miu_train:0.06961,    lossmean:3.677e-05\n",
      "Epoch [54800/100000], Loss: 31.03,   LOSS_function: 30.91,   LOSS_E:0.007184,    LOSS_initial: 6.755e-06,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3494.1459555625916\n",
      "loss_compared with real:1.2508e-05,   miu_train:0.06972,    lossmean:0.0001016\n",
      "Epoch [54900/100000], Loss: 30.89,   LOSS_function: 30.67,   LOSS_E:0.007095,    LOSS_initial: 1.226e-05,\n",
      "lamda1:1,    lamda3:1.758e+04,      learn rate:5.617e-05,    time: 3500.248513698578\n",
      "loss_compared with real:1.2786e-05,   miu_train:0.06989,    lossmean:2.725e-05\n",
      "Epoch [55000/100000], Loss: 32.62,   LOSS_function: 31.58,   LOSS_E:0.007165,    LOSS_initial: 5.261e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3506.448742389679\n",
      "loss_compared with real:1.2999e-05,   miu_train:0.06984,    lossmean:9.513e-05\n",
      "Epoch [55100/100000], Loss: 30.51,   LOSS_function: 30.42,   LOSS_E:0.0071,    LOSS_initial: 4.165e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3512.820647954941\n",
      "loss_compared with real:1.2171e-05,   miu_train:0.07012,    lossmean:8.988e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55200/100000], Loss: 30.43,   LOSS_function: 30.35,   LOSS_E:0.007069,    LOSS_initial: 3.926e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3518.95690369606\n",
      "loss_compared with real:1.1983e-05,   miu_train:0.07031,    lossmean:0.0001173\n",
      "Epoch [55300/100000], Loss: 30.32,   LOSS_function: 30.21,   LOSS_E:0.00711,    LOSS_initial: 5.817e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3525.019282102585\n",
      "loss_compared with real:1.201e-05,   miu_train:0.07049,    lossmean:9.909e-05\n",
      "Epoch [55400/100000], Loss: 30.41,   LOSS_function: 30.35,   LOSS_E:0.007024,    LOSS_initial: 3.182e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3531.149521112442\n",
      "loss_compared with real:1.2054e-05,   miu_train:0.07059,    lossmean:7.456e-05\n",
      "Epoch [55500/100000], Loss: 30.22,   LOSS_function: 30.1,   LOSS_E:0.007076,    LOSS_initial: 6.285e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3537.543434858322\n",
      "loss_compared with real:1.2017e-05,   miu_train:0.07072,    lossmean:9.766e-05\n",
      "Epoch [55600/100000], Loss: 30.11,   LOSS_function: 30.03,   LOSS_E:0.007066,    LOSS_initial: 3.938e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3543.7639334201813\n",
      "loss_compared with real:1.1941e-05,   miu_train:0.07083,    lossmean:9.426e-05\n",
      "Epoch [55700/100000], Loss: 30.43,   LOSS_function: 30.16,   LOSS_E:0.007095,    LOSS_initial: 1.367e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3549.8844656944275\n",
      "loss_compared with real:1.1731e-05,   miu_train:0.07097,    lossmean:0.0001216\n",
      "Epoch [55800/100000], Loss: 42.98,   LOSS_function: 34.64,   LOSS_E:0.007087,    LOSS_initial: 0.0004229,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3556.0719923973083\n",
      "loss_compared with real:1.1745e-05,   miu_train:0.07105,    lossmean:0.0002235\n",
      "Epoch [55900/100000], Loss: 30.82,   LOSS_function: 30.32,   LOSS_E:0.006919,    LOSS_initial: 2.56e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.347e-05,    time: 3562.1485714912415\n",
      "loss_compared with real:1.218e-05,   miu_train:0.07122,    lossmean:5.251e-05\n",
      "Epoch [56000/100000], Loss: 29.86,   LOSS_function: 29.7,   LOSS_E:0.006984,    LOSS_initial: 7.57e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3568.304156064987\n",
      "loss_compared with real:1.1818e-05,   miu_train:0.07136,    lossmean:0.0001167\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5207, -0.5066, -0.2888, -0.9672, -0.0644, -0.3191,  0.4301, -0.8256,\n",
      "         0.8657,  0.3139,  0.7665,  0.5152,  0.5938, -0.0302,  0.6967, -0.3218,\n",
      "         0.8295,  0.0230,  0.7913, -0.8030, -0.2651, -0.9688, -0.4832, -0.3206,\n",
      "        -0.2985, -0.3498,  0.6960, -0.6251, -0.2323,  0.4143, -0.3064, -0.1900,\n",
      "         0.1032,  0.6318, -0.6926, -0.7986, -0.7076, -0.5419, -0.2546, -0.0374,\n",
      "        -0.8232, -0.9693, -0.0507,  0.8011, -0.5782,  0.8645, -0.6890,  0.9032,\n",
      "         0.6184, -0.9112, -0.7521, -0.3413,  0.8456, -0.6027,  0.9214, -0.1108,\n",
      "        -0.8963,  0.4123, -0.2538, -0.8650,  0.8317, -0.3148,  0.2532, -0.1145,\n",
      "        -0.5066, -0.0813, -0.0235,  0.4047, -0.4052, -0.3427,  0.5316, -0.4199,\n",
      "        -0.4837,  0.8815,  0.7985, -0.4216, -0.4408,  0.0219, -0.3102, -0.5239,\n",
      "        -0.7537, -0.6533,  0.9150,  0.0177,  0.1161,  0.7532,  0.6708,  0.2240,\n",
      "        -0.0343, -0.0856,  0.6276,  0.7116, -0.6025,  0.9421,  0.2199,  0.5758,\n",
      "        -0.6441, -0.1340,  0.5836,  0.0291, -0.8527,  0.0765, -0.0115, -0.1969,\n",
      "         0.4045,  0.4942,  0.6590,  0.0577,  0.2391,  0.6247, -0.6245, -0.2592,\n",
      "         0.5793,  0.7721,  0.7175,  0.0098, -0.9605,  0.8766, -0.2916, -0.8851,\n",
      "        -0.9646,  0.8995, -0.2296,  0.3605, -0.2263,  0.4239, -0.2016,  0.1836],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2949, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0225, -0.0332,  0.0239,  0.0669, -0.0389, -0.0376, -0.0320,  0.0324,\n",
      "        -0.0309,  0.0435, -0.0113, -0.0998,  0.0482, -0.0391,  0.0726,  0.0268,\n",
      "        -0.0438, -0.0218, -0.0119,  0.0355, -0.0689,  0.0625,  0.0349,  0.0176,\n",
      "         0.0120, -0.0129,  0.0642, -0.0437, -0.0363, -0.0784,  0.0296, -0.0647,\n",
      "         0.0852, -0.0437,  0.0609,  0.0014, -0.0710,  0.0561,  0.0361, -0.0585,\n",
      "        -0.0941, -0.0742,  0.0103,  0.0751,  0.0620,  0.0778, -0.0331,  0.0843,\n",
      "        -0.0301,  0.0051,  0.0403,  0.0156, -0.0264,  0.0155,  0.0049, -0.0059,\n",
      "         0.0599,  0.0298,  0.0346,  0.0335,  0.0060, -0.0165, -0.0242,  0.0530,\n",
      "         0.0594,  0.0039,  0.0724,  0.0133,  0.0351,  0.0238,  0.0481,  0.0065,\n",
      "        -0.0301,  0.0074, -0.0782,  0.0034, -0.0346,  0.0832, -0.0025,  0.0120,\n",
      "         0.0362, -0.0329, -0.0153,  0.0456,  0.0218, -0.0924, -0.0236, -0.0002,\n",
      "         0.0839,  0.0779,  0.0445,  0.0512, -0.0499, -0.0673,  0.0662, -0.0686,\n",
      "         0.0282,  0.0395,  0.0317,  0.0861,  0.0785,  0.0447,  0.0498,  0.0852,\n",
      "         0.0714, -0.0073, -0.0701, -0.0761,  0.0203, -0.0390,  0.0403,  0.0334,\n",
      "        -0.0153, -0.0451, -0.0033,  0.0232,  0.0317, -0.0724, -0.1062,  0.0315,\n",
      "         0.0700,  0.0170,  0.0254, -0.0193,  0.0152,  0.0177, -0.0624,  0.0640],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2653, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0753, -0.0478, -0.0370,  0.0264, -0.0629, -0.0254, -0.0509, -0.0089,\n",
      "        -0.0267,  0.0493,  0.0115, -0.0267, -0.0303, -0.0129, -0.0286, -0.0832,\n",
      "        -0.0448,  0.0437,  0.0329, -0.1186,  0.0195, -0.0278, -0.0439, -0.0076,\n",
      "         0.0404,  0.0114,  0.0580,  0.0113, -0.0914, -0.0737, -0.0249,  0.0237,\n",
      "         0.0192, -0.0250,  0.0616,  0.0828,  0.1018,  0.0182,  0.0344,  0.1041,\n",
      "        -0.0392,  0.0262,  0.0002, -0.0547,  0.0598,  0.0378, -0.0802, -0.0858,\n",
      "         0.0152, -0.0227, -0.0641,  0.0625,  0.0397, -0.0751,  0.0418,  0.0427,\n",
      "         0.0152, -0.0871,  0.0079, -0.0745,  0.0244,  0.0494, -0.0260,  0.0393,\n",
      "         0.0774, -0.0067,  0.0248, -0.0053,  0.0379,  0.0261, -0.0870, -0.0366,\n",
      "        -0.0157,  0.0456, -0.0033,  0.0672,  0.0849,  0.0046,  0.0002, -0.0167,\n",
      "         0.1259,  0.0130, -0.0600,  0.0973, -0.0172, -0.0141,  0.0142,  0.0682,\n",
      "        -0.0050, -0.0909,  0.0497, -0.0777,  0.0070, -0.0570, -0.0580,  0.0580,\n",
      "        -0.0574, -0.0904, -0.0858,  0.0716, -0.0705,  0.0212,  0.0233,  0.0368,\n",
      "        -0.0355, -0.0661,  0.0517, -0.0777, -0.1043, -0.0570, -0.0530,  0.0071,\n",
      "         0.0549, -0.0485, -0.0533, -0.0258, -0.0199, -0.0217,  0.0947,  0.0155,\n",
      "        -0.0355,  0.0234,  0.0820,  0.0942, -0.0388, -0.0848,  0.0039, -0.0707],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1013, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0665, -0.0431,  0.0089,  0.1150, -0.0971,  0.0490, -0.0320, -0.0305,\n",
      "         0.0587,  0.0047,  0.0431,  0.0573,  0.0593, -0.1270, -0.0671,  0.0315,\n",
      "        -0.0211, -0.0108, -0.0276, -0.0246, -0.0197,  0.0368,  0.0948,  0.0609,\n",
      "         0.0437, -0.0538, -0.0098, -0.0270, -0.0357,  0.0488,  0.0033,  0.0506,\n",
      "         0.0177,  0.0080, -0.0594,  0.0746, -0.0352, -0.1186, -0.0860,  0.0281,\n",
      "         0.0606, -0.0901,  0.0556,  0.0526,  0.0515, -0.0790,  0.0784, -0.0019,\n",
      "        -0.1181, -0.0865, -0.0380, -0.0801, -0.0449,  0.0628,  0.0226,  0.0339,\n",
      "        -0.0264, -0.0668,  0.0545,  0.0193,  0.0251, -0.0511, -0.0385, -0.0250,\n",
      "         0.0321, -0.0992, -0.0864, -0.0845,  0.0427, -0.0551, -0.0772, -0.0543,\n",
      "        -0.0175, -0.0171, -0.0698, -0.0042, -0.0174, -0.0747,  0.0549, -0.0195,\n",
      "        -0.0855,  0.0507, -0.0235,  0.0708,  0.0348, -0.1180, -0.0132, -0.0633,\n",
      "        -0.0183,  0.0190, -0.0811, -0.0856,  0.0847,  0.0740, -0.0013,  0.0594,\n",
      "        -0.0955, -0.0628,  0.0678, -0.0526, -0.0488,  0.0093, -0.0444, -0.0267,\n",
      "         0.0434,  0.0725,  0.0416, -0.0950,  0.0416, -0.1004,  0.0557,  0.0653,\n",
      "        -0.0352, -0.0277,  0.0876, -0.0127, -0.0836,  0.0102, -0.0247,  0.0632,\n",
      "         0.0853, -0.0368,  0.1044, -0.0883, -0.0582,  0.0301,  0.0052,  0.0618],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0676, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0108, 0.0267, 0.0771], requires_grad=True)\n",
      "Epoch [56100/100000], Loss: 29.81,   LOSS_function: 29.58,   LOSS_E:0.007012,    LOSS_initial: 1.16e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3574.423675775528\n",
      "loss_compared with real:1.1561e-05,   miu_train:0.07173,    lossmean:0.0001244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56200/100000], Loss: 29.74,   LOSS_function: 29.59,   LOSS_E:0.006966,    LOSS_initial: 7.588e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3580.589648962021\n",
      "loss_compared with real:1.1748e-05,   miu_train:0.07168,    lossmean:0.0001072\n",
      "Epoch [56300/100000], Loss: 30.52,   LOSS_function: 29.67,   LOSS_E:0.006938,    LOSS_initial: 4.29e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3586.654983520508\n",
      "loss_compared with real:1.1682e-05,   miu_train:0.07174,    lossmean:9.305e-05\n",
      "Epoch [56400/100000], Loss: 29.91,   LOSS_function: 29.84,   LOSS_E:0.007162,    LOSS_initial: 3.644e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3592.832488298416\n",
      "loss_compared with real:1.1837e-05,   miu_train:0.07189,    lossmean:3.927e-05\n",
      "Epoch [56500/100000], Loss: 29.73,   LOSS_function: 29.4,   LOSS_E:0.007022,    LOSS_initial: 1.649e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3599.4472513198853\n",
      "loss_compared with real:1.1695e-05,   miu_train:0.07217,    lossmean:9.968e-05\n",
      "Epoch [56600/100000], Loss: 29.8,   LOSS_function: 29.52,   LOSS_E:0.00714,    LOSS_initial: 1.397e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3606.3163492679596\n",
      "loss_compared with real:1.1408e-05,   miu_train:0.07223,    lossmean:0.0001422\n",
      "Epoch [56700/100000], Loss: 29.42,   LOSS_function: 29.38,   LOSS_E:0.006977,    LOSS_initial: 1.785e-06,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3613.083627462387\n",
      "loss_compared with real:1.1609e-05,   miu_train:0.07236,    lossmean:7.914e-05\n",
      "Epoch [56800/100000], Loss: 46.23,   LOSS_function: 39.36,   LOSS_E:0.006951,    LOSS_initial: 0.0003482,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3619.664896249771\n",
      "loss_compared with real:1.2547e-05,   miu_train:0.07235,    lossmean:-2.44e-05\n",
      "Epoch [56900/100000], Loss: 31.95,   LOSS_function: 31.18,   LOSS_E:0.00713,    LOSS_initial: 3.93e-05,\n",
      "lamda1:1,    lamda3:1.971e+04,      learn rate:5.09e-05,    time: 3626.206745862961\n",
      "loss_compared with real:1.1971e-05,   miu_train:0.07249,    lossmean:8.7e-05\n",
      "Epoch [57000/100000], Loss: 32.41,   LOSS_function: 30.7,   LOSS_E:0.007009,    LOSS_initial: 8.825e-05,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3632.828315973282\n",
      "loss_compared with real:1.1305e-05,   miu_train:0.07273,    lossmean:9.705e-05\n",
      "Epoch [57100/100000], Loss: 28.99,   LOSS_function: 28.92,   LOSS_E:0.006931,    LOSS_initial: 3.756e-06,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3639.4654133319855\n",
      "loss_compared with real:1.1416e-05,   miu_train:0.07306,    lossmean:8.968e-05\n",
      "Epoch [57200/100000], Loss: 37.19,   LOSS_function: 31.68,   LOSS_E:0.006835,    LOSS_initial: 0.0002851,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3646.054127931595\n",
      "loss_compared with real:1.2013e-05,   miu_train:0.07338,    lossmean:2.747e-06\n",
      "Epoch [57300/100000], Loss: 32.86,   LOSS_function: 29.92,   LOSS_E:0.006818,    LOSS_initial: 0.000152,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3652.6764488220215\n",
      "loss_compared with real:1.1477e-05,   miu_train:0.07318,    lossmean:4.979e-05\n",
      "Epoch [57400/100000], Loss: 29.29,   LOSS_function: 29.05,   LOSS_E:0.006888,    LOSS_initial: 1.219e-05,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3659.519121646881\n",
      "loss_compared with real:1.165e-05,   miu_train:0.07342,    lossmean:7.889e-05\n",
      "Epoch [57500/100000], Loss: 28.76,   LOSS_function: 28.69,   LOSS_E:0.006885,    LOSS_initial: 3.709e-06,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3666.1065015792847\n",
      "loss_compared with real:1.1342e-05,   miu_train:0.07358,    lossmean:7.893e-05\n",
      "Epoch [57600/100000], Loss: 31.05,   LOSS_function: 29.66,   LOSS_E:0.007009,    LOSS_initial: 7.187e-05,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3672.7163722515106\n",
      "loss_compared with real:1.1804e-05,   miu_train:0.07367,    lossmean:-1.847e-05\n",
      "Epoch [57700/100000], Loss: 29.24,   LOSS_function: 28.63,   LOSS_E:0.007222,    LOSS_initial: 3.169e-05,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3679.3489911556244\n",
      "loss_compared with real:1.1546e-05,   miu_train:0.07397,    lossmean:3.989e-05\n",
      "Epoch [57800/100000], Loss: 32.82,   LOSS_function: 30.51,   LOSS_E:0.006728,    LOSS_initial: 0.0001193,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3685.9545619487762\n",
      "loss_compared with real:1.1079e-05,   miu_train:0.0739,    lossmean:0.0001494\n",
      "Epoch [57900/100000], Loss: 30.04,   LOSS_function: 28.4,   LOSS_E:0.006852,    LOSS_initial: 8.466e-05,\n",
      "lamda1:1,    lamda3:1.934e+04,      learn rate:4.846e-05,    time: 3692.5479929447174\n",
      "loss_compared with real:1.1266e-05,   miu_train:0.07395,    lossmean:4.35e-05\n",
      "Epoch [58000/100000], Loss: 29.46,   LOSS_function: 29.08,   LOSS_E:0.00683,    LOSS_initial: 2.41e-05,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3699.2435953617096\n",
      "loss_compared with real:1.1715e-05,   miu_train:0.07419,    lossmean:-2.305e-05\n",
      "Epoch [58100/100000], Loss: 28.22,   LOSS_function: 28.14,   LOSS_E:0.006834,    LOSS_initial: 5.484e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3705.816679954529\n",
      "loss_compared with real:1.1677e-05,   miu_train:0.07451,    lossmean:3.631e-05\n",
      "Epoch [58200/100000], Loss: 29.73,   LOSS_function: 29.54,   LOSS_E:0.006764,    LOSS_initial: 1.165e-05,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3712.4173851013184\n",
      "loss_compared with real:1.1649e-05,   miu_train:0.07458,    lossmean:5.382e-05\n",
      "Epoch [58300/100000], Loss: 69.18,   LOSS_function: 68.85,   LOSS_E:0.007122,    LOSS_initial: 2.059e-05,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3719.3251123428345\n",
      "loss_compared with real:1.2087e-05,   miu_train:0.07482,    lossmean:3.28e-05\n",
      "Epoch [58400/100000], Loss: 27.98,   LOSS_function: 27.89,   LOSS_E:0.006822,    LOSS_initial: 5.611e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3725.9954268932343\n",
      "loss_compared with real:1.1591e-05,   miu_train:0.07486,    lossmean:4.109e-05\n",
      "Epoch [58500/100000], Loss: 28.18,   LOSS_function: 28.01,   LOSS_E:0.006873,    LOSS_initial: 1.046e-05,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3732.5752758979797\n",
      "loss_compared with real:1.1569e-05,   miu_train:0.07491,    lossmean:-6.88e-07\n",
      "Epoch [58600/100000], Loss: 70.02,   LOSS_function: 61.94,   LOSS_E:0.007415,    LOSS_initial: 0.0005124,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3739.165118455887\n",
      "loss_compared with real:1.353e-05,   miu_train:0.07526,    lossmean:-0.000281\n",
      "Epoch [58700/100000], Loss: 27.74,   LOSS_function: 27.65,   LOSS_E:0.006797,    LOSS_initial: 5.613e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3745.8140184879303\n",
      "loss_compared with real:1.1497e-05,   miu_train:0.07533,    lossmean:3.618e-05\n",
      "Epoch [58800/100000], Loss: 27.68,   LOSS_function: 27.53,   LOSS_E:0.006729,    LOSS_initial: 9.559e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3752.5347242355347\n",
      "loss_compared with real:1.1414e-05,   miu_train:0.07552,    lossmean:5.371e-05\n",
      "Epoch [58900/100000], Loss: 27.6,   LOSS_function: 27.52,   LOSS_E:0.006693,    LOSS_initial: 4.577e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.614e-05,    time: 3759.1857573986053\n",
      "loss_compared with real:1.1518e-05,   miu_train:0.07554,    lossmean:5.94e-05\n",
      "Epoch [59000/100000], Loss: 27.62,   LOSS_function: 27.57,   LOSS_E:0.0068,    LOSS_initial: 3.285e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3765.776234149933\n",
      "loss_compared with real:1.1434e-05,   miu_train:0.07565,    lossmean:4.019e-05\n",
      "Epoch [59100/100000], Loss: 27.41,   LOSS_function: 27.33,   LOSS_E:0.006744,    LOSS_initial: 5.363e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3772.202575445175\n",
      "loss_compared with real:1.1316e-05,   miu_train:0.07608,    lossmean:3.289e-05\n",
      "Epoch [59200/100000], Loss: 27.32,   LOSS_function: 27.25,   LOSS_E:0.006723,    LOSS_initial: 4.851e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3778.6231892108917\n",
      "loss_compared with real:1.1266e-05,   miu_train:0.07636,    lossmean:3.408e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59300/100000], Loss: 27.26,   LOSS_function: 27.12,   LOSS_E:0.006672,    LOSS_initial: 8.822e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3784.7413556575775\n",
      "loss_compared with real:1.1199e-05,   miu_train:0.07643,    lossmean:4.811e-05\n",
      "Epoch [59400/100000], Loss: 27.17,   LOSS_function: 27.09,   LOSS_E:0.006691,    LOSS_initial: 5.125e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3790.8883440494537\n",
      "loss_compared with real:1.1217e-05,   miu_train:0.07648,    lossmean:4.017e-05\n",
      "Epoch [59500/100000], Loss: 27.19,   LOSS_function: 27.07,   LOSS_E:0.006682,    LOSS_initial: 7.861e-06,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3796.997935771942\n",
      "loss_compared with real:1.1128e-05,   miu_train:0.0766,    lossmean:2.844e-05\n",
      "Epoch [59600/100000], Loss: 31.74,   LOSS_function: 29.99,   LOSS_E:0.006827,    LOSS_initial: 0.0001106,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3803.132956504822\n",
      "loss_compared with real:1.145e-05,   miu_train:0.077,    lossmean:-5.434e-05\n",
      "Epoch [59700/100000], Loss: 36.84,   LOSS_function: 33.15,   LOSS_E:0.006552,    LOSS_initial: 0.0002343,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3809.621243238449\n",
      "loss_compared with real:1.1247e-05,   miu_train:0.07703,    lossmean:6.674e-05\n",
      "Epoch [59800/100000], Loss: 28.98,   LOSS_function: 27.91,   LOSS_E:0.006609,    LOSS_initial: 6.802e-05,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3815.786446094513\n",
      "loss_compared with real:1.1292e-05,   miu_train:0.07715,    lossmean:0.0001213\n",
      "Epoch [59900/100000], Loss: 34.74,   LOSS_function: 27.57,   LOSS_E:0.006826,    LOSS_initial: 0.0004553,\n",
      "lamda1:1,    lamda3:1.575e+04,      learn rate:4.392e-05,    time: 3821.8993928432465\n",
      "loss_compared with real:9.9237e-06,   miu_train:0.0775,    lossmean:0.0001697\n",
      "Epoch [60000/100000], Loss: 26.78,   LOSS_function: 26.56,   LOSS_E:0.006587,    LOSS_initial: 2.438e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3828.0823125839233\n",
      "loss_compared with real:1.1022e-05,   miu_train:0.07761,    lossmean:4.071e-06\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5209, -0.5059, -0.2889, -0.9670, -0.0645, -0.3191,  0.4299, -0.8258,\n",
      "         0.8659,  0.3139,  0.7666,  0.5144,  0.5932, -0.0304,  0.6967, -0.3220,\n",
      "         0.8296,  0.0231,  0.7913, -0.8027, -0.2655, -0.9688, -0.4829, -0.3205,\n",
      "        -0.2984, -0.3497,  0.6960, -0.6253, -0.2322,  0.4141, -0.3067, -0.1896,\n",
      "         0.1035,  0.6316, -0.6924, -0.7990, -0.7077, -0.5411, -0.2549, -0.0373,\n",
      "        -0.8235, -0.9702, -0.0508,  0.8011, -0.5773,  0.8644, -0.6891,  0.9032,\n",
      "         0.6190, -0.9112, -0.7518, -0.3411,  0.8458, -0.6028,  0.9211, -0.1108,\n",
      "        -0.8969,  0.4118, -0.2540, -0.8648,  0.8318, -0.3147,  0.2533, -0.1143,\n",
      "        -0.5067, -0.0813, -0.0238,  0.4044, -0.4059, -0.3427,  0.5314, -0.4197,\n",
      "        -0.4828,  0.8819,  0.7991, -0.4214, -0.4407,  0.0215, -0.3104, -0.5239,\n",
      "        -0.7534, -0.6532,  0.9150,  0.0173,  0.1159,  0.7531,  0.6709,  0.2241,\n",
      "        -0.0341, -0.0854,  0.6273,  0.7121, -0.6025,  0.9424,  0.2194,  0.5759,\n",
      "        -0.6436, -0.1338,  0.5834,  0.0288, -0.8527,  0.0765, -0.0112, -0.1968,\n",
      "         0.4045,  0.4939,  0.6592,  0.0573,  0.2391,  0.6249, -0.6240, -0.2590,\n",
      "         0.5795,  0.7721,  0.7171,  0.0094, -0.9608,  0.8765, -0.2918, -0.8855,\n",
      "        -0.9647,  0.8996, -0.2294,  0.3606, -0.2265,  0.4236, -0.2018,  0.1835],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2949, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0226, -0.0330,  0.0243,  0.0669, -0.0386, -0.0374, -0.0316,  0.0332,\n",
      "        -0.0312,  0.0436, -0.0118, -0.0998,  0.0482, -0.0389,  0.0727,  0.0268,\n",
      "        -0.0446, -0.0216, -0.0117,  0.0355, -0.0685,  0.0625,  0.0352,  0.0177,\n",
      "         0.0120, -0.0128,  0.0641, -0.0438, -0.0363, -0.0782,  0.0293, -0.0648,\n",
      "         0.0846, -0.0436,  0.0609,  0.0015, -0.0709,  0.0560,  0.0359, -0.0588,\n",
      "        -0.0941, -0.0739,  0.0105,  0.0751,  0.0617,  0.0778, -0.0332,  0.0842,\n",
      "        -0.0301,  0.0048,  0.0403,  0.0157, -0.0267,  0.0153,  0.0047, -0.0065,\n",
      "         0.0604,  0.0300,  0.0348,  0.0335,  0.0062, -0.0169, -0.0240,  0.0530,\n",
      "         0.0594,  0.0039,  0.0725,  0.0131,  0.0350,  0.0238,  0.0482,  0.0065,\n",
      "        -0.0305,  0.0071, -0.0781,  0.0031, -0.0344,  0.0831, -0.0027,  0.0121,\n",
      "         0.0358, -0.0327, -0.0152,  0.0457,  0.0215, -0.0924, -0.0235, -0.0003,\n",
      "         0.0837,  0.0780,  0.0445,  0.0514, -0.0500, -0.0673,  0.0662, -0.0689,\n",
      "         0.0281,  0.0399,  0.0314,  0.0862,  0.0784,  0.0449,  0.0496,  0.0849,\n",
      "         0.0714, -0.0077, -0.0699, -0.0770,  0.0206, -0.0391,  0.0402,  0.0332,\n",
      "        -0.0161, -0.0450, -0.0032,  0.0231,  0.0315, -0.0729, -0.1065,  0.0315,\n",
      "         0.0702,  0.0169,  0.0257, -0.0193,  0.0147,  0.0175, -0.0626,  0.0643],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2662, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0751, -0.0478, -0.0370,  0.0261, -0.0629, -0.0254, -0.0502, -0.0090,\n",
      "        -0.0264,  0.0493,  0.0117, -0.0261, -0.0308, -0.0131, -0.0287, -0.0840,\n",
      "        -0.0448,  0.0437,  0.0328, -0.1185,  0.0194, -0.0282, -0.0439, -0.0077,\n",
      "         0.0403,  0.0112,  0.0579,  0.0113, -0.0912, -0.0737, -0.0248,  0.0236,\n",
      "         0.0196, -0.0247,  0.0618,  0.0831,  0.1015,  0.0179,  0.0346,  0.1042,\n",
      "        -0.0388,  0.0260,  0.0002, -0.0550,  0.0597,  0.0378, -0.0803, -0.0858,\n",
      "         0.0151, -0.0228, -0.0643,  0.0627,  0.0398, -0.0748,  0.0420,  0.0432,\n",
      "         0.0147, -0.0872,  0.0078, -0.0747,  0.0245,  0.0494, -0.0259,  0.0390,\n",
      "         0.0770, -0.0068,  0.0247, -0.0052,  0.0381,  0.0259, -0.0870, -0.0365,\n",
      "        -0.0156,  0.0452, -0.0030,  0.0670,  0.0850,  0.0045,  0.0005, -0.0167,\n",
      "         0.1259,  0.0133, -0.0602,  0.0974, -0.0172, -0.0141,  0.0142,  0.0686,\n",
      "        -0.0049, -0.0911,  0.0498, -0.0777,  0.0073, -0.0570, -0.0577,  0.0583,\n",
      "        -0.0572, -0.0901, -0.0857,  0.0715, -0.0701,  0.0214,  0.0234,  0.0366,\n",
      "        -0.0354, -0.0661,  0.0512, -0.0781, -0.1043, -0.0573, -0.0533,  0.0071,\n",
      "         0.0549, -0.0480, -0.0532, -0.0256, -0.0198, -0.0219,  0.0950,  0.0156,\n",
      "        -0.0356,  0.0235,  0.0818,  0.0940, -0.0386, -0.0853,  0.0046, -0.0707],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1017, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0666, -0.0429,  0.0094,  0.1150, -0.0972,  0.0489, -0.0320, -0.0305,\n",
      "         0.0586,  0.0047,  0.0428,  0.0575,  0.0591, -0.1271, -0.0673,  0.0322,\n",
      "        -0.0212, -0.0112, -0.0279, -0.0246, -0.0196,  0.0369,  0.0946,  0.0608,\n",
      "         0.0435, -0.0538, -0.0096, -0.0271, -0.0357,  0.0490,  0.0036,  0.0506,\n",
      "         0.0180,  0.0078, -0.0592,  0.0745, -0.0353, -0.1186, -0.0861,  0.0282,\n",
      "         0.0607, -0.0901,  0.0555,  0.0524,  0.0517, -0.0790,  0.0781, -0.0019,\n",
      "        -0.1180, -0.0862, -0.0381, -0.0801, -0.0450,  0.0627,  0.0227,  0.0339,\n",
      "        -0.0264, -0.0667,  0.0545,  0.0195,  0.0252, -0.0510, -0.0385, -0.0247,\n",
      "         0.0323, -0.0991, -0.0862, -0.0846,  0.0426, -0.0552, -0.0772, -0.0540,\n",
      "        -0.0178, -0.0171, -0.0698, -0.0043, -0.0173, -0.0754,  0.0547, -0.0186,\n",
      "        -0.0855,  0.0508, -0.0237,  0.0705,  0.0347, -0.1183, -0.0133, -0.0633,\n",
      "        -0.0182,  0.0189, -0.0813, -0.0857,  0.0849,  0.0742, -0.0012,  0.0594,\n",
      "        -0.0955, -0.0628,  0.0678, -0.0525, -0.0488,  0.0093, -0.0444, -0.0267,\n",
      "         0.0433,  0.0725,  0.0416, -0.0951,  0.0417, -0.1004,  0.0556,  0.0653,\n",
      "        -0.0352, -0.0277,  0.0875, -0.0126, -0.0836,  0.0100, -0.0246,  0.0632,\n",
      "         0.0852, -0.0367,  0.1051, -0.0883, -0.0584,  0.0299,  0.0051,  0.0617],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0680, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0128, 0.0267, 0.0789], requires_grad=True)\n",
      "Epoch [60100/100000], Loss: 26.52,   LOSS_function: 26.38,   LOSS_E:0.006611,    LOSS_initial: 1.456e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3834.386533021927\n",
      "loss_compared with real:1.411e-05,   miu_train:0.07782,    lossmean:-0.0001559\n",
      "Epoch [60200/100000], Loss: 26.45,   LOSS_function: 26.32,   LOSS_E:0.006557,    LOSS_initial: 1.43e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3840.54154253006\n",
      "loss_compared with real:1.4015e-05,   miu_train:0.07787,    lossmean:-0.0001411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60300/100000], Loss: 26.38,   LOSS_function: 26.24,   LOSS_E:0.006594,    LOSS_initial: 1.428e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3846.691369533539\n",
      "loss_compared with real:1.4074e-05,   miu_train:0.07792,    lossmean:-0.0001354\n",
      "Epoch [60400/100000], Loss: 26.26,   LOSS_function: 26.12,   LOSS_E:0.006569,    LOSS_initial: 1.502e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3852.808680295944\n",
      "loss_compared with real:1.3995e-05,   miu_train:0.07832,    lossmean:-0.0001514\n",
      "Epoch [60500/100000], Loss: 26.18,   LOSS_function: 26.04,   LOSS_E:0.006586,    LOSS_initial: 1.476e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3858.845897912979\n",
      "loss_compared with real:1.3997e-05,   miu_train:0.07836,    lossmean:-0.0001445\n",
      "Epoch [60600/100000], Loss: 26.09,   LOSS_function: 25.95,   LOSS_E:0.00659,    LOSS_initial: 1.487e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3865.02356505394\n",
      "loss_compared with real:1.4033e-05,   miu_train:0.07838,    lossmean:-0.0001492\n",
      "Epoch [60700/100000], Loss: 26.69,   LOSS_function: 26.46,   LOSS_E:0.006509,    LOSS_initial: 2.521e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3871.1900062561035\n",
      "loss_compared with real:1.3948e-05,   miu_train:0.07884,    lossmean:-0.0001364\n",
      "Epoch [60800/100000], Loss: 27.98,   LOSS_function: 27.89,   LOSS_E:0.006589,    LOSS_initial: 1.022e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3877.485834121704\n",
      "loss_compared with real:1.444e-05,   miu_train:0.07874,    lossmean:-6.692e-05\n",
      "Epoch [60900/100000], Loss: 25.81,   LOSS_function: 25.67,   LOSS_E:0.006539,    LOSS_initial: 1.453e-05,\n",
      "lamda1:1,    lamda3:9157,      learn rate:4.181e-05,    time: 3883.5895750522614\n",
      "loss_compared with real:1.3754e-05,   miu_train:0.07912,    lossmean:-0.0001512\n",
      "Epoch [61000/100000], Loss: 25.93,   LOSS_function: 25.69,   LOSS_E:0.006463,    LOSS_initial: 1.616e-05,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3889.792047739029\n",
      "loss_compared with real:1.2793e-05,   miu_train:0.07922,    lossmean:-1.92e-05\n",
      "Epoch [61100/100000], Loss: 25.99,   LOSS_function: 25.92,   LOSS_E:0.006609,    LOSS_initial: 4.425e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3896.2210717201233\n",
      "loss_compared with real:1.1361e-05,   miu_train:0.07854,    lossmean:4.403e-05\n",
      "Epoch [61200/100000], Loss: 25.79,   LOSS_function: 25.7,   LOSS_E:0.006636,    LOSS_initial: 5.603e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3902.48384642601\n",
      "loss_compared with real:1.0874e-05,   miu_train:0.07934,    lossmean:5.855e-07\n",
      "Epoch [61300/100000], Loss: 25.69,   LOSS_function: 25.61,   LOSS_E:0.006586,    LOSS_initial: 5.361e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3909.053234577179\n",
      "loss_compared with real:1.0653e-05,   miu_train:0.0798,    lossmean:1.508e-06\n",
      "Epoch [61400/100000], Loss: 25.6,   LOSS_function: 25.52,   LOSS_E:0.006541,    LOSS_initial: 5.215e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3915.725548028946\n",
      "loss_compared with real:1.0531e-05,   miu_train:0.08014,    lossmean:9.897e-06\n",
      "Epoch [61500/100000], Loss: 25.51,   LOSS_function: 25.43,   LOSS_E:0.006506,    LOSS_initial: 5.156e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3922.3362724781036\n",
      "loss_compared with real:1.0453e-05,   miu_train:0.08043,    lossmean:1.653e-05\n",
      "Epoch [61600/100000], Loss: 25.54,   LOSS_function: 25.46,   LOSS_E:0.006618,    LOSS_initial: 5.091e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3928.991333961487\n",
      "loss_compared with real:1.0665e-05,   miu_train:0.08049,    lossmean:-4.81e-05\n",
      "Epoch [61700/100000], Loss: 25.35,   LOSS_function: 25.27,   LOSS_E:0.006463,    LOSS_initial: 5.2e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3935.616985321045\n",
      "loss_compared with real:1.0357e-05,   miu_train:0.08081,    lossmean:2.473e-05\n",
      "Epoch [61800/100000], Loss: 25.3,   LOSS_function: 25.23,   LOSS_E:0.00644,    LOSS_initial: 4.564e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3942.440545797348\n",
      "loss_compared with real:1.0383e-05,   miu_train:0.08085,    lossmean:2.159e-05\n",
      "Epoch [61900/100000], Loss: 25.35,   LOSS_function: 25.27,   LOSS_E:0.00648,    LOSS_initial: 5.324e-06,\n",
      "lamda1:1,    lamda3:1.516e+04,      learn rate:3.981e-05,    time: 3948.9991664886475\n",
      "loss_compared with real:1.0338e-05,   miu_train:0.08104,    lossmean:1.562e-05\n",
      "Epoch [62000/100000], Loss: 45.63,   LOSS_function: 40.43,   LOSS_E:0.006613,    LOSS_initial: 0.0001178,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3956.086194753647\n",
      "loss_compared with real:1.8057e-05,   miu_train:0.08116,    lossmean:-0.0009612\n",
      "Epoch [62100/100000], Loss: 31.2,   LOSS_function: 31.11,   LOSS_E:0.01183,    LOSS_initial: 2.204e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3962.670773267746\n",
      "loss_compared with real:1.993e-05,   miu_train:0.07691,    lossmean:-0.000434\n",
      "Epoch [62200/100000], Loss: 27.64,   LOSS_function: 27.57,   LOSS_E:0.007337,    LOSS_initial: 1.683e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3969.31799864769\n",
      "loss_compared with real:1.0484e-05,   miu_train:0.0779,    lossmean:0.0001354\n",
      "Epoch [62300/100000], Loss: 26.54,   LOSS_function: 26.48,   LOSS_E:0.006753,    LOSS_initial: 1.205e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3975.9270145893097\n",
      "loss_compared with real:9.5055e-06,   miu_train:0.07879,    lossmean:0.0002227\n",
      "Epoch [62400/100000], Loss: 26.04,   LOSS_function: 26,   LOSS_E:0.006509,    LOSS_initial: 9.749e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3982.5834124088287\n",
      "loss_compared with real:9.145e-06,   miu_train:0.0794,    lossmean:0.0002522\n",
      "Epoch [62500/100000], Loss: 25.78,   LOSS_function: 25.74,   LOSS_E:0.006414,    LOSS_initial: 8.377e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3989.1489129066467\n",
      "loss_compared with real:8.9726e-06,   miu_train:0.07984,    lossmean:0.0002567\n",
      "Epoch [62600/100000], Loss: 25.63,   LOSS_function: 25.6,   LOSS_E:0.006387,    LOSS_initial: 7.584e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 3995.8294270038605\n",
      "loss_compared with real:8.8758e-06,   miu_train:0.08017,    lossmean:0.0002513\n",
      "Epoch [62700/100000], Loss: 25.53,   LOSS_function: 25.5,   LOSS_E:0.00638,    LOSS_initial: 7.074e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 4002.4475903511047\n",
      "loss_compared with real:8.8114e-06,   miu_train:0.08045,    lossmean:0.0002445\n",
      "Epoch [62800/100000], Loss: 25.46,   LOSS_function: 25.43,   LOSS_E:0.006378,    LOSS_initial: 6.84e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 4009.19487118721\n",
      "loss_compared with real:8.7647e-06,   miu_train:0.08069,    lossmean:0.0002394\n",
      "Epoch [62900/100000], Loss: 25.4,   LOSS_function: 25.37,   LOSS_E:0.006377,    LOSS_initial: 6.541e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.789e-05,    time: 4016.14058303833\n",
      "loss_compared with real:8.7303e-06,   miu_train:0.0809,    lossmean:0.0002347\n",
      "Epoch [63000/100000], Loss: 25.34,   LOSS_function: 25.31,   LOSS_E:0.006377,    LOSS_initial: 6.432e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4022.7499051094055\n",
      "loss_compared with real:8.703e-06,   miu_train:0.08109,    lossmean:0.000232\n",
      "Epoch [63100/100000], Loss: 25.29,   LOSS_function: 25.26,   LOSS_E:0.006374,    LOSS_initial: 6.213e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4029.272518157959\n",
      "loss_compared with real:8.6809e-06,   miu_train:0.08126,    lossmean:0.0002298\n",
      "Epoch [63200/100000], Loss: 25.24,   LOSS_function: 25.22,   LOSS_E:0.006368,    LOSS_initial: 6.344e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4035.8331813812256\n",
      "loss_compared with real:8.6608e-06,   miu_train:0.08142,    lossmean:0.000229\n",
      "Epoch [63300/100000], Loss: 25.2,   LOSS_function: 25.17,   LOSS_E:0.006364,    LOSS_initial: 5.929e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4042.371758699417\n",
      "loss_compared with real:8.6412e-06,   miu_train:0.08158,    lossmean:0.0002283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63400/100000], Loss: 25.25,   LOSS_function: 25.2,   LOSS_E:0.006447,    LOSS_initial: 1.097e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4048.981417655945\n",
      "loss_compared with real:8.623e-06,   miu_train:0.08172,    lossmean:0.0002148\n",
      "Epoch [63500/100000], Loss: 25.11,   LOSS_function: 25.08,   LOSS_E:0.006366,    LOSS_initial: 5.65e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4055.5799787044525\n",
      "loss_compared with real:8.6132e-06,   miu_train:0.08186,    lossmean:0.0002249\n",
      "Epoch [63600/100000], Loss: 25.08,   LOSS_function: 25.06,   LOSS_E:0.00643,    LOSS_initial: 4.064e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4062.2280197143555\n",
      "loss_compared with real:8.6277e-06,   miu_train:0.08194,    lossmean:0.0002187\n",
      "Epoch [63700/100000], Loss: 25.02,   LOSS_function: 24.99,   LOSS_E:0.006372,    LOSS_initial: 5.643e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4068.8639028072357\n",
      "loss_compared with real:8.5872e-06,   miu_train:0.08213,    lossmean:0.0002217\n",
      "Epoch [63800/100000], Loss: 26.47,   LOSS_function: 25.36,   LOSS_E:0.006458,    LOSS_initial: 2.52e-05,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4075.5247089862823\n",
      "loss_compared with real:8.5517e-06,   miu_train:0.08227,    lossmean:0.0001909\n",
      "Epoch [63900/100000], Loss: 24.92,   LOSS_function: 24.9,   LOSS_E:0.006365,    LOSS_initial: 5.77e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.608e-05,    time: 4081.6794810295105\n",
      "loss_compared with real:8.5486e-06,   miu_train:0.08242,    lossmean:0.0002197\n",
      "Epoch [64000/100000], Loss: 24.92,   LOSS_function: 24.82,   LOSS_E:0.00639,    LOSS_initial: 2.259e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4087.9116671085358\n",
      "loss_compared with real:8.5854e-06,   miu_train:0.08249,    lossmean:0.0002249\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5209, -0.5054, -0.2890, -0.9669, -0.0646, -0.3190,  0.4298, -0.8258,\n",
      "         0.8660,  0.3139,  0.7666,  0.5138,  0.5931, -0.0306,  0.6967, -0.3220,\n",
      "         0.8296,  0.0233,  0.7913, -0.8027, -0.2656, -0.9689, -0.4826, -0.3205,\n",
      "        -0.2983, -0.3497,  0.6961, -0.6255, -0.2322,  0.4139, -0.3067, -0.1892,\n",
      "         0.1036,  0.6317, -0.6924, -0.7993, -0.7079, -0.5406, -0.2547, -0.0373,\n",
      "        -0.8237, -0.9704, -0.0510,  0.8011, -0.5771,  0.8642, -0.6891,  0.9035,\n",
      "         0.6193, -0.9114, -0.7518, -0.3410,  0.8458, -0.6036,  0.9210, -0.1110,\n",
      "        -0.8971,  0.4117, -0.2541, -0.8650,  0.8320, -0.3145,  0.2534, -0.1142,\n",
      "        -0.5065, -0.0811, -0.0241,  0.4040, -0.4059, -0.3427,  0.5314, -0.4197,\n",
      "        -0.4821,  0.8822,  0.7994, -0.4214, -0.4403,  0.0211, -0.3104, -0.5240,\n",
      "        -0.7533, -0.6532,  0.9151,  0.0170,  0.1157,  0.7530,  0.6711,  0.2242,\n",
      "        -0.0338, -0.0851,  0.6271,  0.7120, -0.6025,  0.9423,  0.2190,  0.5758,\n",
      "        -0.6435, -0.1337,  0.5835,  0.0285, -0.8527,  0.0766, -0.0108, -0.1968,\n",
      "         0.4042,  0.4937,  0.6592,  0.0569,  0.2390,  0.6251, -0.6236, -0.2590,\n",
      "         0.5794,  0.7721,  0.7170,  0.0090, -0.9611,  0.8764, -0.2919, -0.8858,\n",
      "        -0.9646,  0.8997, -0.2291,  0.3606, -0.2265,  0.4235, -0.2018,  0.1833],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2949, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0226, -0.0329,  0.0247,  0.0670, -0.0386, -0.0375, -0.0316,  0.0336,\n",
      "        -0.0314,  0.0438, -0.0122, -0.0999,  0.0482, -0.0391,  0.0729,  0.0268,\n",
      "        -0.0445, -0.0214, -0.0117,  0.0354, -0.0684,  0.0627,  0.0352,  0.0182,\n",
      "         0.0121, -0.0130,  0.0642, -0.0439, -0.0364, -0.0780,  0.0290, -0.0646,\n",
      "         0.0844, -0.0436,  0.0609,  0.0018, -0.0708,  0.0560,  0.0360, -0.0591,\n",
      "        -0.0941, -0.0735,  0.0106,  0.0752,  0.0615,  0.0779, -0.0332,  0.0842,\n",
      "        -0.0300,  0.0049,  0.0403,  0.0158, -0.0268,  0.0151,  0.0045, -0.0067,\n",
      "         0.0605,  0.0300,  0.0348,  0.0335,  0.0062, -0.0167, -0.0237,  0.0529,\n",
      "         0.0596,  0.0038,  0.0725,  0.0131,  0.0350,  0.0240,  0.0481,  0.0065,\n",
      "        -0.0309,  0.0067, -0.0778,  0.0031, -0.0347,  0.0828, -0.0028,  0.0122,\n",
      "         0.0357, -0.0326, -0.0152,  0.0456,  0.0215, -0.0922, -0.0235, -0.0004,\n",
      "         0.0835,  0.0782,  0.0446,  0.0516, -0.0498, -0.0673,  0.0662, -0.0690,\n",
      "         0.0288,  0.0399,  0.0315,  0.0863,  0.0784,  0.0448,  0.0496,  0.0848,\n",
      "         0.0711, -0.0078, -0.0698, -0.0775,  0.0208, -0.0391,  0.0403,  0.0332,\n",
      "        -0.0163, -0.0449, -0.0031,  0.0229,  0.0313, -0.0721, -0.1067,  0.0315,\n",
      "         0.0705,  0.0170,  0.0260, -0.0193,  0.0147,  0.0174, -0.0628,  0.0645],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2667, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0752, -0.0479, -0.0371,  0.0253, -0.0629, -0.0255, -0.0509, -0.0092,\n",
      "        -0.0264,  0.0493,  0.0120, -0.0260, -0.0309, -0.0132, -0.0286, -0.0844,\n",
      "        -0.0447,  0.0437,  0.0327, -0.1181,  0.0193, -0.0284, -0.0440, -0.0078,\n",
      "         0.0402,  0.0111,  0.0577,  0.0112, -0.0911, -0.0737, -0.0248,  0.0235,\n",
      "         0.0198, -0.0243,  0.0618,  0.0833,  0.1015,  0.0178,  0.0350,  0.1041,\n",
      "        -0.0384,  0.0256,  0.0005, -0.0557,  0.0596,  0.0380, -0.0805, -0.0855,\n",
      "         0.0152, -0.0230, -0.0645,  0.0628,  0.0398, -0.0747,  0.0422,  0.0434,\n",
      "         0.0145, -0.0875,  0.0075, -0.0745,  0.0246,  0.0493, -0.0258,  0.0386,\n",
      "         0.0770, -0.0070,  0.0247, -0.0051,  0.0382,  0.0256, -0.0872, -0.0366,\n",
      "        -0.0156,  0.0453, -0.0029,  0.0668,  0.0849,  0.0044,  0.0007, -0.0168,\n",
      "         0.1258,  0.0132, -0.0603,  0.0973, -0.0173, -0.0143,  0.0143,  0.0687,\n",
      "        -0.0049, -0.0913,  0.0498, -0.0777,  0.0075, -0.0572, -0.0574,  0.0587,\n",
      "        -0.0570, -0.0899, -0.0855,  0.0715, -0.0700,  0.0214,  0.0231,  0.0367,\n",
      "        -0.0355, -0.0660,  0.0510, -0.0783, -0.1039, -0.0573, -0.0536,  0.0072,\n",
      "         0.0550, -0.0479, -0.0530, -0.0256, -0.0197, -0.0222,  0.0953,  0.0158,\n",
      "        -0.0357,  0.0237,  0.0817,  0.0938, -0.0385, -0.0855,  0.0046, -0.0706],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1019, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0667, -0.0428,  0.0096,  0.1152, -0.0972,  0.0488, -0.0319, -0.0305,\n",
      "         0.0586,  0.0048,  0.0426,  0.0577,  0.0592, -0.1270, -0.0674,  0.0326,\n",
      "        -0.0213, -0.0114, -0.0281, -0.0246, -0.0196,  0.0370,  0.0944,  0.0607,\n",
      "         0.0430, -0.0537, -0.0095, -0.0269, -0.0358,  0.0491,  0.0038,  0.0505,\n",
      "         0.0181,  0.0076, -0.0592,  0.0745, -0.0351, -0.1191, -0.0863,  0.0284,\n",
      "         0.0607, -0.0902,  0.0556,  0.0522,  0.0518, -0.0791,  0.0779, -0.0019,\n",
      "        -0.1180, -0.0861, -0.0386, -0.0801, -0.0449,  0.0627,  0.0228,  0.0339,\n",
      "        -0.0262, -0.0667,  0.0539,  0.0197,  0.0253, -0.0509, -0.0386, -0.0244,\n",
      "         0.0323, -0.0988, -0.0861, -0.0847,  0.0426, -0.0553, -0.0779, -0.0546,\n",
      "        -0.0180, -0.0172, -0.0699, -0.0042, -0.0173, -0.0757,  0.0539, -0.0177,\n",
      "        -0.0855,  0.0508, -0.0241,  0.0704,  0.0346, -0.1187, -0.0139, -0.0633,\n",
      "        -0.0182,  0.0190, -0.0807, -0.0857,  0.0851,  0.0746, -0.0012,  0.0594,\n",
      "        -0.0954, -0.0625,  0.0677, -0.0525, -0.0485,  0.0093, -0.0444, -0.0267,\n",
      "         0.0433,  0.0725,  0.0416, -0.0952,  0.0418, -0.1005,  0.0556,  0.0652,\n",
      "        -0.0353, -0.0275,  0.0874, -0.0125, -0.0836,  0.0097, -0.0245,  0.0631,\n",
      "         0.0852, -0.0365,  0.1058, -0.0884, -0.0587,  0.0300,  0.0051,  0.0616],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0681, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0132, 0.0269, 0.0799], requires_grad=True)\n",
      "Epoch [64100/100000], Loss: 24.83,   LOSS_function: 24.8,   LOSS_E:0.006357,    LOSS_initial: 6.137e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4093.9450073242188\n",
      "loss_compared with real:8.5051e-06,   miu_train:0.08272,    lossmean:0.0002171\n",
      "Epoch [64200/100000], Loss: 24.8,   LOSS_function: 24.72,   LOSS_E:0.006346,    LOSS_initial: 1.917e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4100.089133501053\n",
      "loss_compared with real:8.4977e-06,   miu_train:0.08288,    lossmean:0.000218\n",
      "Epoch [64300/100000], Loss: 25,   LOSS_function: 24.82,   LOSS_E:0.006359,    LOSS_initial: 3.885e-06,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4106.190057754517\n",
      "loss_compared with real:8.4594e-06,   miu_train:0.08298,    lossmean:0.0002115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64400/100000], Loss: 24.72,   LOSS_function: 24.68,   LOSS_E:0.006469,    LOSS_initial: 8.13e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4112.673857688904\n",
      "loss_compared with real:8.5425e-06,   miu_train:0.08316,    lossmean:0.0002073\n",
      "Epoch [64500/100000], Loss: 28.88,   LOSS_function: 24.9,   LOSS_E:0.006139,    LOSS_initial: 9.03e-05,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4118.860420227051\n",
      "loss_compared with real:8.4372e-06,   miu_train:0.08319,    lossmean:0.0002678\n",
      "Epoch [64600/100000], Loss: 24.58,   LOSS_function: 24.55,   LOSS_E:0.006305,    LOSS_initial: 6.408e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4125.076505422592\n",
      "loss_compared with real:8.3933e-06,   miu_train:0.08346,    lossmean:0.0002181\n",
      "Epoch [64700/100000], Loss: 26.53,   LOSS_function: 25.15,   LOSS_E:0.006427,    LOSS_initial: 3.139e-05,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4131.162314891815\n",
      "loss_compared with real:8.4105e-06,   miu_train:0.08352,    lossmean:0.0002328\n",
      "Epoch [64800/100000], Loss: 28.24,   LOSS_function: 24.78,   LOSS_E:0.006232,    LOSS_initial: 7.834e-05,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4137.679876089096\n",
      "loss_compared with real:8.3769e-06,   miu_train:0.08385,    lossmean:0.0002088\n",
      "Epoch [64900/100000], Loss: 24.43,   LOSS_function: 24.39,   LOSS_E:0.006284,    LOSS_initial: 8.215e-07,\n",
      "lamda1:1,    lamda3:4.413e+04,      learn rate:3.434e-05,    time: 4143.8287580013275\n",
      "loss_compared with real:8.3246e-06,   miu_train:0.08392,    lossmean:0.000216\n",
      "Epoch [65000/100000], Loss: 33.05,   LOSS_function: 27.84,   LOSS_E:0.006431,    LOSS_initial: 0.0003228,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4150.0018265247345\n",
      "loss_compared with real:8.6723e-06,   miu_train:0.08395,    lossmean:0.0001992\n",
      "Epoch [65100/100000], Loss: 24.26,   LOSS_function: 24.2,   LOSS_E:0.006252,    LOSS_initial: 3.857e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4156.11563372612\n",
      "loss_compared with real:9.4867e-06,   miu_train:0.08419,    lossmean:5.708e-05\n",
      "Epoch [65200/100000], Loss: 24.2,   LOSS_function: 24.13,   LOSS_E:0.006238,    LOSS_initial: 4.087e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4162.23094701767\n",
      "loss_compared with real:9.4445e-06,   miu_train:0.08436,    lossmean:5.774e-05\n",
      "Epoch [65300/100000], Loss: 24.13,   LOSS_function: 24.07,   LOSS_E:0.006224,    LOSS_initial: 4.035e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4168.347988605499\n",
      "loss_compared with real:9.4067e-06,   miu_train:0.08454,    lossmean:5.918e-05\n",
      "Epoch [65400/100000], Loss: 24.06,   LOSS_function: 24,   LOSS_E:0.00621,    LOSS_initial: 4.016e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4174.535448312759\n",
      "loss_compared with real:9.3699e-06,   miu_train:0.08472,    lossmean:6.146e-05\n",
      "Epoch [65500/100000], Loss: 24,   LOSS_function: 23.93,   LOSS_E:0.006196,    LOSS_initial: 3.954e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4180.657348155975\n",
      "loss_compared with real:9.3543e-06,   miu_train:0.08483,    lossmean:6.522e-05\n",
      "Epoch [65600/100000], Loss: 23.93,   LOSS_function: 23.86,   LOSS_E:0.006182,    LOSS_initial: 4.151e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4186.833397388458\n",
      "loss_compared with real:9.3067e-06,   miu_train:0.08503,    lossmean:6.691e-05\n",
      "Epoch [65700/100000], Loss: 23.86,   LOSS_function: 23.79,   LOSS_E:0.006165,    LOSS_initial: 4.198e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4192.9585518836975\n",
      "loss_compared with real:9.2895e-06,   miu_train:0.08516,    lossmean:6.856e-05\n",
      "Epoch [65800/100000], Loss: 23.79,   LOSS_function: 23.72,   LOSS_E:0.00616,    LOSS_initial: 3.805e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4199.455715179443\n",
      "loss_compared with real:9.2591e-06,   miu_train:0.08532,    lossmean:6.857e-05\n",
      "Epoch [65900/100000], Loss: 23.91,   LOSS_function: 23.86,   LOSS_E:0.006188,    LOSS_initial: 2.618e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.27e-05,    time: 4205.9125373363495\n",
      "loss_compared with real:9.3035e-06,   miu_train:0.08543,    lossmean:5.853e-05\n",
      "Epoch [66000/100000], Loss: 23.71,   LOSS_function: 23.65,   LOSS_E:0.006162,    LOSS_initial: 3.283e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4212.557629108429\n",
      "loss_compared with real:9.1981e-06,   miu_train:0.08563,    lossmean:7.024e-05\n",
      "Epoch [66100/100000], Loss: 23.56,   LOSS_function: 23.5,   LOSS_E:0.006131,    LOSS_initial: 3.919e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4219.143418550491\n",
      "loss_compared with real:9.1652e-06,   miu_train:0.08587,    lossmean:6.998e-05\n",
      "Epoch [66200/100000], Loss: 23.56,   LOSS_function: 23.51,   LOSS_E:0.006156,    LOSS_initial: 3.108e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4225.726601839066\n",
      "loss_compared with real:9.1786e-06,   miu_train:0.08596,    lossmean:6.84e-05\n",
      "Epoch [66300/100000], Loss: 29.19,   LOSS_function: 28.9,   LOSS_E:0.006204,    LOSS_initial: 1.794e-05,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4232.286949396133\n",
      "loss_compared with real:9.0787e-06,   miu_train:0.08624,    lossmean:8.793e-05\n",
      "Epoch [66400/100000], Loss: 23.43,   LOSS_function: 23.39,   LOSS_E:0.006108,    LOSS_initial: 2.612e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4238.992130756378\n",
      "loss_compared with real:9.1194e-06,   miu_train:0.08643,    lossmean:5.671e-05\n",
      "Epoch [66500/100000], Loss: 23.27,   LOSS_function: 23.21,   LOSS_E:0.006085,    LOSS_initial: 3.702e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4245.582114458084\n",
      "loss_compared with real:9.0551e-06,   miu_train:0.08655,    lossmean:7.081e-05\n",
      "Epoch [66600/100000], Loss: 23.29,   LOSS_function: 23.25,   LOSS_E:0.00611,    LOSS_initial: 2.798e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4252.245381832123\n",
      "loss_compared with real:8.9991e-06,   miu_train:0.08676,    lossmean:7.509e-05\n",
      "Epoch [66700/100000], Loss: 23.19,   LOSS_function: 23.14,   LOSS_E:0.006087,    LOSS_initial: 3.209e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4259.143288135529\n",
      "loss_compared with real:9.0521e-06,   miu_train:0.08689,    lossmean:5.709e-05\n",
      "Epoch [66800/100000], Loss: 30.5,   LOSS_function: 28.78,   LOSS_E:0.005929,    LOSS_initial: 0.0001064,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4265.795306682587\n",
      "loss_compared with real:9.1619e-06,   miu_train:0.08711,    lossmean:7.173e-05\n",
      "Epoch [66900/100000], Loss: 23.91,   LOSS_function: 23.88,   LOSS_E:0.006088,    LOSS_initial: 2.105e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:3.113e-05,    time: 4272.447158098221\n",
      "loss_compared with real:9.1432e-06,   miu_train:0.08725,    lossmean:2.709e-05\n",
      "Epoch [67000/100000], Loss: 22.9,   LOSS_function: 22.82,   LOSS_E:0.006031,    LOSS_initial: 4.939e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4279.131628274918\n",
      "loss_compared with real:8.8744e-06,   miu_train:0.08761,    lossmean:7.491e-05\n",
      "Epoch [67100/100000], Loss: 23.17,   LOSS_function: 23.13,   LOSS_E:0.006045,    LOSS_initial: 2.302e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4285.660336256027\n",
      "loss_compared with real:8.8353e-06,   miu_train:0.08795,    lossmean:4.865e-05\n",
      "Epoch [67200/100000], Loss: 36.05,   LOSS_function: 35.05,   LOSS_E:0.006028,    LOSS_initial: 6.182e-05,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4292.491269350052\n",
      "loss_compared with real:9.9342e-06,   miu_train:0.08809,    lossmean:-0.0001103\n",
      "Epoch [67300/100000], Loss: 22.66,   LOSS_function: 22.59,   LOSS_E:0.006009,    LOSS_initial: 3.747e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4299.184161663055\n",
      "loss_compared with real:8.7948e-06,   miu_train:0.08824,    lossmean:6.907e-05\n",
      "Epoch [67400/100000], Loss: 23.48,   LOSS_function: 23.31,   LOSS_E:0.006086,    LOSS_initial: 1.038e-05,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4305.83623456955\n",
      "loss_compared with real:8.7213e-06,   miu_train:0.08849,    lossmean:6.801e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67500/100000], Loss: 24.95,   LOSS_function: 24.71,   LOSS_E:0.006005,    LOSS_initial: 1.499e-05,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4312.4073877334595\n",
      "loss_compared with real:8.8678e-06,   miu_train:0.08861,    lossmean:2.946e-05\n",
      "Epoch [67600/100000], Loss: 22.42,   LOSS_function: 22.34,   LOSS_E:0.005963,    LOSS_initial: 4.871e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4319.328226566315\n",
      "loss_compared with real:8.6676e-06,   miu_train:0.08899,    lossmean:7.246e-05\n",
      "Epoch [67700/100000], Loss: 22.34,   LOSS_function: 22.29,   LOSS_E:0.005946,    LOSS_initial: 3.493e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4325.899908542633\n",
      "loss_compared with real:8.6501e-06,   miu_train:0.08921,    lossmean:7.468e-05\n",
      "Epoch [67800/100000], Loss: 22.38,   LOSS_function: 22.27,   LOSS_E:0.005956,    LOSS_initial: 6.301e-06,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4332.646188497543\n",
      "loss_compared with real:8.582e-06,   miu_train:0.08934,    lossmean:9.006e-05\n",
      "Epoch [67900/100000], Loss: 24.3,   LOSS_function: 22.41,   LOSS_E:0.005717,    LOSS_initial: 0.0001168,\n",
      "lamda1:1,    lamda3:1.614e+04,      learn rate:2.963e-05,    time: 4339.37201833725\n",
      "loss_compared with real:8.4852e-06,   miu_train:0.08964,    lossmean:8.762e-05\n",
      "Epoch [68000/100000], Loss: 23.58,   LOSS_function: 23.13,   LOSS_E:0.005976,    LOSS_initial: 2.122e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4346.076102018356\n",
      "loss_compared with real:8.3859e-06,   miu_train:0.09003,    lossmean:8.224e-05\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5209, -0.5049, -0.2891, -0.9668, -0.0646, -0.3189,  0.4297, -0.8258,\n",
      "         0.8662,  0.3138,  0.7667,  0.5129,  0.5927, -0.0307,  0.6967, -0.3220,\n",
      "         0.8297,  0.0233,  0.7912, -0.8025, -0.2661, -0.9688, -0.4824, -0.3206,\n",
      "        -0.2982, -0.3496,  0.6962, -0.6256, -0.2322,  0.4139, -0.3070, -0.1890,\n",
      "         0.1038,  0.6315, -0.6922, -0.7996, -0.7081, -0.5405, -0.2550, -0.0372,\n",
      "        -0.8239, -0.9712, -0.0511,  0.8011, -0.5764,  0.8642, -0.6892,  0.9037,\n",
      "         0.6196, -0.9114, -0.7514, -0.3408,  0.8459, -0.6038,  0.9209, -0.1110,\n",
      "        -0.8976,  0.4114, -0.2541, -0.8648,  0.8319, -0.3143,  0.2534, -0.1140,\n",
      "        -0.5067, -0.0810, -0.0242,  0.4036, -0.4063, -0.3427,  0.5315, -0.4196,\n",
      "        -0.4813,  0.8824,  0.7999, -0.4212, -0.4402,  0.0208, -0.3105, -0.5241,\n",
      "        -0.7530, -0.6531,  0.9151,  0.0167,  0.1155,  0.7529,  0.6708,  0.2242,\n",
      "        -0.0336, -0.0849,  0.6268,  0.7124, -0.6025,  0.9425,  0.2187,  0.5758,\n",
      "        -0.6433, -0.1335,  0.5833,  0.0283, -0.8526,  0.0764, -0.0106, -0.1967,\n",
      "         0.4042,  0.4933,  0.6592,  0.0566,  0.2390,  0.6254, -0.6232, -0.2589,\n",
      "         0.5795,  0.7721,  0.7167,  0.0087, -0.9612,  0.8764, -0.2920, -0.8861,\n",
      "        -0.9647,  0.8999, -0.2289,  0.3606, -0.2266,  0.4233, -0.2020,  0.1832],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2948, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0227, -0.0329,  0.0249,  0.0670, -0.0384, -0.0374, -0.0313,  0.0345,\n",
      "        -0.0316,  0.0439, -0.0125, -0.0999,  0.0481, -0.0389,  0.0730,  0.0268,\n",
      "        -0.0449, -0.0212, -0.0116,  0.0354, -0.0681,  0.0626,  0.0353,  0.0182,\n",
      "         0.0122, -0.0128,  0.0642, -0.0439, -0.0363, -0.0778,  0.0287, -0.0647,\n",
      "         0.0839, -0.0437,  0.0609,  0.0017, -0.0707,  0.0559,  0.0358, -0.0594,\n",
      "        -0.0941, -0.0734,  0.0107,  0.0753,  0.0614,  0.0779, -0.0330,  0.0841,\n",
      "        -0.0299,  0.0047,  0.0403,  0.0159, -0.0271,  0.0150,  0.0045, -0.0070,\n",
      "         0.0608,  0.0302,  0.0349,  0.0335,  0.0063, -0.0171, -0.0236,  0.0529,\n",
      "         0.0596,  0.0038,  0.0725,  0.0129,  0.0349,  0.0238,  0.0483,  0.0064,\n",
      "        -0.0310,  0.0065, -0.0780,  0.0030, -0.0347,  0.0828, -0.0029,  0.0122,\n",
      "         0.0355, -0.0326, -0.0151,  0.0459,  0.0216, -0.0922, -0.0234, -0.0005,\n",
      "         0.0833,  0.0784,  0.0446,  0.0517, -0.0500, -0.0672,  0.0662, -0.0693,\n",
      "         0.0287,  0.0402,  0.0311,  0.0863,  0.0784,  0.0450,  0.0490,  0.0846,\n",
      "         0.0711, -0.0081, -0.0697, -0.0778,  0.0212, -0.0391,  0.0401,  0.0332,\n",
      "        -0.0168, -0.0448, -0.0030,  0.0229,  0.0313, -0.0724, -0.1070,  0.0316,\n",
      "         0.0707,  0.0170,  0.0262, -0.0193,  0.0143,  0.0173, -0.0628,  0.0647],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2673, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0751, -0.0478, -0.0370,  0.0252, -0.0629, -0.0255, -0.0503, -0.0093,\n",
      "        -0.0263,  0.0492,  0.0120, -0.0257, -0.0313, -0.0133, -0.0287, -0.0849,\n",
      "        -0.0445,  0.0438,  0.0326, -0.1180,  0.0191, -0.0288, -0.0441, -0.0079,\n",
      "         0.0401,  0.0110,  0.0577,  0.0111, -0.0910, -0.0736, -0.0247,  0.0236,\n",
      "         0.0200, -0.0240,  0.0619,  0.0836,  0.1013,  0.0175,  0.0353,  0.1042,\n",
      "        -0.0382,  0.0254,  0.0006, -0.0559,  0.0595,  0.0378, -0.0806, -0.0853,\n",
      "         0.0151, -0.0230, -0.0646,  0.0629,  0.0399, -0.0746,  0.0424,  0.0436,\n",
      "         0.0142, -0.0876,  0.0074, -0.0745,  0.0247,  0.0493, -0.0256,  0.0385,\n",
      "         0.0768, -0.0071,  0.0246, -0.0051,  0.0384,  0.0255, -0.0873, -0.0365,\n",
      "        -0.0156,  0.0449, -0.0026,  0.0664,  0.0849,  0.0043,  0.0009, -0.0167,\n",
      "         0.1259,  0.0134, -0.0604,  0.0974, -0.0174, -0.0143,  0.0143,  0.0690,\n",
      "        -0.0048, -0.0917,  0.0497, -0.0777,  0.0076, -0.0572, -0.0571,  0.0588,\n",
      "        -0.0567, -0.0899, -0.0853,  0.0713, -0.0699,  0.0215,  0.0230,  0.0365,\n",
      "        -0.0354, -0.0660,  0.0510, -0.0786, -0.1039, -0.0574, -0.0539,  0.0071,\n",
      "         0.0550, -0.0480, -0.0529, -0.0253, -0.0196, -0.0224,  0.0956,  0.0159,\n",
      "        -0.0358,  0.0236,  0.0815,  0.0937, -0.0383, -0.0858,  0.0052, -0.0705],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1025, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0667, -0.0427,  0.0098,  0.1153, -0.0973,  0.0488, -0.0319, -0.0304,\n",
      "         0.0586,  0.0048,  0.0420,  0.0578,  0.0591, -0.1271, -0.0676,  0.0329,\n",
      "        -0.0214, -0.0118, -0.0283, -0.0246, -0.0196,  0.0371,  0.0944,  0.0606,\n",
      "         0.0428, -0.0537, -0.0094, -0.0269, -0.0358,  0.0492,  0.0040,  0.0506,\n",
      "         0.0182,  0.0075, -0.0591,  0.0745, -0.0353, -0.1191, -0.0864,  0.0286,\n",
      "         0.0607, -0.0902,  0.0556,  0.0521,  0.0519, -0.0790,  0.0777, -0.0019,\n",
      "        -0.1179, -0.0860, -0.0388, -0.0799, -0.0449,  0.0626,  0.0229,  0.0339,\n",
      "        -0.0261, -0.0666,  0.0543,  0.0199,  0.0254, -0.0508, -0.0386, -0.0241,\n",
      "         0.0325, -0.0987, -0.0858, -0.0849,  0.0426, -0.0554, -0.0779, -0.0543,\n",
      "        -0.0184, -0.0173, -0.0699, -0.0042, -0.0172, -0.0762,  0.0537, -0.0165,\n",
      "        -0.0854,  0.0509, -0.0243,  0.0704,  0.0345, -0.1188, -0.0140, -0.0633,\n",
      "        -0.0182,  0.0190, -0.0811, -0.0857,  0.0853,  0.0747, -0.0012,  0.0594,\n",
      "        -0.0954, -0.0625,  0.0679, -0.0525, -0.0485,  0.0093, -0.0445, -0.0267,\n",
      "         0.0430,  0.0725,  0.0416, -0.0953,  0.0418, -0.1005,  0.0557,  0.0652,\n",
      "        -0.0353, -0.0275,  0.0871, -0.0124, -0.0836,  0.0096, -0.0244,  0.0632,\n",
      "         0.0852, -0.0365,  0.1062, -0.0882, -0.0588,  0.0299,  0.0051,  0.0615],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0684, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0150, 0.0269, 0.0807], requires_grad=True)\n",
      "Epoch [68100/100000], Loss: 22.13,   LOSS_function: 22.09,   LOSS_E:0.005879,    LOSS_initial: 1.743e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4352.662405967712\n",
      "loss_compared with real:8.0558e-06,   miu_train:0.08969,    lossmean:0.0001321\n",
      "Epoch [68200/100000], Loss: 22.04,   LOSS_function: 21.99,   LOSS_E:0.005926,    LOSS_initial: 2.187e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4359.334983587265\n",
      "loss_compared with real:7.9627e-06,   miu_train:0.09016,    lossmean:0.0001153\n",
      "Epoch [68300/100000], Loss: 22.18,   LOSS_function: 22.07,   LOSS_E:0.005943,    LOSS_initial: 5.265e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4365.898373603821\n",
      "loss_compared with real:7.8851e-06,   miu_train:0.09052,    lossmean:9.722e-05\n",
      "Epoch [68400/100000], Loss: 21.9,   LOSS_function: 21.84,   LOSS_E:0.005873,    LOSS_initial: 2.4e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4372.537892818451\n",
      "loss_compared with real:7.8414e-06,   miu_train:0.09082,    lossmean:0.00012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68500/100000], Loss: 21.85,   LOSS_function: 21.8,   LOSS_E:0.005884,    LOSS_initial: 2.126e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4379.107802391052\n",
      "loss_compared with real:7.7964e-06,   miu_train:0.09104,    lossmean:0.0001328\n",
      "Epoch [68600/100000], Loss: 22.24,   LOSS_function: 21.81,   LOSS_E:0.005922,    LOSS_initial: 2.042e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4385.273132801056\n",
      "loss_compared with real:8.1101e-06,   miu_train:0.09124,    lossmean:5.312e-05\n",
      "Epoch [68700/100000], Loss: 21.68,   LOSS_function: 21.63,   LOSS_E:0.005819,    LOSS_initial: 2.453e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4391.363513708115\n",
      "loss_compared with real:7.724e-06,   miu_train:0.09155,    lossmean:0.0001255\n",
      "Epoch [68800/100000], Loss: 21.62,   LOSS_function: 21.57,   LOSS_E:0.005798,    LOSS_initial: 2.346e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4397.521247386932\n",
      "loss_compared with real:7.7039e-06,   miu_train:0.09176,    lossmean:0.0001285\n",
      "Epoch [68900/100000], Loss: 29.62,   LOSS_function: 27.75,   LOSS_E:0.00594,    LOSS_initial: 8.802e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.821e-05,    time: 4403.719866037369\n",
      "loss_compared with real:8.6375e-06,   miu_train:0.09193,    lossmean:-9.83e-05\n",
      "Epoch [69000/100000], Loss: 21.96,   LOSS_function: 21.81,   LOSS_E:0.005837,    LOSS_initial: 7.336e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4409.840337753296\n",
      "loss_compared with real:7.6461e-06,   miu_train:0.09213,    lossmean:0.0001172\n",
      "Epoch [69100/100000], Loss: 21.4,   LOSS_function: 21.36,   LOSS_E:0.005769,    LOSS_initial: 1.951e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4416.266205787659\n",
      "loss_compared with real:7.6054e-06,   miu_train:0.09245,    lossmean:0.0001236\n",
      "Epoch [69200/100000], Loss: 21.61,   LOSS_function: 21.29,   LOSS_E:0.005702,    LOSS_initial: 1.476e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4422.4014258384705\n",
      "loss_compared with real:7.5134e-06,   miu_train:0.09277,    lossmean:0.0001589\n",
      "Epoch [69300/100000], Loss: 22.15,   LOSS_function: 21.53,   LOSS_E:0.00565,    LOSS_initial: 2.951e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4428.508302688599\n",
      "loss_compared with real:7.5811e-06,   miu_train:0.0929,    lossmean:0.0001493\n",
      "Epoch [69400/100000], Loss: 22.29,   LOSS_function: 21.86,   LOSS_E:0.005775,    LOSS_initial: 2.038e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4434.620943069458\n",
      "loss_compared with real:7.9596e-06,   miu_train:0.09308,    lossmean:3.14e-05\n",
      "Epoch [69500/100000], Loss: 21.5,   LOSS_function: 21.41,   LOSS_E:0.00566,    LOSS_initial: 3.83e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4440.955971956253\n",
      "loss_compared with real:7.4354e-06,   miu_train:0.09339,    lossmean:0.0001261\n",
      "Epoch [69600/100000], Loss: 21.35,   LOSS_function: 21.03,   LOSS_E:0.00566,    LOSS_initial: 1.523e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4447.1526873111725\n",
      "loss_compared with real:7.4118e-06,   miu_train:0.09366,    lossmean:0.0001536\n",
      "Epoch [69700/100000], Loss: 20.97,   LOSS_function: 20.93,   LOSS_E:0.005683,    LOSS_initial: 2.059e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4453.238722324371\n",
      "loss_compared with real:7.4089e-06,   miu_train:0.09391,    lossmean:0.0001253\n",
      "Epoch [69800/100000], Loss: 20.93,   LOSS_function: 20.88,   LOSS_E:0.005651,    LOSS_initial: 2.336e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4459.378743648529\n",
      "loss_compared with real:7.3876e-06,   miu_train:0.09408,    lossmean:0.0001225\n",
      "Epoch [69900/100000], Loss: 20.83,   LOSS_function: 20.8,   LOSS_E:0.005642,    LOSS_initial: 1.674e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.686e-05,    time: 4465.535112142563\n",
      "loss_compared with real:7.327e-06,   miu_train:0.09435,    lossmean:0.0001326\n",
      "Epoch [70000/100000], Loss: 20.85,   LOSS_function: 20.78,   LOSS_E:0.005666,    LOSS_initial: 3.076e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4471.774742364883\n",
      "loss_compared with real:7.3993e-06,   miu_train:0.09458,    lossmean:0.000118\n",
      "Epoch [70100/100000], Loss: 20.68,   LOSS_function: 20.64,   LOSS_E:0.00562,    LOSS_initial: 1.912e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4477.9412314891815\n",
      "loss_compared with real:7.2584e-06,   miu_train:0.09492,    lossmean:0.0001281\n",
      "Epoch [70200/100000], Loss: 20.82,   LOSS_function: 20.74,   LOSS_E:0.005669,    LOSS_initial: 3.558e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4484.072041988373\n",
      "loss_compared with real:7.2411e-06,   miu_train:0.09511,    lossmean:0.0001332\n",
      "Epoch [70300/100000], Loss: 20.56,   LOSS_function: 20.51,   LOSS_E:0.005612,    LOSS_initial: 2.675e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4490.138168334961\n",
      "loss_compared with real:7.2659e-06,   miu_train:0.0953,    lossmean:0.0001116\n",
      "Epoch [70400/100000], Loss: 20.67,   LOSS_function: 20.42,   LOSS_E:0.005572,    LOSS_initial: 1.166e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4496.260596752167\n",
      "loss_compared with real:7.2447e-06,   miu_train:0.09562,    lossmean:0.0001209\n",
      "Epoch [70500/100000], Loss: 20.91,   LOSS_function: 20.8,   LOSS_E:0.005648,    LOSS_initial: 5.258e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4502.641760826111\n",
      "loss_compared with real:7.2406e-06,   miu_train:0.09583,    lossmean:8.157e-05\n",
      "Epoch [70600/100000], Loss: 20.42,   LOSS_function: 20.3,   LOSS_E:0.005545,    LOSS_initial: 5.648e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4509.11398100853\n",
      "loss_compared with real:7.0563e-06,   miu_train:0.09605,    lossmean:0.0001475\n",
      "Epoch [70700/100000], Loss: 23.57,   LOSS_function: 22.84,   LOSS_E:0.005535,    LOSS_initial: 3.426e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4515.708643913269\n",
      "loss_compared with real:7.1051e-06,   miu_train:0.09645,    lossmean:0.0001344\n",
      "Epoch [70800/100000], Loss: 20.65,   LOSS_function: 20.57,   LOSS_E:0.005596,    LOSS_initial: 3.694e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4522.353966712952\n",
      "loss_compared with real:7.1836e-06,   miu_train:0.09656,    lossmean:8.299e-05\n",
      "Epoch [70900/100000], Loss: 20.11,   LOSS_function: 20.08,   LOSS_E:0.005494,    LOSS_initial: 1.613e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.557e-05,    time: 4529.207266330719\n",
      "loss_compared with real:6.9925e-06,   miu_train:0.09689,    lossmean:0.0001306\n",
      "Epoch [71000/100000], Loss: 21.05,   LOSS_function: 20.95,   LOSS_E:0.00549,    LOSS_initial: 4.255e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4536.068010091782\n",
      "loss_compared with real:7.1262e-06,   miu_train:0.09712,    lossmean:6.01e-05\n",
      "Epoch [71100/100000], Loss: 19.97,   LOSS_function: 19.93,   LOSS_E:0.005477,    LOSS_initial: 1.589e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4542.651751279831\n",
      "loss_compared with real:6.9344e-06,   miu_train:0.09746,    lossmean:0.0001259\n",
      "Epoch [71200/100000], Loss: 19.9,   LOSS_function: 19.86,   LOSS_E:0.005446,    LOSS_initial: 2.033e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4549.335437774658\n",
      "loss_compared with real:6.8826e-06,   miu_train:0.09764,    lossmean:0.0001379\n",
      "Epoch [71300/100000], Loss: 19.85,   LOSS_function: 19.8,   LOSS_E:0.005448,    LOSS_initial: 2.263e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4555.9057450294495\n",
      "loss_compared with real:6.8891e-06,   miu_train:0.0979,    lossmean:0.0001252\n",
      "Epoch [71400/100000], Loss: 21.83,   LOSS_function: 20.98,   LOSS_E:0.005489,    LOSS_initial: 4.005e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4562.843568563461\n",
      "loss_compared with real:6.951e-06,   miu_train:0.09814,    lossmean:0.0001143\n",
      "Epoch [71500/100000], Loss: 20.81,   LOSS_function: 20.51,   LOSS_E:0.005462,    LOSS_initial: 1.414e-05,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4569.442368745804\n",
      "loss_compared with real:6.6413e-06,   miu_train:0.09842,    lossmean:0.0002155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71600/100000], Loss: 32.37,   LOSS_function: 27.58,   LOSS_E:0.005547,    LOSS_initial: 0.0002257,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4576.163033485413\n",
      "loss_compared with real:7.003e-06,   miu_train:0.09882,    lossmean:2.113e-05\n",
      "Epoch [71700/100000], Loss: 33.82,   LOSS_function: 31.43,   LOSS_E:0.005488,    LOSS_initial: 0.0001123,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4582.788932323456\n",
      "loss_compared with real:7.796e-06,   miu_train:0.09888,    lossmean:-9.064e-05\n",
      "Epoch [71800/100000], Loss: 19.55,   LOSS_function: 19.41,   LOSS_E:0.005348,    LOSS_initial: 6.516e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4589.472789764404\n",
      "loss_compared with real:6.7197e-06,   miu_train:0.09917,    lossmean:0.0001393\n",
      "Epoch [71900/100000], Loss: 19.42,   LOSS_function: 19.39,   LOSS_E:0.005357,    LOSS_initial: 1.474e-06,\n",
      "lamda1:1,    lamda3:2.123e+04,      learn rate:2.434e-05,    time: 4596.079055309296\n",
      "loss_compared with real:6.6974e-06,   miu_train:0.09947,    lossmean:0.0001248\n",
      "Epoch [72000/100000], Loss: 21.53,   LOSS_function: 20.52,   LOSS_E:0.005269,    LOSS_initial: 3.534e-05,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4602.820525407791\n",
      "loss_compared with real:6.4056e-06,   miu_train:0.09972,    lossmean:0.000276\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5208, -0.5039, -0.2893, -0.9667, -0.0648, -0.3188,  0.4295, -0.8257,\n",
      "         0.8663,  0.3138,  0.7668,  0.5123,  0.5924, -0.0308,  0.6968, -0.3220,\n",
      "         0.8297,  0.0234,  0.7910, -0.8023, -0.2669, -0.9687, -0.4821, -0.3207,\n",
      "        -0.2981, -0.3496,  0.6962, -0.6256, -0.2320,  0.4138, -0.3073, -0.1887,\n",
      "         0.1040,  0.6312, -0.6920, -0.7997, -0.7082, -0.5402, -0.2553, -0.0372,\n",
      "        -0.8241, -0.9717, -0.0512,  0.8011, -0.5751,  0.8642, -0.6893,  0.9039,\n",
      "         0.6200, -0.9116, -0.7511, -0.3405,  0.8459, -0.6040,  0.9210, -0.1111,\n",
      "        -0.8979,  0.4110, -0.2541, -0.8646,  0.8319, -0.3142,  0.2534, -0.1139,\n",
      "        -0.5071, -0.0809, -0.0244,  0.4030, -0.4066, -0.3426,  0.5319, -0.4195,\n",
      "        -0.4803,  0.8825,  0.8005, -0.4210, -0.4401,  0.0205, -0.3106, -0.5244,\n",
      "        -0.7528, -0.6530,  0.9151,  0.0164,  0.1153,  0.7528,  0.6706,  0.2243,\n",
      "        -0.0333, -0.0847,  0.6263,  0.7126, -0.6025,  0.9426,  0.2183,  0.5757,\n",
      "        -0.6433, -0.1334,  0.5832,  0.0281, -0.8525,  0.0757, -0.0103, -0.1965,\n",
      "         0.4042,  0.4931,  0.6593,  0.0562,  0.2390,  0.6257, -0.6227, -0.2589,\n",
      "         0.5794,  0.7720,  0.7162,  0.0084, -0.9614,  0.8764, -0.2921, -0.8864,\n",
      "        -0.9648,  0.9001, -0.2286,  0.3608, -0.2267,  0.4231, -0.2022,  0.1831],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2945, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0226, -0.0328,  0.0250,  0.0670, -0.0382, -0.0373, -0.0312,  0.0351,\n",
      "        -0.0318,  0.0440, -0.0127, -0.0999,  0.0481, -0.0386,  0.0731,  0.0269,\n",
      "        -0.0451, -0.0211, -0.0116,  0.0354, -0.0677,  0.0626,  0.0356,  0.0182,\n",
      "         0.0123, -0.0129,  0.0641, -0.0439, -0.0363, -0.0775,  0.0282, -0.0647,\n",
      "         0.0835, -0.0437,  0.0610,  0.0017, -0.0706,  0.0559,  0.0357, -0.0596,\n",
      "        -0.0941, -0.0733,  0.0108,  0.0755,  0.0613,  0.0778, -0.0331,  0.0841,\n",
      "        -0.0300,  0.0045,  0.0403,  0.0160, -0.0273,  0.0147,  0.0046, -0.0073,\n",
      "         0.0609,  0.0302,  0.0350,  0.0334,  0.0064, -0.0174, -0.0235,  0.0529,\n",
      "         0.0596,  0.0038,  0.0726,  0.0129,  0.0347,  0.0237,  0.0486,  0.0064,\n",
      "        -0.0310,  0.0062, -0.0780,  0.0029, -0.0348,  0.0828, -0.0030,  0.0123,\n",
      "         0.0354, -0.0325, -0.0152,  0.0461,  0.0217, -0.0923, -0.0234, -0.0005,\n",
      "         0.0830,  0.0786,  0.0445,  0.0518, -0.0500, -0.0672,  0.0662, -0.0696,\n",
      "         0.0290,  0.0405,  0.0307,  0.0865,  0.0785,  0.0453,  0.0488,  0.0843,\n",
      "         0.0711, -0.0082, -0.0697, -0.0781,  0.0215, -0.0392,  0.0398,  0.0332,\n",
      "        -0.0174, -0.0447, -0.0030,  0.0229,  0.0313, -0.0725, -0.1075,  0.0317,\n",
      "         0.0710,  0.0170,  0.0264, -0.0193,  0.0141,  0.0172, -0.0628,  0.0648],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2681, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0752, -0.0477, -0.0370,  0.0251, -0.0630, -0.0256, -0.0501, -0.0093,\n",
      "        -0.0262,  0.0491,  0.0119, -0.0256, -0.0317, -0.0136, -0.0287, -0.0854,\n",
      "        -0.0443,  0.0438,  0.0326, -0.1178,  0.0190, -0.0290, -0.0441, -0.0078,\n",
      "         0.0400,  0.0110,  0.0576,  0.0110, -0.0909, -0.0736, -0.0247,  0.0237,\n",
      "         0.0203, -0.0236,  0.0620,  0.0839,  0.1008,  0.0172,  0.0357,  0.1042,\n",
      "        -0.0380,  0.0253,  0.0006, -0.0562,  0.0594,  0.0377, -0.0809, -0.0851,\n",
      "         0.0149, -0.0230, -0.0647,  0.0630,  0.0399, -0.0746,  0.0425,  0.0439,\n",
      "         0.0141, -0.0877,  0.0073, -0.0743,  0.0250,  0.0493, -0.0253,  0.0385,\n",
      "         0.0767, -0.0073,  0.0243, -0.0052,  0.0387,  0.0254, -0.0874, -0.0365,\n",
      "        -0.0155,  0.0444, -0.0023,  0.0663,  0.0849,  0.0043,  0.0011, -0.0167,\n",
      "         0.1259,  0.0134, -0.0604,  0.0974, -0.0175, -0.0142,  0.0144,  0.0695,\n",
      "        -0.0047, -0.0922,  0.0497, -0.0778,  0.0078, -0.0572, -0.0567,  0.0593,\n",
      "        -0.0564, -0.0898, -0.0849,  0.0711, -0.0698,  0.0216,  0.0228,  0.0365,\n",
      "        -0.0354, -0.0660,  0.0510, -0.0788, -0.1039, -0.0576, -0.0542,  0.0071,\n",
      "         0.0550, -0.0485, -0.0529, -0.0252, -0.0194, -0.0226,  0.0959,  0.0159,\n",
      "        -0.0359,  0.0235,  0.0812,  0.0936, -0.0382, -0.0860,  0.0059, -0.0704],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1033, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0669, -0.0428,  0.0099,  0.1154, -0.0974,  0.0487, -0.0319, -0.0304,\n",
      "         0.0585,  0.0048,  0.0417,  0.0577,  0.0587, -0.1272, -0.0677,  0.0332,\n",
      "        -0.0214, -0.0121, -0.0286, -0.0246, -0.0195,  0.0371,  0.0944,  0.0605,\n",
      "         0.0426, -0.0537, -0.0094, -0.0268, -0.0358,  0.0493,  0.0042,  0.0506,\n",
      "         0.0183,  0.0075, -0.0590,  0.0745, -0.0354, -0.1191, -0.0865,  0.0287,\n",
      "         0.0608, -0.0902,  0.0555,  0.0519,  0.0520, -0.0789,  0.0775, -0.0019,\n",
      "        -0.1178, -0.0860, -0.0389, -0.0798, -0.0449,  0.0625,  0.0230,  0.0339,\n",
      "        -0.0260, -0.0666,  0.0544,  0.0200,  0.0256, -0.0506, -0.0386, -0.0238,\n",
      "         0.0327, -0.0985, -0.0855, -0.0850,  0.0425, -0.0554, -0.0779, -0.0541,\n",
      "        -0.0187, -0.0173, -0.0700, -0.0042, -0.0172, -0.0763,  0.0535, -0.0149,\n",
      "        -0.0853,  0.0509, -0.0244,  0.0704,  0.0345, -0.1189, -0.0142, -0.0635,\n",
      "        -0.0182,  0.0188, -0.0813, -0.0858,  0.0854,  0.0748, -0.0012,  0.0595,\n",
      "        -0.0954, -0.0625,  0.0680, -0.0525, -0.0484,  0.0092, -0.0445, -0.0268,\n",
      "         0.0429,  0.0725,  0.0416, -0.0953,  0.0419, -0.1005,  0.0559,  0.0653,\n",
      "        -0.0352, -0.0275,  0.0869, -0.0123, -0.0837,  0.0095, -0.0244,  0.0633,\n",
      "         0.0851, -0.0366,  0.1066, -0.0881, -0.0588,  0.0297,  0.0050,  0.0614],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0688, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0167, 0.0270, 0.0811], requires_grad=True)\n",
      "Epoch [72100/100000], Loss: 19.41,   LOSS_function: 19.36,   LOSS_E:0.005322,    LOSS_initial: 1.72e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4609.373423099518\n",
      "loss_compared with real:6.4991e-06,   miu_train:0.09917,    lossmean:0.0001729\n",
      "Epoch [72200/100000], Loss: 19.33,   LOSS_function: 19.3,   LOSS_E:0.005346,    LOSS_initial: 1.013e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4615.952024698257\n",
      "loss_compared with real:6.3926e-06,   miu_train:0.09964,    lossmean:0.0001658\n",
      "Epoch [72300/100000], Loss: 19.27,   LOSS_function: 19.25,   LOSS_E:0.00533,    LOSS_initial: 9.865e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4622.809271812439\n",
      "loss_compared with real:6.3288e-06,   miu_train:0.09999,    lossmean:0.0001622\n",
      "Epoch [72400/100000], Loss: 19.22,   LOSS_function: 19.19,   LOSS_E:0.005311,    LOSS_initial: 9.545e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4629.496514558792\n",
      "loss_compared with real:6.281e-06,   miu_train:0.1003,    lossmean:0.000162\n",
      "Epoch [72500/100000], Loss: 19.17,   LOSS_function: 19.14,   LOSS_E:0.005293,    LOSS_initial: 9.4e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4636.095790147781\n",
      "loss_compared with real:6.2424e-06,   miu_train:0.1006,    lossmean:0.0001622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72600/100000], Loss: 19.16,   LOSS_function: 19.12,   LOSS_E:0.005296,    LOSS_initial: 1.386e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4642.701788663864\n",
      "loss_compared with real:6.2562e-06,   miu_train:0.1008,    lossmean:0.0001487\n",
      "Epoch [72700/100000], Loss: 19.38,   LOSS_function: 19.17,   LOSS_E:0.005276,    LOSS_initial: 7.475e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4649.309061050415\n",
      "loss_compared with real:6.231e-06,   miu_train:0.1011,    lossmean:0.0001407\n",
      "Epoch [72800/100000], Loss: 19.01,   LOSS_function: 18.98,   LOSS_E:0.005234,    LOSS_initial: 9.284e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4655.931605100632\n",
      "loss_compared with real:6.1514e-06,   miu_train:0.1013,    lossmean:0.0001702\n",
      "Epoch [72900/100000], Loss: 18.96,   LOSS_function: 18.92,   LOSS_E:0.00524,    LOSS_initial: 1.319e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.317e-05,    time: 4662.4863657951355\n",
      "loss_compared with real:6.1551e-06,   miu_train:0.1015,    lossmean:0.0001623\n",
      "Epoch [73000/100000], Loss: 18.96,   LOSS_function: 18.87,   LOSS_E:0.005239,    LOSS_initial: 2.88e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4669.277600765228\n",
      "loss_compared with real:6.1384e-06,   miu_train:0.1017,    lossmean:0.0001683\n",
      "Epoch [73100/100000], Loss: 18.84,   LOSS_function: 18.82,   LOSS_E:0.0052,    LOSS_initial: 8.998e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4675.85718870163\n",
      "loss_compared with real:6.081e-06,   miu_train:0.102,    lossmean:0.0001676\n",
      "Epoch [73200/100000], Loss: 26.33,   LOSS_function: 20.23,   LOSS_E:0.005015,    LOSS_initial: 0.0002136,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4682.399463891983\n",
      "loss_compared with real:6.4191e-06,   miu_train:0.1021,    lossmean:0.0001808\n",
      "Epoch [73300/100000], Loss: 22.41,   LOSS_function: 21.24,   LOSS_E:0.00514,    LOSS_initial: 4.084e-05,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4688.456886768341\n",
      "loss_compared with real:5.91e-06,   miu_train:0.1025,    lossmean:0.0003192\n",
      "Epoch [73400/100000], Loss: 18.74,   LOSS_function: 18.64,   LOSS_E:0.005155,    LOSS_initial: 3.638e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4694.591255426407\n",
      "loss_compared with real:6.004e-06,   miu_train:0.1026,    lossmean:0.0001767\n",
      "Epoch [73500/100000], Loss: 18.7,   LOSS_function: 18.58,   LOSS_E:0.005145,    LOSS_initial: 4.081e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4700.652693271637\n",
      "loss_compared with real:5.985e-06,   miu_train:0.1028,    lossmean:0.0001736\n",
      "Epoch [73600/100000], Loss: 27.67,   LOSS_function: 23.59,   LOSS_E:0.005054,    LOSS_initial: 0.0001428,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4706.827345609665\n",
      "loss_compared with real:5.8885e-06,   miu_train:0.1031,    lossmean:0.0003376\n",
      "Epoch [73700/100000], Loss: 18.84,   LOSS_function: 18.69,   LOSS_E:0.005141,    LOSS_initial: 5.303e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4712.961936712265\n",
      "loss_compared with real:5.9392e-06,   miu_train:0.1033,    lossmean:0.0001586\n",
      "Epoch [73800/100000], Loss: 19.85,   LOSS_function: 18.69,   LOSS_E:0.005192,    LOSS_initial: 4.038e-05,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4719.438269138336\n",
      "loss_compared with real:5.76e-06,   miu_train:0.1036,    lossmean:0.0002199\n",
      "Epoch [73900/100000], Loss: 18.43,   LOSS_function: 18.34,   LOSS_E:0.005104,    LOSS_initial: 3.136e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.206e-05,    time: 4725.545870304108\n",
      "loss_compared with real:5.9004e-06,   miu_train:0.1038,    lossmean:0.0001645\n",
      "Epoch [74000/100000], Loss: 18.43,   LOSS_function: 18.35,   LOSS_E:0.005114,    LOSS_initial: 2.57e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4731.8219294548035\n",
      "loss_compared with real:5.8652e-06,   miu_train:0.104,    lossmean:0.0001659\n",
      "Epoch [74100/100000], Loss: 18.27,   LOSS_function: 18.24,   LOSS_E:0.00506,    LOSS_initial: 8.991e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4737.992179632187\n",
      "loss_compared with real:5.82e-06,   miu_train:0.1043,    lossmean:0.0001678\n",
      "Epoch [74200/100000], Loss: 18.29,   LOSS_function: 18.27,   LOSS_E:0.005045,    LOSS_initial: 6.756e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4744.386400461197\n",
      "loss_compared with real:5.7949e-06,   miu_train:0.1045,    lossmean:0.0001663\n",
      "Epoch [74300/100000], Loss: 18.77,   LOSS_function: 18.47,   LOSS_E:0.00511,    LOSS_initial: 1.035e-05,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4750.447575569153\n",
      "loss_compared with real:5.6642e-06,   miu_train:0.1048,    lossmean:0.0002182\n",
      "Epoch [74400/100000], Loss: 18.27,   LOSS_function: 18.17,   LOSS_E:0.005046,    LOSS_initial: 3.579e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4756.6019785404205\n",
      "loss_compared with real:5.7866e-06,   miu_train:0.105,    lossmean:0.000156\n",
      "Epoch [74500/100000], Loss: 18.06,   LOSS_function: 18.05,   LOSS_E:0.005011,    LOSS_initial: 4.491e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4762.652849912643\n",
      "loss_compared with real:5.7239e-06,   miu_train:0.1052,    lossmean:0.0001609\n",
      "Epoch [74600/100000], Loss: 19.02,   LOSS_function: 18.72,   LOSS_E:0.005038,    LOSS_initial: 1.038e-05,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4768.81312417984\n",
      "loss_compared with real:5.8562e-06,   miu_train:0.1054,    lossmean:0.0001105\n",
      "Epoch [74700/100000], Loss: 17.95,   LOSS_function: 17.9,   LOSS_E:0.005002,    LOSS_initial: 1.57e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4774.9084260463715\n",
      "loss_compared with real:5.6505e-06,   miu_train:0.1057,    lossmean:0.0001753\n",
      "Epoch [74800/100000], Loss: 18,   LOSS_function: 17.96,   LOSS_E:0.004965,    LOSS_initial: 1.222e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4781.132876873016\n",
      "loss_compared with real:5.6862e-06,   miu_train:0.1059,    lossmean:0.0001447\n",
      "Epoch [74900/100000], Loss: 17.8,   LOSS_function: 17.78,   LOSS_E:0.004947,    LOSS_initial: 6.666e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:2.1e-05,    time: 4787.267297029495\n",
      "loss_compared with real:5.6141e-06,   miu_train:0.1062,    lossmean:0.0001674\n",
      "Epoch [75000/100000], Loss: 17.74,   LOSS_function: 17.71,   LOSS_E:0.004931,    LOSS_initial: 1.149e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4793.450886487961\n",
      "loss_compared with real:5.5933e-06,   miu_train:0.1064,    lossmean:0.0001697\n",
      "Epoch [75100/100000], Loss: 17.68,   LOSS_function: 17.66,   LOSS_E:0.004923,    LOSS_initial: 7.571e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4799.939820051193\n",
      "loss_compared with real:5.5635e-06,   miu_train:0.1067,    lossmean:0.0001656\n",
      "Epoch [75200/100000], Loss: 17.65,   LOSS_function: 17.6,   LOSS_E:0.004902,    LOSS_initial: 1.462e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4806.088049650192\n",
      "loss_compared with real:5.5114e-06,   miu_train:0.1069,    lossmean:0.0001728\n",
      "Epoch [75300/100000], Loss: 17.57,   LOSS_function: 17.53,   LOSS_E:0.004886,    LOSS_initial: 1.187e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4812.483514308929\n",
      "loss_compared with real:5.5129e-06,   miu_train:0.1072,    lossmean:0.0001701\n",
      "Epoch [75400/100000], Loss: 17.51,   LOSS_function: 17.49,   LOSS_E:0.004883,    LOSS_initial: 8.319e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4819.120020389557\n",
      "loss_compared with real:5.5038e-06,   miu_train:0.1074,    lossmean:0.000163\n",
      "Epoch [75500/100000], Loss: 17.49,   LOSS_function: 17.4,   LOSS_E:0.00485,    LOSS_initial: 3.153e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4825.661477565765\n",
      "loss_compared with real:5.4369e-06,   miu_train:0.1076,    lossmean:0.0001813\n",
      "Epoch [75600/100000], Loss: 17.4,   LOSS_function: 17.35,   LOSS_E:0.004834,    LOSS_initial: 1.858e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4832.301718235016\n",
      "loss_compared with real:5.4336e-06,   miu_train:0.1079,    lossmean:0.0001734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75700/100000], Loss: 17.33,   LOSS_function: 17.31,   LOSS_E:0.004835,    LOSS_initial: 7.03e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4838.847055435181\n",
      "loss_compared with real:5.4169e-06,   miu_train:0.1081,    lossmean:0.0001683\n",
      "Epoch [75800/100000], Loss: 17.3,   LOSS_function: 17.27,   LOSS_E:0.00482,    LOSS_initial: 9.25e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4845.516796588898\n",
      "loss_compared with real:5.383e-06,   miu_train:0.1083,    lossmean:0.0001698\n",
      "Epoch [75900/100000], Loss: 17.25,   LOSS_function: 17.22,   LOSS_E:0.00484,    LOSS_initial: 8.794e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.999e-05,    time: 4852.110158443451\n",
      "loss_compared with real:5.416e-06,   miu_train:0.1086,    lossmean:0.0001559\n",
      "Epoch [76000/100000], Loss: 17.21,   LOSS_function: 17.15,   LOSS_E:0.004793,    LOSS_initial: 2.074e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4859.218619585037\n",
      "loss_compared with real:5.3904e-06,   miu_train:0.1088,    lossmean:0.000148\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5208, -0.5030, -0.2894, -0.9667, -0.0648, -0.3187,  0.4294, -0.8256,\n",
      "         0.8663,  0.3138,  0.7669,  0.5119,  0.5922, -0.0309,  0.6969, -0.3221,\n",
      "         0.8297,  0.0235,  0.7908, -0.8022, -0.2679, -0.9686, -0.4819, -0.3208,\n",
      "        -0.2980, -0.3496,  0.6962, -0.6256, -0.2319,  0.4138, -0.3075, -0.1886,\n",
      "         0.1041,  0.6310, -0.6918, -0.7998, -0.7083, -0.5401, -0.2554, -0.0372,\n",
      "        -0.8243, -0.9720, -0.0513,  0.8011, -0.5743,  0.8643, -0.6893,  0.9042,\n",
      "         0.6202, -0.9117, -0.7509, -0.3403,  0.8459, -0.6041,  0.9210, -0.1112,\n",
      "        -0.8980,  0.4108, -0.2541, -0.8645,  0.8319, -0.3141,  0.2534, -0.1139,\n",
      "        -0.5075, -0.0808, -0.0246,  0.4026, -0.4070, -0.3426,  0.5322, -0.4194,\n",
      "        -0.4797,  0.8825,  0.8008, -0.4209, -0.4400,  0.0203, -0.3106, -0.5247,\n",
      "        -0.7526, -0.6529,  0.9151,  0.0162,  0.1152,  0.7528,  0.6703,  0.2243,\n",
      "        -0.0331, -0.0845,  0.6261,  0.7126, -0.6026,  0.9426,  0.2180,  0.5755,\n",
      "        -0.6434, -0.1333,  0.5831,  0.0279, -0.8525,  0.0748, -0.0101, -0.1964,\n",
      "         0.4042,  0.4928,  0.6593,  0.0559,  0.2390,  0.6259, -0.6223, -0.2589,\n",
      "         0.5794,  0.7719,  0.7160,  0.0081, -0.9616,  0.8764, -0.2921, -0.8865,\n",
      "        -0.9649,  0.9003, -0.2284,  0.3609, -0.2268,  0.4230, -0.2024,  0.1829],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2942, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0226, -0.0328,  0.0250,  0.0669, -0.0380, -0.0372, -0.0311,  0.0355,\n",
      "        -0.0318,  0.0441, -0.0129, -0.1000,  0.0481, -0.0385,  0.0731,  0.0270,\n",
      "        -0.0451, -0.0210, -0.0117,  0.0353, -0.0674,  0.0626,  0.0356,  0.0182,\n",
      "         0.0125, -0.0129,  0.0641, -0.0439, -0.0363, -0.0774,  0.0280, -0.0647,\n",
      "         0.0833, -0.0437,  0.0610,  0.0017, -0.0705,  0.0559,  0.0356, -0.0597,\n",
      "        -0.0942, -0.0730,  0.0109,  0.0756,  0.0614,  0.0777, -0.0332,  0.0841,\n",
      "        -0.0301,  0.0044,  0.0403,  0.0160, -0.0274,  0.0146,  0.0047, -0.0076,\n",
      "         0.0610,  0.0303,  0.0352,  0.0334,  0.0064, -0.0176, -0.0235,  0.0529,\n",
      "         0.0596,  0.0038,  0.0727,  0.0129,  0.0344,  0.0237,  0.0488,  0.0064,\n",
      "        -0.0310,  0.0059, -0.0779,  0.0029, -0.0350,  0.0828, -0.0030,  0.0123,\n",
      "         0.0353, -0.0325, -0.0152,  0.0462,  0.0217, -0.0923, -0.0234, -0.0006,\n",
      "         0.0829,  0.0788,  0.0445,  0.0518, -0.0500, -0.0672,  0.0662, -0.0698,\n",
      "         0.0292,  0.0407,  0.0304,  0.0865,  0.0785,  0.0454,  0.0485,  0.0841,\n",
      "         0.0711, -0.0083, -0.0696, -0.0783,  0.0218, -0.0393,  0.0396,  0.0332,\n",
      "        -0.0177, -0.0446, -0.0029,  0.0229,  0.0313, -0.0724, -0.1078,  0.0318,\n",
      "         0.0713,  0.0171,  0.0265, -0.0193,  0.0139,  0.0171, -0.0628,  0.0649],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2687, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0753, -0.0476, -0.0370,  0.0250, -0.0631, -0.0257, -0.0500, -0.0094,\n",
      "        -0.0261,  0.0491,  0.0120, -0.0255, -0.0320, -0.0139, -0.0287, -0.0858,\n",
      "        -0.0441,  0.0439,  0.0326, -0.1176,  0.0188, -0.0292, -0.0441, -0.0076,\n",
      "         0.0399,  0.0110,  0.0575,  0.0109, -0.0909, -0.0736, -0.0247,  0.0237,\n",
      "         0.0205, -0.0234,  0.0621,  0.0841,  0.1006,  0.0170,  0.0361,  0.1041,\n",
      "        -0.0378,  0.0251,  0.0007, -0.0564,  0.0594,  0.0375, -0.0811, -0.0850,\n",
      "         0.0149, -0.0230, -0.0648,  0.0631,  0.0400, -0.0746,  0.0426,  0.0441,\n",
      "         0.0140, -0.0878,  0.0073, -0.0740,  0.0252,  0.0492, -0.0251,  0.0385,\n",
      "         0.0767, -0.0075,  0.0242, -0.0052,  0.0389,  0.0254, -0.0875, -0.0364,\n",
      "        -0.0155,  0.0441, -0.0022,  0.0662,  0.0849,  0.0043,  0.0012, -0.0168,\n",
      "         0.1259,  0.0135, -0.0604,  0.0975, -0.0176, -0.0141,  0.0146,  0.0697,\n",
      "        -0.0046, -0.0928,  0.0497, -0.0779,  0.0079, -0.0572, -0.0565,  0.0595,\n",
      "        -0.0561, -0.0898, -0.0846,  0.0709, -0.0698,  0.0216,  0.0226,  0.0364,\n",
      "        -0.0355, -0.0660,  0.0510, -0.0789, -0.1039, -0.0577, -0.0544,  0.0070,\n",
      "         0.0550, -0.0489, -0.0529, -0.0251, -0.0193, -0.0227,  0.0961,  0.0160,\n",
      "        -0.0361,  0.0234,  0.0811,  0.0935, -0.0380, -0.0862,  0.0063, -0.0703],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1040, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0670, -0.0429,  0.0099,  0.1155, -0.0975,  0.0486, -0.0318, -0.0304,\n",
      "         0.0585,  0.0048,  0.0413,  0.0577,  0.0582, -0.1273, -0.0677,  0.0332,\n",
      "        -0.0215, -0.0122, -0.0288, -0.0246, -0.0195,  0.0371,  0.0944,  0.0605,\n",
      "         0.0424, -0.0536, -0.0095, -0.0267, -0.0357,  0.0495,  0.0044,  0.0505,\n",
      "         0.0183,  0.0075, -0.0590,  0.0744, -0.0355, -0.1191, -0.0866,  0.0288,\n",
      "         0.0608, -0.0902,  0.0555,  0.0519,  0.0521, -0.0789,  0.0774, -0.0019,\n",
      "        -0.1177, -0.0859, -0.0391, -0.0797, -0.0448,  0.0625,  0.0229,  0.0339,\n",
      "        -0.0260, -0.0667,  0.0546,  0.0200,  0.0257, -0.0505, -0.0386, -0.0233,\n",
      "         0.0328, -0.0983, -0.0854, -0.0851,  0.0425, -0.0554, -0.0780, -0.0540,\n",
      "        -0.0189, -0.0173, -0.0701, -0.0042, -0.0171, -0.0765,  0.0533, -0.0138,\n",
      "        -0.0851,  0.0509, -0.0244,  0.0704,  0.0345, -0.1190, -0.0143, -0.0635,\n",
      "        -0.0181,  0.0186, -0.0815, -0.0858,  0.0855,  0.0749, -0.0013,  0.0596,\n",
      "        -0.0955, -0.0625,  0.0681, -0.0524, -0.0483,  0.0092, -0.0446, -0.0269,\n",
      "         0.0427,  0.0724,  0.0415, -0.0954,  0.0419, -0.1005,  0.0561,  0.0654,\n",
      "        -0.0352, -0.0274,  0.0866, -0.0123, -0.0838,  0.0094, -0.0243,  0.0634,\n",
      "         0.0851, -0.0366,  0.1069, -0.0879, -0.0589,  0.0297,  0.0050,  0.0613],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0690, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0183, 0.0272, 0.0811], requires_grad=True)\n",
      "Epoch [76100/100000], Loss: 17.1,   LOSS_function: 17.08,   LOSS_E:0.00478,    LOSS_initial: 7.535e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4866.020980834961\n",
      "loss_compared with real:5.3141e-06,   miu_train:0.1091,    lossmean:0.0001656\n",
      "Epoch [76200/100000], Loss: 17.05,   LOSS_function: 17.04,   LOSS_E:0.004769,    LOSS_initial: 5.796e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4872.685994148254\n",
      "loss_compared with real:5.2779e-06,   miu_train:0.1093,    lossmean:0.0001663\n",
      "Epoch [76300/100000], Loss: 16.99,   LOSS_function: 16.97,   LOSS_E:0.004755,    LOSS_initial: 7.304e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4879.263080835342\n",
      "loss_compared with real:5.2842e-06,   miu_train:0.1096,    lossmean:0.0001609\n",
      "Epoch [76400/100000], Loss: 17.11,   LOSS_function: 17.03,   LOSS_E:0.004764,    LOSS_initial: 2.727e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4885.941903352737\n",
      "loss_compared with real:5.2348e-06,   miu_train:0.1098,    lossmean:0.000161\n",
      "Epoch [76500/100000], Loss: 17.81,   LOSS_function: 17.49,   LOSS_E:0.004744,    LOSS_initial: 1.099e-05,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4892.504755973816\n",
      "loss_compared with real:5.4242e-06,   miu_train:0.1101,    lossmean:8.247e-05\n",
      "Epoch [76600/100000], Loss: 17.46,   LOSS_function: 17.17,   LOSS_E:0.004732,    LOSS_initial: 9.926e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4899.151725769043\n",
      "loss_compared with real:5.2143e-06,   miu_train:0.1103,    lossmean:0.000148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76700/100000], Loss: 17.06,   LOSS_function: 17.02,   LOSS_E:0.004743,    LOSS_initial: 1.321e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4905.728665351868\n",
      "loss_compared with real:5.2216e-06,   miu_train:0.1105,    lossmean:0.000161\n",
      "Epoch [76800/100000], Loss: 16.75,   LOSS_function: 16.72,   LOSS_E:0.004702,    LOSS_initial: 1.009e-06,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4912.293582439423\n",
      "loss_compared with real:5.1722e-06,   miu_train:0.1108,    lossmean:0.0001555\n",
      "Epoch [76900/100000], Loss: 16.66,   LOSS_function: 16.64,   LOSS_E:0.004677,    LOSS_initial: 6.393e-07,\n",
      "lamda1:1,    lamda3:2.859e+04,      learn rate:1.903e-05,    time: 4918.915648460388\n",
      "loss_compared with real:5.0977e-06,   miu_train:0.111,    lossmean:0.0001672\n",
      "Epoch [77000/100000], Loss: 21.97,   LOSS_function: 19.28,   LOSS_E:0.004767,    LOSS_initial: 0.00016,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4925.803027391434\n",
      "loss_compared with real:5.2331e-06,   miu_train:0.1112,    lossmean:0.000161\n",
      "Epoch [77100/100000], Loss: 16.51,   LOSS_function: 16.48,   LOSS_E:0.004631,    LOSS_initial: 2.236e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4932.454823732376\n",
      "loss_compared with real:5.6373e-06,   miu_train:0.1115,    lossmean:0.0001114\n",
      "Epoch [77200/100000], Loss: 16.46,   LOSS_function: 16.42,   LOSS_E:0.004614,    LOSS_initial: 2.116e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4939.117526769638\n",
      "loss_compared with real:5.6078e-06,   miu_train:0.1117,    lossmean:0.0001092\n",
      "Epoch [77300/100000], Loss: 16.4,   LOSS_function: 16.36,   LOSS_E:0.004595,    LOSS_initial: 2.122e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4945.666061401367\n",
      "loss_compared with real:5.5777e-06,   miu_train:0.1119,    lossmean:0.0001122\n",
      "Epoch [77400/100000], Loss: 16.34,   LOSS_function: 16.31,   LOSS_E:0.004582,    LOSS_initial: 1.974e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4952.354763031006\n",
      "loss_compared with real:5.5524e-06,   miu_train:0.1122,    lossmean:0.0001116\n",
      "Epoch [77500/100000], Loss: 16.28,   LOSS_function: 16.24,   LOSS_E:0.004566,    LOSS_initial: 2.12e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4958.952903747559\n",
      "loss_compared with real:5.5258e-06,   miu_train:0.1124,    lossmean:0.0001141\n",
      "Epoch [77600/100000], Loss: 16.22,   LOSS_function: 16.18,   LOSS_E:0.004567,    LOSS_initial: 2.1e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4965.511897087097\n",
      "loss_compared with real:5.5219e-06,   miu_train:0.1127,    lossmean:0.0001106\n",
      "Epoch [77700/100000], Loss: 16.16,   LOSS_function: 16.12,   LOSS_E:0.004537,    LOSS_initial: 1.88e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4972.047620534897\n",
      "loss_compared with real:5.4793e-06,   miu_train:0.1129,    lossmean:0.0001104\n",
      "Epoch [77800/100000], Loss: 16.17,   LOSS_function: 16.14,   LOSS_E:0.004562,    LOSS_initial: 1.422e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4978.71902680397\n",
      "loss_compared with real:5.5535e-06,   miu_train:0.1132,    lossmean:8.509e-05\n",
      "Epoch [77900/100000], Loss: 16.04,   LOSS_function: 16.01,   LOSS_E:0.004514,    LOSS_initial: 1.71e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.812e-05,    time: 4985.099159479141\n",
      "loss_compared with real:5.4166e-06,   miu_train:0.1135,    lossmean:0.0001139\n",
      "Epoch [78000/100000], Loss: 16.09,   LOSS_function: 16.08,   LOSS_E:0.004529,    LOSS_initial: 9.158e-07,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 4991.3077001571655\n",
      "loss_compared with real:5.4791e-06,   miu_train:0.1137,    lossmean:7.435e-05\n",
      "Epoch [78100/100000], Loss: 15.9,   LOSS_function: 15.87,   LOSS_E:0.004487,    LOSS_initial: 1.957e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 4997.423891782761\n",
      "loss_compared with real:5.3666e-06,   miu_train:0.114,    lossmean:0.0001101\n",
      "Epoch [78200/100000], Loss: 16.07,   LOSS_function: 16.01,   LOSS_E:0.004501,    LOSS_initial: 3.476e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5003.533083677292\n",
      "loss_compared with real:5.2977e-06,   miu_train:0.1143,    lossmean:0.0001352\n",
      "Epoch [78300/100000], Loss: 15.83,   LOSS_function: 15.82,   LOSS_E:0.004459,    LOSS_initial: 9.918e-07,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5009.665962457657\n",
      "loss_compared with real:5.3089e-06,   miu_train:0.1146,    lossmean:0.0001046\n",
      "Epoch [78400/100000], Loss: 15.72,   LOSS_function: 15.68,   LOSS_E:0.004437,    LOSS_initial: 2.649e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5015.833856105804\n",
      "loss_compared with real:5.2707e-06,   miu_train:0.1149,    lossmean:0.0001177\n",
      "Epoch [78500/100000], Loss: 15.65,   LOSS_function: 15.62,   LOSS_E:0.004422,    LOSS_initial: 2.037e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5022.2980670928955\n",
      "loss_compared with real:5.2547e-06,   miu_train:0.1151,    lossmean:0.0001122\n",
      "Epoch [78600/100000], Loss: 15.6,   LOSS_function: 15.56,   LOSS_E:0.00442,    LOSS_initial: 2.412e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5028.431356906891\n",
      "loss_compared with real:5.2342e-06,   miu_train:0.1154,    lossmean:0.000109\n",
      "Epoch [78700/100000], Loss: 16.77,   LOSS_function: 16.42,   LOSS_E:0.004383,    LOSS_initial: 2.063e-05,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5034.528096914291\n",
      "loss_compared with real:5.2417e-06,   miu_train:0.1156,    lossmean:9.845e-05\n",
      "Epoch [78800/100000], Loss: 15.47,   LOSS_function: 15.43,   LOSS_E:0.004381,    LOSS_initial: 1.966e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5041.01997423172\n",
      "loss_compared with real:5.1838e-06,   miu_train:0.1159,    lossmean:0.0001088\n",
      "Epoch [78900/100000], Loss: 15.56,   LOSS_function: 15.42,   LOSS_E:0.004312,    LOSS_initial: 8.212e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.725e-05,    time: 5047.148521184921\n",
      "loss_compared with real:5.0568e-06,   miu_train:0.1163,    lossmean:0.0001237\n",
      "Epoch [79000/100000], Loss: 15.42,   LOSS_function: 15.37,   LOSS_E:0.004356,    LOSS_initial: 3.108e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5053.314531803131\n",
      "loss_compared with real:5.1481e-06,   miu_train:0.1166,    lossmean:9.769e-05\n",
      "Epoch [79100/100000], Loss: 15.3,   LOSS_function: 15.28,   LOSS_E:0.004324,    LOSS_initial: 1.416e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5059.476931810379\n",
      "loss_compared with real:5.1054e-06,   miu_train:0.1169,    lossmean:9.702e-05\n",
      "Epoch [79200/100000], Loss: 18.73,   LOSS_function: 17.94,   LOSS_E:0.004311,    LOSS_initial: 4.702e-05,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5065.715343475342\n",
      "loss_compared with real:5.0387e-06,   miu_train:0.1172,    lossmean:0.0001642\n",
      "Epoch [79300/100000], Loss: 15.14,   LOSS_function: 15.11,   LOSS_E:0.004293,    LOSS_initial: 1.873e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5071.789749860764\n",
      "loss_compared with real:5.0277e-06,   miu_train:0.1174,    lossmean:0.0001092\n",
      "Epoch [79400/100000], Loss: 15.18,   LOSS_function: 15.14,   LOSS_E:0.004332,    LOSS_initial: 2.264e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5077.969307899475\n",
      "loss_compared with real:5.0085e-06,   miu_train:0.1177,    lossmean:9.493e-05\n",
      "Epoch [79500/100000], Loss: 18.59,   LOSS_function: 17.73,   LOSS_E:0.004217,    LOSS_initial: 5.079e-05,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5084.038514375687\n",
      "loss_compared with real:5.2332e-06,   miu_train:0.118,    lossmean:5.483e-05\n",
      "Epoch [79600/100000], Loss: 14.96,   LOSS_function: 14.92,   LOSS_E:0.004245,    LOSS_initial: 1.955e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5090.188212633133\n",
      "loss_compared with real:4.9445e-06,   miu_train:0.1183,    lossmean:0.0001092\n",
      "Epoch [79700/100000], Loss: 14.9,   LOSS_function: 14.86,   LOSS_E:0.004219,    LOSS_initial: 2.211e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5096.278531551361\n",
      "loss_compared with real:4.9039e-06,   miu_train:0.1186,    lossmean:0.000116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79800/100000], Loss: 14.93,   LOSS_function: 14.89,   LOSS_E:0.004227,    LOSS_initial: 2.33e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5102.710810184479\n",
      "loss_compared with real:4.9142e-06,   miu_train:0.1189,    lossmean:0.0001084\n",
      "Epoch [79900/100000], Loss: 14.83,   LOSS_function: 14.8,   LOSS_E:0.004232,    LOSS_initial: 2.126e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.642e-05,    time: 5108.77663898468\n",
      "loss_compared with real:4.9017e-06,   miu_train:0.1191,    lossmean:9.098e-05\n",
      "Epoch [80000/100000], Loss: 14.8,   LOSS_function: 14.75,   LOSS_E:0.004198,    LOSS_initial: 3.129e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5115.369382858276\n",
      "loss_compared with real:4.7571e-06,   miu_train:0.1195,    lossmean:0.0001229\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5207, -0.5019, -0.2896, -0.9668, -0.0649, -0.3186,  0.4292, -0.8254,\n",
      "         0.8664,  0.3138,  0.7670,  0.5113,  0.5920, -0.0310,  0.6970, -0.3221,\n",
      "         0.8296,  0.0236,  0.7904, -0.8021, -0.2692, -0.9684, -0.4816, -0.3210,\n",
      "        -0.2980, -0.3494,  0.6962, -0.6256, -0.2318,  0.4138, -0.3079, -0.1884,\n",
      "         0.1043,  0.6306, -0.6917, -0.7998, -0.7084, -0.5399, -0.2556, -0.0371,\n",
      "        -0.8244, -0.9723, -0.0514,  0.8012, -0.5733,  0.8643, -0.6894,  0.9046,\n",
      "         0.6204, -0.9118, -0.7507, -0.3401,  0.8459, -0.6042,  0.9211, -0.1112,\n",
      "        -0.8982,  0.4104, -0.2541, -0.8644,  0.8318, -0.3138,  0.2533, -0.1139,\n",
      "        -0.5082, -0.0807, -0.0248,  0.4018, -0.4074, -0.3424,  0.5326, -0.4193,\n",
      "        -0.4789,  0.8826,  0.8012, -0.4208, -0.4398,  0.0200, -0.3106, -0.5253,\n",
      "        -0.7525, -0.6527,  0.9152,  0.0159,  0.1150,  0.7527,  0.6700,  0.2243,\n",
      "        -0.0328, -0.0843,  0.6258,  0.7126, -0.6027,  0.9426,  0.2177,  0.5752,\n",
      "        -0.6435, -0.1332,  0.5830,  0.0276, -0.8524,  0.0741, -0.0098, -0.1963,\n",
      "         0.4042,  0.4925,  0.6594,  0.0555,  0.2390,  0.6262, -0.6217, -0.2589,\n",
      "         0.5794,  0.7718,  0.7157,  0.0078, -0.9617,  0.8763, -0.2922, -0.8867,\n",
      "        -0.9649,  0.9006, -0.2281,  0.3611, -0.2269,  0.4228, -0.2026,  0.1827],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2938, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0226, -0.0327,  0.0249,  0.0669, -0.0379, -0.0371, -0.0310,  0.0360,\n",
      "        -0.0319,  0.0441, -0.0130, -0.1001,  0.0482, -0.0383,  0.0732,  0.0271,\n",
      "        -0.0451, -0.0209, -0.0117,  0.0353, -0.0671,  0.0626,  0.0357,  0.0181,\n",
      "         0.0126, -0.0129,  0.0640, -0.0438, -0.0362, -0.0772,  0.0277, -0.0647,\n",
      "         0.0830, -0.0436,  0.0610,  0.0017, -0.0704,  0.0558,  0.0355, -0.0599,\n",
      "        -0.0944, -0.0729,  0.0110,  0.0758,  0.0614,  0.0776, -0.0333,  0.0840,\n",
      "        -0.0300,  0.0044,  0.0403,  0.0161, -0.0276,  0.0144,  0.0048, -0.0078,\n",
      "         0.0610,  0.0303,  0.0353,  0.0333,  0.0065, -0.0178, -0.0235,  0.0528,\n",
      "         0.0595,  0.0038,  0.0728,  0.0129,  0.0341,  0.0236,  0.0489,  0.0064,\n",
      "        -0.0309,  0.0057, -0.0779,  0.0029, -0.0353,  0.0827, -0.0030,  0.0123,\n",
      "         0.0353, -0.0324, -0.0154,  0.0462,  0.0217, -0.0920, -0.0234, -0.0006,\n",
      "         0.0827,  0.0789,  0.0446,  0.0518, -0.0501, -0.0671,  0.0663, -0.0701,\n",
      "         0.0294,  0.0409,  0.0301,  0.0866,  0.0785,  0.0456,  0.0482,  0.0839,\n",
      "         0.0712, -0.0085, -0.0695, -0.0787,  0.0221, -0.0393,  0.0394,  0.0333,\n",
      "        -0.0180, -0.0445, -0.0028,  0.0229,  0.0314, -0.0723, -0.1080,  0.0318,\n",
      "         0.0715,  0.0172,  0.0267, -0.0193,  0.0138,  0.0170, -0.0628,  0.0650],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2694, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0754, -0.0475, -0.0369,  0.0248, -0.0631, -0.0258, -0.0498, -0.0094,\n",
      "        -0.0260,  0.0491,  0.0120, -0.0255, -0.0325, -0.0141, -0.0287, -0.0861,\n",
      "        -0.0439,  0.0439,  0.0326, -0.1175,  0.0186, -0.0293, -0.0441, -0.0075,\n",
      "         0.0398,  0.0110,  0.0574,  0.0108, -0.0908, -0.0735, -0.0247,  0.0237,\n",
      "         0.0207, -0.0232,  0.0621,  0.0843,  0.1003,  0.0167,  0.0365,  0.1040,\n",
      "        -0.0376,  0.0250,  0.0008, -0.0567,  0.0593,  0.0373, -0.0814, -0.0848,\n",
      "         0.0148, -0.0230, -0.0648,  0.0632,  0.0401, -0.0747,  0.0427,  0.0442,\n",
      "         0.0139, -0.0879,  0.0072, -0.0737,  0.0256,  0.0492, -0.0249,  0.0385,\n",
      "         0.0766, -0.0077,  0.0240, -0.0053,  0.0390,  0.0254, -0.0875, -0.0364,\n",
      "        -0.0156,  0.0436, -0.0022,  0.0662,  0.0849,  0.0043,  0.0012, -0.0168,\n",
      "         0.1260,  0.0134, -0.0604,  0.0975, -0.0177, -0.0140,  0.0147,  0.0701,\n",
      "        -0.0045, -0.0933,  0.0497, -0.0781,  0.0080, -0.0572, -0.0562,  0.0599,\n",
      "        -0.0558, -0.0898, -0.0841,  0.0708, -0.0699,  0.0216,  0.0225,  0.0364,\n",
      "        -0.0355, -0.0659,  0.0510, -0.0791, -0.1038, -0.0579, -0.0545,  0.0069,\n",
      "         0.0550, -0.0494, -0.0528, -0.0250, -0.0194, -0.0228,  0.0963,  0.0161,\n",
      "        -0.0362,  0.0233,  0.0809,  0.0935, -0.0378, -0.0863,  0.0067, -0.0703],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1048, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0671, -0.0430,  0.0099,  0.1156, -0.0976,  0.0486, -0.0318, -0.0305,\n",
      "         0.0584,  0.0048,  0.0410,  0.0576,  0.0577, -0.1274, -0.0678,  0.0330,\n",
      "        -0.0216, -0.0124, -0.0291, -0.0246, -0.0194,  0.0371,  0.0944,  0.0604,\n",
      "         0.0422, -0.0536, -0.0095, -0.0266, -0.0357,  0.0498,  0.0046,  0.0506,\n",
      "         0.0183,  0.0075, -0.0589,  0.0744, -0.0355, -0.1192, -0.0867,  0.0289,\n",
      "         0.0609, -0.0902,  0.0556,  0.0517,  0.0521, -0.0788,  0.0771, -0.0019,\n",
      "        -0.1177, -0.0859, -0.0393, -0.0795, -0.0448,  0.0623,  0.0229,  0.0338,\n",
      "        -0.0259, -0.0667,  0.0549,  0.0201,  0.0258, -0.0504, -0.0386, -0.0230,\n",
      "         0.0330, -0.0981, -0.0852, -0.0852,  0.0426, -0.0554, -0.0780, -0.0539,\n",
      "        -0.0193, -0.0174, -0.0703, -0.0043, -0.0171, -0.0765,  0.0532, -0.0130,\n",
      "        -0.0850,  0.0509, -0.0245,  0.0705,  0.0344, -0.1192, -0.0144, -0.0636,\n",
      "        -0.0181,  0.0184, -0.0816, -0.0858,  0.0856,  0.0750, -0.0013,  0.0596,\n",
      "        -0.0955, -0.0626,  0.0683, -0.0524, -0.0482,  0.0091, -0.0447, -0.0270,\n",
      "         0.0425,  0.0724,  0.0414, -0.0954,  0.0419, -0.1005,  0.0565,  0.0655,\n",
      "        -0.0352, -0.0274,  0.0864, -0.0123, -0.0838,  0.0094, -0.0243,  0.0635,\n",
      "         0.0850, -0.0366,  0.1070, -0.0878, -0.0589,  0.0296,  0.0050,  0.0612],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0694, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0196, 0.0274, 0.0811], requires_grad=True)\n",
      "Epoch [80100/100000], Loss: 14.67,   LOSS_function: 14.64,   LOSS_E:0.004168,    LOSS_initial: 1.895e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5121.936822652817\n",
      "loss_compared with real:4.7559e-06,   miu_train:0.1198,    lossmean:0.0001163\n",
      "Epoch [80200/100000], Loss: 14.87,   LOSS_function: 14.81,   LOSS_E:0.00416,    LOSS_initial: 3.623e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5128.7014853954315\n",
      "loss_compared with real:4.7545e-06,   miu_train:0.1201,    lossmean:0.0001161\n",
      "Epoch [80300/100000], Loss: 14.52,   LOSS_function: 14.49,   LOSS_E:0.004119,    LOSS_initial: 2.215e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5135.254601478577\n",
      "loss_compared with real:4.765e-06,   miu_train:0.1204,    lossmean:0.0001021\n",
      "Epoch [80400/100000], Loss: 14.45,   LOSS_function: 14.41,   LOSS_E:0.004102,    LOSS_initial: 2.198e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5141.871132850647\n",
      "loss_compared with real:4.7137e-06,   miu_train:0.1207,    lossmean:0.0001095\n",
      "Epoch [80500/100000], Loss: 14.4,   LOSS_function: 14.37,   LOSS_E:0.004085,    LOSS_initial: 1.564e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5148.436272382736\n",
      "loss_compared with real:4.6951e-06,   miu_train:0.121,    lossmean:0.0001062\n",
      "Epoch [80600/100000], Loss: 14.41,   LOSS_function: 14.29,   LOSS_E:0.004055,    LOSS_initial: 6.855e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5155.097738265991\n",
      "loss_compared with real:4.6507e-06,   miu_train:0.1213,    lossmean:0.0001262\n",
      "Epoch [80700/100000], Loss: 14.26,   LOSS_function: 14.23,   LOSS_E:0.004054,    LOSS_initial: 1.953e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5161.992626667023\n",
      "loss_compared with real:4.6412e-06,   miu_train:0.1216,    lossmean:0.0001077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80800/100000], Loss: 14.45,   LOSS_function: 14.41,   LOSS_E:0.004053,    LOSS_initial: 2.723e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5168.5672397613525\n",
      "loss_compared with real:4.5418e-06,   miu_train:0.1219,    lossmean:0.000135\n",
      "Epoch [80900/100000], Loss: 14.16,   LOSS_function: 14.11,   LOSS_E:0.004016,    LOSS_initial: 2.673e-06,\n",
      "lamda1:1,    lamda3:1.677e+04,      learn rate:1.563e-05,    time: 5175.18346118927\n",
      "loss_compared with real:4.5594e-06,   miu_train:0.1222,    lossmean:0.0001164\n",
      "Epoch [81000/100000], Loss: 14.66,   LOSS_function: 14.42,   LOSS_E:0.004042,    LOSS_initial: 1.591e-05,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5181.853225469589\n",
      "loss_compared with real:4.5175e-06,   miu_train:0.1225,    lossmean:0.0001015\n",
      "Epoch [81100/100000], Loss: 14.01,   LOSS_function: 13.98,   LOSS_E:0.003985,    LOSS_initial: 2.137e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5188.4170434474945\n",
      "loss_compared with real:4.6774e-06,   miu_train:0.1228,    lossmean:9.308e-05\n",
      "Epoch [81200/100000], Loss: 15,   LOSS_function: 14.96,   LOSS_E:0.004035,    LOSS_initial: 2.993e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5195.182702064514\n",
      "loss_compared with real:4.6296e-06,   miu_train:0.1231,    lossmean:0.0001435\n",
      "Epoch [81300/100000], Loss: 13.93,   LOSS_function: 13.9,   LOSS_E:0.003959,    LOSS_initial: 1.539e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5201.770378828049\n",
      "loss_compared with real:4.6389e-06,   miu_train:0.1234,    lossmean:8.544e-05\n",
      "Epoch [81400/100000], Loss: 13.9,   LOSS_function: 13.87,   LOSS_E:0.003925,    LOSS_initial: 2.197e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5208.419885158539\n",
      "loss_compared with real:4.6538e-06,   miu_train:0.1237,    lossmean:8.432e-05\n",
      "Epoch [81500/100000], Loss: 13.76,   LOSS_function: 13.72,   LOSS_E:0.003906,    LOSS_initial: 2.645e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5215.079242706299\n",
      "loss_compared with real:4.5594e-06,   miu_train:0.124,    lossmean:9.775e-05\n",
      "Epoch [81600/100000], Loss: 13.78,   LOSS_function: 13.76,   LOSS_E:0.003944,    LOSS_initial: 1.552e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5222.041352987289\n",
      "loss_compared with real:4.5831e-06,   miu_train:0.1243,    lossmean:8.915e-05\n",
      "Epoch [81700/100000], Loss: 13.75,   LOSS_function: 13.69,   LOSS_E:0.00389,    LOSS_initial: 3.805e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5228.533593654633\n",
      "loss_compared with real:4.5747e-06,   miu_train:0.1246,    lossmean:7.16e-05\n",
      "Epoch [81800/100000], Loss: 13.58,   LOSS_function: 13.52,   LOSS_E:0.003847,    LOSS_initial: 4.289e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5235.119281768799\n",
      "loss_compared with real:4.489e-06,   miu_train:0.1249,    lossmean:9.903e-05\n",
      "Epoch [81900/100000], Loss: 13.52,   LOSS_function: 13.5,   LOSS_E:0.003851,    LOSS_initial: 1.321e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.488e-05,    time: 5241.721156835556\n",
      "loss_compared with real:4.4345e-06,   miu_train:0.1252,    lossmean:9.8e-05\n",
      "Epoch [82000/100000], Loss: 13.45,   LOSS_function: 13.42,   LOSS_E:0.003823,    LOSS_initial: 1.802e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5248.347947835922\n",
      "loss_compared with real:4.4258e-06,   miu_train:0.1256,    lossmean:8.905e-05\n",
      "Epoch [82100/100000], Loss: 13.38,   LOSS_function: 13.34,   LOSS_E:0.003802,    LOSS_initial: 2.395e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5254.887788534164\n",
      "loss_compared with real:4.3905e-06,   miu_train:0.1259,    lossmean:9.204e-05\n",
      "Epoch [82200/100000], Loss: 13.33,   LOSS_function: 13.31,   LOSS_E:0.003797,    LOSS_initial: 1.226e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5261.613723278046\n",
      "loss_compared with real:4.3457e-06,   miu_train:0.1262,    lossmean:0.0001032\n",
      "Epoch [82300/100000], Loss: 13.29,   LOSS_function: 13.24,   LOSS_E:0.003773,    LOSS_initial: 3.009e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5268.185730218887\n",
      "loss_compared with real:4.3377e-06,   miu_train:0.1265,    lossmean:9.876e-05\n",
      "Epoch [82400/100000], Loss: 13.19,   LOSS_function: 13.16,   LOSS_E:0.00375,    LOSS_initial: 1.982e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5274.727092027664\n",
      "loss_compared with real:4.3165e-06,   miu_train:0.1268,    lossmean:9.012e-05\n",
      "Epoch [82500/100000], Loss: 13.56,   LOSS_function: 13.43,   LOSS_E:0.003742,    LOSS_initial: 8.162e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5281.597193241119\n",
      "loss_compared with real:4.4376e-06,   miu_train:0.1271,    lossmean:0.000101\n",
      "Epoch [82600/100000], Loss: 19.5,   LOSS_function: 18.28,   LOSS_E:0.003787,    LOSS_initial: 8.012e-05,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5287.797073602676\n",
      "loss_compared with real:4.3647e-06,   miu_train:0.1275,    lossmean:2.66e-05\n",
      "Epoch [82700/100000], Loss: 13.46,   LOSS_function: 13.37,   LOSS_E:0.003654,    LOSS_initial: 5.528e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5293.914566278458\n",
      "loss_compared with real:4.3973e-06,   miu_train:0.1278,    lossmean:6.732e-05\n",
      "Epoch [82800/100000], Loss: 13.96,   LOSS_function: 13.78,   LOSS_E:0.003707,    LOSS_initial: 1.169e-05,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5300.10284781456\n",
      "loss_compared with real:4.1546e-06,   miu_train:0.1281,    lossmean:8.816e-05\n",
      "Epoch [82900/100000], Loss: 15.58,   LOSS_function: 15.45,   LOSS_E:0.003641,    LOSS_initial: 8.183e-06,\n",
      "lamda1:1,    lamda3:1.514e+04,      learn rate:1.417e-05,    time: 5306.234485387802\n",
      "loss_compared with real:4.5264e-06,   miu_train:0.1284,    lossmean:3.127e-06\n",
      "Epoch [83000/100000], Loss: 14.19,   LOSS_function: 13.76,   LOSS_E:0.003664,    LOSS_initial: 1.747e-05,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5312.42698931694\n",
      "loss_compared with real:4.0428e-06,   miu_train:0.1288,    lossmean:8.454e-05\n",
      "Epoch [83100/100000], Loss: 12.85,   LOSS_function: 12.83,   LOSS_E:0.003675,    LOSS_initial: 1.002e-06,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5318.569042444229\n",
      "loss_compared with real:3.7742e-06,   miu_train:0.1284,    lossmean:0.0001503\n",
      "Epoch [83200/100000], Loss: 12.8,   LOSS_function: 12.79,   LOSS_E:0.003635,    LOSS_initial: 7.687e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5325.041379928589\n",
      "loss_compared with real:3.6897e-06,   miu_train:0.1287,    lossmean:0.000144\n",
      "Epoch [83300/100000], Loss: 12.77,   LOSS_function: 12.75,   LOSS_E:0.003625,    LOSS_initial: 7.569e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5331.169776916504\n",
      "loss_compared with real:3.6553e-06,   miu_train:0.129,    lossmean:0.0001401\n",
      "Epoch [83400/100000], Loss: 12.74,   LOSS_function: 12.72,   LOSS_E:0.003613,    LOSS_initial: 7.229e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5337.284533262253\n",
      "loss_compared with real:3.6292e-06,   miu_train:0.1293,    lossmean:0.0001383\n",
      "Epoch [83500/100000], Loss: 12.7,   LOSS_function: 12.68,   LOSS_E:0.003598,    LOSS_initial: 7.167e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5343.6569480896\n",
      "loss_compared with real:3.6052e-06,   miu_train:0.1295,    lossmean:0.0001381\n",
      "Epoch [83600/100000], Loss: 12.66,   LOSS_function: 12.65,   LOSS_E:0.003584,    LOSS_initial: 7.249e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5349.810382843018\n",
      "loss_compared with real:3.5842e-06,   miu_train:0.1298,    lossmean:0.0001387\n",
      "Epoch [83700/100000], Loss: 12.63,   LOSS_function: 12.61,   LOSS_E:0.003571,    LOSS_initial: 6.902e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5355.923500299454\n",
      "loss_compared with real:3.5645e-06,   miu_train:0.13,    lossmean:0.0001381\n",
      "Epoch [83800/100000], Loss: 12.59,   LOSS_function: 12.57,   LOSS_E:0.003556,    LOSS_initial: 7.007e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5362.012358903885\n",
      "loss_compared with real:3.5454e-06,   miu_train:0.1303,    lossmean:0.0001383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83900/100000], Loss: 12.81,   LOSS_function: 12.72,   LOSS_E:0.003562,    LOSS_initial: 3.708e-06,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.349e-05,    time: 5368.094002246857\n",
      "loss_compared with real:3.5176e-06,   miu_train:0.1305,    lossmean:0.0001147\n",
      "Epoch [84000/100000], Loss: 12.5,   LOSS_function: 12.48,   LOSS_E:0.003527,    LOSS_initial: 7.299e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5374.259534358978\n",
      "loss_compared with real:3.509e-06,   miu_train:0.1308,    lossmean:0.00014\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5205, -0.5010, -0.2897, -0.9668, -0.0649, -0.3185,  0.4289, -0.8252,\n",
      "         0.8664,  0.3139,  0.7672,  0.5110,  0.5918, -0.0311,  0.6972, -0.3222,\n",
      "         0.8296,  0.0237,  0.7900, -0.8019, -0.2701, -0.9683, -0.4814, -0.3212,\n",
      "        -0.2980, -0.3493,  0.6961, -0.6255, -0.2316,  0.4138, -0.3081, -0.1883,\n",
      "         0.1044,  0.6301, -0.6916, -0.7998, -0.7085, -0.5397, -0.2558, -0.0370,\n",
      "        -0.8246, -0.9726, -0.0515,  0.8012, -0.5724,  0.8644, -0.6895,  0.9050,\n",
      "         0.6205, -0.9118, -0.7505, -0.3399,  0.8459, -0.6042,  0.9211, -0.1113,\n",
      "        -0.8982,  0.4101, -0.2540, -0.8644,  0.8317, -0.3135,  0.2532, -0.1139,\n",
      "        -0.5091, -0.0806, -0.0250,  0.4007, -0.4078, -0.3423,  0.5330, -0.4190,\n",
      "        -0.4780,  0.8826,  0.8017, -0.4207, -0.4395,  0.0196, -0.3105, -0.5261,\n",
      "        -0.7523, -0.6525,  0.9154,  0.0155,  0.1147,  0.7526,  0.6698,  0.2243,\n",
      "        -0.0325, -0.0841,  0.6256,  0.7126, -0.6029,  0.9425,  0.2173,  0.5749,\n",
      "        -0.6436, -0.1331,  0.5830,  0.0274, -0.8523,  0.0735, -0.0095, -0.1962,\n",
      "         0.4041,  0.4923,  0.6595,  0.0550,  0.2391,  0.6266, -0.6210, -0.2589,\n",
      "         0.5794,  0.7716,  0.7157,  0.0074, -0.9618,  0.8763, -0.2921, -0.8869,\n",
      "        -0.9650,  0.9009, -0.2279,  0.3613, -0.2269,  0.4226, -0.2028,  0.1825],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2933, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0225, -0.0326,  0.0248,  0.0669, -0.0378, -0.0371, -0.0309,  0.0364,\n",
      "        -0.0320,  0.0442, -0.0131, -0.1002,  0.0483, -0.0382,  0.0732,  0.0272,\n",
      "        -0.0451, -0.0208, -0.0118,  0.0353, -0.0669,  0.0625,  0.0357,  0.0181,\n",
      "         0.0128, -0.0129,  0.0640, -0.0437, -0.0362, -0.0770,  0.0276, -0.0646,\n",
      "         0.0828, -0.0437,  0.0611,  0.0016, -0.0704,  0.0557,  0.0355, -0.0600,\n",
      "        -0.0945, -0.0728,  0.0111,  0.0761,  0.0614,  0.0775, -0.0334,  0.0840,\n",
      "        -0.0300,  0.0043,  0.0403,  0.0161, -0.0277,  0.0142,  0.0049, -0.0079,\n",
      "         0.0611,  0.0303,  0.0353,  0.0333,  0.0065, -0.0179, -0.0236,  0.0528,\n",
      "         0.0594,  0.0038,  0.0730,  0.0129,  0.0337,  0.0236,  0.0490,  0.0063,\n",
      "        -0.0308,  0.0054, -0.0778,  0.0030, -0.0355,  0.0827, -0.0031,  0.0122,\n",
      "         0.0353, -0.0323, -0.0155,  0.0463,  0.0218, -0.0918, -0.0234, -0.0007,\n",
      "         0.0826,  0.0790,  0.0446,  0.0519, -0.0502, -0.0670,  0.0663, -0.0703,\n",
      "         0.0296,  0.0411,  0.0299,  0.0866,  0.0786,  0.0457,  0.0481,  0.0837,\n",
      "         0.0713, -0.0085, -0.0694, -0.0790,  0.0223, -0.0394,  0.0393,  0.0333,\n",
      "        -0.0182, -0.0444, -0.0027,  0.0229,  0.0316, -0.0722, -0.1083,  0.0317,\n",
      "         0.0717,  0.0173,  0.0268, -0.0193,  0.0138,  0.0170, -0.0628,  0.0651],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2701, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0755, -0.0473, -0.0370,  0.0246, -0.0632, -0.0259, -0.0497, -0.0094,\n",
      "        -0.0260,  0.0491,  0.0123, -0.0255, -0.0330, -0.0142, -0.0288, -0.0863,\n",
      "        -0.0438,  0.0439,  0.0326, -0.1173,  0.0184, -0.0294, -0.0441, -0.0073,\n",
      "         0.0396,  0.0111,  0.0573,  0.0107, -0.0908, -0.0734, -0.0247,  0.0236,\n",
      "         0.0211, -0.0231,  0.0621,  0.0845,  0.0999,  0.0164,  0.0369,  0.1038,\n",
      "        -0.0375,  0.0250,  0.0008, -0.0571,  0.0592,  0.0372, -0.0816, -0.0848,\n",
      "         0.0148, -0.0231, -0.0648,  0.0632,  0.0402, -0.0748,  0.0428,  0.0444,\n",
      "         0.0138, -0.0880,  0.0072, -0.0735,  0.0259,  0.0492, -0.0246,  0.0386,\n",
      "         0.0766, -0.0078,  0.0238, -0.0053,  0.0391,  0.0254, -0.0876, -0.0365,\n",
      "        -0.0156,  0.0433, -0.0022,  0.0662,  0.0849,  0.0042,  0.0013, -0.0168,\n",
      "         0.1260,  0.0134, -0.0604,  0.0975, -0.0178, -0.0139,  0.0149,  0.0704,\n",
      "        -0.0044, -0.0938,  0.0497, -0.0784,  0.0080, -0.0572, -0.0560,  0.0601,\n",
      "        -0.0555, -0.0899, -0.0837,  0.0707, -0.0700,  0.0216,  0.0224,  0.0364,\n",
      "        -0.0355, -0.0659,  0.0512, -0.0791, -0.1037, -0.0582, -0.0546,  0.0069,\n",
      "         0.0550, -0.0498, -0.0528, -0.0249, -0.0195, -0.0229,  0.0964,  0.0162,\n",
      "        -0.0363,  0.0232,  0.0807,  0.0936, -0.0377, -0.0865,  0.0070, -0.0702],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1056, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0673, -0.0431,  0.0099,  0.1156, -0.0977,  0.0486, -0.0318, -0.0305,\n",
      "         0.0584,  0.0048,  0.0409,  0.0574,  0.0573, -0.1275, -0.0678,  0.0327,\n",
      "        -0.0217, -0.0125, -0.0293, -0.0246, -0.0194,  0.0371,  0.0945,  0.0604,\n",
      "         0.0421, -0.0535, -0.0096, -0.0266, -0.0356,  0.0500,  0.0046,  0.0506,\n",
      "         0.0182,  0.0075, -0.0588,  0.0744, -0.0356, -0.1191, -0.0868,  0.0290,\n",
      "         0.0609, -0.0902,  0.0556,  0.0516,  0.0522, -0.0788,  0.0769, -0.0019,\n",
      "        -0.1176, -0.0859, -0.0394, -0.0793, -0.0448,  0.0622,  0.0228,  0.0338,\n",
      "        -0.0259, -0.0667,  0.0552,  0.0201,  0.0259, -0.0503, -0.0386, -0.0228,\n",
      "         0.0331, -0.0979, -0.0850, -0.0853,  0.0426, -0.0555, -0.0781, -0.0538,\n",
      "        -0.0197, -0.0174, -0.0705, -0.0043, -0.0171, -0.0765,  0.0531, -0.0125,\n",
      "        -0.0849,  0.0509, -0.0245,  0.0706,  0.0343, -0.1193, -0.0145, -0.0637,\n",
      "        -0.0181,  0.0183, -0.0817, -0.0858,  0.0856,  0.0752, -0.0013,  0.0597,\n",
      "        -0.0956, -0.0626,  0.0684, -0.0524, -0.0481,  0.0091, -0.0447, -0.0272,\n",
      "         0.0424,  0.0724,  0.0413, -0.0955,  0.0418, -0.1005,  0.0568,  0.0656,\n",
      "        -0.0352, -0.0274,  0.0862, -0.0123, -0.0839,  0.0094, -0.0242,  0.0636,\n",
      "         0.0849, -0.0366,  0.1072, -0.0878, -0.0588,  0.0295,  0.0049,  0.0610],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0698, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0203, 0.0276, 0.0813], requires_grad=True)\n",
      "Epoch [84100/100000], Loss: 12.46,   LOSS_function: 12.44,   LOSS_E:0.003515,    LOSS_initial: 6.222e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5380.404057025909\n",
      "loss_compared with real:3.4911e-06,   miu_train:0.131,    lossmean:0.0001383\n",
      "Epoch [84200/100000], Loss: 12.5,   LOSS_function: 12.41,   LOSS_E:0.0035,    LOSS_initial: 3.561e-06,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5386.543306350708\n",
      "loss_compared with real:3.4811e-06,   miu_train:0.1313,    lossmean:0.0001505\n",
      "Epoch [84300/100000], Loss: 12.65,   LOSS_function: 12.5,   LOSS_E:0.003534,    LOSS_initial: 5.947e-06,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5392.738278627396\n",
      "loss_compared with real:3.3757e-06,   miu_train:0.1315,    lossmean:0.0001559\n",
      "Epoch [84400/100000], Loss: 12.82,   LOSS_function: 12.52,   LOSS_E:0.003455,    LOSS_initial: 1.2e-05,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5398.8841733932495\n",
      "loss_compared with real:3.44e-06,   miu_train:0.1317,    lossmean:0.0001552\n",
      "Epoch [84500/100000], Loss: 12.28,   LOSS_function: 12.27,   LOSS_E:0.003462,    LOSS_initial: 6.416e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5405.263124704361\n",
      "loss_compared with real:3.424e-06,   miu_train:0.132,    lossmean:0.0001377\n",
      "Epoch [84600/100000], Loss: 12.28,   LOSS_function: 12.23,   LOSS_E:0.003446,    LOSS_initial: 1.896e-06,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5411.41396021843\n",
      "loss_compared with real:3.4026e-06,   miu_train:0.1323,    lossmean:0.0001503\n",
      "Epoch [84700/100000], Loss: 12.19,   LOSS_function: 12.17,   LOSS_E:0.003432,    LOSS_initial: 7.88e-07,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5417.936638593674\n",
      "loss_compared with real:3.3881e-06,   miu_train:0.1325,    lossmean:0.0001395\n",
      "Epoch [84800/100000], Loss: 12.78,   LOSS_function: 12.69,   LOSS_E:0.003447,    LOSS_initial: 3.759e-06,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5424.550447702408\n",
      "loss_compared with real:3.4746e-06,   miu_train:0.1328,    lossmean:9.026e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84900/100000], Loss: 12.64,   LOSS_function: 12.3,   LOSS_E:0.003429,    LOSS_initial: 1.36e-05,\n",
      "lamda1:1,    lamda3:2.435e+04,      learn rate:1.284e-05,    time: 5431.092484474182\n",
      "loss_compared with real:3.2514e-06,   miu_train:0.1331,    lossmean:0.000168\n",
      "Epoch [85000/100000], Loss: 13.3,   LOSS_function: 12.57,   LOSS_E:0.003356,    LOSS_initial: 3.575e-05,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5437.836654186249\n",
      "loss_compared with real:3.4058e-06,   miu_train:0.1334,    lossmean:0.0001543\n",
      "Epoch [85100/100000], Loss: 12,   LOSS_function: 11.98,   LOSS_E:0.003374,    LOSS_initial: 9.616e-07,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5444.4186108112335\n",
      "loss_compared with real:3.4293e-06,   miu_train:0.1336,    lossmean:0.0001219\n",
      "Epoch [85200/100000], Loss: 12.16,   LOSS_function: 12.15,   LOSS_E:0.003363,    LOSS_initial: 7.921e-07,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5451.12503027916\n",
      "loss_compared with real:3.4571e-06,   miu_train:0.1339,    lossmean:8.337e-05\n",
      "Epoch [85300/100000], Loss: 11.9,   LOSS_function: 11.88,   LOSS_E:0.003343,    LOSS_initial: 9.557e-07,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5457.785717248917\n",
      "loss_compared with real:3.3867e-06,   miu_train:0.1342,    lossmean:0.0001229\n",
      "Epoch [85400/100000], Loss: 11.86,   LOSS_function: 11.84,   LOSS_E:0.003333,    LOSS_initial: 1.047e-06,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5464.74304151535\n",
      "loss_compared with real:3.3793e-06,   miu_train:0.1344,    lossmean:0.0001174\n",
      "Epoch [85500/100000], Loss: 11.8,   LOSS_function: 11.78,   LOSS_E:0.003312,    LOSS_initial: 8.719e-07,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5471.305782794952\n",
      "loss_compared with real:3.3485e-06,   miu_train:0.1347,    lossmean:0.0001222\n",
      "Epoch [85600/100000], Loss: 11.9,   LOSS_function: 11.84,   LOSS_E:0.003293,    LOSS_initial: 2.642e-06,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5477.920454978943\n",
      "loss_compared with real:3.3641e-06,   miu_train:0.135,    lossmean:0.0001085\n",
      "Epoch [85700/100000], Loss: 11.71,   LOSS_function: 11.7,   LOSS_E:0.003289,    LOSS_initial: 4.604e-07,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5484.5185124874115\n",
      "loss_compared with real:3.303e-06,   miu_train:0.1353,    lossmean:0.0001179\n",
      "Epoch [85800/100000], Loss: 11.68,   LOSS_function: 11.66,   LOSS_E:0.00328,    LOSS_initial: 7.774e-07,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5491.153646230698\n",
      "loss_compared with real:3.2616e-06,   miu_train:0.1356,    lossmean:0.0001469\n",
      "Epoch [85900/100000], Loss: 11.62,   LOSS_function: 11.59,   LOSS_E:0.003262,    LOSS_initial: 1.165e-06,\n",
      "lamda1:1,    lamda3:2.038e+04,      learn rate:1.222e-05,    time: 5497.796966314316\n",
      "loss_compared with real:3.2723e-06,   miu_train:0.1359,    lossmean:0.000124\n",
      "Epoch [86000/100000], Loss: 12.76,   LOSS_function: 12.35,   LOSS_E:0.003257,    LOSS_initial: 1.34e-05,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5504.411384820938\n",
      "loss_compared with real:3.0063e-06,   miu_train:0.1362,    lossmean:0.0002326\n",
      "Epoch [86100/100000], Loss: 11.55,   LOSS_function: 11.54,   LOSS_E:0.00331,    LOSS_initial: 3.779e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5510.973939180374\n",
      "loss_compared with real:3.0977e-06,   miu_train:0.1361,    lossmean:0.000142\n",
      "Epoch [86200/100000], Loss: 11.52,   LOSS_function: 11.5,   LOSS_E:0.003233,    LOSS_initial: 4.062e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5517.6381294727325\n",
      "loss_compared with real:3.0422e-06,   miu_train:0.1364,    lossmean:0.0001527\n",
      "Epoch [86300/100000], Loss: 11.49,   LOSS_function: 11.47,   LOSS_E:0.00322,    LOSS_initial: 3.879e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5524.623492240906\n",
      "loss_compared with real:3.0193e-06,   miu_train:0.1366,    lossmean:0.0001522\n",
      "Epoch [86400/100000], Loss: 11.46,   LOSS_function: 11.44,   LOSS_E:0.00321,    LOSS_initial: 3.815e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5531.250844478607\n",
      "loss_compared with real:3.0011e-06,   miu_train:0.1369,    lossmean:0.0001507\n",
      "Epoch [86500/100000], Loss: 11.42,   LOSS_function: 11.41,   LOSS_E:0.003199,    LOSS_initial: 3.752e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5537.8378229141235\n",
      "loss_compared with real:2.9857e-06,   miu_train:0.1371,    lossmean:0.0001496\n",
      "Epoch [86600/100000], Loss: 11.39,   LOSS_function: 11.38,   LOSS_E:0.003186,    LOSS_initial: 4.312e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5544.437877655029\n",
      "loss_compared with real:2.9699e-06,   miu_train:0.1373,    lossmean:0.0001503\n",
      "Epoch [86700/100000], Loss: 11.36,   LOSS_function: 11.35,   LOSS_E:0.003175,    LOSS_initial: 2.639e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5551.035176992416\n",
      "loss_compared with real:2.9566e-06,   miu_train:0.1376,    lossmean:0.0001493\n",
      "Epoch [86800/100000], Loss: 17.19,   LOSS_function: 13.41,   LOSS_E:0.003249,    LOSS_initial: 0.0001232,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5557.706509590149\n",
      "loss_compared with real:2.9781e-06,   miu_train:0.1378,    lossmean:9.811e-05\n",
      "Epoch [86900/100000], Loss: 11.28,   LOSS_function: 11.27,   LOSS_E:0.003149,    LOSS_initial: 4.421e-07,\n",
      "lamda1:1,    lamda3:3.067e+04,      learn rate:1.164e-05,    time: 5564.265567541122\n",
      "loss_compared with real:2.9275e-06,   miu_train:0.138,    lossmean:0.0001511\n",
      "Epoch [87000/100000], Loss: 12.35,   LOSS_function: 11.83,   LOSS_E:0.003175,    LOSS_initial: 2.536e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5570.8951053619385\n",
      "loss_compared with real:2.9196e-06,   miu_train:0.1382,    lossmean:0.0001461\n",
      "Epoch [87100/100000], Loss: 11.2,   LOSS_function: 11.18,   LOSS_E:0.003123,    LOSS_initial: 8.276e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5577.460206031799\n",
      "loss_compared with real:3.0983e-06,   miu_train:0.1385,    lossmean:0.0001199\n",
      "Epoch [87200/100000], Loss: 11.16,   LOSS_function: 11.15,   LOSS_E:0.003111,    LOSS_initial: 8.289e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5584.274271249771\n",
      "loss_compared with real:3.0828e-06,   miu_train:0.1387,    lossmean:0.0001199\n",
      "Epoch [87300/100000], Loss: 11.12,   LOSS_function: 11.1,   LOSS_E:0.003098,    LOSS_initial: 8.261e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5590.54617190361\n",
      "loss_compared with real:3.0653e-06,   miu_train:0.139,    lossmean:0.0001198\n",
      "Epoch [87400/100000], Loss: 11.08,   LOSS_function: 11.06,   LOSS_E:0.003083,    LOSS_initial: 8.068e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5596.718025684357\n",
      "loss_compared with real:3.0483e-06,   miu_train:0.1392,    lossmean:0.0001194\n",
      "Epoch [87500/100000], Loss: 11.09,   LOSS_function: 11.08,   LOSS_E:0.00308,    LOSS_initial: 5.565e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5602.801564693451\n",
      "loss_compared with real:3.0484e-06,   miu_train:0.1395,    lossmean:0.0001112\n",
      "Epoch [87600/100000], Loss: 11,   LOSS_function: 10.98,   LOSS_E:0.003056,    LOSS_initial: 7.021e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5608.900121688843\n",
      "loss_compared with real:3.0105e-06,   miu_train:0.1398,    lossmean:0.0001209\n",
      "Epoch [87700/100000], Loss: 12.01,   LOSS_function: 11.83,   LOSS_E:0.003044,    LOSS_initial: 8.678e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5615.040341615677\n",
      "loss_compared with real:2.967e-06,   miu_train:0.1401,    lossmean:0.0001653\n",
      "Epoch [87800/100000], Loss: 10.9,   LOSS_function: 10.88,   LOSS_E:0.003026,    LOSS_initial: 8.748e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5621.414238214493\n",
      "loss_compared with real:2.9797e-06,   miu_train:0.1403,    lossmean:0.0001204\n",
      "Epoch [87900/100000], Loss: 10.87,   LOSS_function: 10.86,   LOSS_E:0.003018,    LOSS_initial: 4.468e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.108e-05,    time: 5627.563423871994\n",
      "loss_compared with real:2.968e-06,   miu_train:0.1406,    lossmean:0.0001144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88000/100000], Loss: 10.82,   LOSS_function: 10.8,   LOSS_E:0.003,    LOSS_initial: 5.927e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5633.708309412003\n",
      "loss_compared with real:2.9445e-06,   miu_train:0.1408,    lossmean:0.0001196\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5204, -0.5003, -0.2898, -0.9668, -0.0650, -0.3184,  0.4289, -0.8251,\n",
      "         0.8664,  0.3139,  0.7672,  0.5107,  0.5916, -0.0312,  0.6973, -0.3222,\n",
      "         0.8295,  0.0237,  0.7897, -0.8018, -0.2706, -0.9681, -0.4811, -0.3214,\n",
      "        -0.2980, -0.3492,  0.6962, -0.6253, -0.2316,  0.4138, -0.3082, -0.1882,\n",
      "         0.1045,  0.6298, -0.6916, -0.7999, -0.7087, -0.5396, -0.2559, -0.0370,\n",
      "        -0.8247, -0.9729, -0.0515,  0.8013, -0.5717,  0.8644, -0.6896,  0.9052,\n",
      "         0.6205, -0.9119, -0.7505, -0.3398,  0.8459, -0.6042,  0.9212, -0.1114,\n",
      "        -0.8982,  0.4098, -0.2540, -0.8643,  0.8316, -0.3134,  0.2532, -0.1139,\n",
      "        -0.5098, -0.0806, -0.0251,  0.4001, -0.4081, -0.3422,  0.5333, -0.4189,\n",
      "        -0.4775,  0.8827,  0.8020, -0.4207, -0.4393,  0.0194, -0.3105, -0.5267,\n",
      "        -0.7522, -0.6524,  0.9154,  0.0153,  0.1146,  0.7525,  0.6697,  0.2243,\n",
      "        -0.0324, -0.0839,  0.6254,  0.7126, -0.6031,  0.9425,  0.2171,  0.5747,\n",
      "        -0.6437, -0.1330,  0.5830,  0.0272, -0.8523,  0.0731, -0.0093, -0.1961,\n",
      "         0.4040,  0.4922,  0.6596,  0.0548,  0.2391,  0.6269, -0.6206, -0.2589,\n",
      "         0.5794,  0.7715,  0.7156,  0.0072, -0.9619,  0.8763, -0.2922, -0.8870,\n",
      "        -0.9651,  0.9011, -0.2276,  0.3614, -0.2270,  0.4225, -0.2028,  0.1823],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2930, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0225, -0.0326,  0.0247,  0.0668, -0.0377, -0.0370, -0.0308,  0.0367,\n",
      "        -0.0321,  0.0443, -0.0132, -0.1003,  0.0483, -0.0381,  0.0732,  0.0273,\n",
      "        -0.0450, -0.0208, -0.0118,  0.0352, -0.0667,  0.0626,  0.0356,  0.0181,\n",
      "         0.0129, -0.0128,  0.0639, -0.0437, -0.0362, -0.0769,  0.0274, -0.0647,\n",
      "         0.0826, -0.0437,  0.0611,  0.0015, -0.0704,  0.0557,  0.0354, -0.0601,\n",
      "        -0.0946, -0.0728,  0.0111,  0.0762,  0.0615,  0.0774, -0.0334,  0.0840,\n",
      "        -0.0300,  0.0043,  0.0403,  0.0161, -0.0278,  0.0141,  0.0050, -0.0080,\n",
      "         0.0611,  0.0303,  0.0353,  0.0333,  0.0065, -0.0180, -0.0237,  0.0528,\n",
      "         0.0594,  0.0037,  0.0731,  0.0129,  0.0336,  0.0235,  0.0491,  0.0063,\n",
      "        -0.0307,  0.0053, -0.0778,  0.0031, -0.0357,  0.0826, -0.0031,  0.0122,\n",
      "         0.0353, -0.0322, -0.0156,  0.0464,  0.0218, -0.0916, -0.0234, -0.0007,\n",
      "         0.0827,  0.0791,  0.0447,  0.0519, -0.0506, -0.0669,  0.0663, -0.0705,\n",
      "         0.0297,  0.0413,  0.0297,  0.0865,  0.0787,  0.0458,  0.0480,  0.0836,\n",
      "         0.0714, -0.0086, -0.0693, -0.0791,  0.0225, -0.0395,  0.0392,  0.0333,\n",
      "        -0.0184, -0.0443, -0.0026,  0.0229,  0.0317, -0.0720, -0.1083,  0.0318,\n",
      "         0.0719,  0.0175,  0.0269, -0.0193,  0.0137,  0.0170, -0.0628,  0.0651],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2706, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0756, -0.0472, -0.0370,  0.0245, -0.0633, -0.0259, -0.0496, -0.0094,\n",
      "        -0.0259,  0.0491,  0.0124, -0.0255, -0.0336, -0.0143, -0.0288, -0.0864,\n",
      "        -0.0437,  0.0440,  0.0326, -0.1171,  0.0182, -0.0294, -0.0441, -0.0072,\n",
      "         0.0395,  0.0111,  0.0572,  0.0107, -0.0908, -0.0734, -0.0247,  0.0236,\n",
      "         0.0213, -0.0230,  0.0621,  0.0845,  0.0998,  0.0163,  0.0372,  0.1036,\n",
      "        -0.0375,  0.0250,  0.0009, -0.0573,  0.0591,  0.0370, -0.0818, -0.0847,\n",
      "         0.0147, -0.0231, -0.0647,  0.0632,  0.0402, -0.0748,  0.0428,  0.0445,\n",
      "         0.0138, -0.0880,  0.0072, -0.0733,  0.0262,  0.0491, -0.0244,  0.0386,\n",
      "         0.0766, -0.0080,  0.0237, -0.0054,  0.0392,  0.0253, -0.0876, -0.0365,\n",
      "        -0.0156,  0.0431, -0.0022,  0.0662,  0.0849,  0.0042,  0.0013, -0.0168,\n",
      "         0.1260,  0.0133, -0.0604,  0.0974, -0.0179, -0.0139,  0.0150,  0.0705,\n",
      "        -0.0044, -0.0942,  0.0497, -0.0786,  0.0081, -0.0571, -0.0558,  0.0603,\n",
      "        -0.0552, -0.0899, -0.0836,  0.0707, -0.0701,  0.0217,  0.0223,  0.0363,\n",
      "        -0.0356, -0.0658,  0.0513, -0.0792, -0.1036, -0.0583, -0.0547,  0.0068,\n",
      "         0.0549, -0.0501, -0.0528, -0.0249, -0.0196, -0.0231,  0.0966,  0.0162,\n",
      "        -0.0364,  0.0231,  0.0806,  0.0936, -0.0376, -0.0865,  0.0072, -0.0702],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1063, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0674, -0.0433,  0.0099,  0.1157, -0.0977,  0.0486, -0.0318, -0.0305,\n",
      "         0.0584,  0.0048,  0.0407,  0.0573,  0.0571, -0.1276, -0.0679,  0.0326,\n",
      "        -0.0218, -0.0126, -0.0295, -0.0245, -0.0194,  0.0371,  0.0945,  0.0604,\n",
      "         0.0420, -0.0534, -0.0096, -0.0265, -0.0355,  0.0502,  0.0047,  0.0506,\n",
      "         0.0182,  0.0075, -0.0588,  0.0744, -0.0356, -0.1191, -0.0868,  0.0291,\n",
      "         0.0610, -0.0902,  0.0556,  0.0516,  0.0523, -0.0788,  0.0767, -0.0020,\n",
      "        -0.1176, -0.0859, -0.0395, -0.0791, -0.0447,  0.0621,  0.0227,  0.0337,\n",
      "        -0.0259, -0.0668,  0.0554,  0.0201,  0.0260, -0.0502, -0.0385, -0.0227,\n",
      "         0.0331, -0.0976, -0.0848, -0.0854,  0.0426, -0.0554, -0.0782, -0.0537,\n",
      "        -0.0198, -0.0174, -0.0707, -0.0043, -0.0171, -0.0764,  0.0530, -0.0122,\n",
      "        -0.0848,  0.0509, -0.0246,  0.0706,  0.0343, -0.1194, -0.0146, -0.0637,\n",
      "        -0.0181,  0.0182, -0.0818, -0.0857,  0.0857,  0.0752, -0.0013,  0.0597,\n",
      "        -0.0956, -0.0627,  0.0685, -0.0524, -0.0480,  0.0090, -0.0448, -0.0273,\n",
      "         0.0423,  0.0723,  0.0412, -0.0955,  0.0418, -0.1005,  0.0569,  0.0657,\n",
      "        -0.0351, -0.0273,  0.0860, -0.0123, -0.0839,  0.0093, -0.0242,  0.0637,\n",
      "         0.0848, -0.0366,  0.1073, -0.0878, -0.0587,  0.0295,  0.0049,  0.0609],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0701, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0207, 0.0277, 0.0814], requires_grad=True)\n",
      "Epoch [88100/100000], Loss: 10.77,   LOSS_function: 10.75,   LOSS_E:0.002984,    LOSS_initial: 8.091e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5639.864518165588\n",
      "loss_compared with real:2.9265e-06,   miu_train:0.1411,    lossmean:0.0001187\n",
      "Epoch [88200/100000], Loss: 10.84,   LOSS_function: 10.82,   LOSS_E:0.002987,    LOSS_initial: 9.894e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5646.320310354233\n",
      "loss_compared with real:2.9021e-06,   miu_train:0.1414,    lossmean:0.0001144\n",
      "Epoch [88300/100000], Loss: 16.43,   LOSS_function: 15.89,   LOSS_E:0.002951,    LOSS_initial: 2.655e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5652.422539234161\n",
      "loss_compared with real:3.047e-06,   miu_train:0.1417,    lossmean:3.986e-05\n",
      "Epoch [88400/100000], Loss: 10.63,   LOSS_function: 10.61,   LOSS_E:0.002941,    LOSS_initial: 7.823e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5658.63072514534\n",
      "loss_compared with real:2.8768e-06,   miu_train:0.1419,    lossmean:0.000118\n",
      "Epoch [88500/100000], Loss: 10.59,   LOSS_function: 10.58,   LOSS_E:0.002928,    LOSS_initial: 6.549e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5664.726370334625\n",
      "loss_compared with real:2.8642e-06,   miu_train:0.1422,    lossmean:0.0001169\n",
      "Epoch [88600/100000], Loss: 12.16,   LOSS_function: 12.02,   LOSS_E:0.002964,    LOSS_initial: 6.51e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5670.907916307449\n",
      "loss_compared with real:2.7788e-06,   miu_train:0.1425,    lossmean:0.0001575\n",
      "Epoch [88700/100000], Loss: 10.77,   LOSS_function: 10.66,   LOSS_E:0.002926,    LOSS_initial: 5.025e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5677.075256347656\n",
      "loss_compared with real:2.7881e-06,   miu_train:0.1428,    lossmean:0.0001051\n",
      "Epoch [88800/100000], Loss: 10.47,   LOSS_function: 10.44,   LOSS_E:0.002882,    LOSS_initial: 1.385e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5683.226543903351\n",
      "loss_compared with real:2.8158e-06,   miu_train:0.1431,    lossmean:0.0001141\n",
      "Epoch [88900/100000], Loss: 10.42,   LOSS_function: 10.41,   LOSS_E:0.002876,    LOSS_initial: 2.768e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.055e-05,    time: 5689.308044195175\n",
      "loss_compared with real:2.7861e-06,   miu_train:0.1434,    lossmean:0.000115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89000/100000], Loss: 10.36,   LOSS_function: 10.33,   LOSS_E:0.002848,    LOSS_initial: 1.216e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5695.512305021286\n",
      "loss_compared with real:2.7813e-06,   miu_train:0.1437,    lossmean:0.0001156\n",
      "Epoch [89100/100000], Loss: 10.68,   LOSS_function: 10.49,   LOSS_E:0.002873,    LOSS_initial: 9.229e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5701.590485095978\n",
      "loss_compared with real:2.6869e-06,   miu_train:0.144,    lossmean:0.0001139\n",
      "Epoch [89200/100000], Loss: 10.27,   LOSS_function: 10.25,   LOSS_E:0.002834,    LOSS_initial: 1.143e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5708.022954940796\n",
      "loss_compared with real:2.7248e-06,   miu_train:0.1443,    lossmean:0.0001214\n",
      "Epoch [89300/100000], Loss: 10.22,   LOSS_function: 10.21,   LOSS_E:0.002812,    LOSS_initial: 4.97e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5714.157699584961\n",
      "loss_compared with real:2.7085e-06,   miu_train:0.1445,    lossmean:0.0001177\n",
      "Epoch [89400/100000], Loss: 10.19,   LOSS_function: 10.18,   LOSS_E:0.002797,    LOSS_initial: 3.959e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5720.880745172501\n",
      "loss_compared with real:2.7084e-06,   miu_train:0.1448,    lossmean:0.0001099\n",
      "Epoch [89500/100000], Loss: 10.15,   LOSS_function: 10.12,   LOSS_E:0.002785,    LOSS_initial: 1.386e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5727.388384342194\n",
      "loss_compared with real:2.6897e-06,   miu_train:0.1451,    lossmean:0.0001167\n",
      "Epoch [89600/100000], Loss: 10.15,   LOSS_function: 10.07,   LOSS_E:0.002761,    LOSS_initial: 3.979e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5734.021795511246\n",
      "loss_compared with real:2.6688e-06,   miu_train:0.1454,    lossmean:0.000119\n",
      "Epoch [89700/100000], Loss: 10.03,   LOSS_function: 10.02,   LOSS_E:0.002758,    LOSS_initial: 5.233e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5740.592051744461\n",
      "loss_compared with real:2.6549e-06,   miu_train:0.1457,    lossmean:0.0001114\n",
      "Epoch [89800/100000], Loss: 9.993,   LOSS_function: 9.973,   LOSS_E:0.002741,    LOSS_initial: 9.263e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5747.280156373978\n",
      "loss_compared with real:2.6151e-06,   miu_train:0.146,    lossmean:0.0001173\n",
      "Epoch [89900/100000], Loss: 9.939,   LOSS_function: 9.92,   LOSS_E:0.002722,    LOSS_initial: 9.248e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:1.004e-05,    time: 5753.846613883972\n",
      "loss_compared with real:2.6055e-06,   miu_train:0.1463,    lossmean:0.0001192\n",
      "Epoch [90000/100000], Loss: 9.907,   LOSS_function: 9.869,   LOSS_E:0.002704,    LOSS_initial: 1.814e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5760.6667194366455\n",
      "loss_compared with real:2.5927e-06,   miu_train:0.1466,    lossmean:0.00012\n",
      "Epoch [90100/100000], Loss: 9.94,   LOSS_function: 9.921,   LOSS_E:0.002701,    LOSS_initial: 8.662e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5767.744174003601\n",
      "loss_compared with real:2.5716e-06,   miu_train:0.1469,    lossmean:0.0001055\n",
      "Epoch [90200/100000], Loss: 9.799,   LOSS_function: 9.78,   LOSS_E:0.002676,    LOSS_initial: 8.8e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5774.342843532562\n",
      "loss_compared with real:2.5618e-06,   miu_train:0.1472,    lossmean:0.0001151\n",
      "Epoch [90300/100000], Loss: 9.773,   LOSS_function: 9.73,   LOSS_E:0.002657,    LOSS_initial: 2.056e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5780.9440705776215\n",
      "loss_compared with real:2.5645e-06,   miu_train:0.1475,    lossmean:0.0001141\n",
      "Epoch [90400/100000], Loss: 9.715,   LOSS_function: 9.692,   LOSS_E:0.002648,    LOSS_initial: 1.099e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5787.677971839905\n",
      "loss_compared with real:2.5228e-06,   miu_train:0.1477,    lossmean:0.000121\n",
      "Epoch [90500/100000], Loss: 9.673,   LOSS_function: 9.643,   LOSS_E:0.002634,    LOSS_initial: 1.42e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5794.226244926453\n",
      "loss_compared with real:2.5177e-06,   miu_train:0.148,    lossmean:0.0001131\n",
      "Epoch [90600/100000], Loss: 9.626,   LOSS_function: 9.618,   LOSS_E:0.002624,    LOSS_initial: 3.545e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5800.920207262039\n",
      "loss_compared with real:2.4872e-06,   miu_train:0.1483,    lossmean:0.000114\n",
      "Epoch [90700/100000], Loss: 9.657,   LOSS_function: 9.598,   LOSS_E:0.002601,    LOSS_initial: 2.857e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5807.46787405014\n",
      "loss_compared with real:2.4832e-06,   miu_train:0.1486,    lossmean:0.0001245\n",
      "Epoch [90800/100000], Loss: 10.04,   LOSS_function: 9.884,   LOSS_E:0.002612,    LOSS_initial: 7.381e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5814.080676794052\n",
      "loss_compared with real:2.4308e-06,   miu_train:0.1489,    lossmean:0.00011\n",
      "Epoch [90900/100000], Loss: 9.489,   LOSS_function: 9.462,   LOSS_E:0.002573,    LOSS_initial: 1.262e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.559e-06,    time: 5820.681704282761\n",
      "loss_compared with real:2.4496e-06,   miu_train:0.1492,    lossmean:0.0001127\n",
      "Epoch [91000/100000], Loss: 9.487,   LOSS_function: 9.457,   LOSS_E:0.002567,    LOSS_initial: 1.465e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5827.679992675781\n",
      "loss_compared with real:2.3871e-06,   miu_train:0.1495,    lossmean:0.000117\n",
      "Epoch [91100/100000], Loss: 10.26,   LOSS_function: 10.16,   LOSS_E:0.002561,    LOSS_initial: 4.826e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5834.222320795059\n",
      "loss_compared with real:2.3626e-06,   miu_train:0.1499,    lossmean:0.0001651\n",
      "Epoch [91200/100000], Loss: 9.365,   LOSS_function: 9.331,   LOSS_E:0.002526,    LOSS_initial: 1.643e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5840.917343616486\n",
      "loss_compared with real:2.3881e-06,   miu_train:0.1501,    lossmean:0.0001124\n",
      "Epoch [91300/100000], Loss: 9.307,   LOSS_function: 9.298,   LOSS_E:0.00252,    LOSS_initial: 4.498e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5847.462068796158\n",
      "loss_compared with real:2.3706e-06,   miu_train:0.1504,    lossmean:0.0001128\n",
      "Epoch [91400/100000], Loss: 9.264,   LOSS_function: 9.252,   LOSS_E:0.002504,    LOSS_initial: 5.293e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5854.210983276367\n",
      "loss_compared with real:2.3598e-06,   miu_train:0.1507,    lossmean:0.0001113\n",
      "Epoch [91500/100000], Loss: 9.219,   LOSS_function: 9.209,   LOSS_E:0.002493,    LOSS_initial: 4.631e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5860.775577068329\n",
      "loss_compared with real:2.3359e-06,   miu_train:0.151,    lossmean:0.000113\n",
      "Epoch [91600/100000], Loss: 9.201,   LOSS_function: 9.165,   LOSS_E:0.002489,    LOSS_initial: 1.712e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5867.448954105377\n",
      "loss_compared with real:2.3346e-06,   miu_train:0.1513,    lossmean:0.0001122\n",
      "Epoch [91700/100000], Loss: 9.135,   LOSS_function: 9.107,   LOSS_E:0.002458,    LOSS_initial: 1.336e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5873.9765112400055\n",
      "loss_compared with real:2.3222e-06,   miu_train:0.1516,    lossmean:0.000112\n",
      "Epoch [91800/100000], Loss: 9.088,   LOSS_function: 9.073,   LOSS_E:0.002445,    LOSS_initial: 7.284e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5880.633971452713\n",
      "loss_compared with real:2.2988e-06,   miu_train:0.1519,    lossmean:0.0001111\n",
      "Epoch [91900/100000], Loss: 9.054,   LOSS_function: 9.036,   LOSS_E:0.002431,    LOSS_initial: 8.701e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:9.1e-06,    time: 5887.337815761566\n",
      "loss_compared with real:2.2718e-06,   miu_train:0.1522,    lossmean:0.0001166\n",
      "Epoch [92000/100000], Loss: 9.002,   LOSS_function: 8.987,   LOSS_E:0.002417,    LOSS_initial: 7.129e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5893.5095336437225\n",
      "loss_compared with real:2.2646e-06,   miu_train:0.1525,    lossmean:0.0001118\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5203, -0.4996, -0.2899, -0.9669, -0.0650, -0.3182,  0.4287, -0.8249,\n",
      "         0.8664,  0.3140,  0.7674,  0.5105,  0.5915, -0.0312,  0.6974, -0.3223,\n",
      "         0.8295,  0.0237,  0.7895, -0.8017, -0.2710, -0.9680, -0.4809, -0.3216,\n",
      "        -0.2980, -0.3491,  0.6962, -0.6252, -0.2315,  0.4139, -0.3083, -0.1880,\n",
      "         0.1046,  0.6293, -0.6916, -0.7999, -0.7089, -0.5396, -0.2561, -0.0369,\n",
      "        -0.8249, -0.9731, -0.0516,  0.8013, -0.5709,  0.8645, -0.6897,  0.9056,\n",
      "         0.6206, -0.9119, -0.7504, -0.3397,  0.8459, -0.6041,  0.9212, -0.1114,\n",
      "        -0.8982,  0.4094, -0.2540, -0.8643,  0.8316, -0.3132,  0.2531, -0.1139,\n",
      "        -0.5106, -0.0805, -0.0252,  0.3992, -0.4086, -0.3420,  0.5337, -0.4188,\n",
      "        -0.4769,  0.8827,  0.8022, -0.4207, -0.4391,  0.0192, -0.3105, -0.5275,\n",
      "        -0.7521, -0.6522,  0.9156,  0.0151,  0.1145,  0.7525,  0.6696,  0.2243,\n",
      "        -0.0322, -0.0838,  0.6252,  0.7125, -0.6033,  0.9424,  0.2168,  0.5744,\n",
      "        -0.6438, -0.1329,  0.5830,  0.0271, -0.8523,  0.0727, -0.0090, -0.1960,\n",
      "         0.4038,  0.4920,  0.6597,  0.0544,  0.2391,  0.6272, -0.6203, -0.2589,\n",
      "         0.5795,  0.7714,  0.7156,  0.0069, -0.9620,  0.8762, -0.2922, -0.8871,\n",
      "        -0.9652,  0.9014, -0.2274,  0.3616, -0.2270,  0.4224, -0.2029,  0.1821],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2926, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0224, -0.0325,  0.0245,  0.0668, -0.0376, -0.0369, -0.0308,  0.0371,\n",
      "        -0.0321,  0.0444, -0.0133, -0.1004,  0.0484, -0.0379,  0.0732,  0.0273,\n",
      "        -0.0449, -0.0208, -0.0119,  0.0352, -0.0665,  0.0625,  0.0356,  0.0181,\n",
      "         0.0129, -0.0128,  0.0639, -0.0437, -0.0362, -0.0768,  0.0273, -0.0646,\n",
      "         0.0825, -0.0437,  0.0611,  0.0015, -0.0704,  0.0556,  0.0354, -0.0601,\n",
      "        -0.0947, -0.0728,  0.0112,  0.0763,  0.0616,  0.0774, -0.0334,  0.0840,\n",
      "        -0.0299,  0.0043,  0.0402,  0.0162, -0.0279,  0.0140,  0.0051, -0.0081,\n",
      "         0.0611,  0.0303,  0.0354,  0.0333,  0.0065, -0.0181, -0.0238,  0.0527,\n",
      "         0.0593,  0.0037,  0.0732,  0.0130,  0.0334,  0.0234,  0.0492,  0.0063,\n",
      "        -0.0307,  0.0052, -0.0777,  0.0031, -0.0358,  0.0826, -0.0032,  0.0121,\n",
      "         0.0353, -0.0321, -0.0157,  0.0464,  0.0219, -0.0915, -0.0235, -0.0007,\n",
      "         0.0827,  0.0792,  0.0447,  0.0518, -0.0509, -0.0668,  0.0663, -0.0707,\n",
      "         0.0297,  0.0414,  0.0296,  0.0865,  0.0788,  0.0459,  0.0479,  0.0836,\n",
      "         0.0715, -0.0086, -0.0692, -0.0793,  0.0227, -0.0396,  0.0390,  0.0333,\n",
      "        -0.0186, -0.0443, -0.0025,  0.0228,  0.0319, -0.0719, -0.1084,  0.0318,\n",
      "         0.0721,  0.0177,  0.0270, -0.0194,  0.0137,  0.0170, -0.0628,  0.0651],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2711, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0756, -0.0471, -0.0371,  0.0243, -0.0633, -0.0259, -0.0495, -0.0094,\n",
      "        -0.0258,  0.0491,  0.0128, -0.0255, -0.0346, -0.0144, -0.0288, -0.0866,\n",
      "        -0.0436,  0.0440,  0.0326, -0.1168,  0.0180, -0.0295, -0.0441, -0.0071,\n",
      "         0.0394,  0.0111,  0.0571,  0.0106, -0.0907, -0.0733, -0.0247,  0.0236,\n",
      "         0.0214, -0.0229,  0.0621,  0.0846,  0.0996,  0.0161,  0.0375,  0.1033,\n",
      "        -0.0374,  0.0250,  0.0009, -0.0575,  0.0591,  0.0369, -0.0820, -0.0847,\n",
      "         0.0147, -0.0231, -0.0647,  0.0633,  0.0403, -0.0749,  0.0428,  0.0445,\n",
      "         0.0137, -0.0880,  0.0072, -0.0732,  0.0264,  0.0491, -0.0243,  0.0387,\n",
      "         0.0765, -0.0082,  0.0235, -0.0055,  0.0392,  0.0253, -0.0877, -0.0365,\n",
      "        -0.0157,  0.0429, -0.0022,  0.0663,  0.0849,  0.0042,  0.0013, -0.0169,\n",
      "         0.1261,  0.0132, -0.0604,  0.0974, -0.0180, -0.0137,  0.0152,  0.0708,\n",
      "        -0.0044, -0.0945,  0.0497, -0.0788,  0.0081, -0.0571, -0.0556,  0.0605,\n",
      "        -0.0550, -0.0899, -0.0833,  0.0707, -0.0702,  0.0217,  0.0222,  0.0363,\n",
      "        -0.0356, -0.0657,  0.0516, -0.0793, -0.1035, -0.0586, -0.0547,  0.0068,\n",
      "         0.0549, -0.0503, -0.0528, -0.0248, -0.0197, -0.0232,  0.0967,  0.0162,\n",
      "        -0.0365,  0.0230,  0.0804,  0.0936, -0.0374, -0.0866,  0.0073, -0.0701],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1071, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0675, -0.0434,  0.0099,  0.1158, -0.0978,  0.0486, -0.0318, -0.0306,\n",
      "         0.0583,  0.0049,  0.0406,  0.0572,  0.0566, -0.1277, -0.0679,  0.0324,\n",
      "        -0.0219, -0.0127, -0.0297, -0.0245, -0.0193,  0.0371,  0.0945,  0.0604,\n",
      "         0.0420, -0.0533, -0.0097, -0.0265, -0.0355,  0.0504,  0.0047,  0.0507,\n",
      "         0.0182,  0.0076, -0.0587,  0.0744, -0.0357, -0.1191, -0.0869,  0.0291,\n",
      "         0.0610, -0.0902,  0.0556,  0.0515,  0.0523, -0.0788,  0.0765, -0.0020,\n",
      "        -0.1176, -0.0859, -0.0396, -0.0790, -0.0447,  0.0621,  0.0226,  0.0337,\n",
      "        -0.0260, -0.0668,  0.0556,  0.0202,  0.0261, -0.0501, -0.0385, -0.0225,\n",
      "         0.0332, -0.0974, -0.0847, -0.0855,  0.0426, -0.0554, -0.0782, -0.0536,\n",
      "        -0.0201, -0.0174, -0.0708, -0.0044, -0.0171, -0.0763,  0.0529, -0.0119,\n",
      "        -0.0847,  0.0509, -0.0246,  0.0707,  0.0343, -0.1195, -0.0147, -0.0637,\n",
      "        -0.0181,  0.0180, -0.0819, -0.0857,  0.0857,  0.0753, -0.0013,  0.0598,\n",
      "        -0.0956, -0.0627,  0.0686, -0.0524, -0.0479,  0.0090, -0.0448, -0.0274,\n",
      "         0.0422,  0.0723,  0.0412, -0.0956,  0.0418, -0.1005,  0.0570,  0.0658,\n",
      "        -0.0351, -0.0273,  0.0858, -0.0123, -0.0840,  0.0093, -0.0241,  0.0638,\n",
      "         0.0846, -0.0366,  0.1073, -0.0877, -0.0587,  0.0294,  0.0049,  0.0607],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0704, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0210, 0.0278, 0.0817], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92100/100000], Loss: 8.961,   LOSS_function: 8.951,   LOSS_E:0.002404,    LOSS_initial: 4.679e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5899.558372497559\n",
      "loss_compared with real:2.2411e-06,   miu_train:0.1528,    lossmean:0.0001112\n",
      "Epoch [92200/100000], Loss: 9.095,   LOSS_function: 9.064,   LOSS_E:0.002397,    LOSS_initial: 1.503e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5905.696297883987\n",
      "loss_compared with real:2.1968e-06,   miu_train:0.1531,    lossmean:0.000136\n",
      "Epoch [92300/100000], Loss: 9.085,   LOSS_function: 8.933,   LOSS_E:0.002371,    LOSS_initial: 7.398e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5911.795724868774\n",
      "loss_compared with real:2.2426e-06,   miu_train:0.1534,    lossmean:0.0001088\n",
      "Epoch [92400/100000], Loss: 10.39,   LOSS_function: 10.18,   LOSS_E:0.002368,    LOSS_initial: 1.025e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5918.119814634323\n",
      "loss_compared with real:2.3292e-06,   miu_train:0.1537,    lossmean:4.282e-05\n",
      "Epoch [92500/100000], Loss: 8.896,   LOSS_function: 8.886,   LOSS_E:0.002345,    LOSS_initial: 4.351e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5924.503834486008\n",
      "loss_compared with real:2.2156e-06,   miu_train:0.154,    lossmean:0.0001001\n",
      "Epoch [92600/100000], Loss: 9.29,   LOSS_function: 9.09,   LOSS_E:0.002335,    LOSS_initial: 9.776e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5930.70455956459\n",
      "loss_compared with real:2.1525e-06,   miu_train:0.1543,    lossmean:0.0001403\n",
      "Epoch [92700/100000], Loss: 8.919,   LOSS_function: 8.884,   LOSS_E:0.002339,    LOSS_initial: 1.659e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5936.776116132736\n",
      "loss_compared with real:2.1144e-06,   miu_train:0.1546,    lossmean:0.0001219\n",
      "Epoch [92800/100000], Loss: 9.729,   LOSS_function: 9.35,   LOSS_E:0.002299,    LOSS_initial: 1.85e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5942.991838693619\n",
      "loss_compared with real:2.1219e-06,   miu_train:0.1549,    lossmean:0.0001522\n",
      "Epoch [92900/100000], Loss: 9.03,   LOSS_function: 8.901,   LOSS_E:0.002264,    LOSS_initial: 6.25e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.663e-06,    time: 5949.338369131088\n",
      "loss_compared with real:2.0994e-06,   miu_train:0.1553,    lossmean:0.0001314\n",
      "Epoch [93000/100000], Loss: 8.635,   LOSS_function: 8.63,   LOSS_E:0.002281,    LOSS_initial: 2.67e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5955.529106378555\n",
      "loss_compared with real:2.1118e-06,   miu_train:0.1555,    lossmean:0.0001009\n",
      "Epoch [93100/100000], Loss: 8.544,   LOSS_function: 8.531,   LOSS_E:0.002263,    LOSS_initial: 5.844e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5961.630589962006\n",
      "loss_compared with real:2.0966e-06,   miu_train:0.1558,    lossmean:0.0001094\n",
      "Epoch [93200/100000], Loss: 8.676,   LOSS_function: 8.64,   LOSS_E:0.002265,    LOSS_initial: 1.781e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5967.7731347084045\n",
      "loss_compared with real:2.0838e-06,   miu_train:0.1561,    lossmean:0.000116\n",
      "Epoch [93300/100000], Loss: 8.484,   LOSS_function: 8.452,   LOSS_E:0.002238,    LOSS_initial: 1.593e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5973.906924009323\n",
      "loss_compared with real:2.0597e-06,   miu_train:0.1564,    lossmean:0.0001124\n",
      "Epoch [93400/100000], Loss: 8.505,   LOSS_function: 8.495,   LOSS_E:0.002234,    LOSS_initial: 4.955e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5980.104611635208\n",
      "loss_compared with real:2.0768e-06,   miu_train:0.1567,    lossmean:9.303e-05\n",
      "Epoch [93500/100000], Loss: 8.412,   LOSS_function: 8.394,   LOSS_E:0.002207,    LOSS_initial: 8.737e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5986.3167679309845\n",
      "loss_compared with real:2.0338e-06,   miu_train:0.157,    lossmean:0.0001121\n",
      "Epoch [93600/100000], Loss: 8.552,   LOSS_function: 8.517,   LOSS_E:0.002203,    LOSS_initial: 1.712e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5992.460503101349\n",
      "loss_compared with real:2.0454e-06,   miu_train:0.1573,    lossmean:9.253e-05\n",
      "Epoch [93700/100000], Loss: 8.386,   LOSS_function: 8.297,   LOSS_E:0.002185,    LOSS_initial: 4.386e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 5998.559680938721\n",
      "loss_compared with real:2.0177e-06,   miu_train:0.1576,    lossmean:0.0001139\n",
      "Epoch [93800/100000], Loss: 8.277,   LOSS_function: 8.264,   LOSS_E:0.002168,    LOSS_initial: 6.505e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 6004.961183309555\n",
      "loss_compared with real:1.998e-06,   miu_train:0.1579,    lossmean:0.0001099\n",
      "Epoch [93900/100000], Loss: 8.635,   LOSS_function: 8.503,   LOSS_E:0.002162,    LOSS_initial: 6.438e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:8.248e-06,    time: 6011.099239587784\n",
      "loss_compared with real:2.0164e-06,   miu_train:0.1582,    lossmean:9.057e-05\n",
      "Epoch [94000/100000], Loss: 8.259,   LOSS_function: 8.248,   LOSS_E:0.002147,    LOSS_initial: 5.421e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6017.423877716064\n",
      "loss_compared with real:1.9572e-06,   miu_train:0.1585,    lossmean:0.0001037\n",
      "Epoch [94100/100000], Loss: 8.155,   LOSS_function: 8.136,   LOSS_E:0.002127,    LOSS_initial: 9.032e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6023.944767713547\n",
      "loss_compared with real:1.9529e-06,   miu_train:0.1588,    lossmean:0.0001104\n",
      "Epoch [94200/100000], Loss: 8.114,   LOSS_function: 8.102,   LOSS_E:0.002116,    LOSS_initial: 6.222e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6030.510902643204\n",
      "loss_compared with real:1.939e-06,   miu_train:0.1591,    lossmean:0.000109\n",
      "Epoch [94300/100000], Loss: 8.1,   LOSS_function: 8.07,   LOSS_E:0.002093,    LOSS_initial: 1.43e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6037.143365383148\n",
      "loss_compared with real:1.9024e-06,   miu_train:0.1594,    lossmean:0.0001164\n",
      "Epoch [94400/100000], Loss: 8.052,   LOSS_function: 8.04,   LOSS_E:0.002098,    LOSS_initial: 5.965e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6043.792211294174\n",
      "loss_compared with real:1.9179e-06,   miu_train:0.1596,    lossmean:0.0001071\n",
      "Epoch [94500/100000], Loss: 8.424,   LOSS_function: 8.353,   LOSS_E:0.002102,    LOSS_initial: 3.463e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6050.481736898422\n",
      "loss_compared with real:1.8697e-06,   miu_train:0.16,    lossmean:0.000126\n",
      "Epoch [94600/100000], Loss: 8.204,   LOSS_function: 8.052,   LOSS_E:0.002075,    LOSS_initial: 7.459e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6057.214037656784\n",
      "loss_compared with real:1.8778e-06,   miu_train:0.1602,    lossmean:0.0001121\n",
      "Epoch [94700/100000], Loss: 8.057,   LOSS_function: 8.02,   LOSS_E:0.002051,    LOSS_initial: 1.779e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6063.843505144119\n",
      "loss_compared with real:1.8644e-06,   miu_train:0.1606,    lossmean:0.00012\n",
      "Epoch [94800/100000], Loss: 7.899,   LOSS_function: 7.889,   LOSS_E:0.002051,    LOSS_initial: 4.99e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6070.778402328491\n",
      "loss_compared with real:1.8519e-06,   miu_train:0.1608,    lossmean:0.0001123\n",
      "Epoch [94900/100000], Loss: 7.869,   LOSS_function: 7.858,   LOSS_E:0.002027,    LOSS_initial: 5.609e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.852e-06,    time: 6077.388822555542\n",
      "loss_compared with real:1.8628e-06,   miu_train:0.1611,    lossmean:0.000106\n",
      "Epoch [95000/100000], Loss: 7.823,   LOSS_function: 7.813,   LOSS_E:0.002014,    LOSS_initial: 4.62e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6084.114429235458\n",
      "loss_compared with real:1.8309e-06,   miu_train:0.1614,    lossmean:0.0001082\n",
      "Epoch [95100/100000], Loss: 7.783,   LOSS_function: 7.772,   LOSS_E:0.002001,    LOSS_initial: 5.61e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6090.721942901611\n",
      "loss_compared with real:1.8202e-06,   miu_train:0.1617,    lossmean:0.0001084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95200/100000], Loss: 7.751,   LOSS_function: 7.735,   LOSS_E:0.001984,    LOSS_initial: 7.775e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6097.428521156311\n",
      "loss_compared with real:1.8073e-06,   miu_train:0.162,    lossmean:0.0001094\n",
      "Epoch [95300/100000], Loss: 7.725,   LOSS_function: 7.719,   LOSS_E:0.001982,    LOSS_initial: 2.931e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6103.9546093940735\n",
      "loss_compared with real:1.7786e-06,   miu_train:0.1623,    lossmean:0.000108\n",
      "Epoch [95400/100000], Loss: 7.682,   LOSS_function: 7.663,   LOSS_E:0.001959,    LOSS_initial: 9.172e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6110.642062902451\n",
      "loss_compared with real:1.7738e-06,   miu_train:0.1626,    lossmean:0.0001127\n",
      "Epoch [95500/100000], Loss: 7.648,   LOSS_function: 7.627,   LOSS_E:0.00195,    LOSS_initial: 1.014e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6117.400814294815\n",
      "loss_compared with real:1.7708e-06,   miu_train:0.1629,    lossmean:0.0001105\n",
      "Epoch [95600/100000], Loss: 7.609,   LOSS_function: 7.597,   LOSS_E:0.001939,    LOSS_initial: 5.854e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6124.049191951752\n",
      "loss_compared with real:1.7566e-06,   miu_train:0.1632,    lossmean:0.0001092\n",
      "Epoch [95700/100000], Loss: 7.975,   LOSS_function: 7.76,   LOSS_E:0.001917,    LOSS_initial: 1.05e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6130.9654405117035\n",
      "loss_compared with real:1.7616e-06,   miu_train:0.1635,    lossmean:0.0001239\n",
      "Epoch [95800/100000], Loss: 7.544,   LOSS_function: 7.532,   LOSS_E:0.001914,    LOSS_initial: 5.433e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6137.581972837448\n",
      "loss_compared with real:1.7369e-06,   miu_train:0.1637,    lossmean:0.0001042\n",
      "Epoch [95900/100000], Loss: 7.511,   LOSS_function: 7.504,   LOSS_E:0.001905,    LOSS_initial: 3.298e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.475e-06,    time: 6144.137078046799\n",
      "loss_compared with real:1.7233e-06,   miu_train:0.164,    lossmean:0.0001073\n",
      "Epoch [96000/100000], Loss: 7.482,   LOSS_function: 7.475,   LOSS_E:0.001896,    LOSS_initial: 3.599e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6150.795348167419\n",
      "loss_compared with real:1.7063e-06,   miu_train:0.1643,    lossmean:0.0001105\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5202, -0.4990, -0.2900, -0.9669, -0.0650, -0.3181,  0.4286, -0.8247,\n",
      "         0.8664,  0.3142,  0.7675,  0.5104,  0.5914, -0.0312,  0.6976, -0.3225,\n",
      "         0.8295,  0.0237,  0.7892, -0.8016, -0.2712, -0.9678, -0.4807, -0.3218,\n",
      "        -0.2981, -0.3491,  0.6962, -0.6250, -0.2314,  0.4140, -0.3084, -0.1879,\n",
      "         0.1047,  0.6289, -0.6917, -0.7999, -0.7091, -0.5395, -0.2562, -0.0369,\n",
      "        -0.8251, -0.9732, -0.0516,  0.8013, -0.5702,  0.8645, -0.6898,  0.9059,\n",
      "         0.6206, -0.9119, -0.7504, -0.3397,  0.8459, -0.6040,  0.9212, -0.1115,\n",
      "        -0.8982,  0.4091, -0.2540, -0.8642,  0.8315, -0.3129,  0.2531, -0.1139,\n",
      "        -0.5113, -0.0805, -0.0253,  0.3985, -0.4091, -0.3419,  0.5340, -0.4186,\n",
      "        -0.4763,  0.8828,  0.8024, -0.4208, -0.4389,  0.0190, -0.3105, -0.5283,\n",
      "        -0.7520, -0.6519,  0.9157,  0.0148,  0.1144,  0.7525,  0.6695,  0.2243,\n",
      "        -0.0320, -0.0836,  0.6250,  0.7125, -0.6035,  0.9423,  0.2166,  0.5742,\n",
      "        -0.6439, -0.1329,  0.5831,  0.0269, -0.8523,  0.0724, -0.0088, -0.1959,\n",
      "         0.4037,  0.4919,  0.6598,  0.0541,  0.2392,  0.6275, -0.6199, -0.2590,\n",
      "         0.5796,  0.7713,  0.7157,  0.0067, -0.9621,  0.8761, -0.2921, -0.8873,\n",
      "        -0.9653,  0.9016, -0.2272,  0.3618, -0.2270,  0.4222, -0.2029,  0.1819],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2922, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0224, -0.0324,  0.0244,  0.0668, -0.0376, -0.0369, -0.0307,  0.0373,\n",
      "        -0.0322,  0.0445, -0.0133, -0.1005,  0.0484, -0.0379,  0.0732,  0.0274,\n",
      "        -0.0448, -0.0208, -0.0119,  0.0351, -0.0664,  0.0625,  0.0355,  0.0181,\n",
      "         0.0130, -0.0128,  0.0639, -0.0437, -0.0362, -0.0767,  0.0272, -0.0646,\n",
      "         0.0823, -0.0438,  0.0611,  0.0015, -0.0704,  0.0555,  0.0353, -0.0602,\n",
      "        -0.0949, -0.0728,  0.0113,  0.0765,  0.0616,  0.0773, -0.0334,  0.0840,\n",
      "        -0.0299,  0.0043,  0.0402,  0.0162, -0.0280,  0.0139,  0.0051, -0.0082,\n",
      "         0.0611,  0.0303,  0.0354,  0.0333,  0.0065, -0.0182, -0.0239,  0.0527,\n",
      "         0.0592,  0.0037,  0.0732,  0.0130,  0.0333,  0.0233,  0.0492,  0.0063,\n",
      "        -0.0306,  0.0050, -0.0777,  0.0033, -0.0359,  0.0826, -0.0033,  0.0121,\n",
      "         0.0353, -0.0320, -0.0158,  0.0465,  0.0219, -0.0914, -0.0235, -0.0007,\n",
      "         0.0828,  0.0793,  0.0447,  0.0518, -0.0511, -0.0667,  0.0663, -0.0708,\n",
      "         0.0297,  0.0415,  0.0295,  0.0865,  0.0788,  0.0459,  0.0478,  0.0835,\n",
      "         0.0715, -0.0086, -0.0691, -0.0794,  0.0228, -0.0396,  0.0389,  0.0333,\n",
      "        -0.0187, -0.0443, -0.0024,  0.0228,  0.0321, -0.0718, -0.1085,  0.0318,\n",
      "         0.0722,  0.0179,  0.0270, -0.0194,  0.0136,  0.0170, -0.0628,  0.0652],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2716, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0757, -0.0470, -0.0372,  0.0241, -0.0634, -0.0259, -0.0494, -0.0093,\n",
      "        -0.0258,  0.0491,  0.0131, -0.0255, -0.0358, -0.0145, -0.0289, -0.0867,\n",
      "        -0.0436,  0.0440,  0.0327, -0.1166,  0.0178, -0.0295, -0.0441, -0.0070,\n",
      "         0.0394,  0.0112,  0.0571,  0.0105, -0.0907, -0.0733, -0.0247,  0.0235,\n",
      "         0.0216, -0.0229,  0.0621,  0.0847,  0.0994,  0.0159,  0.0377,  0.1031,\n",
      "        -0.0373,  0.0250,  0.0010, -0.0577,  0.0591,  0.0368, -0.0821, -0.0848,\n",
      "         0.0147, -0.0231, -0.0647,  0.0634,  0.0403, -0.0749,  0.0428,  0.0445,\n",
      "         0.0137, -0.0880,  0.0072, -0.0731,  0.0267,  0.0491, -0.0241,  0.0388,\n",
      "         0.0765, -0.0083,  0.0234, -0.0055,  0.0392,  0.0253, -0.0877, -0.0365,\n",
      "        -0.0157,  0.0427, -0.0022,  0.0664,  0.0849,  0.0042,  0.0014, -0.0169,\n",
      "         0.1261,  0.0131, -0.0604,  0.0974, -0.0181, -0.0136,  0.0153,  0.0710,\n",
      "        -0.0044, -0.0947,  0.0496, -0.0790,  0.0081, -0.0570, -0.0554,  0.0607,\n",
      "        -0.0547, -0.0900, -0.0831,  0.0707, -0.0703,  0.0217,  0.0222,  0.0363,\n",
      "        -0.0357, -0.0656,  0.0518, -0.0793, -0.1034, -0.0588, -0.0547,  0.0067,\n",
      "         0.0549, -0.0505, -0.0528, -0.0247, -0.0199, -0.0233,  0.0968,  0.0162,\n",
      "        -0.0367,  0.0229,  0.0803,  0.0936, -0.0374, -0.0866,  0.0074, -0.0701],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1077, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0677, -0.0435,  0.0099,  0.1159, -0.0978,  0.0486, -0.0318, -0.0306,\n",
      "         0.0583,  0.0049,  0.0404,  0.0571,  0.0562, -0.1278, -0.0680,  0.0322,\n",
      "        -0.0219, -0.0128, -0.0298, -0.0245, -0.0193,  0.0371,  0.0945,  0.0604,\n",
      "         0.0419, -0.0532, -0.0096, -0.0264, -0.0354,  0.0506,  0.0046,  0.0508,\n",
      "         0.0182,  0.0076, -0.0587,  0.0743, -0.0359, -0.1191, -0.0869,  0.0292,\n",
      "         0.0611, -0.0902,  0.0556,  0.0515,  0.0524, -0.0787,  0.0762, -0.0021,\n",
      "        -0.1176, -0.0859, -0.0397, -0.0788, -0.0447,  0.0620,  0.0226,  0.0336,\n",
      "        -0.0260, -0.0669,  0.0558,  0.0202,  0.0262, -0.0500, -0.0385, -0.0224,\n",
      "         0.0332, -0.0972, -0.0845, -0.0855,  0.0426, -0.0554, -0.0783, -0.0536,\n",
      "        -0.0204, -0.0174, -0.0710, -0.0044, -0.0171, -0.0761,  0.0529, -0.0117,\n",
      "        -0.0846,  0.0509, -0.0247,  0.0708,  0.0342, -0.1195, -0.0148, -0.0637,\n",
      "        -0.0180,  0.0179, -0.0820, -0.0857,  0.0858,  0.0754, -0.0013,  0.0598,\n",
      "        -0.0957, -0.0628,  0.0686, -0.0524, -0.0478,  0.0089, -0.0449, -0.0275,\n",
      "         0.0421,  0.0723,  0.0411, -0.0956,  0.0417, -0.1005,  0.0572,  0.0658,\n",
      "        -0.0351, -0.0273,  0.0857, -0.0123, -0.0840,  0.0093, -0.0241,  0.0638,\n",
      "         0.0845, -0.0366,  0.1074, -0.0877, -0.0586,  0.0294,  0.0049,  0.0606],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0707, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0212, 0.0279, 0.0821], requires_grad=True)\n",
      "Epoch [96100/100000], Loss: 7.436,   LOSS_function: 7.426,   LOSS_E:0.001879,    LOSS_initial: 5.214e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6157.412451028824\n",
      "loss_compared with real:1.6975e-06,   miu_train:0.1646,    lossmean:0.0001065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96200/100000], Loss: 7.421,   LOSS_function: 7.391,   LOSS_E:0.001866,    LOSS_initial: 1.48e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6164.135516643524\n",
      "loss_compared with real:1.6876e-06,   miu_train:0.1649,    lossmean:0.0001116\n",
      "Epoch [96300/100000], Loss: 7.37,   LOSS_function: 7.356,   LOSS_E:0.001856,    LOSS_initial: 6.956e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6170.706640720367\n",
      "loss_compared with real:1.6763e-06,   miu_train:0.1652,    lossmean:0.0001068\n",
      "Epoch [96400/100000], Loss: 9.189,   LOSS_function: 8.536,   LOSS_E:0.001879,    LOSS_initial: 3.193e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6177.406361341476\n",
      "loss_compared with real:1.6308e-06,   miu_train:0.1654,    lossmean:7.87e-05\n",
      "Epoch [96500/100000], Loss: 7.356,   LOSS_function: 7.343,   LOSS_E:0.001838,    LOSS_initial: 6.383e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6184.1278121471405\n",
      "loss_compared with real:1.6484e-06,   miu_train:0.1657,    lossmean:0.0001061\n",
      "Epoch [96600/100000], Loss: 7.291,   LOSS_function: 7.278,   LOSS_E:0.001821,    LOSS_initial: 6.523e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6190.87369966507\n",
      "loss_compared with real:1.6446e-06,   miu_train:0.166,    lossmean:0.0001075\n",
      "Epoch [96700/100000], Loss: 7.272,   LOSS_function: 7.23,   LOSS_E:0.001804,    LOSS_initial: 2.043e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6196.89987206459\n",
      "loss_compared with real:1.6325e-06,   miu_train:0.1663,    lossmean:0.000107\n",
      "Epoch [96800/100000], Loss: 7.208,   LOSS_function: 7.195,   LOSS_E:0.001797,    LOSS_initial: 6.073e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6203.0499432086945\n",
      "loss_compared with real:1.6149e-06,   miu_train:0.1666,    lossmean:0.0001095\n",
      "Epoch [96900/100000], Loss: 7.182,   LOSS_function: 7.163,   LOSS_E:0.001788,    LOSS_initial: 9.425e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:7.116e-06,    time: 6209.1460313797\n",
      "loss_compared with real:1.5956e-06,   miu_train:0.1669,    lossmean:0.0001078\n",
      "Epoch [97000/100000], Loss: 7.161,   LOSS_function: 7.152,   LOSS_E:0.001781,    LOSS_initial: 4.445e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6215.356482505798\n",
      "loss_compared with real:1.5894e-06,   miu_train:0.1671,    lossmean:0.00011\n",
      "Epoch [97100/100000], Loss: 7.111,   LOSS_function: 7.098,   LOSS_E:0.001763,    LOSS_initial: 6.286e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6221.464346885681\n",
      "loss_compared with real:1.5845e-06,   miu_train:0.1674,    lossmean:0.0001065\n",
      "Epoch [97200/100000], Loss: 7.079,   LOSS_function: 7.065,   LOSS_E:0.001752,    LOSS_initial: 6.477e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6227.959065914154\n",
      "loss_compared with real:1.5744e-06,   miu_train:0.1677,    lossmean:0.0001065\n",
      "Epoch [97300/100000], Loss: 7.049,   LOSS_function: 7.035,   LOSS_E:0.001741,    LOSS_initial: 7.04e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6234.058695077896\n",
      "loss_compared with real:1.5651e-06,   miu_train:0.168,    lossmean:0.0001062\n",
      "Epoch [97400/100000], Loss: 7.022,   LOSS_function: 7.011,   LOSS_E:0.001726,    LOSS_initial: 5.255e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6240.199188947678\n",
      "loss_compared with real:1.5489e-06,   miu_train:0.1683,    lossmean:0.0001078\n",
      "Epoch [97500/100000], Loss: 6.988,   LOSS_function: 6.98,   LOSS_E:0.001719,    LOSS_initial: 4.1e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6246.71977186203\n",
      "loss_compared with real:1.535e-06,   miu_train:0.1685,    lossmean:0.0001074\n",
      "Epoch [97600/100000], Loss: 6.975,   LOSS_function: 6.959,   LOSS_E:0.001708,    LOSS_initial: 8.063e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6252.968986272812\n",
      "loss_compared with real:1.5284e-06,   miu_train:0.1688,    lossmean:0.0001063\n",
      "Epoch [97700/100000], Loss: 8.127,   LOSS_function: 7.652,   LOSS_E:0.001719,    LOSS_initial: 2.32e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6259.020067691803\n",
      "loss_compared with real:1.4674e-06,   miu_train:0.1691,    lossmean:9.295e-05\n",
      "Epoch [97800/100000], Loss: 7.578,   LOSS_function: 7.512,   LOSS_E:0.001687,    LOSS_initial: 3.259e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6265.1669409275055\n",
      "loss_compared with real:1.5685e-06,   miu_train:0.1693,    lossmean:5.99e-05\n",
      "Epoch [97900/100000], Loss: 6.887,   LOSS_function: 6.88,   LOSS_E:0.001677,    LOSS_initial: 3.433e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.774e-06,    time: 6271.267770767212\n",
      "loss_compared with real:1.5021e-06,   miu_train:0.1696,    lossmean:0.0001044\n",
      "Epoch [98000/100000], Loss: 6.84,   LOSS_function: 6.827,   LOSS_E:0.001665,    LOSS_initial: 6.213e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6277.506100893021\n",
      "loss_compared with real:1.4785e-06,   miu_train:0.1699,    lossmean:0.0001081\n",
      "Epoch [98100/100000], Loss: 6.805,   LOSS_function: 6.796,   LOSS_E:0.001654,    LOSS_initial: 4.151e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6283.613042354584\n",
      "loss_compared with real:1.4767e-06,   miu_train:0.1702,    lossmean:0.0001056\n",
      "Epoch [98200/100000], Loss: 6.96,   LOSS_function: 6.943,   LOSS_E:0.001638,    LOSS_initial: 8.246e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6289.792038202286\n",
      "loss_compared with real:1.4974e-06,   miu_train:0.1704,    lossmean:8.309e-05\n",
      "Epoch [98300/100000], Loss: 6.746,   LOSS_function: 6.739,   LOSS_E:0.001634,    LOSS_initial: 3.161e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6296.003224134445\n",
      "loss_compared with real:1.454e-06,   miu_train:0.1707,    lossmean:0.0001059\n",
      "Epoch [98400/100000], Loss: 6.821,   LOSS_function: 6.809,   LOSS_E:0.001616,    LOSS_initial: 5.702e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6302.162759780884\n",
      "loss_compared with real:1.4666e-06,   miu_train:0.171,    lossmean:9.09e-05\n",
      "Epoch [98500/100000], Loss: 6.695,   LOSS_function: 6.685,   LOSS_E:0.001611,    LOSS_initial: 4.879e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6308.518861055374\n",
      "loss_compared with real:1.4347e-06,   miu_train:0.1713,    lossmean:0.0001095\n",
      "Epoch [98600/100000], Loss: 6.797,   LOSS_function: 6.773,   LOSS_E:0.001597,    LOSS_initial: 1.179e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6314.834074497223\n",
      "loss_compared with real:1.4668e-06,   miu_train:0.1715,    lossmean:8.473e-05\n",
      "Epoch [98700/100000], Loss: 6.808,   LOSS_function: 6.725,   LOSS_E:0.001592,    LOSS_initial: 4.035e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6321.178567647934\n",
      "loss_compared with real:1.4433e-06,   miu_train:0.1718,    lossmean:0.0001069\n",
      "Epoch [98800/100000], Loss: 6.618,   LOSS_function: 6.612,   LOSS_E:0.00158,    LOSS_initial: 2.719e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6327.801542043686\n",
      "loss_compared with real:1.415e-06,   miu_train:0.1721,    lossmean:0.0001009\n",
      "Epoch [98900/100000], Loss: 6.837,   LOSS_function: 6.786,   LOSS_E:0.001587,    LOSS_initial: 2.521e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.449e-06,    time: 6334.397742271423\n",
      "loss_compared with real:1.4324e-06,   miu_train:0.1723,    lossmean:8.849e-05\n",
      "Epoch [99000/100000], Loss: 6.91,   LOSS_function: 6.787,   LOSS_E:0.001569,    LOSS_initial: 5.989e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6341.0748925209045\n",
      "loss_compared with real:1.3585e-06,   miu_train:0.1726,    lossmean:8.455e-05\n",
      "Epoch [99100/100000], Loss: 6.517,   LOSS_function: 6.507,   LOSS_E:0.00155,    LOSS_initial: 4.511e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6347.619495868683\n",
      "loss_compared with real:1.3782e-06,   miu_train:0.1729,    lossmean:0.0001057\n",
      "Epoch [99200/100000], Loss: 7.286,   LOSS_function: 7.07,   LOSS_E:0.001547,    LOSS_initial: 1.057e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6354.251260519028\n",
      "loss_compared with real:1.3622e-06,   miu_train:0.1731,    lossmean:8.011e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99300/100000], Loss: 6.941,   LOSS_function: 6.786,   LOSS_E:0.001534,    LOSS_initial: 7.564e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6360.863038301468\n",
      "loss_compared with real:1.3221e-06,   miu_train:0.1734,    lossmean:8.955e-05\n",
      "Epoch [99400/100000], Loss: 7.08,   LOSS_function: 6.786,   LOSS_E:0.001507,    LOSS_initial: 1.439e-05,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6367.807355880737\n",
      "loss_compared with real:1.3449e-06,   miu_train:0.1737,    lossmean:0.0001366\n",
      "Epoch [99500/100000], Loss: 6.509,   LOSS_function: 6.493,   LOSS_E:0.001515,    LOSS_initial: 7.489e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6374.326970338821\n",
      "loss_compared with real:1.3471e-06,   miu_train:0.1739,    lossmean:9.256e-05\n",
      "Epoch [99600/100000], Loss: 6.495,   LOSS_function: 6.43,   LOSS_E:0.001499,    LOSS_initial: 3.155e-06,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6381.033726930618\n",
      "loss_compared with real:1.2713e-06,   miu_train:0.1742,    lossmean:0.0001243\n",
      "Epoch [99700/100000], Loss: 6.371,   LOSS_function: 6.364,   LOSS_E:0.001495,    LOSS_initial: 3.286e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6387.607350111008\n",
      "loss_compared with real:1.3091e-06,   miu_train:0.1745,    lossmean:0.000105\n",
      "Epoch [99800/100000], Loss: 6.327,   LOSS_function: 6.317,   LOSS_E:0.00148,    LOSS_initial: 4.548e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6394.270894527435\n",
      "loss_compared with real:1.3099e-06,   miu_train:0.1747,    lossmean:0.0001075\n",
      "Epoch [99900/100000], Loss: 6.302,   LOSS_function: 6.297,   LOSS_E:0.001474,    LOSS_initial: 2.296e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:6.14e-06,    time: 6400.862481832504\n",
      "loss_compared with real:1.308e-06,   miu_train:0.175,    lossmean:0.0001029\n",
      "Epoch [100000/100000], Loss: 6.289,   LOSS_function: 6.279,   LOSS_E:0.001459,    LOSS_initial: 4.668e-07,\n",
      "lamda1:1,    lamda3:2.044e+04,      learn rate:5.845e-06,    time: 6407.494384527206\n",
      "loss_compared with real:1.289e-06,   miu_train:0.1752,    lossmean:0.0001073\n",
      "net.0.bias Parameter containing:\n",
      "tensor([-0.5201, -0.4987, -0.2901, -0.9669, -0.0650, -0.3180,  0.4285, -0.8246,\n",
      "         0.8664,  0.3143,  0.7677,  0.5104,  0.5913, -0.0313,  0.6977, -0.3227,\n",
      "         0.8294,  0.0237,  0.7890, -0.8015, -0.2713, -0.9677, -0.4805, -0.3219,\n",
      "        -0.2982, -0.3490,  0.6962, -0.6248, -0.2314,  0.4141, -0.3084, -0.1878,\n",
      "         0.1048,  0.6285, -0.6918, -0.7999, -0.7093, -0.5395, -0.2563, -0.0368,\n",
      "        -0.8253, -0.9734, -0.0516,  0.8013, -0.5696,  0.8646, -0.6899,  0.9062,\n",
      "         0.6206, -0.9119, -0.7504, -0.3396,  0.8460, -0.6040,  0.9212, -0.1115,\n",
      "        -0.8982,  0.4088, -0.2540, -0.8642,  0.8315, -0.3128,  0.2530, -0.1140,\n",
      "        -0.5119, -0.0805, -0.0253,  0.3979, -0.4095, -0.3418,  0.5343, -0.4185,\n",
      "        -0.4758,  0.8829,  0.8025, -0.4209, -0.4387,  0.0188, -0.3105, -0.5290,\n",
      "        -0.7520, -0.6517,  0.9158,  0.0146,  0.1143,  0.7524,  0.6695,  0.2243,\n",
      "        -0.0319, -0.0835,  0.6248,  0.7125, -0.6037,  0.9423,  0.2165,  0.5739,\n",
      "        -0.6440, -0.1328,  0.5832,  0.0268, -0.8523,  0.0721, -0.0086, -0.1959,\n",
      "         0.4035,  0.4917,  0.6599,  0.0538,  0.2392,  0.6278, -0.6196, -0.2590,\n",
      "         0.5796,  0.7711,  0.7157,  0.0065, -0.9622,  0.8760, -0.2921, -0.8874,\n",
      "        -0.9653,  0.9018, -0.2270,  0.3619, -0.2270,  0.4221, -0.2028,  0.1817],\n",
      "       requires_grad=True)\n",
      "net.1.a Parameter containing:\n",
      "tensor(0.2919, requires_grad=True)\n",
      "net.2.bias Parameter containing:\n",
      "tensor([ 0.0223, -0.0323,  0.0242,  0.0668, -0.0376, -0.0368, -0.0307,  0.0375,\n",
      "        -0.0323,  0.0445, -0.0133, -0.1006,  0.0485, -0.0378,  0.0733,  0.0275,\n",
      "        -0.0448, -0.0208, -0.0119,  0.0351, -0.0662,  0.0625,  0.0355,  0.0182,\n",
      "         0.0130, -0.0127,  0.0638, -0.0436, -0.0362, -0.0766,  0.0272, -0.0646,\n",
      "         0.0822, -0.0438,  0.0611,  0.0015, -0.0704,  0.0555,  0.0353, -0.0603,\n",
      "        -0.0950, -0.0728,  0.0113,  0.0766,  0.0617,  0.0772, -0.0334,  0.0840,\n",
      "        -0.0298,  0.0043,  0.0402,  0.0162, -0.0280,  0.0138,  0.0052, -0.0083,\n",
      "         0.0611,  0.0302,  0.0354,  0.0334,  0.0064, -0.0183, -0.0239,  0.0527,\n",
      "         0.0591,  0.0037,  0.0733,  0.0130,  0.0333,  0.0233,  0.0492,  0.0062,\n",
      "        -0.0306,  0.0049, -0.0776,  0.0034, -0.0360,  0.0826, -0.0033,  0.0121,\n",
      "         0.0353, -0.0319, -0.0158,  0.0465,  0.0219, -0.0913, -0.0235, -0.0007,\n",
      "         0.0829,  0.0793,  0.0448,  0.0518, -0.0512, -0.0666,  0.0663, -0.0709,\n",
      "         0.0297,  0.0416,  0.0294,  0.0865,  0.0789,  0.0459,  0.0478,  0.0834,\n",
      "         0.0716, -0.0086, -0.0691, -0.0795,  0.0228, -0.0396,  0.0388,  0.0333,\n",
      "        -0.0188, -0.0443, -0.0024,  0.0228,  0.0323, -0.0717, -0.1085,  0.0318,\n",
      "         0.0723,  0.0180,  0.0271, -0.0194,  0.0136,  0.0170, -0.0628,  0.0652],\n",
      "       requires_grad=True)\n",
      "net.3.a Parameter containing:\n",
      "tensor(0.2720, requires_grad=True)\n",
      "net.4.bias Parameter containing:\n",
      "tensor([ 0.0757, -0.0470, -0.0374,  0.0239, -0.0634, -0.0259, -0.0493, -0.0093,\n",
      "        -0.0257,  0.0491,  0.0133, -0.0255, -0.0364, -0.0145, -0.0289, -0.0869,\n",
      "        -0.0435,  0.0441,  0.0327, -0.1164,  0.0177, -0.0295, -0.0441, -0.0069,\n",
      "         0.0393,  0.0112,  0.0570,  0.0105, -0.0907, -0.0733, -0.0248,  0.0235,\n",
      "         0.0217, -0.0228,  0.0621,  0.0848,  0.0992,  0.0158,  0.0379,  0.1028,\n",
      "        -0.0373,  0.0250,  0.0010, -0.0579,  0.0590,  0.0367, -0.0823, -0.0848,\n",
      "         0.0148, -0.0231, -0.0646,  0.0634,  0.0404, -0.0750,  0.0427,  0.0445,\n",
      "         0.0137, -0.0880,  0.0072, -0.0731,  0.0269,  0.0491, -0.0240,  0.0388,\n",
      "         0.0765, -0.0084,  0.0233, -0.0056,  0.0393,  0.0253, -0.0877, -0.0365,\n",
      "        -0.0157,  0.0427, -0.0023,  0.0665,  0.0848,  0.0042,  0.0014, -0.0169,\n",
      "         0.1261,  0.0130, -0.0604,  0.0974, -0.0181, -0.0135,  0.0154,  0.0711,\n",
      "        -0.0044, -0.0949,  0.0495, -0.0792,  0.0081, -0.0570, -0.0552,  0.0608,\n",
      "        -0.0545, -0.0900, -0.0830,  0.0707, -0.0705,  0.0218,  0.0221,  0.0362,\n",
      "        -0.0357, -0.0655,  0.0520, -0.0793, -0.1033, -0.0591, -0.0547,  0.0067,\n",
      "         0.0548, -0.0507, -0.0527, -0.0247, -0.0200, -0.0234,  0.0969,  0.0162,\n",
      "        -0.0367,  0.0229,  0.0803,  0.0936, -0.0373, -0.0867,  0.0075, -0.0700],\n",
      "       requires_grad=True)\n",
      "net.5.a Parameter containing:\n",
      "tensor(0.1083, requires_grad=True)\n",
      "net.6.bias Parameter containing:\n",
      "tensor([-0.0678, -0.0435,  0.0100,  0.1159, -0.0979,  0.0486, -0.0318, -0.0307,\n",
      "         0.0583,  0.0049,  0.0403,  0.0570,  0.0559, -0.1279, -0.0680,  0.0321,\n",
      "        -0.0220, -0.0129, -0.0299, -0.0245, -0.0193,  0.0370,  0.0946,  0.0604,\n",
      "         0.0419, -0.0532, -0.0094, -0.0264, -0.0354,  0.0507,  0.0045,  0.0508,\n",
      "         0.0182,  0.0076, -0.0586,  0.0742, -0.0360, -0.1190, -0.0869,  0.0292,\n",
      "         0.0611, -0.0902,  0.0556,  0.0514,  0.0524, -0.0787,  0.0760, -0.0021,\n",
      "        -0.1175, -0.0859, -0.0397, -0.0786, -0.0447,  0.0620,  0.0225,  0.0336,\n",
      "        -0.0260, -0.0669,  0.0560,  0.0201,  0.0263, -0.0499, -0.0385, -0.0223,\n",
      "         0.0332, -0.0970, -0.0844, -0.0856,  0.0426, -0.0554, -0.0783, -0.0535,\n",
      "        -0.0206, -0.0174, -0.0712, -0.0044, -0.0171, -0.0760,  0.0528, -0.0115,\n",
      "        -0.0846,  0.0509, -0.0247,  0.0709,  0.0341, -0.1195, -0.0148, -0.0638,\n",
      "        -0.0180,  0.0178, -0.0821, -0.0857,  0.0858,  0.0755, -0.0013,  0.0599,\n",
      "        -0.0957, -0.0628,  0.0687, -0.0524, -0.0478,  0.0089, -0.0449, -0.0275,\n",
      "         0.0420,  0.0723,  0.0411, -0.0957,  0.0416, -0.1005,  0.0573,  0.0659,\n",
      "        -0.0351, -0.0272,  0.0855, -0.0123, -0.0839,  0.0093, -0.0241,  0.0639,\n",
      "         0.0843, -0.0367,  0.1074, -0.0876, -0.0585,  0.0293,  0.0049,  0.0604],\n",
      "       requires_grad=True)\n",
      "net.7.a Parameter containing:\n",
      "tensor(0.0710, requires_grad=True)\n",
      "net.8.bias Parameter containing:\n",
      "tensor([0.0213, 0.0279, 0.0825], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()#计时\n",
    "epochs = 100000  #训练次数\n",
    "opt = torch.optim.Adam(u.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(epochs):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    lpde=LOSS(u)[0]\n",
    "    lE=LOSS(u)[1]\n",
    "    l0=LOSS(u)[2]\n",
    "  \n",
    "    if (i+1)%1000== 0:\n",
    "        gradient_lpde=funcweight(lpde)\n",
    "       # gradient_lE=funcweight(lE)\n",
    "        gradient_l0=funcweight(l0) \n",
    "\n",
    "    if (i+1)%1000== 0 and lpde>1e-5:\n",
    "        lamda1=0.2*lamda1+0.8*(  (gradient_lpde+gradient_l0)/gradient_lpde  )\n",
    "    if (i+1)%1000== 0 and l0>1e-5:\n",
    "        lamda3=0.2*lamda3+0.8*(  (gradient_lpde+gradient_l0)/gradient_l0  )\n",
    "#     if (i+1)%1000== 0 and lE>1e-5:\n",
    "#         lamda2=0.2*lamda2+0.8*(  (gradient_lpde+gradient_l0+gradient_lE)/gradient_lE  )\n",
    "        \n",
    "    l_total=lamda1*lpde+lamda3*l0#+lamda2*lE\n",
    "    l_withoutweight=lpde+l0+lE\n",
    "    l_total.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    \n",
    "    if (i+1)%1000 == 0:\n",
    "        learnr = opt.param_groups[0]['lr']\n",
    "        \n",
    "        #更新学习率\n",
    "        learning_rate *=0.952\n",
    "        for param_group in opt.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "    \n",
    "    if (i+1)%(n_epoch*40)==0:\n",
    "        Save()\n",
    "    \n",
    "\n",
    "    if (i+1)%n_epoch == 0 or i==0:\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        learnr = opt.param_groups[0]['lr']\n",
    "        time_test =torch.arange(interval*jump, interval*(n_all+1+jump), interval*int(n_all/n_test))\n",
    "        t_test = time_test.view(-1, 1).requires_grad_(True)\n",
    "        x_test = u(t_test)[:, 0].view(-1, 1)\n",
    "        y_test = u(t_test)[:, 1].view(-1, 1)\n",
    "        z_test = u(t_test)[:, 2].view(-1, 1)\n",
    "        vx_test = gradients(x_test,t_test,1)\n",
    "        vy_test = gradients(y_test,t_test,1)\n",
    "        vz_test = gradients(z_test,t_test,1)\n",
    "        loss_test = loss(x_test,x_real)+loss(y_test,y_real)+loss(z_test,z_real)\n",
    "        miu_train=funcmiu(x_test,y_test,z_test,vx_test,vy_test,vz_test)\n",
    "        #lcq=lE+lmiu_test#注意这里！！\n",
    "        lossmean_test = torch.sum(x_test-x_real+y_test-y_real+z_test-z_real)/n\n",
    "        print(f'Epoch [{i+1}/{epochs}], Loss: {l_total.item():.4g},   LOSS_function: {lpde.item():.4g},   LOSS_E:{lE.item():.4g},    LOSS_initial: {l0.item():.4g},')\n",
    "        print(f'lamda1:{lamda1:.4g},    lamda3:{lamda3:.4g},      learn rate:{learnr:.4g},    time: {total_time}' )\n",
    "        print(f'loss_compared with real:{loss_test:.5g},   miu_train:{miu_train.mean():.4g},    lossmean:{lossmean_test.item():.4g}') \n",
    "        loss_list.append(l_total.item())\n",
    "        lpde_list.append(lpde.item())\n",
    "        l0_list.append(l0.item())\n",
    "        lE_list.append(lE.item())\n",
    "#         lamda1_list.append(lamda1)\n",
    "       \n",
    "#         lamda3_list.append(lamda3)\n",
    "#         l_withoutweight_list.append(l_withoutweight.item())\n",
    "#         time_list.append(total_time)\n",
    "        loss_test_list.append(loss_test.item())\n",
    "        lossmean_test_list.append(lossmean_test.item())\n",
    "#         miu_train_list.append(miu_train.mean())\n",
    "    \n",
    "    if (i+1)%4000 == 0:\n",
    "        for name, param in u.named_parameters():\n",
    "            if 'a' in name:  # 筛选出包含'a'的参数\n",
    "                print(name, param)\n",
    "        \n",
    "        \n",
    "    if l_total <= stop_condition:#刚才写成loss_test了，感觉不妥，毕竟应该不知道真实数字是多少\n",
    "        print(f'Training stopped at No.{i+1} time. Loss ({l_total}) is below the specified threshold ({stop_condition}).')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932983a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_uname='hh.pth'\n",
    "#保存神经网络\n",
    "torch.save(u.state_dict(), new_prefix + old_uname[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d00ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_lists = [loss_list, lpde_list, l0_list, lE_list, loss_test_list, lossmean_test_list]\n",
    "# file_names = ['hh_loss.txt', 'hh_lpde.txt', 'hh_l0.txt', 'hh_lE.txt', 'hh_loss_test.txt', 'hh_lossmean_test.txt']\n",
    "\n",
    "# for file_list, old_name in zip(file_lists, file_names):\n",
    "#     new_name = new_prefix + old_name[2:]  # 保留原始文件名中的后缀部分\n",
    "#     with open(new_name, 'w') as f:\n",
    "#         for item in file_list:\n",
    "#             f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "41a2718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算神经网络的轨迹\n",
    "output_history= []#想要缩短周期，就调大Bz\n",
    "for i in range(jump,(n_all+1+jump)):\n",
    "        # 将当前状态输入神经网络得到下一时刻的状态\n",
    "        next_state = u.forward(torch.tensor([interval*i]) )#+torch.rand(1) * interval )\n",
    "\n",
    "        # 记录输出值\n",
    "        output_history.append(next_state)\n",
    "\n",
    "import numpy as np\n",
    "x_coordinates = np.array([x[0].item() for x in output_history])\n",
    "y_coordinates = np.array([x[1].item() for x in output_history])\n",
    "z_coordinates = np.array([x[2].item() for x in output_history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ca0b5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.loadtxt('通行x_real.txt')\n",
    "\n",
    "# 将所选数据转换为PyTorch张量\n",
    "\n",
    "\n",
    "ydata = np.loadtxt('通行y_real.txt')\n",
    "\n",
    "\n",
    "zdata = np.loadtxt('通行z_real.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#全500点，用于后续绘图\n",
    "x_plt=xdata[jump:(n_all+1+jump):1]\n",
    "y_plt=ydata[jump:(n_all+1+jump):1]\n",
    "z_plt=zdata[jump:(n_all+1+jump):1]\n",
    "x_real_plt=torch.tensor(x_plt, dtype=torch.float32).view(-1,1)#真实值的0~500点，\n",
    "y_real_plt=torch.tensor(y_plt, dtype=torch.float32).view(-1,1)\n",
    "z_real_plt=torch.tensor(z_plt, dtype=torch.float32).view(-1,1)\n",
    "vxdata = (np.loadtxt('通行vx_real.txt'))*1e-6\n",
    "vydata = (np.loadtxt('通行vy_real.txt'))*1e-6\n",
    "vzdata = (np.loadtxt('通行vz_real.txt'))*1e-6\n",
    "vx_real_plt=torch.tensor(vxdata[jump:(n_all+1+jump):1], dtype=torch.float32).view(-1,1)\n",
    "vy_real_plt=torch.tensor(vydata[jump:(n_all+1+jump):1], dtype=torch.float32).view(-1,1)\n",
    "vz_real_plt=torch.tensor(vzdata[jump:(n_all+1+jump):1], dtype=torch.float32).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dab0c957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制轨迹，2维\n",
    "plt.plot(x_coordinates,y_coordinates,linestyle='--', label='PINN')\n",
    "plt.plot(x_real_plt, y_real_plt,label='VPA')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "# plt.title('PINN results VS classic results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0f1f7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = [x_coordinates, y_coordinates, z_coordinates]\n",
    "file_names = ['hh_outputx.txt', 'hh_outputy.txt', 'hh_outputz.txt']\n",
    "\n",
    "for file_list, old_name in zip(file_lists, file_names):\n",
    "    new_name = new_prefix + old_name[2:]  # 保留原始文件名中的后缀部分\n",
    "    with open(new_name, 'w') as f:\n",
    "        for item in file_list:\n",
    "            f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bdf8262b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制轨迹 3维\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(x_plt[::int(n_all/50)], y_plt[::int(n_all/50)] ,z_plt[::int(n_all/50)],color='red',label='VPA')\n",
    "#ax.plot(x_coordinates[::int(n_all/100)],y_coordinates[::int(n_all/100)],z_coordinates[::int(n_all/100)],label='neural network')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "# ax.set_title('Particle Motion in Electromagnetic Field')\n",
    "plt.show()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.plot(x_plt[::int(n_all/100)], y_plt[::int(n_all/100)] ,z_plt[::int(n_all/100)],label='classic computation')\n",
    "ax.plot(x_coordinates[::int(n_all/50)],y_coordinates[::int(n_all/50)],z_coordinates[::int(n_all/50)],label='PINN')\n",
    "ax.legend()\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "# ax.set_title('Particle Motion in Electromagnetic Field')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b6e29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_prefix +'_loss.txt', 'r') as file2:\n",
    "    loss_list = [float(line.strip()) for line in file2.readlines()]\n",
    "with open(new_prefix +'_lpde.txt', 'r') as file3:\n",
    "    lpde_list = [float(line.strip()) for line in file3.readlines()]\n",
    "with open(new_prefix +'_l0.txt', 'r') as file4:\n",
    "    l0_list = [float(line.strip()) for line in file4.readlines()]\n",
    "with open(new_prefix +'_lE.txt', 'r') as file5:\n",
    "    lE_list = [float(line.strip()) for line in file5.readlines()]\n",
    "with open(new_prefix +'_loss_test.txt', 'r') as file6:\n",
    "    loss_test_list = [float(line.strip()) for line in file6.readlines()]\n",
    "with open(new_prefix +'_lossmean_test.txt', 'r') as file6:\n",
    "    lossmean_test_list = [float(line.strip()) for line in file6.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e8ed937d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制各loss成分随训练次数epoch变化图\n",
    "epoch_total = len(loss_list)\n",
    "epoch_array = np.array(range(0, epoch_total * n_epoch, n_epoch))\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # 设置图像大小为原始大小的1.3倍，10英寸6英寸\n",
    "plt.plot(epoch_array,lpde_list,label=r'$L_{r}(\\theta)$')\n",
    "#plt.plot(epoch_array,lmiu_list, label='Loss of μ ')\n",
    "plt.plot(epoch_array,lE_list, label=r'$L_{E}(\\theta)\\;(untrained)$')\n",
    "plt.plot(epoch_array,l0_list, label=r'$L_{ic}(\\theta)$')\n",
    "plt.plot(epoch_array,loss_list, label=r'$L(\\theta)$')\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "plt.ylabel(r'$Rel.\\;L^2\\;Error$', fontsize='x-large')\n",
    "# plt.title(r'$Convergence\\;of\\;rel.\\;L^2\\;error\\;during\\;training\\;process$')\n",
    "# 添加图例并设置字体大小，并将其放在图形外部\n",
    "plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "plt.tight_layout()# 自动调整布局，确保图像完整显示\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(epoch_array,lamda1_list,label=r'$λ_{r}(\\theta)$')\n",
    "\n",
    "# plt.plot(epoch_array,lamda3_list,label=r'$λ_{ic}(\\theta)$')\n",
    "# #plt.plot(epoch_array,lamda4_list,label='λ for loss of μ')\n",
    "# plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "# plt.xlabel('Epoch', fontsize='x-large')\n",
    "# plt.ylabel('Adaptive weights', fontsize='x-large')\n",
    "# # plt.title('Adaptive weights during training process')\n",
    "# plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# plt.show()#绘图\n",
    "\n",
    "plt.plot(epoch_array,loss_test_list)\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "plt.ylabel('Squared Euclidean Error', fontsize='x-large')\n",
    "# plt.title('Geometric difference of position from classic data during training process')\n",
    "\n",
    "plt.show()#绘图\n",
    "\n",
    "plt.plot(epoch_array,lossmean_test_list)\n",
    "plt.xlabel('Epoch', fontsize='x-large')\n",
    "plt.ylabel('Summed Error', fontsize='x-large')\n",
    "# plt.title('Arithmetic difference of position from classic data during training process')\n",
    "\n",
    "plt.show()#绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01238435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hxm\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#绘制损失函数在各时刻的分布\n",
    "lpde_tl_list=[]\n",
    "\n",
    "lE_tl_list=[]\n",
    "\n",
    "loss_test_tl_list=[]\n",
    "\n",
    "lossmean_test_tl_list=[]\n",
    "for i in range(jump,(n_all+1+jump),10):\n",
    "    t_tl = torch.tensor([i*interval]).view(-1, 1).requires_grad_(True)#tl:trainloss\n",
    "    x_tl = u(t_tl)[:,0]\n",
    "    y_tl = u(t_tl)[:,1]\n",
    "    z_tl = u(t_tl)[:,2]\n",
    "    vx_tl = gradients(x_tl, t_tl, 1)\n",
    "    vy_tl = gradients(y_tl, t_tl, 1)\n",
    "    vz_tl = gradients(z_tl, t_tl, 1)\n",
    "    lpde1_tl = loss(gradients(vx_tl, t_tl, 1), q_over_m*(Ex + vy_tl * Bz(x_tl,y_tl,z_tl) - vz_tl * By(x_tl,y_tl,z_tl)))\n",
    "    lpde2_tl = loss(gradients(vy_tl, t_tl, 1), q_over_m*(Ey + vz_tl * Bx(x_tl,y_tl,z_tl) - vx_tl * Bz(x_tl,y_tl,z_tl)))\n",
    "    lpde3_tl = loss(gradients(vz_tl, t_tl, 1), q_over_m*(Ez + vx_tl * By(x_tl,y_tl,z_tl) - vy_tl * Bx(x_tl,y_tl,z_tl)))\n",
    "    lE_tl = loss((vx_tl**2+vy_tl**2+vz_tl**2)**0.5,tensortarget)\n",
    "    lpde_tl = lpde1_tl + lpde2_tl + lpde3_tl\n",
    "    x_real_tl = x_real_plt[i-jump]\n",
    "    y_real_tl = y_real_plt[i-jump]\n",
    "    z_real_tl = z_real_plt[i-jump]\n",
    "    vx_real_tl = vx_real_plt[i-jump]\n",
    "    vy_real_tl = vy_real_plt[i-jump]\n",
    "    vz_real_tl = vz_real_plt[i-jump]\n",
    "    loss_test_tl = loss(x_tl,x_real_tl)+loss(y_tl,y_real_tl)+loss(z_tl,z_real_tl)\n",
    "    lossmean_test_tl = (x_tl-x_real_tl+y_tl-y_real_tl+z_tl-z_real_tl)\n",
    "    lpde_tl_list.append(lpde_tl.item())\n",
    "    lE_tl_list.append(lE_tl.item())\n",
    "    loss_test_tl_list.append(loss_test_tl.item())\n",
    "    lossmean_test_tl_list.append(lossmean_test_tl.item())\n",
    "tl_array = np.arange(jump*interval, (n_all+1+jump)*interval, 10*interval)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c19e73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用作提醒\n",
    "# lpde_tl_list=[]\n",
    "# lcq_tl_list=[]\n",
    "# lE_tl_list=[]\n",
    "# lmiu_tl_list=[]\n",
    "# loss_test_tl_list=[]\n",
    "# lmiu_test_tl_list=[]\n",
    "# lossmean_test_tl_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "781e2de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))  # 设置图像大小为原始大小的1.3倍，10英寸6英寸\n",
    "plt.plot(tl_array,lpde_tl_list,label=r'$L_{r}(\\theta)$')\n",
    "plt.plot(tl_array,lE_tl_list,label=r'$L_{E}(\\theta)\\;(untrained)$')\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('t/μs', fontsize='x-large')\n",
    "plt.ylabel(r'$Rel.\\;L^2\\;Error$', fontsize='x-large')\n",
    "# plt.title('Loss of ODEs and loss of E from real data during motion process')\n",
    "plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()# 自动调整布局，确保图像完整显示\n",
    "plt.show()\n",
    "plt.plot(tl_array,loss_test_tl_list)\n",
    "plt.yscale('log')  # 设置纵轴为对数刻度\n",
    "plt.xlabel('t/μs', fontsize='x-large')\n",
    "plt.ylabel('Squared Euclidean Error', fontsize='x-large')\n",
    "# plt.title('Geometric differences of position from real data during motion process')\n",
    "\n",
    "plt.show()#绘图\n",
    "plt.plot(tl_array,lossmean_test_tl_list)\n",
    "plt.xlabel('t/μs', fontsize='x-large')\n",
    "plt.ylabel('Summed Error', fontsize='x-large')\n",
    "# plt.title('Arithmetic differences of position from real data during motion process')\n",
    "\n",
    "plt.show()#绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "58213125",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = [lpde_tl_list,  lE_tl_list,  loss_test_tl_list, lossmean_test_tl_list]\n",
    "file_names = ['hh_lpde_tl_list.txt', 'hh_lE_tl_list.txt',  'hh_loss_test_tl_list.txt', 'hh_lossmean_test_tl_list.txt']\n",
    "\n",
    "for file_list, old_name in zip(file_lists, file_names):\n",
    "    new_name = new_prefix + old_name[2:]  # 保留原始文件名中的后缀部分\n",
    "    with open(new_name, 'w') as f:\n",
    "        for item in file_list:\n",
    "            f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef640e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
